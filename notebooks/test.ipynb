{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.core.utils.openbb_helpers import obb_login\n",
    "from openbb import obb\n",
    "from humbldata.core.utils.env import Env\n",
    "import polars as pl\n",
    "\n",
    "# obb_login()\n",
    "obb.account.login(pat=Env().OBB_PAT, remember_me=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from humbldata.toolbox.technical.mandelbrot_channel.model import (\n",
    "    calc_mandelbrot_channel,\n",
    "    calc_mandelbrot_channel_historical,\n",
    ")\n",
    "\n",
    "\n",
    "data = (\n",
    "    obb.equity.price.historical(\n",
    "        [\"AAPL\"],\n",
    "        provider=\"yfinance\",\n",
    "        start_date=\"2020-01-01\",\n",
    "        end_date=\"2024-01-01\",\n",
    "        adjustment=\"splits_and_dividends\",\n",
    "    ).to_polars()\n",
    ").drop([\"dividends\", \"stock_splits\"]).with_columns(pl.lit(\"AAPL\").alias(\"symbol\"))\n",
    "\n",
    "mandelbrot = calc_mandelbrot_channel_historical(  # noqa: ERA001\n",
    "        data,\n",
    "        window=\"1m\",\n",
    "        rv_adjustment=True,\n",
    "        rv_method=\"std\",\n",
    "        rv_grouped_mean=False,\n",
    "        rs_method=\"RS\",\n",
    "        live_price=False,\n",
    "    ).collect()\n",
    "mandelbrot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `calc_up_down_pct`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from humbldata.portfolio.analytics.user_table.helpers import calc_up_down_pct\n",
    "\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"symbol\": [\"AAPL\", \"GOOGL\", \"MSFT\"],\n",
    "    \"bottom_price\": [5.18, 15.07, 16.24],\n",
    "    \"recent_price\": [10.05, 20.31, 16.42],\n",
    "    \"top_price\": [11.23, 25.17, 30.09],\n",
    "})\n",
    "result = calc_up_down_pct(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up UserTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.core.standard_models.portfolio.analytics.user_table import UserTableQueryParams\n",
    "from humbldata.core.utils.openbb_helpers import get_latest_price\n",
    "\n",
    "\n",
    "symbols = UserTableQueryParams(symbol=\"AAPL, MSFT, NVDA\").symbol\n",
    "symbols\n",
    "\n",
    "\n",
    "\n",
    "get_latest_price(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesing Async\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sector Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.core.utils.openbb_helpers import aget_etf_category\n",
    "import polars as pl\n",
    "\n",
    "stocks = pl.Series([\n",
    "    \"GOOGL\",  # Communication Services\n",
    "    \"AMZN\",   # Consumer Discretionary\n",
    "    \"KO\",     # Consumer Staples\n",
    "    \"XOM\",    # Energy\n",
    "    \"JPM\",    # Financials\n",
    "    \"JNJ\",    # Health Care\n",
    "    \"HON\",    # Industrials\n",
    "    \"AAPL\",   # Information Technology\n",
    "    \"LIN\",    # Materials\n",
    "    \"PLD\",    # Real Estate\n",
    "    \"NEE\"     # Utilities\n",
    "])\n",
    "test = (await aget_etf_category(symbols=[\"AAPL\", \"XLE\", \"DBA\"], provider=\"yfinance\")).collect()\n",
    "# test2 = (await aget_equity_sector(symbols=stocks, provider=\"yfinance\")).collect()\n",
    "# test2 = (await aget_equity_sector(symbols=[\"XLE\", \"AAPL\"], provider=\"yfinance\")).collect()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"CORN\", 'SLV', 'DBA', \"XLE\", \"AAPL\", \"FXE\", \"SPY\", \"QQQ\", \"BITO\", \"MAXI\", \"SATO\", \"BIL\", \"LQD\", \"QAI\", \"MNA\", \"CLSE\"]\n",
    "symbols2 = [\"AAPL\", \"FXE\", \"SPY\", \"MAXI\", \"GLD\"]\n",
    "symbols3 = commodity_etf_symbols = [\"GLD\", \"IAU\", \"SLV\", \"GLDM\", \"PDBC\", \"SGOL\", \"FTGC\", \"DBC\", \"SIVR\", \"USO\", \"IAUM\", \"GSG\", \"BCI\", \"PPLT\", \"COMT\", \"GLTR\", \"OUNZ\", \"BAR\", \"UNG\", \"DBA\", \"AAAU\", \"DJP\", \"CMDT\", \"KRBN\", \"PALL\", \"COM\", \"NBCM\", \"CMDY\", \"DBO\", \"BCD\", \"KCCA\", \"CPER\", \"HGER\", \"USCI\", \"DBB\", \"DBP\", \"GCC\", \"WEAT\", \"BNO\", \"UGA\", \"DGP\", \"IGLD\", \"COMB\", \"DBE\", \"FGDL\", \"CORN\", \"USL\", \"CCRV\", \"DJCB\", \"IAUF\", \"PLTM\", \"BDRY\", \"PDBA\", \"BGLD\", \"UCIB\", \"SOYB\", \"GRN\", \"PIT\", \"BCIM\", \"RENW\", \"SDCI\", \"UNL\", \"SHNY\", \"DCMT\", \"TAGS\", \"CANE\", \"TMET\", \"KEUA\", \"HCOM\", \"HARD\", \"EVMT\", \"USG\", \"AMPD\", \"DZZ\", \"DGZ\", \"KMET\", \"CMCI\", \"USOY\", \"ZSC\", \"TILL\", \"BWET\", \"DULL\", \"ZSB\", \"LNGG\", \"USOI\", \"OILK\", \"SLVO\", \"GLDI\", \"BOIL\", \"KOLD\", \"AGQ\", \"GLL\", \"UGL\", \"ZSL\", \"UCO\", \"SCO\"]\n",
    "\n",
    "\n",
    "\n",
    "df = (await aget_etf_category(symbols=[\"AAPL\", \"XLE\", \"DBA\"])).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from humbldata.portfolio.analytics.user_table.helpers import normalize_asset_class\n",
    "\n",
    "\n",
    "normalized_df = normalize_asset_class(df).select([\"symbol\", \"category\"])\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.core.utils.openbb_helpers import aget_etf_category\n",
    "\n",
    "\n",
    "df2 = (await aget_etf_category(symbols=[\"AAPL\", \"XLE\", \"DBA\"])).collect()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.core.standard_models.portfolio.analytics.etf_category import ETFCategoryData\n",
    "\n",
    "\n",
    "ETFCategoryData(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.portfolio.analytics.user_table.helpers import aget_asset_class_filter\n",
    "\n",
    "\n",
    "(await aget_asset_class_filter(symbols=[\"AAPL\", \"XLE\", \"DBA\"])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test aget_sector_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.portfolio.analytics.user_table.helpers import aget_sector_filter\n",
    "\n",
    "\n",
    "(await aget_sector_filter(symbols=[\"XLU\", \"XLE\", \"XLF\", \"XLC\", \"KO\", \"AAPL\"])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test aggregate_user_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from humbldata.portfolio.analytics.user_table.helpers import aggregate_user_table_data\n",
    "import polars as pl\n",
    "\n",
    "out: pl.LazyFrame = (await aggregate_user_table_data(symbols=[\"XLU\", \"XLE\", \"AAPL\"]))\n",
    "out.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from humbldata.core.utils.openbb_helpers import aget_latest_price\n",
    "\n",
    "\n",
    "(await aget_latest_price(symbol=[\"AAPL\", \"NVDA\", \"XLE\"])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_data = await aget_etf_category(symbols=[\"AAPL\", \"XLE\", \"DBA\"])\n",
    "(await aget_sector_filter(symbols=[\"AAPL\", \"XLE\", \"DBA\"], etf_data=etf_data)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test UserTableFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Portfolio(symbols=['AAPL', 'XLE', 'DBA'], provider=yahoo, user_role=basic)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from humbldata.portfolio.portfolio_controller import Portfolio\n",
    "\n",
    "portfolio = Portfolio(symbols=[\"AAPL\", \"XLE\", \"DBA\"])\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaError",
     "evalue": "column 'upside' not in dataframe\nnaive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n\nSLICE[offset: 0, len: 5]\n  RENAME\n    RENAME\n      RENAME\n         SELECT [col(\"date\"), col(\"symbol\"), col(\"bottom_price\"), col(\"recent_price\"), col(\"top_price\"), col(\"ud_pct\"), col(\"ud_ratio\"), col(\"sector\"), col(\"asset_class\")] FROM\n           WITH_COLUMNS:\n           [String(-).str.concat_horizontal([[([([(col(\"recent_price\")) - (col(\"bottom_price\"))]) / (col(\"recent_price\"))]) * (100.0)].abs().round().strict_cast(String), String( / +), [([([(col(\"top_price\")) - (col(\"recent_price\"))]) / (col(\"recent_price\"))]) * (100.0)].round().strict_cast(String)]).alias(\"ud_pct\"), [([(col(\"recent_price\")) - (col(\"bottom_price\"))]) / ([(col(\"top_price\")) - (col(\"recent_price\"))])].round().alias(\"ud_ratio\")], [] \n            LEFT JOIN:\n            LEFT PLAN ON: [col(\"symbol\")]\n              SORT BY [col(\"symbol\")]\n                simple π 4/5 [\"last_price\", \"symbol\", ... 2 other columns]\n                   WITH_COLUMNS:\n                   [col(\"symbol\").coalesce([col(\"symbol_PL_CONCAT_RIGHT\")])], [] \n                    FULL JOIN:\n                    LEFT PLAN ON: [col(\"symbol\")]\n                      simple π 3/4 [\"last_price\", \"symbol\", ... 1 other column]\n                         WITH_COLUMNS:\n                         [col(\"symbol\").coalesce([col(\"symbol_PL_CONCAT_RIGHT\")])], [] \n                          FULL JOIN:\n                          LEFT PLAN ON: [col(\"symbol\")]\n                             SELECT [when([(col(\"asset_type\")) == (String(ETF))]).then(col(\"prev_close\")).otherwise(col(\"last_price\")).alias(\"last_price\"), col(\"symbol\")] FROM\n                              DF [\"symbol\", \"asset_type\", \"name\", \"exchange\"]; PROJECT */21 COLUMNS; SELECTION: None\n                          RIGHT PLAN ON: [col(\"symbol\")]\n                            UNION\n                              PLAN 0:\n                                FILTER col(\"sector\").is_not_null() FROM\n                                  DF [\"symbol\", \"sector\"]; PROJECT */2 COLUMNS; SELECTION: None\n                              PLAN 1:\n                                 WITH_COLUMNS:\n                                 [col(\"sector\").replace([Series, Series])], [] \n                                  RENAME\n                                    FILTER col(\"category\").is_not_null() FROM\n                                       WITH_COLUMNS:\n                                       [when(col(\"category\").is_null()).then(null.strict_cast(String)).otherwise(col(\"category\")).alias(\"category\")], [] \n                                        LEFT JOIN:\n                                        LEFT PLAN ON: [col(\"symbol\")]\n                                          DF [\"symbol\"]; PROJECT */1 COLUMNS; SELECTION: None\n                                        RIGHT PLAN ON: [col(\"symbol\")]\n                                          DF [\"symbol\", \"category\"]; PROJECT */2 COLUMNS; SELECTION: None\n                                        END LEFT JOIN\n                            END UNION\n                          END FULL JOIN\n                    RIGHT PLAN ON: [col(\"symbol\")]\n                      RENAME\n                         WITH_COLUMNS:\n                         [when(col(\"symbol\").is_in([Series])).then(String(Foreign Exchange)).otherwise(when(col(\"symbol\").is_in([Series])).then(String(Cash)).otherwise(when(col(\"symbol\").is_in([Series])).then(String(Crypto)).otherwise(when(col(\"symbol\").is_in([Series])).then(String(Commodity)).otherwise(col(\"category\").str.replace([String(^(?:\\w+\\s){0,2}\\w*\\bBond\\b\\w*(?:\\s\\w+){0,2}$), String(Fixed Income)]).str.replace([String(.*Commodities.*), String(Commodity)]).str.replace([String(.*Digital.*), String(Crypto)]).str.replace([String(.*Currency.*), String(Foreign Exchange)]).str.replace([String(.*Equity.*), String(Equity)]).str.replace([String(Utilities), String(Equity)]))))).alias(\"category\")], [] \n                           WITH_COLUMNS:\n                           [when(col(\"category\").is_null()).then(String(Equity)).otherwise(col(\"category\")).alias(\"category\")], [] \n                             WITH_COLUMNS:\n                             [when(col(\"category\").is_null()).then(null.strict_cast(String)).otherwise(col(\"category\")).alias(\"category\")], [] \n                              LEFT JOIN:\n                              LEFT PLAN ON: [col(\"symbol\")]\n                                DF [\"symbol\"]; PROJECT */1 COLUMNS; SELECTION: None\n                              RIGHT PLAN ON: [col(\"symbol\")]\n                                DF [\"symbol\", \"category\"]; PROJECT */2 COLUMNS; SELECTION: None\n                              END LEFT JOIN\n                    END FULL JOIN\n            RIGHT PLAN ON: [col(\"symbol\")]\n               SELECT [col(\"date\"), col(\"symbol\"), col(\"bottom_price\"), col(\"recent_price\"), col(\"top_price\")] FROM\n                 WITH_COLUMNS:\n                 [[(col(\"recent_price\")) + ([(col(\"price_range\")) * (col(\"top_modifier\"))])].round().alias(\"top_price\"), [(col(\"recent_price\")) + ([(col(\"price_range\")) * (col(\"bottom_modifier\"))])].round().alias(\"bottom_price\")], [] \n                   WITH_COLUMNS:\n                   [when([([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))]) != (0.0)]).then([(col(\"last_cum_sum_max\")) / ([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))])]).otherwise(1.0).alias(\"top_modifier\"), when([([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))]) != (0.0)]).then([(col(\"last_cum_sum_min\")) / ([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))])]).otherwise(1.0).alias(\"bottom_modifier\")], [] \n                    SORT BY [col(\"symbol\")]\n                       WITH_COLUMNS:\n                       [[([(col(\"RS\")) * (col(\"std_detrended_log_returns\"))]) * (col(\"recent_price\"))].alias(\"price_range\")], [] \n                        AGGREGATE\n                        \t[col(\"date\").max(), col(\"detrended_log_returns\").std().alias(\"std_detrended_log_returns\"), col(\"close\").last().alias(\"recent_price\"), col(\"cum_sum_max\").last().alias(\"last_cum_sum_max\"), col(\"cum_sum_min\").last().alias(\"last_cum_sum_min\"), col(\"RS\").last().alias(\"RS\")] BY [col(\"symbol\")] FROM\n                           WITH_COLUMNS:\n                           [[(col(\"cum_sum_range\")) / (col(\"cum_sum_std\"))].alias(\"RS\")], [] \n                            SORT BY [col(\"symbol\"), col(\"date\")]\n                              simple π 19/20 [\"date\", \"open\", \"high\", \"low\", ... 15 other columns]\n                                FILTER [(col(\"vol_bucket\")) == (col(\"last_vol_bucket\"))].over([col(\"symbol\")]) FROM\n                                   WITH_COLUMNS:\n                                   [col(\"vol_bucket\").last().over([col(\"symbol\")]).alias(\"last_vol_bucket\")], [] \n                                     WITH_COLUMNS:\n                                     [col(\"realized_volatility\").qcut().over([col(\"symbol\")]).strict_cast(String).alias(\"vol_bucket\")], [] \n                                      RENAME\n                                        FILTER col(\"std_volatility_pct_30D\").is_not_null().cast(Boolean) FROM\n                                           WITH_COLUMNS:\n                                           [[([(col(\"log_returns\").rolling_std_by([col(\"date\")])) * (15.874508)]) * (100.0)].alias(\"std_volatility_pct_30D\")], [] \n                                             WITH_COLUMNS:\n                                             [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                              SORT BY [col(\"symbol\"), col(\"date\")]\n                                                 WITH_COLUMNS:\n                                                 [col(\"cum_sum\").std().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum_std\")], [] \n                                                   WITH_COLUMNS:\n                                                   [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                     WITH_COLUMNS:\n                                                     [[(col(\"cum_sum_max\")) - (col(\"cum_sum_min\"))].alias(\"cum_sum_range\")], [] \n                                                      SORT BY [col(\"symbol\"), col(\"date\")]\n                                                         WITH_COLUMNS:\n                                                         [col(\"cum_sum\").min().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum_min\"), col(\"cum_sum\").max().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum_max\")], [] \n                                                           WITH_COLUMNS:\n                                                           [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                            SORT BY [col(\"symbol\"), col(\"date\")]\n                                                               WITH_COLUMNS:\n                                                               [col(\"detrended_log_returns\").cum_sum().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum\")], [] \n                                                                 WITH_COLUMNS:\n                                                                 [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                  SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                     WITH_COLUMNS:\n                                                                     [[(col(\"log_returns\")) - (col(\"window_mean\"))].alias(\"detrended_log_returns\")], [] \n                                                                       WITH_COLUMNS:\n                                                                       [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                        SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                           WITH_COLUMNS:\n                                                                           [col(\"log_returns\").mean().over([col(\"symbol\"), col(\"window_index\")]).alias(\"window_mean\")], [] \n                                                                             WITH_COLUMNS:\n                                                                             [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                              SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                                FILTER col(\"log_returns\").is_not_null().cast(Boolean) FROM\n                                                                                   WITH_COLUMNS:\n                                                                                   [col(\"close\").log().diff().alias(\"log_returns\")], [] \n                                                                                     WITH_COLUMNS:\n                                                                                     [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                                      SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                                         WITH_COLUMNS:\n                                                                                         [[([([([(12) * ([(col(\"date\").last().dt.year()) - (col(\"date\").dt.year())])]) + ([(col(\"date\").last().dt.month()) - (col(\"date\").dt.month())].cast(Int32))]) - ([(col(\"date\").dt.day()) > (col(\"date\").last().dt.day())].cast(Int32))]) floor_div (1)].over([col(\"symbol\")]).alias(\"window_index\")], [] \n                                                                                          simple π 8/10 [\"date\", \"open\", \"high\", \"low\", ... 4 other columns]\n                                                                                            DF [\"date\", \"open\", \"high\", \"low\"]; PROJECT */10 COLUMNS; SELECTION: None\n            END LEFT JOIN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m portfolio\u001b[38;5;241m.\u001b[39manalytics\u001b[38;5;241m.\u001b[39muser_table()\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/src/humbldata/core/standard_models/portfolio/analytics/user_table.py:290\u001b[0m, in \u001b[0;36mUserTableFetcher.fetch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_query()\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_data()\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_data()\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HumblObject(\n\u001b[1;32m    293\u001b[0m     results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformed_data,\n\u001b[1;32m    294\u001b[0m     provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mprovider,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m     command_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_params,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/src/humbldata/core/standard_models/portfolio/analytics/user_table.py:270\u001b[0m, in \u001b[0;36mUserTableFetcher.transform_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Implement data transformation logic here\u001b[39;00m\n\u001b[1;32m    264\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aggregate_user_table_data(\n\u001b[1;32m    265\u001b[0m     symbols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39msymbols,\n\u001b[1;32m    266\u001b[0m     etf_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metf_data,\n\u001b[1;32m    267\u001b[0m     mandelbrot_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmandelbrot,\n\u001b[1;32m    268\u001b[0m     toolbox\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbox,\n\u001b[1;32m    269\u001b[0m )\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformed_data \u001b[38;5;241m=\u001b[39m \u001b[43mUserTableData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformed_data\u001b[38;5;241m.\u001b[39mserialize()\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/menv/lib/python3.11/site-packages/pandera/api/dataframe/model.py:138\u001b[0m, in \u001b[0;36mDataFrameModel.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;129m@docstring_substitution\u001b[39m(validate_doc\u001b[38;5;241m=\u001b[39mBaseSchema\u001b[38;5;241m.\u001b[39mvalidate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrameBase[TDataFrameModel]:  \u001b[38;5;66;03m# type: ignore [misc]\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"%(validate_doc)s\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m--> 138\u001b[0m         DataFrameBase[TDataFrameModel], \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/menv/lib/python3.11/site-packages/pandera/api/dataframe/model.py:289\u001b[0m, in \u001b[0;36mDataFrameModel.validate\u001b[0;34m(cls, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;129m@docstring_substitution\u001b[39m(validate_doc\u001b[38;5;241m=\u001b[39mBaseSchema\u001b[38;5;241m.\u001b[39mvalidate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m     inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrameBase[TDataFrameModel]:\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"%(validate_doc)s\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    288\u001b[0m         DataFrameBase[TDataFrameModel],\n\u001b[0;32m--> 289\u001b[0m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    292\u001b[0m     )\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/menv/lib/python3.11/site-packages/pandera/api/polars/container.py:58\u001b[0m, in \u001b[0;36mDataFrameSchema.validate\u001b[0;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataframe:\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;66;03m# if validating a polars DataFrame, use the global config setting\u001b[39;00m\n\u001b[1;32m     56\u001b[0m         check_obj \u001b[38;5;241m=\u001b[39m check_obj\u001b[38;5;241m.\u001b[39mlazy()\n\u001b[0;32m---> 58\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dataframe:\n\u001b[1;32m     70\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/menv/lib/python3.11/site-packages/pandera/backends/polars/container.py:111\u001b[0m, in \u001b[0;36mDataFrameSchemaBackend.validate\u001b[0;34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m             error \u001b[38;5;241m=\u001b[39m SchemaError(\n\u001b[1;32m    102\u001b[0m                 schema,\n\u001b[1;32m    103\u001b[0m                 data\u001b[38;5;241m=\u001b[39mcheck_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 reason_code\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mreason_code,\n\u001b[1;32m    110\u001b[0m             )\n\u001b[0;32m--> 111\u001b[0m         \u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_exc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_handler\u001b[38;5;241m.\u001b[39mcollected_errors:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_invalid_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/github/humblFINANCE-org/humblDATA/menv/lib/python3.11/site-packages/pandera/api/base/error_handler.py:54\u001b[0m, in \u001b[0;36mErrorHandler.collect_error\u001b[0;34m(self, error_type, reason_code, schema_error, original_exc)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m:param error_type: type of error\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moriginal_exc\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mSchemaError\u001b[0m: column 'upside' not in dataframe\nnaive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n\nSLICE[offset: 0, len: 5]\n  RENAME\n    RENAME\n      RENAME\n         SELECT [col(\"date\"), col(\"symbol\"), col(\"bottom_price\"), col(\"recent_price\"), col(\"top_price\"), col(\"ud_pct\"), col(\"ud_ratio\"), col(\"sector\"), col(\"asset_class\")] FROM\n           WITH_COLUMNS:\n           [String(-).str.concat_horizontal([[([([(col(\"recent_price\")) - (col(\"bottom_price\"))]) / (col(\"recent_price\"))]) * (100.0)].abs().round().strict_cast(String), String( / +), [([([(col(\"top_price\")) - (col(\"recent_price\"))]) / (col(\"recent_price\"))]) * (100.0)].round().strict_cast(String)]).alias(\"ud_pct\"), [([(col(\"recent_price\")) - (col(\"bottom_price\"))]) / ([(col(\"top_price\")) - (col(\"recent_price\"))])].round().alias(\"ud_ratio\")], [] \n            LEFT JOIN:\n            LEFT PLAN ON: [col(\"symbol\")]\n              SORT BY [col(\"symbol\")]\n                simple π 4/5 [\"last_price\", \"symbol\", ... 2 other columns]\n                   WITH_COLUMNS:\n                   [col(\"symbol\").coalesce([col(\"symbol_PL_CONCAT_RIGHT\")])], [] \n                    FULL JOIN:\n                    LEFT PLAN ON: [col(\"symbol\")]\n                      simple π 3/4 [\"last_price\", \"symbol\", ... 1 other column]\n                         WITH_COLUMNS:\n                         [col(\"symbol\").coalesce([col(\"symbol_PL_CONCAT_RIGHT\")])], [] \n                          FULL JOIN:\n                          LEFT PLAN ON: [col(\"symbol\")]\n                             SELECT [when([(col(\"asset_type\")) == (String(ETF))]).then(col(\"prev_close\")).otherwise(col(\"last_price\")).alias(\"last_price\"), col(\"symbol\")] FROM\n                              DF [\"symbol\", \"asset_type\", \"name\", \"exchange\"]; PROJECT */21 COLUMNS; SELECTION: None\n                          RIGHT PLAN ON: [col(\"symbol\")]\n                            UNION\n                              PLAN 0:\n                                FILTER col(\"sector\").is_not_null() FROM\n                                  DF [\"symbol\", \"sector\"]; PROJECT */2 COLUMNS; SELECTION: None\n                              PLAN 1:\n                                 WITH_COLUMNS:\n                                 [col(\"sector\").replace([Series, Series])], [] \n                                  RENAME\n                                    FILTER col(\"category\").is_not_null() FROM\n                                       WITH_COLUMNS:\n                                       [when(col(\"category\").is_null()).then(null.strict_cast(String)).otherwise(col(\"category\")).alias(\"category\")], [] \n                                        LEFT JOIN:\n                                        LEFT PLAN ON: [col(\"symbol\")]\n                                          DF [\"symbol\"]; PROJECT */1 COLUMNS; SELECTION: None\n                                        RIGHT PLAN ON: [col(\"symbol\")]\n                                          DF [\"symbol\", \"category\"]; PROJECT */2 COLUMNS; SELECTION: None\n                                        END LEFT JOIN\n                            END UNION\n                          END FULL JOIN\n                    RIGHT PLAN ON: [col(\"symbol\")]\n                      RENAME\n                         WITH_COLUMNS:\n                         [when(col(\"symbol\").is_in([Series])).then(String(Foreign Exchange)).otherwise(when(col(\"symbol\").is_in([Series])).then(String(Cash)).otherwise(when(col(\"symbol\").is_in([Series])).then(String(Crypto)).otherwise(when(col(\"symbol\").is_in([Series])).then(String(Commodity)).otherwise(col(\"category\").str.replace([String(^(?:\\w+\\s){0,2}\\w*\\bBond\\b\\w*(?:\\s\\w+){0,2}$), String(Fixed Income)]).str.replace([String(.*Commodities.*), String(Commodity)]).str.replace([String(.*Digital.*), String(Crypto)]).str.replace([String(.*Currency.*), String(Foreign Exchange)]).str.replace([String(.*Equity.*), String(Equity)]).str.replace([String(Utilities), String(Equity)]))))).alias(\"category\")], [] \n                           WITH_COLUMNS:\n                           [when(col(\"category\").is_null()).then(String(Equity)).otherwise(col(\"category\")).alias(\"category\")], [] \n                             WITH_COLUMNS:\n                             [when(col(\"category\").is_null()).then(null.strict_cast(String)).otherwise(col(\"category\")).alias(\"category\")], [] \n                              LEFT JOIN:\n                              LEFT PLAN ON: [col(\"symbol\")]\n                                DF [\"symbol\"]; PROJECT */1 COLUMNS; SELECTION: None\n                              RIGHT PLAN ON: [col(\"symbol\")]\n                                DF [\"symbol\", \"category\"]; PROJECT */2 COLUMNS; SELECTION: None\n                              END LEFT JOIN\n                    END FULL JOIN\n            RIGHT PLAN ON: [col(\"symbol\")]\n               SELECT [col(\"date\"), col(\"symbol\"), col(\"bottom_price\"), col(\"recent_price\"), col(\"top_price\")] FROM\n                 WITH_COLUMNS:\n                 [[(col(\"recent_price\")) + ([(col(\"price_range\")) * (col(\"top_modifier\"))])].round().alias(\"top_price\"), [(col(\"recent_price\")) + ([(col(\"price_range\")) * (col(\"bottom_modifier\"))])].round().alias(\"bottom_price\")], [] \n                   WITH_COLUMNS:\n                   [when([([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))]) != (0.0)]).then([(col(\"last_cum_sum_max\")) / ([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))])]).otherwise(1.0).alias(\"top_modifier\"), when([([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))]) != (0.0)]).then([(col(\"last_cum_sum_min\")) / ([(col(\"last_cum_sum_max\")) - (col(\"last_cum_sum_min\"))])]).otherwise(1.0).alias(\"bottom_modifier\")], [] \n                    SORT BY [col(\"symbol\")]\n                       WITH_COLUMNS:\n                       [[([(col(\"RS\")) * (col(\"std_detrended_log_returns\"))]) * (col(\"recent_price\"))].alias(\"price_range\")], [] \n                        AGGREGATE\n                        \t[col(\"date\").max(), col(\"detrended_log_returns\").std().alias(\"std_detrended_log_returns\"), col(\"close\").last().alias(\"recent_price\"), col(\"cum_sum_max\").last().alias(\"last_cum_sum_max\"), col(\"cum_sum_min\").last().alias(\"last_cum_sum_min\"), col(\"RS\").last().alias(\"RS\")] BY [col(\"symbol\")] FROM\n                           WITH_COLUMNS:\n                           [[(col(\"cum_sum_range\")) / (col(\"cum_sum_std\"))].alias(\"RS\")], [] \n                            SORT BY [col(\"symbol\"), col(\"date\")]\n                              simple π 19/20 [\"date\", \"open\", \"high\", \"low\", ... 15 other columns]\n                                FILTER [(col(\"vol_bucket\")) == (col(\"last_vol_bucket\"))].over([col(\"symbol\")]) FROM\n                                   WITH_COLUMNS:\n                                   [col(\"vol_bucket\").last().over([col(\"symbol\")]).alias(\"last_vol_bucket\")], [] \n                                     WITH_COLUMNS:\n                                     [col(\"realized_volatility\").qcut().over([col(\"symbol\")]).strict_cast(String).alias(\"vol_bucket\")], [] \n                                      RENAME\n                                        FILTER col(\"std_volatility_pct_30D\").is_not_null().cast(Boolean) FROM\n                                           WITH_COLUMNS:\n                                           [[([(col(\"log_returns\").rolling_std_by([col(\"date\")])) * (15.874508)]) * (100.0)].alias(\"std_volatility_pct_30D\")], [] \n                                             WITH_COLUMNS:\n                                             [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                              SORT BY [col(\"symbol\"), col(\"date\")]\n                                                 WITH_COLUMNS:\n                                                 [col(\"cum_sum\").std().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum_std\")], [] \n                                                   WITH_COLUMNS:\n                                                   [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                     WITH_COLUMNS:\n                                                     [[(col(\"cum_sum_max\")) - (col(\"cum_sum_min\"))].alias(\"cum_sum_range\")], [] \n                                                      SORT BY [col(\"symbol\"), col(\"date\")]\n                                                         WITH_COLUMNS:\n                                                         [col(\"cum_sum\").min().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum_min\"), col(\"cum_sum\").max().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum_max\")], [] \n                                                           WITH_COLUMNS:\n                                                           [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                            SORT BY [col(\"symbol\"), col(\"date\")]\n                                                               WITH_COLUMNS:\n                                                               [col(\"detrended_log_returns\").cum_sum().over([col(\"symbol\"), col(\"window_index\")]).alias(\"cum_sum\")], [] \n                                                                 WITH_COLUMNS:\n                                                                 [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                  SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                     WITH_COLUMNS:\n                                                                     [[(col(\"log_returns\")) - (col(\"window_mean\"))].alias(\"detrended_log_returns\")], [] \n                                                                       WITH_COLUMNS:\n                                                                       [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                        SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                           WITH_COLUMNS:\n                                                                           [col(\"log_returns\").mean().over([col(\"symbol\"), col(\"window_index\")]).alias(\"window_mean\")], [] \n                                                                             WITH_COLUMNS:\n                                                                             [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                              SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                                FILTER col(\"log_returns\").is_not_null().cast(Boolean) FROM\n                                                                                   WITH_COLUMNS:\n                                                                                   [col(\"close\").log().diff().alias(\"log_returns\")], [] \n                                                                                     WITH_COLUMNS:\n                                                                                     [col(\"symbol\").set_sorted(), col(\"date\").set_sorted()], [] \n                                                                                      SORT BY [col(\"symbol\"), col(\"date\")]\n                                                                                         WITH_COLUMNS:\n                                                                                         [[([([([(12) * ([(col(\"date\").last().dt.year()) - (col(\"date\").dt.year())])]) + ([(col(\"date\").last().dt.month()) - (col(\"date\").dt.month())].cast(Int32))]) - ([(col(\"date\").dt.day()) > (col(\"date\").last().dt.day())].cast(Int32))]) floor_div (1)].over([col(\"symbol\")]).alias(\"window_index\")], [] \n                                                                                          simple π 8/10 [\"date\", \"open\", \"high\", \"low\", ... 4 other columns]\n                                                                                            DF [\"date\", \"open\", \"high\", \"low\"]; PROJECT */10 COLUMNS; SELECTION: None\n            END LEFT JOIN"
     ]
    }
   ],
   "source": [
    "await portfolio.analytics.user_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
