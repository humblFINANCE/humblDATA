{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"humbldata <p>the humbldata package is thin wrapper around the most popular open-source financial data providers, with some extra flair. it has modern financial statistics and tools (based on the same math) as the big guys. how do i know? because i used to pay a pretty penny for it! no longer... OSS is here to save the day</p>"},{"location":"roadmap/","title":"\ud83d\ude97 Roadmap","text":""},{"location":"roadmap/#package-features","title":"\u2728 Package Features \u2728","text":"<ul> <li> <p> Add Volatility Adjusted Positioning</p> <ul> <li>this is implied volatility analysis that looks at IVOl premiums and discounts to determine a the best times to gross/de-gross your positions.</li> </ul> </li> <li> <p> Add backtesting capability to Mandelbrot Channel prices.</p> <ul> <li>a simple backtesting module to look at the perfromance if you were to buy and sell assets when they got close to the upper or lower bounds of the Mandelbrot Channel.</li> </ul> </li> </ul>"},{"location":"roadmap/#development","title":"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbb Development \ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbb","text":"<ul> <li> Add support for Nox for automated testing across various platforms and python versions, instead of Tox.</li> <li> Replace <code>commitizen</code> with <code>cz-git</code> for commit message generation.</li> </ul>"},{"location":"code_design/","title":"Index","text":""},{"location":"code_design/#code-design","title":"\ud83e\uddf1 Code Design","text":"<p>Here...you will learn about the design paradigm that was chosen and used while developing this project. This will include the architecture, the design patterns. The coding standards, will be available in the contributing section.</p>"},{"location":"code_design/cccc_method/","title":"CCCC: core, context, category, command","text":"<p>THe purpose of this design paradigm is to always be thinking of your application and features that you are implementing in a nested hierarchical structure. We do this for 3 main benefits, namely:</p> <ol> <li>It is easy to tell where you should put your piece of code.</li> <li>It is easy to create reusable functions for multiple use cases.</li> <li>It is easy to diagram a flow chart of your application, given that you know where larger modules should go (core/context/category) and where endpoints of the graph (commands) should go.</li> </ol> <p>The point of CCCC is to make creation of Models, View &amp; Controllers simpler.The nested strucutre allows for easy mental organization.</p> <p>CCCC Explained</p> <code>Core</code> <p>The core of your app. Logic used in controllers goes here. This module is intended to contain sub-modules and functions that are not directly utilized from the package, but rather used in building the package itself.</p> <p>The core will hold the standard_models, for all of the functions in the package. The core will also hold modules like the <code>utils</code> module, that is used in the humbldata package itself, and not publicly exposed.</p> <code>Context</code> <p>This is a grouping of multiple categories. The highest level of modules should go here.</p> <p>i.e <code>context</code> is a top-level directory that contains multiple <code>categories</code>. The <code>Toolbox</code> is an example of a context, becuase it contains <code>Technical</code>, <code>Quantitative</code> &amp; <code>Fundamental</code> categories. This directory is at the same level as the <code>core</code> directory. This context holds all the <code>categories</code> that are used to build the <code>Toolbox</code>.</p> <code>Category</code> <p>This is the grouping of multiple commands that belongs to a context. Categories can be extended to as many &lt;<code>sub-categories</code>&gt; as needed.</p> <code>Command</code> <p>This is the smallest unit of code that can be executed.</p>"},{"location":"code_design/cccc_method/#cccc-framework","title":"CCCC Framework","text":"<p>This is an example of how the CCCC framework can be used to create a simple API. This showcases the <code>mandelbrot_channel</code> command, in the <code>Technical</code> category from the <code>Toolbox</code> context.</p> <pre><code>classDiagram\n    class Toolbox {\n        &lt;&lt;Context&gt;&gt;\n        @property +technical\n    }\n    class Technical {\n        &lt;&lt;Category&gt;&gt;\n        -context_params: ToolboxQueryParams\n        +mandelbrot_channel(command_params: MandelbrotChannelQueryParams) HumblObject\n    }\n    class MandelbrotChannelQueryParams {\n        &lt;&lt;Standard Model (pydantic)&gt;&gt;\n        +window: str\n        +rv_adjustment: bool\n        -_rv_method: str\n        -_rs_method: str\n        -_rv_grouped_mean: bool\n        -_live_price: bool\n    }\n    class MandelbrotChannelData {\n        &lt;&lt;Standard Model (pydantic)&gt;&gt;\n        +date: date\n        +symbol: str\n        +bottom_price: f64\n        +recent_price: f64\n        +top_price: f64\n    }\n    class ToolboxQueryParams {\n        &lt;&lt;Standard Model (pydantic)&gt;&gt;\n        symbol: str\n        interval: str | None\n        start_date: str\n        end_date: str\n        provider: OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS\n    }\n    class MandelbrotChannelFetcher {\n        -context_params: ToolboxQueryParams\n        +command_params: MandelbrotChannelQueryParams\n        +transform_query(self)\n        +extract_data(self)\n        +transform_data(self)\n        +fetch_data(self)  HumblObject\n    }\n\n    %% not actually a class\n    class mandelbrot_channel {\n        &lt;&lt;Command&gt;&gt;\n        +command_params: MandelbrotChannelQueryParams\n        +fetcher.fetch_data() HumblObject\n\n    }\n\n    Toolbox --&gt;  Technical : returns\n    Technical --&gt; mandelbrot_channel : returns\n    mandelbrot_channel &lt;--&gt; MandelbrotChannelFetcher : calls\n    MandelbrotChannelFetcher &lt;-- MandelbrotChannelQueryParams : validates command query\n    MandelbrotChannelFetcher &lt;-- MandelbrotChannelData : validates data\n    MandelbrotChannelFetcher &lt;-- ToolboxQueryParams : validates context query\n\n\n    note for MandelbrotChannelFetcher \"The 'Fetcher' uses the DUMB \\n `calc_mandelbrot_channel()` \\n function to perform the core \\n command logic on the collected data.\"</code></pre>"},{"location":"code_design/mvcdb/","title":"M-V-C-DB","text":"<pre><code>graph LR\n    User --&gt;|requests| Routes\n    Routes --&gt;|defines| Controller\n    Controller --&gt;|manipulates| Model\n    Model --&gt; |returns data| Controller\n    Model --&gt;|queries| Database\n    Database --&gt;|returns data| Model\n    Model --&gt;|updates| View\n    View --&gt;|renders to| Controller\n    Controller --&gt;|shows data| User</code></pre>"},{"location":"code_design/mvcdb/#model","title":"\ud83e\udde0 Model","text":"<p>The Model represents the data structure and the business logic of the application. It directly manages the data and logic. A model can respond to requests for information, respond to instructions to change its state, and even notify observers in an event-driven system. This layer is where the core functionality of the application resides, dealing with the retrieval, insertion, update, and deletion of data. The model communicates with the database and processes the business logic based on the data received from the controller. It is completely independent of the user interface.</p>"},{"location":"code_design/mvcdb/#view","title":"\ud83d\udc40 View","text":"<p>The View is the user interface of the application. It is responsible for displaying the data that is received from the model. The view is completely independent of the model and the controller. It is only responsible for displaying the data and the user interface.</p>"},{"location":"code_design/mvcdb/#controller","title":"\ud83c\udfae Controller","text":"<p>The Controller is the bridge between the User and the Model/View. It is responsible for processing the user's input and updating the model with the correct <code>QueryParams</code>. The controller is responsible for processing the user's input and updating the model. The controller is the only layer that interacts with the user. It receives the user's input and processes it. It then sends the processed data to the model for processing. The controller is responsible for updating the model based on the user's input and then sending the updated data to the view for display.</p>"},{"location":"code_design/mvcdb/#database","title":"\ud83d\uddc4\ufe0f Database","text":"<p>The Database is the storage of the application. It is responsible for storing the data that is received from the model. The database is completely independent of the model, view, and controller. It is only responsible for storing the data. The only interaction the database has is with the model, to store and retrieve data.</p>"},{"location":"code_design/standardization_framework/","title":"Standardization Framework","text":""},{"location":"code_documentation/","title":"\ud83d\udcda Code Documentation","text":"<p>This is an all encompassing documentation of the code base.</p> <p>It is handwritten and generated from mkdocstrings. Unlike Sphinx, it lacks the <code>.autosummary::</code> syntax for recursive documentation generation, but this design choice facilitates precise introduction and management of how the code base is presented and interacted with.</p> <p>Using the CCCC Organization method is an easier way to showcase a codebase to a new developer rather than just a list of all the Classes, Methods, Functions and Scripts.</p> <p>Yes, there is some low-level recursion to document the codebase, and yes, there is some room for recursive improvement, but, this is a beautiful way to showcase code, and makes you very familiar with the codebase, and in doing so, helps direct your focus towards important areas of the codebase; streamlining and speeding up development time.</p>"},{"location":"code_documentation/api_reference/","title":"\ud83d\udcd1 API Reference","text":"<p>This section holds a comprehensive documentation of all of classes, methods and functions in the <code>humbldata</code> package.</p> <p>humbldata package.</p>"},{"location":"code_documentation/api_reference/#humbldata.cli","title":"humbldata.cli","text":"<p>humbldata CLI.</p>"},{"location":"code_documentation/api_reference/#humbldata.cli.say","title":"humbldata.cli.say","text":"<pre><code>say(message: str = '') -&gt; None\n</code></pre> <p>Say a message.</p> Source code in <code>src/humbldata/cli.py</code> <pre><code>@app.command()\ndef say(message: str = \"\") -&gt; None:\n    \"\"\"Say a message.\"\"\"\n    typer.echo(message)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio","title":"humbldata.portfolio","text":""},{"location":"code_documentation/api_reference/#humbldata.portfolio.portfolio_controller","title":"humbldata.portfolio.portfolio_controller","text":"<p>Context: Portfolio.</p> <p>The Portfolio Controller Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.portfolio_controller.Portfolio","title":"humbldata.portfolio.portfolio_controller.Portfolio","text":"<p>             Bases: <code>PortfolioQueryParams</code></p> <p>A top-level Portfolio controller for data analysis tools in <code>humblDATA</code>.</p> <p>This module serves as the primary controller, routing user-specified PortfolioQueryParams as core arguments that are used to fetch time series data.</p> <p>The <code>portfolio</code> controller also gives access to all sub-modules and their functions.</p> <p>It is designed to facilitate the collection of data across various types such as stocks, options, or alternative time series by requiring minimal input from the user.</p> Submodules <p>The <code>Portfolio</code> controller is composed of the following submodules:</p> <ul> <li><code>analytics</code>:</li> </ul> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str or list of str</code> <p>The stock symbol(s) to query. Default is \"AAPL\".</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider for historical price data. Default is \"yahoo\".</p> required <code>membership</code> <p>The membership level of the user. Default is \"anonymous\".</p> required Parameter Notes <p>The parameters are the <code>PortfolioQueryParams</code>. They are used for data collection further down the pipeline in other commands. Intended to execute operations on core data sets. This approach enables composable and standardized querying while accommodating data-specific collection logic.</p> <p>The symbols you input here will be used as <code>Portfolio</code> symbols for the methods available in the <code>analytics</code> submodule.</p> Source code in <code>src/humbldata/portfolio/portfolio_controller.py</code> <pre><code>class Portfolio(PortfolioQueryParams):\n    \"\"\"\n    A top-level Portfolio controller for data analysis tools in `humblDATA`.\n\n    This module serves as the primary controller, routing user-specified\n    PortfolioQueryParams as core arguments that are used to fetch time series\n    data.\n\n    The `portfolio` controller also gives access to all sub-modules and their\n    functions.\n\n    It is designed to facilitate the collection of data across various types such as\n    stocks, options, or alternative time series by requiring minimal input from the user.\n\n    Submodules\n    ----------\n    The `Portfolio` controller is composed of the following submodules:\n\n    - `analytics`:\n\n    Parameters\n    ----------\n    symbol : str or list of str\n        The stock symbol(s) to query. Default is \"AAPL\".\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS\n        The data provider for historical price data. Default is \"yahoo\".\n    membership: Literal[\"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"humblPERMANENT\", \"admin\"]\n        The membership level of the user. Default is \"anonymous\".\n\n    Parameter Notes\n    -----\n    The parameters are the `PortfolioQueryParams`. They are used\n    for data collection further down the pipeline in other commands.\n    Intended to execute operations on core data sets. This approach enables\n    composable and standardized querying while accommodating data-specific\n    collection logic.\n\n    The symbols you input here will be used as `Portfolio` symbols for the\n    methods available in the `analytics` submodule.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initialize the Portfolio module.\n\n        This method does not take any parameters and does not return anything.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @property\n    def analytics(self):\n        \"\"\"\n        The analytics submodule of the Portfolio controller.\n\n        Access to all the Analytics indicators. When the Portfolio class is\n        instantiated the parameters are initialized with the PortfolioQueryParams\n        class, which hold all the fields needed for the context_params, like the\n        symbol, interval, start_date, and end_date.\n        \"\"\"\n        return Analytics(context_params=self)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.portfolio_controller.Portfolio.__init__","title":"humbldata.portfolio.portfolio_controller.Portfolio.__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Initialize the Portfolio module.</p> <p>This method does not take any parameters and does not return anything.</p> Source code in <code>src/humbldata/portfolio/portfolio_controller.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initialize the Portfolio module.\n\n    This method does not take any parameters and does not return anything.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.portfolio_controller.Portfolio.analytics","title":"humbldata.portfolio.portfolio_controller.Portfolio.analytics  <code>property</code>","text":"<pre><code>analytics\n</code></pre> <p>The analytics submodule of the Portfolio controller.</p> <p>Access to all the Analytics indicators. When the Portfolio class is instantiated the parameters are initialized with the PortfolioQueryParams class, which hold all the fields needed for the context_params, like the symbol, interval, start_date, and end_date.</p>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics","title":"humbldata.portfolio.analytics","text":""},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.analytics_controller","title":"humbldata.portfolio.analytics.analytics_controller","text":"<p>Context: Portfolio || Category: Analytics.</p> <p>A controller to manage and compile all of the Analytics models available in the <code>portfolio</code> context. This will be passed as a <code>@property</code> to the <code>portfolio()</code> class, giving access to the Analytics module and its functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.analytics_controller.Analytics","title":"humbldata.portfolio.analytics.analytics_controller.Analytics","text":"<p>Module for all Analytics analysis.</p> <p>Attributes:</p> Name Type Description <code>context_params</code> <code>PortfolioQueryParams</code> <p>The standard query parameters for portfolio data.</p> <p>Methods:</p> Name Description <code>user_table</code> <p>Execute the UserTable command.</p> Source code in <code>src/humbldata/portfolio/analytics/analytics_controller.py</code> <pre><code>class Analytics:\n    \"\"\"\n    Module for all Analytics analysis.\n\n    Attributes\n    ----------\n    context_params : PortfolioQueryParams\n        The standard query parameters for portfolio data.\n\n    Methods\n    -------\n    user_table(command_params: UserTableQueryParams)\n        Execute the UserTable command.\n\n    \"\"\"\n\n    def __init__(self, context_params: PortfolioQueryParams):\n        self.context_params = context_params\n\n    def user_table(self, **kwargs: UserTableQueryParams):\n        \"\"\"\n        Execute the UserTable command.\n\n        Explain the functionality...\n        \"\"\"\n        from humbldata.core.standard_models.portfolio.analytics.user_table import (\n            UserTableFetcher,\n        )\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = UserTableFetcher(\n            context_params=self.context_params, command_params=kwargs\n        )\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.analytics_controller.Analytics.user_table","title":"humbldata.portfolio.analytics.analytics_controller.Analytics.user_table","text":"<pre><code>user_table(**kwargs: UserTableQueryParams)\n</code></pre> <p>Execute the UserTable command.</p> <p>Explain the functionality...</p> Source code in <code>src/humbldata/portfolio/analytics/analytics_controller.py</code> <pre><code>def user_table(self, **kwargs: UserTableQueryParams):\n    \"\"\"\n    Execute the UserTable command.\n\n    Explain the functionality...\n    \"\"\"\n    from humbldata.core.standard_models.portfolio.analytics.user_table import (\n        UserTableFetcher,\n    )\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = UserTableFetcher(\n        context_params=self.context_params, command_params=kwargs\n    )\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table","title":"humbldata.portfolio.analytics.user_table","text":""},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.helpers","title":"humbldata.portfolio.analytics.user_table.helpers","text":"<p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>The UserTable Helpers Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.helpers.aget_sector_filter","title":"humbldata.portfolio.analytics.user_table.helpers.aget_sector_filter  <code>async</code>","text":"<pre><code>aget_sector_filter(symbols: str | list[str] | Series, provider: OBB_EQUITY_PROFILE_PROVIDERS | None = 'yfinance', etf_data: ETFCategoryData | None = None) -&gt; LazyFrame\n</code></pre> <p>Context: Portfolio || Category: Analytics || Command: User Table || Command: aget_sector_filter.</p> <p>Retrieves equity sector information for given symbols, filling in the ETF sector with the <code>obb.etf.info</code> category column from <code>aget_etf_sector</code>. This function also normalizes the sector to GICS_SECTORS via the <code>.replace(GICS_SECTOR_MAPPING)</code> method, and renames the <code>category</code> column to <code>sector</code>. The normalization is different from the normalization in <code>aget_asset_class_filter</code> in that this function uses <code>.str.replace()</code> to normalize the sector, while <code>aget_asset_class_filter</code> uses <code>.replace()</code>. Using <code>.str.replace()</code> allows for Regex matching, but this method since all values are known is slightly more performant.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | Series</code> <p>The symbols to query for sector/category information.</p> required <code>provider</code> <code>OBB_EQUITY_PROFILE_PROVIDERS | None</code> <p>The data provider to use. Default is \"yfinance\".</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for symbols and their corresponding sectors/categories.</p> Notes <p>This function uses aget_equity_sector() to fetch sector information and aget_etf_category() for symbols without sectors. It then combines the results.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/helpers.py</code> <pre><code>async def aget_sector_filter(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PROFILE_PROVIDERS | None = \"yfinance\",\n    etf_data: ETFCategoryData | None = None,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Portfolio || Category: Analytics || Command: User Table || **Command: aget_sector_filter**.\n\n    Retrieves equity sector information for given symbols, filling in the ETF sector\n    with the `obb.etf.info` category column from `aget_etf_sector`. This function\n    also normalizes the sector to GICS_SECTORS via the\n    `.replace(GICS_SECTOR_MAPPING)` method, and renames the `category` column to\n    `sector`. The normalization is different from the normalization in\n    `aget_asset_class_filter` in that this function uses `.str.replace()` to\n    normalize the sector, while `aget_asset_class_filter` uses `.replace()`.\n    Using `.str.replace()` allows for Regex matching, but this method since all\n    values are known is slightly more performant.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | pl.Series\n        The symbols to query for sector/category information.\n    provider : OBB_EQUITY_PROFILE_PROVIDERS | None, optional\n        The data provider to use. Default is \"yfinance\".\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for symbols and their corresponding sectors/categories.\n\n    Notes\n    -----\n    This function uses aget_equity_sector() to fetch sector information and aget_etf_category()\n    for symbols without sectors. It then combines the results.\n    \"\"\"\n    # Get sector information\n    equity_sectors = await aget_equity_sector(symbols, provider=\"yfinance\")\n\n    # Identify symbols with null sectors\n    etf_symbols = (\n        equity_sectors.lazy()\n        .filter(pl.col(\"sector\").is_null())\n        .select([\"symbol\"])\n        .collect()\n        .to_series()\n        .to_list()\n    )\n    equity_sectors = equity_sectors.filter(pl.col(\"sector\").is_not_null())\n\n    # Get ETF categories for symbols with null sectors\n    if etf_symbols:\n        if etf_data is None:\n            etf_categories = await aget_etf_category(\n                etf_symbols, provider=\"yfinance\"\n            )\n        else:\n            # Remove columns with NULL (incoming equity symbols from ETF_DATA)\n            # since only etf symbols are collected from logic above\n            # Validation\n            etf_data = etf_data.filter(pl.col(\"symbol\").is_in(etf_symbols))\n            etf_categories = ETFCategoryData(etf_data)\n\n        # Normalize Sectors to GICS_SECTORS\n        etf_categories = etf_categories.rename(\n            {\"category\": \"sector\"}\n        ).with_columns(pl.col(\"sector\").replace(GICS_SECTOR_MAPPING))\n\n        # If all symbols are ETFs, return the ETF sectors (no need to combine)\n        if etf_symbols == symbols:\n            out_sectors = etf_categories\n        else:\n            out_sectors = pl.concat(\n                [equity_sectors, etf_categories], how=\"vertical\"\n            )\n    else:\n        out_sectors = equity_sectors\n\n    return out_sectors\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.helpers.normalize_asset_class","title":"humbldata.portfolio.analytics.user_table.helpers.normalize_asset_class","text":"<pre><code>normalize_asset_class(data: LazyFrame) -&gt; LazyFrame\n</code></pre> <p>Normalize the asset class in the given LazyFrame to standard ASSET_CLASSES values.</p> <p>This function uses string replacement to standardize asset class names in the 'category' column of the input LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The input LazyFrame containing 'symbol' and 'category' columns to be normalized.</p> required <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A new LazyFrame with the 'category' column normalized to standard asset classes.</p> Notes <p>This function assumes that the input LazyFrame has 'symbol' and 'category' columns. If these columns don't exist, the function may raise an error.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/helpers.py</code> <pre><code>def normalize_asset_class(data: pl.LazyFrame) -&gt; pl.LazyFrame:\n    \"\"\"\n    Normalize the asset class in the given LazyFrame to standard ASSET_CLASSES values.\n\n    This function uses string replacement to standardize asset class names in\n    the 'category' column of the input LazyFrame.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The input LazyFrame containing 'symbol' and 'category' columns to be normalized.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A new LazyFrame with the 'category' column normalized to standard asset classes.\n\n    Notes\n    -----\n    This function assumes that the input LazyFrame has 'symbol' and 'category' columns.\n    If these columns don't exist, the function may raise an error.\n    \"\"\"\n    out = data.with_columns(\n        pl.when(pl.col(\"symbol\").is_in([\"GLD\", \"FGDL\", \"BGLD\"]))\n        .then(pl.lit(\"Foreign Exchange\"))\n        .when(pl.col(\"symbol\").is_in([\"UUP\", \"UDN\", \"USDU\"]))\n        .then(pl.lit(\"Cash\"))\n        .when(pl.col(\"symbol\").is_in([\"BITI\", \"ETHU\", \"ZZZ\"]))\n        .then(pl.lit(\"Crypto\"))\n        .when(pl.col(\"symbol\").is_in([\"BDRY\", \"LNGG\", \"AMPD\", \"USOY\"]))\n        .then(pl.lit(\"Commodity\"))\n        .otherwise(\n            pl.col(\"category\")\n            .str.replace(\n                r\"^(?:\\w+\\s){0,2}\\w*\\bBond\\b\\w*(?:\\s\\w+){0,2}$\", \"Fixed Income\"\n            )\n            .str.replace(r\".*Commodities.*\", \"Commodity\")\n            .str.replace(r\".*Digital.*\", \"Crypto\")\n            .str.replace(r\".*Currency.*\", \"Foreign Exchange\")\n            .str.replace(r\".*Equity.*\", \"Equity\")\n            .str.replace(\"Utilities\", \"Equity\")\n            .str.replace(\"Financial\", \"Equity\")\n            .str.replace(\"Technology\", \"Equity\")\n        )\n        .alias(\"category\")\n    )\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.helpers.aget_asset_class_filter","title":"humbldata.portfolio.analytics.user_table.helpers.aget_asset_class_filter  <code>async</code>","text":"<pre><code>aget_asset_class_filter(symbols: str | list[str] | Series, provider: OBB_ETF_INFO_PROVIDERS | None = 'yfinance', etf_data: ETFCategoryData | None = None) -&gt; LazyFrame\n</code></pre> <p>Context: Portfolio || Category: Analytics || Command: User Table || Command: aget_asset_class_filter.</p> <p>This function takes in a list of symbols and returns a LazyFrame with the asset class for each symbol. Unlike aget_sector_filter, this function normalizes the asset class using the normalize_asset_class() method, which employs <code>.str.replace()</code> for Regex matching. This approach allows for more flexible pattern matching but may be slightly less performant than the direct <code>.replace()</code> method used in aget_sector_filter.</p> <p>The function also renames the 'category' column to 'asset_class'. The normalization process maps the asset classes to standard ASSET_CLASSES values.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/helpers.py</code> <pre><code>async def aget_asset_class_filter(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_ETF_INFO_PROVIDERS | None = \"yfinance\",\n    etf_data: ETFCategoryData | None = None,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Portfolio || Category: Analytics || Command: User Table || **Command: aget_asset_class_filter**.\n\n    This function takes in a list of symbols and returns a LazyFrame with the\n    asset class for each symbol. Unlike aget_sector_filter, this function\n    normalizes the asset class using the normalize_asset_class() method, which\n    employs `.str.replace()` for Regex matching. This approach allows for more\n    flexible pattern matching but may be slightly less performant than the\n    direct `.replace()` method used in aget_sector_filter.\n\n    The function also renames the 'category' column to 'asset_class'. The\n    normalization process maps the asset classes to standard ASSET_CLASSES values.\n    \"\"\"\n    if etf_data is None:\n        out = await aget_etf_category(symbols, provider=provider)\n    else:\n        out = ETFCategoryData(etf_data)\n    out = out.lazy().with_columns(\n        [\n            pl.when(pl.col(\"category\").is_null())\n            .then(pl.lit(\"Equity\"))\n            .otherwise(pl.col(\"category\"))\n            .alias(\"category\")\n        ]\n    )\n    return out.pipe(normalize_asset_class).rename({\"category\": \"asset_class\"})\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.helpers.calc_up_down_pct","title":"humbldata.portfolio.analytics.user_table.helpers.calc_up_down_pct","text":"<pre><code>calc_up_down_pct(data: LazyFrame, recent_price_col: str = 'recent_price', bottom_price_col: str = 'bottom_price', top_price_col: str = 'top_price', pct_output_col: str = 'ud_pct', ratio_output_col: str = 'ud_ratio') -&gt; LazyFrame\n</code></pre> <p>Calculate the difference between recent and bottom prices, and recent and top prices, and express the ratio of the two.</p> <p>This function computes the percentage change from the recent price to the bottom price, and from the recent price to the top price. The results are combined into a single string column, and the ratio is provided in a separate column normalized between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input DataFrame containing price data.</p> required <code>recent_price_col</code> <code>str</code> <p>Name of the column containing recent prices. Default is \"recent_price\".</p> <code>'recent_price'</code> <code>bottom_price_col</code> <code>str</code> <p>Name of the column containing bottom prices. Default is \"bottom_price\".</p> <code>'bottom_price'</code> <code>top_price_col</code> <code>str</code> <p>Name of the column containing top prices. Default is \"top_price\".</p> <code>'top_price'</code> <code>pct_output_col</code> <code>str</code> <p>Name of the output column for price percentages. Default is \"price_percentages\".</p> <code>'ud_pct'</code> <code>ratio_output_col</code> <code>str</code> <p>Name of the output column for the up/down ratio. Default is \"ud_ratio\".</p> <code>'ud_ratio'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with additional columns containing the calculated price percentages and normalized ratio.</p> Notes <p>The output column will contain strings in the format \"-X.XX / +Y.YY\", where X.XX is the percentage decrease from recent to bottom price, and Y.YY is the percentage increase from recent to top price. The ratio column will contain a normalized value between 0 and 1, where values closer to 1 indicate a better upside/downside ratio.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/helpers.py</code> <pre><code>def calc_up_down_pct(\n    data: pl.LazyFrame,\n    recent_price_col: str = \"recent_price\",\n    bottom_price_col: str = \"bottom_price\",\n    top_price_col: str = \"top_price\",\n    pct_output_col: str = \"ud_pct\",\n    ratio_output_col: str = \"ud_ratio\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate the difference between recent and bottom prices, and recent and top prices, and express the ratio of the two.\n\n    This function computes the percentage change from the recent price to the bottom price,\n    and from the recent price to the top price. The results are combined into a single string\n    column, and the ratio is provided in a separate column normalized between 0 and 1.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        Input DataFrame containing price data.\n    recent_price_col : str, optional\n        Name of the column containing recent prices. Default is \"recent_price\".\n    bottom_price_col : str, optional\n        Name of the column containing bottom prices. Default is \"bottom_price\".\n    top_price_col : str, optional\n        Name of the column containing top prices. Default is \"top_price\".\n    pct_output_col : str, optional\n        Name of the output column for price percentages. Default is \"price_percentages\".\n    ratio_output_col : str, optional\n        Name of the output column for the up/down ratio. Default is \"ud_ratio\".\n\n    Returns\n    -------\n    pl.DataFrame\n        DataFrame with additional columns containing the calculated price percentages and normalized ratio.\n\n    Notes\n    -----\n    The output column will contain strings in the format \"-X.XX / +Y.YY\", where X.XX is the\n    percentage decrease from recent to bottom price, and Y.YY is the percentage increase from\n    recent to top price. The ratio column will contain a normalized value between 0 and 1,\n    where values closer to 1 indicate a better upside/downside ratio.\n    \"\"\"\n    return data.with_columns(\n        [\n            (\n                pl.concat_str(\n                    [\n                        pl.lit(\"-\"),\n                        (\n                            (\n                                pl.col(recent_price_col)\n                                - pl.col(bottom_price_col)\n                            )\n                            / pl.col(recent_price_col)\n                            * 100\n                        )\n                        .abs()\n                        .round(2)\n                        .cast(pl.Utf8),\n                        pl.lit(\" / +\"),\n                        (\n                            (pl.col(top_price_col) - pl.col(recent_price_col))\n                            / pl.col(recent_price_col)\n                            * 100\n                        )\n                        .round(2)\n                        .cast(pl.Utf8),\n                    ]\n                )\n            ).alias(pct_output_col),\n            (\n                (pl.col(top_price_col) - pl.col(recent_price_col)).abs()\n                / (\n                    (pl.col(top_price_col) - pl.col(recent_price_col)).abs()\n                    + (\n                        pl.col(recent_price_col) - pl.col(bottom_price_col)\n                    ).abs()\n                )\n            )\n            .round(2)\n            .alias(ratio_output_col),\n        ]\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.model","title":"humbldata.portfolio.analytics.user_table.model","text":"<p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>The user_table Command Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.model.user_table_engine","title":"humbldata.portfolio.analytics.user_table.model.user_table_engine  <code>async</code>","text":"<pre><code>user_table_engine(symbols: str | list[str] | Series, etf_data: LazyFrame | None = None, toolbox: Toolbox | None = None, mandelbrot_data: LazyFrame | None = None, membership: Literal['anonymous', 'humblPEON', 'humblPREMIUM', 'humblPOWER', 'admin'] = 'anonymous')\n</code></pre> <p>Aggregate user table data from various sources.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str or list of str or pl.Series</code> <p>The stock symbols to aggregate data for.</p> required <code>etf_data</code> <code>LazyFrame or None</code> <p>Pre-fetched ETF data. If None, it will be fetched, by default None.</p> <code>None</code> <code>toolbox</code> <code>Toolbox or None</code> <p>Pre-generated toolbox. If None, it will be generated, by default None.</p> <code>None</code> <code>mandelbrot_data</code> <code>LazyFrame or None</code> <p>Pre-calculated Mandelbrot channel data. If None, it will be calculated, by default None.</p> <code>None</code> <code>membership</code> <code>Literal['anonymous', 'humblPEON', 'humblPREMIUM', 'humblPOWER', 'admin']</code> <p>The user's role. If None, it will be calculated, by default None.</p> <code>'anonymous'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame containing the aggregated user table data with columns: date, symbol, bottom_price, recent_price, top_price, ud_pct, ud_ratio, sector, and asset_class.</p> Notes <p>This function performs the following steps: 1. Fetches ETF data if not provided 2. Generates a toolbox if not provided 3. Calculates Mandelbrot channel if not provided 4. Concurrently fetches latest price, sector, and asset class data 5. Combines all data into a single LazyFrame 6. Calculates up/down percentages and ratios 7. Selects and returns relevant columns</p> <p>The function uses asynchronous operations for improved performance when fetching data from multiple sources.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/model.py</code> <pre><code>async def user_table_engine(\n    symbols: str | list[str] | pl.Series,\n    etf_data: pl.LazyFrame | None = None,\n    toolbox: Toolbox | None = None,\n    mandelbrot_data: pl.LazyFrame | None = None,\n    membership: Literal[\n        \"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"admin\"\n    ] = \"anonymous\",\n):\n    \"\"\"\n    Aggregate user table data from various sources.\n\n    Parameters\n    ----------\n    symbols : str or list of str or pl.Series\n        The stock symbols to aggregate data for.\n    etf_data : pl.LazyFrame or None, optional\n        Pre-fetched ETF data. If None, it will be fetched, by default None.\n    toolbox : Toolbox or None, optional\n        Pre-generated toolbox. If None, it will be generated, by default None.\n    mandelbrot_data : pl.LazyFrame or None, optional\n        Pre-calculated Mandelbrot channel data. If None, it will be calculated, by default None.\n    membership : Literal[\"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"admin\"], optional\n        The user's role. If None, it will be calculated, by default None.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame containing the aggregated user table data with columns:\n        date, symbol, bottom_price, recent_price, top_price, ud_pct, ud_ratio,\n        sector, and asset_class.\n\n    Notes\n    -----\n    This function performs the following steps:\n    1. Fetches ETF data if not provided\n    2. Generates a toolbox if not provided\n    3. Calculates Mandelbrot channel if not provided\n    4. Concurrently fetches latest price, sector, and asset class data\n    5. Combines all data into a single LazyFrame\n    6. Calculates up/down percentages and ratios\n    7. Selects and returns relevant columns\n\n    The function uses asynchronous operations for improved performance when\n    fetching data from multiple sources.\n    \"\"\"\n    # Fetch ETF data if not provided\n    if etf_data is None:\n        etf_data = await aget_etf_category(symbols=symbols)\n\n    # Calculate Mandelbrot channel if not provided\n    if mandelbrot_data is None:\n        # Generate toolbox params based on membership if not provided\n        if toolbox is None:\n            toolbox = Toolbox(symbols=symbols, membership=membership)\n        mandelbrot_data = toolbox.technical.mandelbrot_channel().to_polars(\n            collect=False\n        )\n    # Fetch data from all sources concurrently, passing etf_data where needed\n    tasks = [\n        aget_latest_price(symbols=symbols),\n        aget_sector_filter(symbols=symbols, etf_data=etf_data),\n        aget_asset_class_filter(symbols=symbols, etf_data=etf_data),\n    ]\n    lazyframes = await asyncio.gather(*tasks)\n\n    # Combine all DataFrames into a single LazyFrame\n    out = (\n        (\n            pl.concat(lazyframes, how=\"align\")\n            .lazy()\n            .join(mandelbrot_data, on=\"symbol\", how=\"left\")\n            .pipe(calc_up_down_pct)\n        )\n        .select(\n            [\n                \"date\",\n                \"symbol\",\n                \"bottom_price\",\n                \"recent_price\",\n                \"top_price\",\n                \"ud_pct\",\n                \"ud_ratio\",\n                \"sector\",\n                \"asset_class\",\n            ]\n        )\n        .rename({\"recent_price\": \"last_price\"})\n        .rename({\"bottom_price\": \"buy_price\"})\n        .rename({\"top_price\": \"sell_price\"})\n    )\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.view","title":"humbldata.portfolio.analytics.user_table.view","text":"<p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>The UserTable View Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.view.create_example_plot","title":"humbldata.portfolio.analytics.user_table.view.create_example_plot","text":"<pre><code>create_example_plot(data: DataFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate an example plot from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing the data to be plotted.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the example plot.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/view.py</code> <pre><code>def create_example_plot(\n    data: pl.DataFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate an example plot from the provided data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing the data to be plotted.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the example plot.\n    \"\"\"\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=data.select(\"x_column\").to_series(),\n            y=data.select(\"y_column\").to_series(),\n            name=\"Example Data\",\n            line=dict(color=\"blue\"),\n        )\n    )\n    fig.update_layout(\n        title=\"Example Plot\",\n        xaxis_title=\"X Axis\",\n        yaxis_title=\"Y Axis\",\n        template=template,\n    )\n    return fig\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.portfolio.analytics.user_table.view.generate_plots","title":"humbldata.portfolio.analytics.user_table.view.generate_plots","text":"<pre><code>generate_plots(data: LazyFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; List[Chart]\n</code></pre> <p>Context: Portfolio || Category: Analytics || Command: user_table || Function: generate_plots().</p> <p>Generate plots from the given dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The LazyFrame containing the data to be plotted.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>List[Chart]</code> <p>A list of Chart objects, each representing a plot.</p> Source code in <code>src/humbldata/portfolio/analytics/user_table/view.py</code> <pre><code>def generate_plots(\n    data: pl.LazyFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; List[Chart]:\n    \"\"\"\n    Context: Portfolio || Category: Analytics || Command: user_table || **Function: generate_plots()**.\n\n    Generate plots from the given dataframe.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The LazyFrame containing the data to be plotted.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure.\n\n    Returns\n    -------\n    List[Chart]\n        A list of Chart objects, each representing a plot.\n    \"\"\"\n    collected_data = data.collect()\n    plot = create_example_plot(collected_data, template)\n    return [Chart(content=plot.to_plotly_json(), fig=plot)]\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox","title":"humbldata.toolbox","text":"<p>Context: Toolbox.</p> <p>A category to group all of the technical indicators available in the <code>Toolbox()</code></p> <p>Technical indicators rely on statistical transformations of time series data. These are raw math operations.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers","title":"humbldata.toolbox.toolbox_helpers","text":"<p>Context: Toolbox || Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.log_returns","title":"humbldata.toolbox.toolbox_helpers.log_returns","text":"<pre><code>log_returns(data: Series | DataFrame | LazyFrame | None = None, _column_name: str = 'adj_close', *, _drop_nulls: bool = True, _sort: bool = True) -&gt; Series | DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: log_returns.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY. Calculates the logarithmic returns for a given Polars Series, DataFrame, or LazyFrame. Logarithmic returns are widely used in the financial industry to measure the rate of return on investments over time. This function supports calculations on both individual series and dataframes containing financial time series data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series | DataFrame | LazyFrame</code> <p>The input data for which to calculate the log returns. Default is None.</p> <code>None</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. Default is True.</p> <code>True</code> <code>_column_name</code> <code>str</code> <p>The column name to use for log return calculations in DataFrame or LazyFrame. Default is \"adj_close\".</p> <code>'adj_close'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by <code>date</code> and <code>symbol</code> before calculation. If you want a DUMB function, set to False. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Series | DataFrame | LazyFrame</code> <p>The original <code>data</code>, with an extra column of <code>log returns</code> of the input data. The return type matches the input type.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If neither a series, DataFrame, nor LazyFrame is provided as input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; series = pl.Series([100, 105, 103])\n&gt;&gt;&gt; log_returns(data=series)\nseries([-inf, 0.048790, -0.019418])\n</code></pre> <pre><code>&gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n&gt;&gt;&gt; log_returns(data=df)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 adj_close \u2506 log_returns\u2502\n\u2502 ---       \u2506 ---        \u2502\n\u2502 f64       \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 100.0     \u2506 NaN        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 105.0     \u2506 0.048790   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 103.0     \u2506 -0.019418  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Improvements <p>Add a parameter <code>_sort_cols: list[str] | None = None</code> to make the function even dumber. This way you could specify certain columns to sort by instead of using default <code>date</code> and <code>symbol</code>. If <code>_sort_cols=None</code> and <code>_sort=True</code>, then the function will use the default <code>date</code> and <code>symbol</code> columns for sorting.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def log_returns(\n    data: pl.Series | pl.DataFrame | pl.LazyFrame | None = None,\n    _column_name: str = \"adj_close\",\n    *,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.Series | pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: log_returns**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n    Calculates the logarithmic returns for a given Polars Series, DataFrame, or\n    LazyFrame. Logarithmic returns are widely used in the financial\n    industry to measure the rate of return on investments over time. This\n    function supports calculations on both individual series and dataframes\n    containing financial time series data.\n\n    Parameters\n    ----------\n    data : pl.Series | pl.DataFrame | pl.LazyFrame, optional\n        The input data for which to calculate the log returns. Default is None.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result. Default is True.\n    _column_name : str, optional\n        The column name to use for log return calculations in DataFrame or\n        LazyFrame. Default is \"adj_close\".\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by `date` and `symbol` before\n        calculation. If you want a DUMB function, set to False.\n        Default is True.\n\n    Returns\n    -------\n    pl.Series | pl.DataFrame | pl.LazyFrame\n        The original `data`, with an extra column of `log returns` of the input\n        data. The return type matches the input type.\n\n    Raises\n    ------\n    HumblDataError\n        If neither a series, DataFrame, nor LazyFrame is provided as input.\n\n    Examples\n    --------\n    &gt;&gt;&gt; series = pl.Series([100, 105, 103])\n    &gt;&gt;&gt; log_returns(data=series)\n    series([-inf, 0.048790, -0.019418])\n\n    &gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n    &gt;&gt;&gt; log_returns(data=df)\n    shape: (3, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 adj_close \u2506 log_returns\u2502\n    \u2502 ---       \u2506 ---        \u2502\n    \u2502 f64       \u2506 f64        \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 100.0     \u2506 NaN        \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 105.0     \u2506 0.048790   \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 103.0     \u2506 -0.019418  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    Improvements\n    -----------\n    Add a parameter `_sort_cols: list[str] | None = None` to make the function even\n    dumber. This way you could specify certain columns to sort by instead of\n    using default `date` and `symbol`. If `_sort_cols=None` and `_sort=True`,\n    then the function will use the default `date` and `symbol` columns for\n    sorting.\n\n    \"\"\"\n    # Calculation for Polars Series\n    if isinstance(data, pl.Series):\n        out = data.log().diff()\n        if _drop_nulls:\n            out = out.drop_nulls()\n    # Calculation for Polars DataFrame or LazyFrame\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n        if \"log_returns\" not in data.collect_schema().names():\n            out = data.with_columns(\n                pl.col(_column_name).log().diff().alias(\"log_returns\")\n            )\n        else:\n            out = data\n        if _drop_nulls:\n            out = out.drop_nulls(subset=\"log_returns\")\n    else:\n        msg = \"No valid data type was provided for `log_returns()` calculation.\"\n        raise HumblDataError(msg)\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.detrend","title":"humbldata.toolbox.toolbox_helpers.detrend","text":"<pre><code>detrend(data: DataFrame | LazyFrame | Series, _detrend_col: str = 'log_returns', _detrend_value_col: str | Series | None = 'window_mean', *, _sort: bool = False) -&gt; DataFrame | LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: detrend.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>Detrends a column in a DataFrame, LazyFrame, or Series by subtracting the values of another column from it. Optionally sorts the data by 'symbol' and 'date' before detrending if _sort is True.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, LazyFrame, Series]</code> <p>The data structure containing the columns to be processed.</p> required <code>_detrend_col</code> <code>str</code> <p>The name of the column from which values will be subtracted.</p> <code>'log_returns'</code> <code>_detrend_value_col</code> <code>str | Series | None</code> <p>The name of the column whose values will be subtracted OR if you pass a pl.Series to the <code>data</code> parameter, then you can use this to pass a second <code>pl.Series</code> to subtract from the first.</p> <code>'window_mean'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the data by 'symbol' and 'date' before detrending. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, LazyFrame, Series]</code> <p>The detrended data structure with the same type as the input, with an added column named <code>f\"detrended_{_detrend_col}\"</code>.</p> Notes <p>Function doesn't use <code>.over()</code> in calculation. Once the data is sorted, subtracting _detrend_value_col from _detrend_col is a simple operation that doesn't need to be grouped, because the sorting has already aligned the rows for subtraction</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def detrend(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _detrend_col: str = \"log_returns\",\n    _detrend_value_col: str | pl.Series | None = \"window_mean\",\n    *,\n    _sort: bool = False,\n) -&gt; pl.DataFrame | pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: detrend**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    Detrends a column in a DataFrame, LazyFrame, or Series by subtracting the\n    values of another column from it. Optionally sorts the data by 'symbol' and\n    'date' before detrending if _sort is True.\n\n    Parameters\n    ----------\n    data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The data structure containing the columns to be processed.\n    _detrend_col : str\n        The name of the column from which values will be subtracted.\n    _detrend_value_col : str | pl.Series | None, optional\n        The name of the column whose values will be subtracted OR if you\n        pass a pl.Series to the `data` parameter, then you can use this to\n        pass a second `pl.Series` to subtract from the first.\n    _sort : bool, optional\n        If True, sorts the data by 'symbol' and 'date' before detrending.\n        Default is False.\n\n    Returns\n    -------\n    Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The detrended data structure with the same type as the input,\n        with an added column named `f\"detrended_{_detrend_col}\"`.\n\n    Notes\n    -----\n    Function doesn't use `.over()` in calculation. Once the data is sorted,\n    subtracting _detrend_value_col from _detrend_col is a simple operation\n    that doesn't need to be grouped, because the sorting has already aligned\n    the rows for subtraction\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        col_names = data.collect_schema().names()\n        if _detrend_value_col not in col_names or _detrend_col not in col_names:\n            msg = f\"Both {_detrend_value_col} and {_detrend_col} must be columns in the data.\"\n            raise HumblDataError(msg)\n        detrended = data.with_columns(\n            (pl.col(_detrend_col) - pl.col(_detrend_value_col)).alias(\n                f\"detrended_{_detrend_col}\"\n            )\n        )\n    elif isinstance(data, pl.Series):\n        if not isinstance(_detrend_value_col, pl.Series):\n            msg = \"When 'data' is a Series, '_detrend_value_col' must also be a Series.\"\n            raise HumblDataError(msg)\n        detrended = data - _detrend_value_col\n        detrended.rename(f\"detrended_{_detrend_col}\")\n\n    return detrended\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.cum_sum","title":"humbldata.toolbox.toolbox_helpers.cum_sum","text":"<pre><code>cum_sum(data: DataFrame | LazyFrame | Series | None = None, _column_name: str = 'detrended_returns', *, _sort: bool = True, _mandelbrot_usage: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: cum_sum.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>Calculate the cumulative sum of a series or column in a DataFrame or LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame | Series | None</code> <p>The data to process.</p> <code>None</code> <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the cumulative sum on, applicable if df is provided.</p> <code>'detrended_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date and symbol before calculation. Default is True.</p> <code>True</code> <code>_mandelbrot_usage</code> <code>bool</code> <p>If True, performs additional checks specific to the Mandelbrot Channel calculation. This should be set to True when you have a cumulative deviate series, and False when not. Please check 'Notes' for more information. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The DataFrame or Series with the cumulative deviate series added as a new column or as itself.</p> Notes <p>This function is used to calculate the cumulative sum for the deviate series of detrended returns for the data in the pipeline for <code>calc_mandelbrot_channel</code>.</p> <p>So, although it is calculating a cumulative sum, it is known as a cumulative deviate because it is a cumulative sum on a deviate series, meaning that the cumulative sum should = 0 for each window. The _mandelbrot_usage parameter allows for checks to ensure the data is suitable for Mandelbrot Channel calculations, i.e that the deviate series was calculated correctly by the end of each series being 0, meaning the trend (the mean over the window_index) was successfully removed from the data.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def cum_sum(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series | None = None,\n    _column_name: str = \"detrended_returns\",\n    *,\n    _sort: bool = True,\n    _mandelbrot_usage: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: cum_sum**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    Calculate the cumulative sum of a series or column in a DataFrame or\n    LazyFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame | pl.Series | None\n        The data to process.\n    _column_name : str\n        The name of the column to calculate the cumulative sum on,\n        applicable if df is provided.\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by date and symbol before\n        calculation. Default is True.\n    _mandelbrot_usage : bool, optional\n        If True, performs additional checks specific to the Mandelbrot Channel\n        calculation. This should be set to True when you have a cumulative\n        deviate series, and False when not. Please check 'Notes' for more\n        information. Default is True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The DataFrame or Series with the cumulative deviate series added as a\n        new column or as itself.\n\n    Notes\n    -----\n    This function is used to calculate the cumulative sum for the deviate series\n    of detrended returns for the data in the pipeline for\n    `calc_mandelbrot_channel`.\n\n    So, although it is calculating a cumulative sum, it is known as a cumulative\n    deviate because it is a cumulative sum on a deviate series, meaning that the\n    cumulative sum should = 0 for each window. The _mandelbrot_usage parameter\n    allows for checks to ensure the data is suitable for Mandelbrot Channel\n    calculations, i.e that the deviate series was calculated correctly by the\n    end of each series being 0, meaning the trend (the mean over the\n    window_index) was successfully removed from the data.\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if over_cols:\n            out = data.with_columns(\n                pl.col(_column_name).cum_sum().over(over_cols).alias(\"cum_sum\")\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).cum_sum().alias(\"cum_sum\")\n            )\n    elif isinstance(data, pl.Series):\n        out = data.cum_sum().alias(\"cum_sum\")\n    else:\n        msg = \"No DataFrame/LazyFrame/Series was provided.\"\n        raise HumblDataError(msg)\n\n    if _mandelbrot_usage:\n        _cumsum_check(out, _column_name=\"cum_sum\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.std","title":"humbldata.toolbox.toolbox_helpers.std","text":"<pre><code>std(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum', *, _sort: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: std.</p> <p>Calculate the standard deviation of the cumulative deviate series within each window of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>LazyFrame</code> <p>The LazyFrame from which to calculate the standard deviation.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column from which to calculate the standard deviation, with \"cumdev\" as the default value.</p> <code>'cum_sum'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date and symbol before calculation. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame with the standard deviation of the specified column for each window, added as a new column named \"S\".</p> Improvements <p>Just need to parametrize <code>.over()</code> call in the function if want an even dumber function, that doesn't calculate each <code>window_index</code>.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def std(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series,\n    _column_name: str = \"cum_sum\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: std**.\n\n    Calculate the standard deviation of the cumulative deviate series within\n    each window of the dataset.\n\n    Parameters\n    ----------\n    df : pl.LazyFrame\n        The LazyFrame from which to calculate the standard deviation.\n    _column_name : str, optional\n        The name of the column from which to calculate the standard deviation,\n        with \"cumdev\" as the default value.\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by date and symbol before\n        calculation. Default is True.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame with the standard deviation of the specified column for each\n        window, added as a new column named \"S\".\n\n    Improvements\n    -----------\n    Just need to parametrize `.over()` call in the function if want an even\n    dumber function, that doesn't calculate each `window_index`.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.std()\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n\n        if over_cols:\n            out = data.with_columns(\n                [\n                    pl.col(_column_name)\n                    .std()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_std\"),  # used to be 'S'\n                ]\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).std().alias(\"S\"),\n            )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.mean","title":"humbldata.toolbox.toolbox_helpers.mean","text":"<pre><code>mean(data: DataFrame | LazyFrame | Series, _column_name: str = 'log_returns', *, _sort: bool = True) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Function: mean.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>This function calculates the mean of a column (&lt;_column_name&gt;) over a each window in the dataset, if there are any. This window is intended to be the <code>window</code> that is passed in the <code>calc_mandelbrot_channel()</code> function. The mean calculated is meant to be used as the mean of each <code>window</code> within the time series. This way, each block of windows has their own mean, which can then be used to normalize the data (i.e remove the mean) from each window section.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The DataFrame or LazyFrame to calculate the mean on.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the mean on.</p> <code>'log_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date before calculation. Default is False.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The original DataFrame or LazyFrame with a <code>window_mean</code> &amp; <code>date</code> column, which contains the mean of 'log_returns' per range/window.</p> Notes <p>Since this function is an aggregation function, it reduces the # of observations in the dataset,thus, unless I take each value and iterate each window_mean value to correlate to the row in the original dataframe, the function will return a dataframe WITHOUT the original data.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def mean(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _column_name: str = \"log_returns\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Function: mean**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    This function calculates the mean of a column (&lt;_column_name&gt;) over a\n    each window in the dataset, if there are any.\n    This window is intended to be the `window` that is passed in the\n    `calc_mandelbrot_channel()` function. The mean calculated is meant to be\n    used as the mean of each `window` within the time series. This\n    way, each block of windows has their own mean, which can then be used to\n    normalize the data (i.e remove the mean) from each window section.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The DataFrame or LazyFrame to calculate the mean on.\n    _column_name : str\n        The name of the column to calculate the mean on.\n    _sort : bool\n        If True, sorts the DataFrame or LazyFrame by date before calculation.\n        Default is False.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The original DataFrame or LazyFrame with a `window_mean` &amp; `date` column,\n        which contains the mean of 'log_returns' per range/window.\n\n\n    Notes\n    -----\n    Since this function is an aggregation function, it reduces the # of\n    observations in the dataset,thus, unless I take each value and iterate each\n    window_mean value to correlate to the row in the original dataframe, the\n    function will return a dataframe WITHOUT the original data.\n\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.mean()\n    else:\n        if data is None:\n            msg = \"No DataFrame was passed to the `mean()` function.\"\n            raise HumblDataError(msg)\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:  # Check if _sort is True\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        if over_cols:\n            out = data.with_columns(\n                pl.col(_column_name).mean().over(over_cols).alias(\"window_mean\")\n            )\n        else:\n            out = data.with_columns(pl.col(_column_name).mean().alias(\"mean\"))\n        if _sort and sort_cols:\n            out = out.sort(sort_cols)\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.range_","title":"humbldata.toolbox.toolbox_helpers.range_","text":"<pre><code>range_(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum', *, _sort: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || Function: mandelbrot_range.</p> <p>Calculate the range (max - min) of the cumulative deviate values of a specified column in a DataFrame for each window in the dataset, if there are any.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The DataFrame to calculate the range from.</p> required <code>_column_name</code> <code>str</code> <p>The column to calculate the range from, by default \"cumdev\".</p> <code>'cum_sum'</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>A DataFrame with the range of the specified column for each window.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def range_(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series,\n    _column_name: str = \"cum_sum\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || **Function: mandelbrot_range**.\n\n    Calculate the range (max - min) of the cumulative deviate values of a\n    specified column in a DataFrame for each window in the dataset, if there are any.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The DataFrame to calculate the range from.\n    _column_name : str, optional\n        The column to calculate the range from, by default \"cumdev\".\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        A DataFrame with the range of the specified column for each window.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.max() - data.min()\n\n    if isinstance(data, pl.LazyFrame | pl.DataFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        if over_cols:\n            out = (\n                data.with_columns(\n                    [\n                        pl.col(_column_name)\n                        .min()\n                        .over(over_cols)\n                        .alias(f\"{_column_name}_min\"),\n                        pl.col(_column_name)\n                        .max()\n                        .over(over_cols)\n                        .alias(f\"{_column_name}_max\"),\n                    ]\n                )\n                .sort(sort_cols)\n                .with_columns(\n                    (\n                        pl.col(f\"{_column_name}_max\")\n                        - pl.col(f\"{_column_name}_min\")\n                    ).alias(f\"{_column_name}_range\"),  # used to be 'R'\n                )\n            )\n    else:\n        out = (\n            data.with_columns(\n                [\n                    pl.col(_column_name).min().alias(f\"{_column_name}_min\"),\n                    pl.col(_column_name).max().alias(f\"{_column_name}_max\"),\n                ]\n            )\n            .sort(sort_cols)\n            .with_columns(\n                (\n                    pl.col(f\"{_column_name}_max\")\n                    - pl.col(f\"{_column_name}_min\")\n                ).alias(f\"{_column_name}_range\"),\n            )\n        )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller","title":"humbldata.toolbox.toolbox_controller","text":"<p>Context: Toolbox.</p> <p>The Toolbox Controller Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox","title":"humbldata.toolbox.toolbox_controller.Toolbox","text":"<p>             Bases: <code>ToolboxQueryParams</code></p> <p>A top-level  controller for data analysis tools in <code>humblDATA</code>. <p>This module serves as the primary controller, routing user-specified ToolboxQueryParams as core arguments that are used to fetch time series data.</p> <p>The <code>Toolbox</code> controller also gives access to all sub-modules adn their functions.</p> <p>It is designed to facilitate the collection of data across various types such as stocks, options, or alternative time series by requiring minimal input from the user.</p> Submodules <p>The <code>Toolbox</code> controller is composed of the following submodules:</p> <ul> <li><code>technical</code>:</li> <li><code>quantitative</code>:</li> <li><code>fundamental</code>:</li> </ul> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol or ticker of the stock.</p> required <code>interval</code> <code>str</code> <p>The interval of the data. Defaults to '1d'.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> required <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> required <code>provider</code> <code>str</code> <p>The provider to use for the data query. Defaults to 'yfinance'.</p> required Parameter Notes <p>The parameters (<code>symbol</code>, <code>interval</code>, <code>start_date</code>, <code>end_date</code>) are the <code>ToolboxQueryParams</code>. They are used for data collection further down the pipeline in other commands. Intended to execute operations on core data sets. This approach enables composable and standardized querying while accommodating data-specific collection logic.</p> Source code in <code>src/humbldata/toolbox/toolbox_controller.py</code> <pre><code>class Toolbox(ToolboxQueryParams):\n    \"\"\"\n\n    A top-level &lt;context&gt; controller for data analysis tools in `humblDATA`.\n\n    This module serves as the primary controller, routing user-specified\n    ToolboxQueryParams as core arguments that are used to fetch time series\n    data.\n\n    The `Toolbox` controller also gives access to all sub-modules adn their\n    functions.\n\n    It is designed to facilitate the collection of data across various types such as\n    stocks, options, or alternative time series by requiring minimal input from the user.\n\n    Submodules\n    ----------\n    The `Toolbox` controller is composed of the following submodules:\n\n    - `technical`:\n    - `quantitative`:\n    - `fundamental`:\n\n    Parameters\n    ----------\n    symbol : str\n        The symbol or ticker of the stock.\n    interval : str, optional\n        The interval of the data. Defaults to '1d'.\n    start_date : str\n        The start date for the data query.\n    end_date : str\n        The end date for the data query.\n    provider : str, optional\n        The provider to use for the data query. Defaults to 'yfinance'.\n\n    Parameter Notes\n    -----\n    The parameters (`symbol`, `interval`, `start_date`, `end_date`)\n    are the `ToolboxQueryParams`. They are used for data collection further\n    down the pipeline in other commands. Intended to execute operations on core\n    data sets. This approach enables composable and standardized querying while\n    accommodating data-specific collection logic.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initialize the Toolbox module.\n\n        This method does not take any parameters and does not return anything.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @property\n    def technical(self):\n        \"\"\"\n        The technical submodule of the Toolbox controller.\n\n        Access to all the technical indicators. WHen the Toolbox class is\n        instatiated the parameters are initialized with the ToolboxQueryParams\n        class, which hold all the fields needed for the context_params, like the\n        symbol, interval, start_date, and end_date.\n        \"\"\"\n        return Technical(context_params=self)\n\n    @property\n    def fundamental(self):\n        \"\"\"\n        The fundamental submodule of the Toolbox controller.\n\n        Access to all the Fundamental indicators. When the Toolbox class is\n        instantiated the parameters are initialized with the ToolboxQueryParams\n        class, which hold all the fields needed for the context_params, like the\n        symbol, interval, start_date, and end_date.\n        \"\"\"\n        return Fundamental(context_params=self)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox.__init__","title":"humbldata.toolbox.toolbox_controller.Toolbox.__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Initialize the Toolbox module.</p> <p>This method does not take any parameters and does not return anything.</p> Source code in <code>src/humbldata/toolbox/toolbox_controller.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initialize the Toolbox module.\n\n    This method does not take any parameters and does not return anything.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox.technical","title":"humbldata.toolbox.toolbox_controller.Toolbox.technical  <code>property</code>","text":"<pre><code>technical\n</code></pre> <p>The technical submodule of the Toolbox controller.</p> <p>Access to all the technical indicators. WHen the Toolbox class is instatiated the parameters are initialized with the ToolboxQueryParams class, which hold all the fields needed for the context_params, like the symbol, interval, start_date, and end_date.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox.fundamental","title":"humbldata.toolbox.toolbox_controller.Toolbox.fundamental  <code>property</code>","text":"<pre><code>fundamental\n</code></pre> <p>The fundamental submodule of the Toolbox controller.</p> <p>Access to all the Fundamental indicators. When the Toolbox class is instantiated the parameters are initialized with the ToolboxQueryParams class, which hold all the fields needed for the context_params, like the symbol, interval, start_date, and end_date.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental","title":"humbldata.toolbox.fundamental","text":"<p>Context: Toolbox || Category: Fundamental.</p> <p>A category to group all of the fundamental indicators available in the <code>Toolbox()</code>.</p> <p>Fundamental indicators relies on earnings data, valuation models of companies, balance sheet metrics etc...</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.fundamental_controller","title":"humbldata.toolbox.fundamental.fundamental_controller","text":"<p>Context: Toolbox || Category: Fundamental.</p> <p>A controller to manage and compile all of the Fundamental models available in the <code>toolbox</code> context. This will be passed as a <code>@property</code> to the <code>toolbox()</code> class, giving access to the Fundamental module and its functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.fundamental_controller.Fundamental","title":"humbldata.toolbox.fundamental.fundamental_controller.Fundamental","text":"<p>Module for all Fundamental analysis.</p> <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>The standard query parameters for toolbox data.</p> <p>Methods:</p> Name Description <code>humbl_compass</code> <p>Execute the HumblCompass command.</p> Source code in <code>src/humbldata/toolbox/fundamental/fundamental_controller.py</code> <pre><code>class Fundamental:\n    \"\"\"\n    Module for all Fundamental analysis.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        The standard query parameters for toolbox data.\n\n    Methods\n    -------\n    humbl_compass(command_params: HumblCompassQueryParams)\n        Execute the HumblCompass command.\n\n    \"\"\"\n\n    def __init__(self, context_params: ToolboxQueryParams):\n        self.context_params = context_params\n\n    def humbl_compass(self, **kwargs):\n        \"\"\"\n        Execute the HumblCompass command.\n\n        Parameters\n        ----------\n        country : str\n            The country or group of countries to analyze\n        recommendations : bool, optional\n            Whether to include investment recommendations based on the HUMBL regime\n        chart : bool, optional\n            Whether to return a chart object\n        template : str, optional\n            The template/theme to use for the plotly figure\n        z_score : str, optional\n            The time window for z-score calculation\n\n        Returns\n        -------\n        HumblObject\n            The HumblObject containing the transformed data and metadata\n        \"\"\"\n        from humbldata.core.standard_models.toolbox.fundamental.humbl_compass import (\n            HumblCompassFetcher,\n            HumblCompassQueryParams,\n        )\n\n        # Convert kwargs to HumblCompassQueryParams\n        command_params = HumblCompassQueryParams(**kwargs)\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = HumblCompassFetcher(\n            context_params=self.context_params, command_params=command_params\n        )\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.fundamental_controller.Fundamental.humbl_compass","title":"humbldata.toolbox.fundamental.fundamental_controller.Fundamental.humbl_compass","text":"<pre><code>humbl_compass(**kwargs)\n</code></pre> <p>Execute the HumblCompass command.</p> <p>Parameters:</p> Name Type Description Default <code>country</code> <code>str</code> <p>The country or group of countries to analyze</p> required <code>recommendations</code> <code>bool</code> <p>Whether to include investment recommendations based on the HUMBL regime</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object</p> required <code>template</code> <code>str</code> <p>The template/theme to use for the plotly figure</p> required <code>z_score</code> <code>str</code> <p>The time window for z-score calculation</p> required <p>Returns:</p> Type Description <code>HumblObject</code> <p>The HumblObject containing the transformed data and metadata</p> Source code in <code>src/humbldata/toolbox/fundamental/fundamental_controller.py</code> <pre><code>def humbl_compass(self, **kwargs):\n    \"\"\"\n    Execute the HumblCompass command.\n\n    Parameters\n    ----------\n    country : str\n        The country or group of countries to analyze\n    recommendations : bool, optional\n        Whether to include investment recommendations based on the HUMBL regime\n    chart : bool, optional\n        Whether to return a chart object\n    template : str, optional\n        The template/theme to use for the plotly figure\n    z_score : str, optional\n        The time window for z-score calculation\n\n    Returns\n    -------\n    HumblObject\n        The HumblObject containing the transformed data and metadata\n    \"\"\"\n    from humbldata.core.standard_models.toolbox.fundamental.humbl_compass import (\n        HumblCompassFetcher,\n        HumblCompassQueryParams,\n    )\n\n    # Convert kwargs to HumblCompassQueryParams\n    command_params = HumblCompassQueryParams(**kwargs)\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = HumblCompassFetcher(\n        context_params=self.context_params, command_params=command_params\n    )\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass","title":"humbldata.toolbox.fundamental.humbl_compass","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass.helpers","title":"humbldata.toolbox.fundamental.humbl_compass.helpers","text":"<p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>The HumblCompass Helpers Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass.model","title":"humbldata.toolbox.fundamental.humbl_compass.model","text":"<p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>The humbl_compass Command Module. This is typically used in the <code>.transform_data()</code> method of the <code>HumblCompassFetcher</code> class.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass.model.humbl_compass","title":"humbldata.toolbox.fundamental.humbl_compass.model.humbl_compass","text":"<pre><code>humbl_compass()\n</code></pre> <p>Context: Toolbox || Category: Fundamental ||| Command: humbl_compass.</p> <p>Execute the humbl_compass command.</p> <p>Parameters:</p> Name Type Description Default <code>Returns</code> required Source code in <code>src/humbldata/toolbox/fundamental/humbl_compass/model.py</code> <pre><code>def humbl_compass():\n    \"\"\"\n    Context: Toolbox || Category: Fundamental ||| **Command: humbl_compass**.\n\n    Execute the humbl_compass command.\n\n    Parameters\n    ----------\n\n    Returns\n    -------\n    \"\"\"\n    pass\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass.view","title":"humbldata.toolbox.fundamental.humbl_compass.view","text":"<p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>The HumblCompass View Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass.view.create_humbl_compass_plot","title":"humbldata.toolbox.fundamental.humbl_compass.view.create_humbl_compass_plot","text":"<pre><code>create_humbl_compass_plot(data: DataFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate a HumblCompass plot from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing the data to be plotted.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the HumblCompass plot.</p> Source code in <code>src/humbldata/toolbox/fundamental/humbl_compass/view.py</code> <pre><code>def create_humbl_compass_plot(\n    data: pl.DataFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate a HumblCompass plot from the provided data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing the data to be plotted.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the HumblCompass plot.\n    \"\"\"\n    # Sort data by date and create a color scale\n    data = data.sort(\"date_month_start\")\n    full_color_scale = sequential.Reds\n    custom_colorscale = sample_colorscale(full_color_scale, [0.2, 0.8])\n\n    fig = go.Figure()\n\n    # Calculate the range for x and y axes based on data\n    x_min, x_max = data[\"cpi_3m_delta\"].min(), data[\"cpi_3m_delta\"].max()\n    y_min, y_max = data[\"cli_3m_delta\"].min(), data[\"cli_3m_delta\"].max()\n\n    # Ensure minimum range of -0.3 to 0.3 on both axes\n    x_min = min(x_min if x_min is not None else 0, -0.3)\n    x_max = max(x_max if x_max is not None else 0, 0.3)\n    y_min = min(y_min if y_min is not None else 0, -0.3)\n    y_max = max(y_max if y_max is not None else 0, 0.3)\n\n    # Add some padding to the ranges (e.g., 10% on each side)\n    x_padding = max((x_max - x_min) * 0.1, 0.05)  # Ensure minimum padding\n    y_padding = max((y_max - y_min) * 0.1, 0.05)  # Ensure minimum padding\n\n    # Calculate tick values (e.g., every 0.1)\n    x_ticks = [\n        round(i * 0.1, 1)\n        for i in range(int(x_min * 10) - 1, int(x_max * 10) + 2)\n    ]\n    y_ticks = [\n        round(i * 0.1, 1)\n        for i in range(int(y_min * 10) - 1, int(y_max * 10) + 2)\n    ]\n\n    # Add colored quadrants from -10 to 10\n    quadrants = [\n        {\n            \"x\": [0, 10],\n            \"y\": [0, 10],\n            \"fillcolor\": \"rgba(173, 216, 230, 0.3)\",\n        },  # Light blue\n        {\n            \"x\": [-10, 0],\n            \"y\": [0, 10],\n            \"fillcolor\": \"rgba(144, 238, 144, 0.3)\",\n        },  # Green\n        {\n            \"x\": [0, 10],\n            \"y\": [-10, 0],\n            \"fillcolor\": \"rgba(255, 165, 0, 0.3)\",\n        },  # Orange\n        {\n            \"x\": [-10, 0],\n            \"y\": [-10, 0],\n            \"fillcolor\": \"rgba(255, 99, 71, 0.3)\",\n        },  # Red\n    ]\n\n    for quadrant in quadrants:\n        fig.add_shape(\n            type=\"rect\",\n            x0=quadrant[\"x\"][0],\n            y0=quadrant[\"y\"][0],\n            x1=quadrant[\"x\"][1],\n            y1=quadrant[\"y\"][1],\n            fillcolor=quadrant[\"fillcolor\"],\n            line_color=\"rgba(0,0,0,0)\",\n            layer=\"below\",\n        )\n\n    # Create a color array based on the date order\n    color_array = list(range(len(data)))\n\n    fig.add_trace(\n        go.Scatter(\n            x=data[\"cpi_3m_delta\"],\n            y=data[\"cli_3m_delta\"],\n            mode=\"lines+markers+text\",\n            name=\"HumblCompass Data\",\n            text=[\n                d.strftime(\"%b %Y\") if isinstance(d, datetime.date) else \"\"\n                for d in data[\"date_month_start\"]\n            ],\n            textposition=\"top center\",\n            textfont={\"size\": 10, \"color\": \"white\"},\n            marker={\n                \"size\": 10,\n                \"color\": color_array,\n                \"colorscale\": custom_colorscale,\n                \"showscale\": False,\n            },\n            line={\n                \"color\": \"white\",\n                \"shape\": \"spline\",\n                \"smoothing\": 1.3,\n            },\n            hovertemplate=\"&lt;b&gt;%{text}&lt;/b&gt;&lt;br&gt;CPI 3m \u0394: %{x:.2f}&lt;br&gt;CLI 3m \u0394: %{y:.2f}&lt;extra&gt;&lt;/extra&gt;\",\n        )\n    )\n\n    # Add axis lines with tick marks\n    fig.add_shape(\n        type=\"line\",\n        x0=x_min - x_padding,\n        y0=0,\n        x1=x_max + x_padding,\n        y1=0,\n        line=dict(color=\"white\", width=1),\n    )\n    fig.add_shape(\n        type=\"line\",\n        x0=0,\n        y0=y_min - y_padding,\n        x1=0,\n        y1=y_max + y_padding,\n        line=dict(color=\"white\", width=1),\n    )\n\n    # Add tick marks and labels to the x-axis\n    for x in x_ticks:\n        if x != 0:  # Skip the center point\n            fig.add_shape(\n                type=\"line\",\n                x0=x,\n                y0=-0.005,\n                x1=x,\n                y1=0.005,\n                line=dict(color=\"white\", width=1),\n            )\n            fig.add_annotation(\n                x=x,\n                y=0,\n                text=f\"{x:.1f}\",\n                showarrow=False,\n                yshift=-15,\n                font=dict(size=8, color=\"white\"),\n            )\n\n    # Add tick marks and labels to the y-axis\n    for y in y_ticks:\n        if y != 0:  # Skip the center point\n            fig.add_shape(\n                type=\"line\",\n                x0=-0.005,\n                y0=y,\n                x1=0.005,\n                y1=y,\n                line=dict(color=\"white\", width=1),\n            )\n            fig.add_annotation(\n                x=0,\n                y=y,\n                text=f\"{y:.1f}\",\n                showarrow=False,\n                xshift=-15,\n                font=dict(size=8, color=\"white\"),\n            )\n\n    # Calculate the center of each visible quadrant\n    x_center_pos = (x_max + x_padding + 0) / 2\n    x_center_neg = (x_min - x_padding + 0) / 2\n    y_center_pos = (y_max + y_padding + 0) / 2\n    y_center_neg = (y_min - y_padding + 0) / 2\n\n    # Add quadrant labels\n    quadrant_labels = [\n        {\n            \"text\": \"humblBOOM\",\n            \"x\": x_center_neg,\n            \"y\": y_center_pos,\n            \"color\": \"rgba(144, 238, 144, 0.5)\",  # Changed opacity to 0.5\n        },\n        {\n            \"text\": \"humblBOUNCE\",\n            \"x\": x_center_pos,\n            \"y\": y_center_pos,\n            \"color\": \"rgba(173, 216, 230, 0.5)\",  # Changed opacity to 0.5\n        },\n        {\n            \"text\": \"humblBLOAT\",\n            \"x\": x_center_pos,\n            \"y\": y_center_neg,\n            \"color\": \"rgba(255, 165, 0, 0.5)\",  # Changed opacity to 0.5\n        },\n        {\n            \"text\": \"humblBUST\",\n            \"x\": x_center_neg,\n            \"y\": y_center_neg,\n            \"color\": \"rgba(255, 99, 71, 0.5)\",  # Changed opacity to 0.5\n        },\n    ]\n\n    for label in quadrant_labels:\n        fig.add_annotation(\n            x=label[\"x\"],\n            y=label[\"y\"],\n            text=label[\"text\"],\n            showarrow=False,\n            font={\"size\": 20, \"color\": label[\"color\"]},\n            opacity=0.5,  # Changed opacity to 0.5\n        )\n\n    # Add custom watermark\n    fig.add_annotation(\n        x=0,\n        y=0,\n        text=\"humblDATA\",\n        showarrow=False,\n        font={\"size\": 40, \"color\": \"rgba(255, 255, 255, 0.1)\"},\n        textangle=-25,\n        xanchor=\"center\",\n        yanchor=\"middle\",\n        xref=\"x\",\n        yref=\"y\",\n    )\n\n    # Create a copy of the template without the watermark\n    custom_template = pio.templates[template.value].to_plotly_json()\n    if (\n        \"layout\" in custom_template\n        and \"annotations\" in custom_template[\"layout\"]\n    ):\n        custom_template[\"layout\"][\"annotations\"] = [\n            ann\n            for ann in custom_template[\"layout\"][\"annotations\"]\n            if ann.get(\"name\") != \"draft watermark\"\n        ]\n\n    # Update layout\n    fig.update_layout(\n        title=\"humblCOMPASS: CLI 3m Delta vs CPI 3m Delta\",\n        title_font_color=\"white\",\n        xaxis_title=\"Inflation (CPI) 3-Month Delta\",\n        yaxis_title=\"Growth (CLI) 3-Month Delta\",\n        xaxis={\n            \"color\": \"white\",\n            \"showgrid\": False,\n            \"zeroline\": False,\n            \"range\": [x_min - x_padding, x_max + x_padding],\n            \"showticklabels\": False,  # Hide default tick labels\n            \"ticks\": \"\",  # Hide default ticks\n        },\n        yaxis={\n            \"color\": \"white\",\n            \"showgrid\": False,\n            \"zeroline\": False,\n            \"range\": [y_min - y_padding, y_max + y_padding],\n            \"showticklabels\": False,  # Hide default tick labels\n            \"ticks\": \"\",  # Hide default ticks\n        },\n        template=custom_template,  # Use the custom template without watermark\n        hovermode=\"closest\",\n        plot_bgcolor=\"rgba(0,0,0,0)\",\n        paper_bgcolor=\"rgba(0,0,0,0)\",\n        font={\"color\": \"white\"},\n        margin={\"l\": 50, \"r\": 50, \"t\": 50, \"b\": 50},\n    )\n\n    return fig\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental.humbl_compass.view.generate_plots","title":"humbldata.toolbox.fundamental.humbl_compass.view.generate_plots","text":"<pre><code>generate_plots(data: LazyFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; List[Chart]\n</code></pre> <p>Context: Toolbox || Category: Fundamental || Command: humbl_compass || Function: generate_plots().</p> <p>Generate plots from the given dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The LazyFrame containing the data to be plotted.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>List[Chart]</code> <p>A list of Chart objects, each representing a plot.</p> Source code in <code>src/humbldata/toolbox/fundamental/humbl_compass/view.py</code> <pre><code>def generate_plots(\n    data: pl.LazyFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; List[Chart]:\n    \"\"\"\n    Context: Toolbox || Category: Fundamental || Command: humbl_compass || **Function: generate_plots()**.\n\n    Generate plots from the given dataframe.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The LazyFrame containing the data to be plotted.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure.\n\n    Returns\n    -------\n    List[Chart]\n        A list of Chart objects, each representing a plot.\n    \"\"\"\n    collected_data = data.collect()\n    plot = create_humbl_compass_plot(collected_data, template)\n    return [Chart(content=plot.to_json(), fig=plot)]\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical","title":"humbldata.toolbox.technical","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.technical_controller","title":"humbldata.toolbox.technical.technical_controller","text":"<p>Context: Toolbox || Category: Technical.</p> <p>A controller to manage and compile all of the technical indicator models available. This will be passed as a <code>@property</code> to the <code>Toolbox()</code> class, giving access to the technical module and its functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.technical_controller.Technical","title":"humbldata.toolbox.technical.technical_controller.Technical","text":"<p>Module for all technical analysis.</p> <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>The standard query parameters for toolbox data.</p> <p>Methods:</p> Name Description <code>mandelbrot_channel</code> <p>Calculate the rescaled range statistics.</p> Source code in <code>src/humbldata/toolbox/technical/technical_controller.py</code> <pre><code>class Technical:\n    \"\"\"\n    Module for all technical analysis.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        The standard query parameters for toolbox data.\n\n    Methods\n    -------\n    mandelbrot_channel(command_params: MandelbrotChannelQueryParams)\n        Calculate the rescaled range statistics.\n\n    \"\"\"\n\n    def __init__(self, context_params: ToolboxQueryParams):\n        self.context_params = context_params\n\n    def mandelbrot_channel(self, **kwargs: MandelbrotChannelQueryParams):\n        \"\"\"\n        Calculate the Mandelbrot Channel.\n\n        Parameters\n        ----------\n        window : str, optional\n            The width of the window used for splitting the data into sections for\n            detrending. Defaults to \"1mo\".\n        rv_adjustment : bool, optional\n            Whether to adjust the calculation for realized volatility. If True, the\n            data is filtered to only include observations in the same volatility bucket\n            that the stock is currently in. Defaults to True.\n        rv_method : str, optional\n            The method to calculate the realized volatility. Only need to define\n            when rv_adjustment is True. Defaults to \"std\".\n        rs_method : Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"], optional\n            The method to use for Range/STD calculation. This is either min, max\n            or mean of all RS ranges per window. If not defined, just used the\n            most recent RS window. Defaults to \"RS\".\n        rv_grouped_mean : bool, optional\n            Whether to calculate the mean value of realized volatility over\n            multiple window lengths. Defaults to False.\n        live_price : bool, optional\n            Whether to calculate the ranges using the current live price, or the\n            most recent 'close' observation. Defaults to False.\n        historical : bool, optional\n            Whether to calculate the Historical Mandelbrot Channel (over-time), and\n            return a time-series of channels from the start to the end date. If\n            False, the Mandelbrot Channel calculation is done aggregating all of the\n            data into one observation. If True, then it will enable daily\n            observations over-time. Defaults to False.\n        chart : bool, optional\n            Whether to return a chart object. Defaults to False.\n        template : str, optional\n            The template/theme to use for the plotly figure. Defaults to \"humbl_dark\".\n\n        Returns\n        -------\n        HumblObject\n            An object containing the Mandelbrot Channel data and metadata.\n        \"\"\"\n        from humbldata.core.standard_models.toolbox.technical.mandelbrot_channel import (\n            MandelbrotChannelFetcher,\n        )\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = MandelbrotChannelFetcher(\n            context_params=self.context_params, command_params=kwargs\n        )\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.technical_controller.Technical.mandelbrot_channel","title":"humbldata.toolbox.technical.technical_controller.Technical.mandelbrot_channel","text":"<pre><code>mandelbrot_channel(**kwargs: MandelbrotChannelQueryParams)\n</code></pre> <p>Calculate the Mandelbrot Channel.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>str</code> <p>The width of the window used for splitting the data into sections for detrending. Defaults to \"1mo\".</p> required <code>rv_adjustment</code> <code>bool</code> <p>Whether to adjust the calculation for realized volatility. If True, the data is filtered to only include observations in the same volatility bucket that the stock is currently in. Defaults to True.</p> required <code>rv_method</code> <code>str</code> <p>The method to calculate the realized volatility. Only need to define when rv_adjustment is True. Defaults to \"std\".</p> required <code>rs_method</code> <code>Literal[RS, RS_min, RS_max, RS_mean]</code> <p>The method to use for Range/STD calculation. This is either min, max or mean of all RS ranges per window. If not defined, just used the most recent RS window. Defaults to \"RS\".</p> required <code>rv_grouped_mean</code> <code>bool</code> <p>Whether to calculate the mean value of realized volatility over multiple window lengths. Defaults to False.</p> required <code>live_price</code> <code>bool</code> <p>Whether to calculate the ranges using the current live price, or the most recent 'close' observation. Defaults to False.</p> required <code>historical</code> <code>bool</code> <p>Whether to calculate the Historical Mandelbrot Channel (over-time), and return a time-series of channels from the start to the end date. If False, the Mandelbrot Channel calculation is done aggregating all of the data into one observation. If True, then it will enable daily observations over-time. Defaults to False.</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object. Defaults to False.</p> required <code>template</code> <code>str</code> <p>The template/theme to use for the plotly figure. Defaults to \"humbl_dark\".</p> required <p>Returns:</p> Type Description <code>HumblObject</code> <p>An object containing the Mandelbrot Channel data and metadata.</p> Source code in <code>src/humbldata/toolbox/technical/technical_controller.py</code> <pre><code>def mandelbrot_channel(self, **kwargs: MandelbrotChannelQueryParams):\n    \"\"\"\n    Calculate the Mandelbrot Channel.\n\n    Parameters\n    ----------\n    window : str, optional\n        The width of the window used for splitting the data into sections for\n        detrending. Defaults to \"1mo\".\n    rv_adjustment : bool, optional\n        Whether to adjust the calculation for realized volatility. If True, the\n        data is filtered to only include observations in the same volatility bucket\n        that the stock is currently in. Defaults to True.\n    rv_method : str, optional\n        The method to calculate the realized volatility. Only need to define\n        when rv_adjustment is True. Defaults to \"std\".\n    rs_method : Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"], optional\n        The method to use for Range/STD calculation. This is either min, max\n        or mean of all RS ranges per window. If not defined, just used the\n        most recent RS window. Defaults to \"RS\".\n    rv_grouped_mean : bool, optional\n        Whether to calculate the mean value of realized volatility over\n        multiple window lengths. Defaults to False.\n    live_price : bool, optional\n        Whether to calculate the ranges using the current live price, or the\n        most recent 'close' observation. Defaults to False.\n    historical : bool, optional\n        Whether to calculate the Historical Mandelbrot Channel (over-time), and\n        return a time-series of channels from the start to the end date. If\n        False, the Mandelbrot Channel calculation is done aggregating all of the\n        data into one observation. If True, then it will enable daily\n        observations over-time. Defaults to False.\n    chart : bool, optional\n        Whether to return a chart object. Defaults to False.\n    template : str, optional\n        The template/theme to use for the plotly figure. Defaults to \"humbl_dark\".\n\n    Returns\n    -------\n    HumblObject\n        An object containing the Mandelbrot Channel data and metadata.\n    \"\"\"\n    from humbldata.core.standard_models.toolbox.technical.mandelbrot_channel import (\n        MandelbrotChannelFetcher,\n    )\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = MandelbrotChannelFetcher(\n        context_params=self.context_params, command_params=kwargs\n    )\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel","title":"humbldata.toolbox.technical.mandelbrot_channel","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.add_window_index","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.add_window_index","text":"<pre><code>add_window_index(data: LazyFrame | DataFrame, window: str) -&gt; LazyFrame | DataFrame\n</code></pre> <pre><code>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n</code></pre> <p>Add a column to the dataframe indicating the window grouping for each row in a time series.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input data frame or lazy frame to which the window index will be added.</p> required <code>window</code> <code>str</code> <p>The window size as a string, used to determine the grouping of rows into windows.</p> required <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The original data frame or lazy frame with an additional column named \"window_index\" indicating the window grouping for each row.</p> Notes <ul> <li>This function is essential for calculating the Mandelbrot Channel, where the dataset is split into numerous 'windows', and statistics are calculated for each window.</li> <li>The function adds a dummy <code>symbol</code> column if the data contains only one symbol, to avoid errors in the <code>group_by_dynamic()</code> function.</li> <li>It is utilized within the <code>log_mean()</code> and <code>calc_mandelbrot_channel()</code> functions for window-based calculations.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n&gt;&gt;&gt; window = \"1d\"\n&gt;&gt;&gt; add_window_index(data, window)\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n\u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n\u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def add_window_index(\n    data: pl.LazyFrame | pl.DataFrame, window: str\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n        Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n\n    Add a column to the dataframe indicating the window grouping for each row in\n    a time series.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input data frame or lazy frame to which the window index will be\n        added.\n    window : str\n        The window size as a string, used to determine the grouping of rows into\n        windows.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The original data frame or lazy frame with an additional column named\n        \"window_index\" indicating\n        the window grouping for each row.\n\n    Notes\n    -----\n    - This function is essential for calculating the Mandelbrot Channel, where\n    the dataset is split into\n    numerous 'windows', and statistics are calculated for each window.\n    - The function adds a dummy `symbol` column if the data contains only one\n    symbol, to avoid errors in the `group_by_dynamic()` function.\n    - It is utilized within the `log_mean()` and `calc_mandelbrot_channel()`\n    functions for window-based calculations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n    &gt;&gt;&gt; window = \"1d\"\n    &gt;&gt;&gt; add_window_index(data, window)\n    shape: (2, 4)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n    \u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n    \u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n\n    def _create_monthly_window_index(col: str, k: int = 1):\n        year_diff = pl.col(col).last().dt.year() - pl.col(col).dt.year()\n        month_diff = pl.col(col).last().dt.month() - pl.col(col).dt.month()\n        day_indicator = pl.col(col).dt.day() &gt; pl.col(col).last().dt.day()\n        return (12 * year_diff + month_diff - day_indicator) // k\n\n    # Clean the window into standardized strings (i.e \"1month\"/\"1 month\" = \"1mo\")\n    window = _window_format(window, _return_timedelta=False)  # returns `str`\n\n    if \"w\" in window or \"d\" in window:\n        msg = \"The window cannot include 'd' or 'w', the window needs to be larger than 1 month!\"\n        raise HumblDataError(msg)\n\n    window_monthly = _window_format_monthly(window)\n\n    data = data.with_columns(\n        _create_monthly_window_index(col=\"date\", k=window_monthly)\n        .alias(\"window_index\")\n        .over(\"symbol\")\n    )\n\n    return data\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets","text":"<pre><code>vol_buckets(data: DataFrame | LazyFrame, lo_quantile: float = 0.4, hi_quantile: float = 0.8, _column_name_volatility: str = 'realized_volatility', *, _boundary_group_down: bool = False) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_buckets.</p> <p>Splitting data observations into 3 volatility buckets: low, mid and high. The function does this for each <code>symbol</code> present in the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input dataframe or lazy frame.</p> required <code>lo_quantile</code> <code>float</code> <p>The lower quantile for bucketing. Default is 0.4.</p> <code>0.4</code> <code>hi_quantile</code> <code>float</code> <p>The higher quantile for bucketing. Default is 0.8.</p> <code>0.8</code> <code>_column_name_volatility</code> <code>str</code> <p>The name of the column to apply volatility bucketing. Default is \"realized_volatility\".</p> <code>'realized_volatility'</code> <code>_boundary_group_down</code> <code>bool</code> <p>If True, then group boundary values down to the lower bucket, using <code>vol_buckets_alt()</code> If False, then group boundary values up to the higher bucket, using the Polars <code>.qcut()</code> method. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The <code>data</code> with an additional column: <code>vol_bucket</code></p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def vol_buckets(\n    data: pl.DataFrame | pl.LazyFrame,\n    lo_quantile: float = 0.4,\n    hi_quantile: float = 0.8,\n    _column_name_volatility: str = \"realized_volatility\",\n    *,\n    _boundary_group_down: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_buckets**.\n\n    Splitting data observations into 3 volatility buckets: low, mid and high.\n    The function does this for each `symbol` present in the data.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input dataframe or lazy frame.\n    lo_quantile : float\n        The lower quantile for bucketing. Default is 0.4.\n    hi_quantile : float\n        The higher quantile for bucketing. Default is 0.8.\n    _column_name_volatility : str\n        The name of the column to apply volatility bucketing. Default is\n        \"realized_volatility\".\n    _boundary_group_down: bool = False\n        If True, then group boundary values down to the lower bucket, using\n        `vol_buckets_alt()` If False, then group boundary values up to the\n        higher bucket, using the Polars `.qcut()` method.\n        Default is False.\n\n    Returns\n    -------\n    pl.LazyFrame\n        The `data` with an additional column: `vol_bucket`\n    \"\"\"\n    _check_required_columns(data, _column_name_volatility, \"symbol\")\n\n    if not _boundary_group_down:\n        # Grouping Boundary Values in Higher Bucket\n        out = data.lazy().with_columns(\n            pl.col(_column_name_volatility)\n            .qcut(\n                [lo_quantile, hi_quantile],\n                labels=[\"low\", \"mid\", \"high\"],\n                left_closed=False,\n                allow_duplicates=True,\n            )\n            .over(\"symbol\")\n            .alias(\"vol_bucket\")\n            .cast(pl.Utf8)\n        )\n    else:\n        out = vol_buckets_alt(\n            data, lo_quantile, hi_quantile, _column_name_volatility\n        )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets_alt","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets_alt","text":"<pre><code>vol_buckets_alt(data: DataFrame | LazyFrame, lo_quantile: float = 0.4, hi_quantile: float = 0.8, _column_name_volatility: str = 'realized_volatility') -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_buckets_alt.</p> <p>This is an alternative implementation of <code>vol_buckets()</code> using expressions, and not using <code>.qcut()</code>. The biggest difference is how the function groups values on the boundaries of quantiles. This function groups boundary values down Splitting data observations into 3 volatility buckets: low, mid and high. The function does this for each <code>symbol</code> present in the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input dataframe or lazy frame.</p> required <code>lo_quantile</code> <code>float</code> <p>The lower quantile for bucketing. Default is 0.4.</p> <code>0.4</code> <code>hi_quantile</code> <code>float</code> <p>The higher quantile for bucketing. Default is 0.8.</p> <code>0.8</code> <code>_column_name_volatility</code> <code>str</code> <p>The name of the column to apply volatility bucketing. Default is \"realized_volatility\".</p> <code>'realized_volatility'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The <code>data</code> with an additional column: <code>vol_bucket</code></p> Notes <p>The biggest difference is how the function groups values on the boundaries of quantiles. This function groups boundary values down to the lower bucket. So, if there is a value that lies on the mid/low border, this function will group it with <code>low</code>, whereas <code>vol_buckets()</code> will group it with <code>mid</code></p> <p>This function is also slightly less performant.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def vol_buckets_alt(\n    data: pl.DataFrame | pl.LazyFrame,\n    lo_quantile: float = 0.4,\n    hi_quantile: float = 0.8,\n    _column_name_volatility: str = \"realized_volatility\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_buckets_alt**.\n\n    This is an alternative implementation of `vol_buckets()` using expressions,\n    and not using `.qcut()`.\n    The biggest difference is how the function groups values on the boundaries\n    of quantiles. This function groups boundary values down\n    Splitting data observations into 3 volatility buckets: low, mid and high.\n    The function does this for each `symbol` present in the data.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input dataframe or lazy frame.\n    lo_quantile : float\n        The lower quantile for bucketing. Default is 0.4.\n    hi_quantile : float\n        The higher quantile for bucketing. Default is 0.8.\n    _column_name_volatility : str\n        The name of the column to apply volatility bucketing. Default is \"realized_volatility\".\n\n    Returns\n    -------\n    pl.LazyFrame\n        The `data` with an additional column: `vol_bucket`\n\n    Notes\n    -----\n    The biggest difference is how the function groups values on the boundaries\n    of quantiles. This function __groups boundary values down__ to the lower bucket.\n    So, if there is a value that lies on the mid/low border, this function will\n    group it with `low`, whereas `vol_buckets()` will group it with `mid`\n\n    This function is also slightly less performant.\n    \"\"\"\n    # Calculate low and high quantiles for each symbol\n    low_vol = pl.col(_column_name_volatility).quantile(lo_quantile)\n    high_vol = pl.col(_column_name_volatility).quantile(hi_quantile)\n\n    # Determine the volatility bucket for each row using expressions\n    vol_bucket = (\n        pl.when(pl.col(_column_name_volatility) &lt;= low_vol)\n        .then(pl.lit(\"low\"))\n        .when(pl.col(_column_name_volatility) &lt;= high_vol)\n        .then(pl.lit(\"mid\"))\n        .otherwise(pl.lit(\"high\"))\n        .alias(\"vol_bucket\")\n    )\n\n    # Add the volatility bucket column to the data\n    out = data.lazy().with_columns(vol_bucket.over(\"symbol\"))\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_filter","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_filter","text":"<pre><code>vol_filter(data: DataFrame | LazyFrame) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_filter.</p> <p>If <code>_rv_adjustment</code> is True, then filter the data to only include rows that are in the same vol_bucket as the latest row for each symbol.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input dataframe or lazy frame. This should be the output of <code>vol_buckets()</code> function in <code>calc_mandelbrot_channel()</code>.</p> required <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The data with only observations in the same volatility bucket as the most recent data observation</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def vol_filter(\n    data: pl.DataFrame | pl.LazyFrame,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_filter**.\n\n    If `_rv_adjustment` is True, then filter the data to only include rows\n    that are in the same vol_bucket as the latest row for each symbol.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input dataframe or lazy frame. This should be the output of\n        `vol_buckets()` function in `calc_mandelbrot_channel()`.\n\n    Returns\n    -------\n    pl.LazyFrame\n        The data with only observations in the same volatility bucket as the\n        most recent data observation\n    \"\"\"\n    _check_required_columns(data, \"vol_bucket\", \"symbol\")\n\n    data = data.lazy().with_columns(\n        pl.col(\"vol_bucket\").last().over(\"symbol\").alias(\"last_vol_bucket\")\n    )\n\n    out = data.filter(\n        (pl.col(\"vol_bucket\") == pl.col(\"last_vol_bucket\")).over(\"symbol\")\n    ).drop(\"last_vol_bucket\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.price_range","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.price_range","text":"<pre><code>price_range(data: LazyFrame | DataFrame, recent_price_data: DataFrame | LazyFrame | None = None, rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', _detrended_returns: str = 'detrended_log_returns', _column_name_cum_sum_max: str = 'cum_sum_max', _column_name_cum_sum_min: str = 'cum_sum_min', *, _rv_adjustment: bool = False, _sort: bool = True, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: price_range.</p> <p>Calculate the price range for a given dataset using the Mandelbrot method.</p> <p>This function computes the price range based on the recent price data, cumulative sum max and min, and RS method specified. It supports adjustments for real volatility and sorting of the data based on symbols and dates.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The dataset containing the financial data.</p> required <code>recent_price_data</code> <code>DataFrame | LazyFrame | None</code> <p>The dataset containing the most recent price data. If None, the most recent prices are extracted from <code>data</code>.</p> <code>None</code> <code>rs_method</code> <code>Literal['RS', 'RS_mean', 'RS_max', 'RS_min']</code> <p>The RS value to use. Must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'. RS is the column that is the Range/STD of the detrended returns.</p> <code>\"RS\"</code> <code>_detrended_returns</code> <code>str</code> <p>The column name for detrended returns in <code>data</code></p> <code>\"detrended_log_returns\"</code> <code>_column_name_cum_sum_max</code> <code>str</code> <p>The column name for cumulative sum max in <code>data</code></p> <code>\"cum_sum_max\"</code> <code>_column_name_cum_sum_min</code> <code>str</code> <p>The column name for cumulative sum min in <code>data</code></p> <code>\"cum_sum_min\"</code> <code>_rv_adjustment</code> <code>bool</code> <p>If True, calculated the <code>std()</code> for all observations (since they have already been filtered by volatility bucket). If False, then calculates the <code>std()</code> for the most recent <code>window_index</code> and uses that to adjust the price range.</p> <code>False</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the data based on symbols and dates.</p> <code>True</code> <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The dataset with calculated price range, including columns for top and bottom prices.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If the RS method specified is not supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; price_range_data = price_range(data, recent_price_data=None, rs_method=\"RS\")\n&gt;&gt;&gt; print(price_range_data.columns)\n['symbol', 'bottom_price', 'recent_price', 'top_price']\n</code></pre> Notes <p>For <code>rs_method</code>, you should know how this affects the mandelbrot channel that is produced. Selecting RS uses the most recent RS value to calculate the price range, whereas selecting RS_mean, RS_max, or RS_min uses the mean, max, or min of the RS values, respectively.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def price_range(\n    data: pl.LazyFrame | pl.DataFrame,\n    recent_price_data: pl.DataFrame | pl.LazyFrame | None = None,\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    _detrended_returns: str = \"detrended_log_returns\",  # Parameterized detrended_returns column\n    _column_name_cum_sum_max: str = \"cum_sum_max\",\n    _column_name_cum_sum_min: str = \"cum_sum_min\",\n    *,\n    _rv_adjustment: bool = False,\n    _sort: bool = True,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **price_range**.\n\n    Calculate the price range for a given dataset using the Mandelbrot method.\n\n    This function computes the price range based on the recent price data,\n    cumulative sum max and min, and RS method specified. It supports adjustments\n    for real volatility and sorting of the data based on symbols and dates.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The dataset containing the financial data.\n    recent_price_data : pl.DataFrame | pl.LazyFrame | None\n        The dataset containing the most recent price data. If None, the most recent prices are extracted from `data`.\n    rs_method : Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"], default \"RS\"\n        The RS value to use. Must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'.\n        RS is the column that is the Range/STD of the detrended returns.\n    _detrended_returns : str, default \"detrended_log_returns\"\n        The column name for detrended returns in `data`\n    _column_name_cum_sum_max : str, default \"cum_sum_max\"\n        The column name for cumulative sum max in `data`\n    _column_name_cum_sum_min : str, default \"cum_sum_min\"\n        The column name for cumulative sum min in `data`\n    _rv_adjustment : bool, default False\n        If True, calculated the `std()` for all observations (since they have\n        already been filtered by volatility bucket). If False, then calculates\n        the `std()` for the most recent `window_index`\n        and uses that to adjust the price range.\n    _sort : bool, default True\n        If True, sorts the data based on symbols and dates.\n    **kwargs\n        Arbitrary keyword arguments.\n\n    Returns\n    -------\n    pl.LazyFrame\n        The dataset with calculated price range, including columns for top and\n        bottom prices.\n\n    Raises\n    ------\n    HumblDataError\n        If the RS method specified is not supported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; price_range_data = price_range(data, recent_price_data=None, rs_method=\"RS\")\n    &gt;&gt;&gt; print(price_range_data.columns)\n    ['symbol', 'bottom_price', 'recent_price', 'top_price']\n\n    Notes\n    -----\n    For `rs_method`, you should know how this affects the mandelbrot channel\n    that is produced. Selecting RS uses the most recent RS value to calculate\n    the price range, whereas selecting RS_mean, RS_max, or RS_min uses the mean,\n    max, or min of the RS values, respectively.\n    \"\"\"\n    # Check if RS_method is one of the allowed values\n    if rs_method not in RS_METHODS:\n        msg = \"RS_method must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'\"\n        raise HumblDataError(msg)\n\n    if isinstance(data, pl.DataFrame):\n        data = data.lazy()\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data.sort(sort_cols)\n\n    # Define Polars Expressions ================================================\n    last_cum_sum_max = (\n        pl.col(_column_name_cum_sum_max).last().alias(\"last_cum_sum_max\")\n    )\n    last_cum_sum_min = (\n        pl.col(_column_name_cum_sum_min).last().alias(\"last_cum_sum_min\")\n    )\n    # Define a conditional expression for std_detrended_returns based on _rv_adjustment\n    std_detrended_returns_expr = (\n        pl.col(_detrended_returns).std().alias(f\"std_{_detrended_returns}\")\n        if _rv_adjustment\n        else pl.col(_detrended_returns)\n        .filter(pl.col(\"window_index\") == pl.col(\"window_index\").min())\n        .std()\n        .alias(f\"std_{_detrended_returns}\")\n    )\n    # if rv_adjustment isnt used, then use the most recent window will be used\n    # for calculating the price_range\n    date_expr = pl.col(\"date\").max()\n    # ===========================================================================\n\n    if rs_method == \"RS\":\n        rs_expr = pl.col(\"RS\").last().alias(\"RS\")\n    elif rs_method == \"RS_mean\":\n        rs_expr = pl.col(\"RS\").mean().alias(\"RS_mean\")\n    elif rs_method == \"RS_max\":\n        rs_expr = pl.col(\"RS\").max().alias(\"RS_max\")\n    elif rs_method == \"RS_min\":\n        rs_expr = pl.col(\"RS\").min().alias(\"RS_min\")\n\n    if recent_price_data is None:\n        # if no recent_prices_data is passed, then pull the most recent prices from the data\n        recent_price_expr = pl.col(\"close\").last().alias(\"recent_price\")\n        # Perform a single group_by operation to calculate both STD of detrended returns and RS statistics\n        price_range_data = (\n            data.group_by(\"symbol\")\n            .agg(\n                [\n                    date_expr,\n                    # Conditional STD calculation based on _rv_adjustment\n                    std_detrended_returns_expr,\n                    # Recent Price Data\n                    recent_price_expr,\n                    # cum_sum_max/min last\n                    last_cum_sum_max,\n                    last_cum_sum_min,\n                    # RS statistics\n                    rs_expr,\n                ]\n            )\n            # Join with recent_price_data on symbol\n            .with_columns(\n                (\n                    pl.col(rs_method)\n                    * pl.col(\"std_detrended_log_returns\")\n                    * pl.col(\"recent_price\")\n                ).alias(\"price_range\")\n            )\n            .sort(\"symbol\")\n        )\n    else:\n        price_range_data = (\n            data.group_by(\"symbol\")\n            .agg(\n                [\n                    date_expr,\n                    # Conditional STD calculation based on _rv_adjustment\n                    std_detrended_returns_expr,\n                    # cum_sum_max/min last\n                    last_cum_sum_max,\n                    last_cum_sum_min,\n                    # RS statistics\n                    rs_expr,\n                ]\n            )\n            # Join with recent_price_data on symbol\n            .join(recent_price_data.lazy(), on=\"symbol\")\n            .with_columns(\n                (\n                    pl.col(rs_method)\n                    * pl.col(\"std_detrended_log_returns\")\n                    * pl.col(\"recent_price\")\n                ).alias(\"price_range\")\n            )\n            .sort(\"symbol\")\n        )\n    # Relative Position Modifier\n    out = _price_range_engine(price_range_data)\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model","title":"humbldata.toolbox.technical.mandelbrot_channel.model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_mandelbrot_channel.</p> <p>A command to generate a Mandelbrot Channel for any time series.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel","title":"humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel","text":"<pre><code>calc_mandelbrot_channel(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: calc_mandelbrot_channel.</p> <p>This command calculates the Mandelbrot Channel for a given time series, utilizing various parameters to adjust the calculation. The Mandelbrot Channel provides insights into the volatility and price range of a stock over a specified window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Mandelbrot Channel. There needs to be a <code>close</code> and <code>date</code> column.</p> required <code>window</code> <code>str</code> <p>The window size for the calculation, specified as a string. This determines the period over which the channel is calculated.</p> <code>'1m'</code> <code>rv_adjustment</code> <code>bool</code> <p>Adjusts the calculation for realized volatility. If True, filters the data to include only observations within the current volatility bucket of the stock.</p> <code>True</code> <code>rv_grouped_mean</code> <code>bool</code> <p>Determines whether to use the grouped mean in the realized volatility calculation.</p> <code>True</code> <code>rv_method</code> <code>str</code> <p>Specifies the method for calculating realized volatility, applicable only if <code>rv_adjustment</code> is True.</p> <code>'std'</code> <code>rs_method</code> <code>Literal['RS', 'RS_mean', 'RS_max', 'RS_min']</code> <p>Defines the method for calculating the range over standard deviation, affecting the width of the Mandelbrot Channel. Options include RS, RS_mean, RS_min, and RS_max.</p> <code>'RS'</code> <code>live_price</code> <code>bool</code> <p>Indicates whether to incorporate live price data into the calculation, which may extend the calculation time by 1-3 seconds.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the function, if you want to change the behavior or pass parameters to internal functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame containing the calculated Mandelbrot Channel data for the specified time series.</p> Notes <p>The function returns a pl.LazyFrame; remember to call <code>.collect()</code> on the result to obtain a DataFrame. This lazy evaluation strategy postpones the calculation until it is explicitly requested.</p> Example <p>To calculate the Mandelbrot Channel for a yearly window with adjustments for realized volatility using the 'yz' method, and incorporating live price data:</p> <pre><code>mandelbrot_channel = calc_mandelbrot_channel(\n    data,\n    window=\"1y\",\n    rv_adjustment=True,\n    rv_method=\"yz\",\n    rv_grouped_mean=False,\n    rs_method=\"RS\",\n    live_price=True\n).collect()\n</code></pre> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel(  # noqa: PLR0913\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: calc_mandelbrot_channel**.\n\n    This command calculates the Mandelbrot Channel for a given time series, utilizing various parameters to adjust the calculation. The Mandelbrot Channel provides insights into the volatility and price range of a stock over a specified window.\n\n    Parameters\n    ----------\n    data: pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Mandelbrot Channel.\n        There needs to be a `close` and `date` column.\n    window: str, default \"1m\"\n        The window size for the calculation, specified as a string. This\n        determines the period over which the channel is calculated.\n    rv_adjustment: bool, default True\n        Adjusts the calculation for realized volatility. If True, filters the\n        data to include only observations within the current volatility bucket\n        of the stock.\n    rv_grouped_mean: bool, default True\n        Determines whether to use the grouped mean in the realized volatility\n        calculation.\n    rv_method: str, default \"std\"\n        Specifies the method for calculating realized volatility, applicable\n        only if `rv_adjustment` is True.\n    rs_method: str, default \"RS\"\n        Defines the method for calculating the range over standard deviation,\n        affecting the width of the Mandelbrot Channel. Options include RS,\n        RS_mean, RS_min, and RS_max.\n    live_price: bool, default True\n        Indicates whether to incorporate live price data into the calculation,\n        which may extend the calculation time by 1-3 seconds.\n    **kwargs\n        Additional keyword arguments to pass to the function, if you want to\n        change the behavior or pass parameters to internal functions.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame containing the calculated Mandelbrot Channel data for the specified time series.\n\n    Notes\n    -----\n    The function returns a pl.LazyFrame; remember to call `.collect()` on the result to obtain a DataFrame. This lazy evaluation strategy postpones the calculation until it is explicitly requested.\n\n    Example\n    -------\n    To calculate the Mandelbrot Channel for a yearly window with adjustments for realized volatility using the 'yz' method, and incorporating live price data:\n\n    ```python\n    mandelbrot_channel = calc_mandelbrot_channel(\n        data,\n        window=\"1y\",\n        rv_adjustment=True,\n        rv_method=\"yz\",\n        rv_grouped_mean=False,\n        rs_method=\"RS\",\n        live_price=True\n    ).collect()\n    ```\n    \"\"\"\n    # Setup ====================================================================\n    # window_datetime = _window_format(window, _return_timedelta=True)\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n\n    data = data.lazy()\n    # Step 1: Collect Price Data -----------------------------------------------\n    # Step X: Add window bins --------------------------------------------------\n    # We want date grouping, non-overlapping window bins\n    data1 = add_window_index(data, window=window)\n\n    # Step X: Calculate Log Returns + Rvol -------------------------------------\n    if \"log_returns\" not in data1.collect_schema().names():\n        data2 = log_returns(data1, _column_name=\"close\")\n    else:\n        data2 = data1\n\n    # Step X: Calculate Log Mean Series ----------------------------------------\n    if isinstance(data2, pl.DataFrame | pl.LazyFrame):\n        data3 = mean(data2)\n    else:\n        msg = \"A series was passed to `mean()` calculation. Please provide a DataFrame or LazyFrame.\"\n        raise HumblDataError(msg)\n    # Step X: Calculate Mean De-trended Series ---------------------------------\n    data4 = detrend(\n        data3, _detrend_value_col=\"window_mean\", _detrend_col=\"log_returns\"\n    )\n    # Step X: Calculate Cumulative Deviate Series ------------------------------\n    data5 = cum_sum(data4, _column_name=\"detrended_log_returns\")\n    # Step X: Calculate Mandelbrot Range ---------------------------------------\n    data6 = range_(data5, _column_name=\"cum_sum\")\n    # Step X: Calculate Standard Deviation -------------------------------------\n    data7 = std(data6, _column_name=\"cum_sum\")\n    # Step X: Calculate Range (R) &amp; Standard Deviation (S) ---------------------\n    if rv_adjustment:\n        # Step 8.1: Calculate Realized Volatility ------------------------------\n        data7 = calc_realized_volatility(\n            data=data7,\n            window=window,\n            method=rv_method,\n            grouped_mean=rv_grouped_mean,\n        )\n        # rename col for easy selection\n        for col in data7.collect_schema().names():\n            if \"volatility_pct\" in col:\n                data7 = data7.rename({col: \"realized_volatility\"})\n        # Step 8.2: Calculate Volatility Bucket Stats --------------------------\n        data7 = vol_buckets(data=data7, lo_quantile=0.3, hi_quantile=0.65)\n        data7 = vol_filter(\n            data7\n        )  # removes rows that arent in the same vol bucket\n\n    # Step X: Calculate RS -----------------------------------------------------\n    data8 = data7.sort(sort_cols).with_columns(\n        (pl.col(\"cum_sum_range\") / pl.col(\"cum_sum_std\")).alias(\"RS\")\n    )\n\n    # Step X: Collect Recent Prices --------------------------------------------\n    if live_price:\n        symbols = (\n            data.select(\"symbol\").unique().sort(\"symbol\").collect().to_series()\n        )\n        recent_prices = get_latest_price(symbols)\n    else:\n        recent_prices = None\n\n    # Step X: Calculate Rescaled Price Range ----------------------------------\n    out = price_range(\n        data=data8,\n        recent_price_data=recent_prices,\n        rs_method=rs_method,\n        _rv_adjustment=rv_adjustment,\n    )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model.acalc_mandelbrot_channel","title":"humbldata.toolbox.technical.mandelbrot_channel.model.acalc_mandelbrot_channel  <code>async</code>","text":"<pre><code>acalc_mandelbrot_channel(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, **kwargs) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || Command: acalc_mandelbrot_channel.</p> <p>Asynchronous wrapper for calc_mandelbrot_channel. This function allows calc_mandelbrot_channel to be called in an async context.</p> Notes <p>This does not make <code>calc_mandelbrot_channel()</code> non-blocking or asynchronous.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>async def acalc_mandelbrot_channel(  # noqa: PLR0913\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    **kwargs,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || **Command: acalc_mandelbrot_channel**.\n\n    Asynchronous wrapper for calc_mandelbrot_channel.\n    This function allows calc_mandelbrot_channel to be called in an async context.\n\n    Notes\n    -----\n    This does not make `calc_mandelbrot_channel()` non-blocking or asynchronous.\n    \"\"\"\n    # Directly call the synchronous calc_mandelbrot_channel function\n\n    return calc_mandelbrot_channel(\n        data=data,\n        window=window,\n        rv_adjustment=rv_adjustment,\n        rv_method=rv_method,\n        rs_method=rs_method,\n        rv_grouped_mean=rv_grouped_mean,\n        live_price=live_price,\n        **kwargs,\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical","title":"humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical","text":"<pre><code>calc_mandelbrot_channel_historical(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || Command: calc_mandelbrot_channel_historical.</p> <p>This function calculates the Mandelbrot Channel for historical data.</p> <p>Synchronous wrapper for the asynchronous Mandelbrot Channel historical calculation.</p> <p>Parameters:</p> Name Type Description Default <code>The</code> required <code>Please</code> required <code>description</code> required <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame containing the historical Mandelbrot Channel calculations.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel_historical(  # noqa: PLR0913\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || **Command: calc_mandelbrot_channel_historical**.\n\n    This function calculates the Mandelbrot Channel for historical data.\n\n    Synchronous wrapper for the asynchronous Mandelbrot Channel historical calculation.\n\n    Parameters\n    ----------\n    The parameters for this function are the same as those for calc_mandelbrot_channel().\n    Please refer to the documentation of calc_mandelbrot_channel() for a detailed\n    description of each parameter.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame containing the historical Mandelbrot Channel calculations.\n    \"\"\"\n    return run_async(\n        _acalc_mandelbrot_channel_historical_engine(\n            data=data,\n            window=window,\n            rv_adjustment=rv_adjustment,\n            rv_method=rv_method,\n            rs_method=rs_method,\n            rv_grouped_mean=rv_grouped_mean,\n            live_price=live_price,\n            **kwargs,\n        )\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical_mp","title":"humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical_mp","text":"<pre><code>calc_mandelbrot_channel_historical_mp(data: DataFrame | LazyFrame, window: str = '1m', rv_adjustment: bool = True, rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_grouped_mean: bool = True, live_price: bool = True, n_processes: int = 1, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Calculate the Mandelbrot Channel historically using multiprocessing.</p> Parameters: <p>n_processes : int, optional     Number of processes to use. If None, it uses all available cores.</p> <p>Other parameters are the same as calc_mandelbrot_channel_historical.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel_historical_mp(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_adjustment: bool = True,\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    n_processes: int = 1,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate the Mandelbrot Channel historically using multiprocessing.\n\n    Parameters:\n    -----------\n    n_processes : int, optional\n        Number of processes to use. If None, it uses all available cores.\n\n    Other parameters are the same as calc_mandelbrot_channel_historical.\n    \"\"\"\n    window_days = _window_format(window, _return_timedelta=True)\n    start_date = data.lazy().select(pl.col(\"date\")).min().collect().row(0)[0]\n    start_date = start_date + window_days\n    end_date = data.lazy().select(\"date\").max().collect().row(0)[0]\n\n    if start_date &gt;= end_date:\n        msg = f\"You set &lt;historical=True&gt; \\n\\\n        This calculation needs *at least* one window of data. \\n\\\n        The (start date + window) is: {start_date} and the dataset ended: {end_date}. \\n\\\n        Please adjust dates accordingly.\"\n        raise HumblDataError(msg)\n\n    dates = (\n        data.lazy()\n        .select(pl.col(\"date\"))\n        .filter(pl.col(\"date\") &gt;= start_date)\n        .unique()\n        .sort(\"date\")\n        .collect()\n        .to_series()\n    )\n\n    # Prepare the partial function with all arguments except the date\n    calc_func = partial(\n        _calc_mandelbrot_for_date,\n        data=data,\n        window=window,\n        rv_adjustment=rv_adjustment,\n        rv_method=rv_method,\n        rs_method=rs_method,\n        rv_grouped_mean=rv_grouped_mean,\n        live_price=live_price,\n        **kwargs,\n    )\n\n    # Use multiprocessing to calculate in parallel\n    with multiprocessing.Pool(processes=n_processes) as pool:\n        results = pool.map(calc_func, dates)\n\n    # Combine results\n    out = pl.concat(results, how=\"vertical\").sort([\"symbol\", \"date\"])\n\n    return out.lazy()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical_concurrent","title":"humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical_concurrent","text":"<pre><code>calc_mandelbrot_channel_historical_concurrent(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, max_workers: int | None = None, use_processes: bool = False, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Calculate the Mandelbrot Channel historically using concurrent.futures.</p> Parameters: <p>max_workers : int, optional     Maximum number of workers to use. If None, it uses the default for ProcessPoolExecutor     or ThreadPoolExecutor (usually the number of processors on the machine, multiplied by 5). use_processes : bool, default True     If True, use ProcessPoolExecutor, otherwise use ThreadPoolExecutor.</p> <p>Other parameters are the same as calc_mandelbrot_channel_historical.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel_historical_concurrent(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    max_workers: int | None = None,\n    use_processes: bool = False,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate the Mandelbrot Channel historically using concurrent.futures.\n\n    Parameters:\n    -----------\n    max_workers : int, optional\n        Maximum number of workers to use. If None, it uses the default for ProcessPoolExecutor\n        or ThreadPoolExecutor (usually the number of processors on the machine, multiplied by 5).\n    use_processes : bool, default True\n        If True, use ProcessPoolExecutor, otherwise use ThreadPoolExecutor.\n\n    Other parameters are the same as calc_mandelbrot_channel_historical.\n    \"\"\"\n    window_days = _window_format(window, _return_timedelta=True)\n    start_date = data.lazy().select(pl.col(\"date\")).min().collect().row(0)[0]\n    start_date = start_date + window_days\n    end_date = data.lazy().select(\"date\").max().collect().row(0)[0]\n\n    if start_date &gt;= end_date:\n        msg = f\"You set &lt;historical=True&gt; \\n\\\n        This calculation needs *at least* one window of data. \\n\\\n        The (start date + window) is: {start_date} and the dataset ended: {end_date}. \\n\\\n        Please adjust dates accordingly.\"\n        raise HumblDataError(msg)\n\n    dates = (\n        data.lazy()\n        .select(pl.col(\"date\"))\n        .filter(pl.col(\"date\") &gt;= start_date)\n        .unique()\n        .sort(\"date\")\n        .collect()\n        .to_series()\n    )\n\n    # Prepare the partial function with all arguments except the date\n    calc_func = partial(\n        _calc_mandelbrot_for_date,\n        data=data,\n        window=window,\n        rv_adjustment=rv_adjustment,\n        rv_method=rv_method,\n        rs_method=rs_method,\n        rv_grouped_mean=rv_grouped_mean,\n        live_price=live_price,\n        **kwargs,\n    )\n\n    # Choose the appropriate executor\n    executor_class = (\n        concurrent.futures.ProcessPoolExecutor\n        if use_processes\n        else concurrent.futures.ThreadPoolExecutor\n    )\n\n    # Use concurrent.futures to calculate in parallel\n    with executor_class(max_workers=max_workers) as executor:\n        futures = [executor.submit(calc_func, date) for date in dates]\n        results = [\n            future.result()\n            for future in concurrent.futures.as_completed(futures)\n        ]\n\n    # Combine results\n    out = pl.concat(results, how=\"vertical\").sort([\"symbol\", \"date\"])\n\n    return out.lazy()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.view","title":"humbldata.toolbox.technical.mandelbrot_channel.view","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.view.create_historical_plot","title":"humbldata.toolbox.technical.mandelbrot_channel.view.create_historical_plot","text":"<pre><code>create_historical_plot(data: DataFrame, symbol: str, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate a historical plot for a given symbol from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing historical data including dates, bottom prices, close prices, and top prices.</p> required <code>symbol</code> <code>str</code> <p>The symbol for which the historical plot is to be generated.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the historical data of the given symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def create_historical_plot(\n    data: pl.DataFrame,\n    symbol: str,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate a historical plot for a given symbol from the provided data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing historical data including dates, bottom prices, close prices, and top prices.\n    symbol : str\n        The symbol for which the historical plot is to be generated.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the historical data of the given symbol.\n    \"\"\"\n    filtered_data = data.filter(pl.col(\"symbol\") == symbol)\n\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_data.select(\"date\").to_series(),\n            y=filtered_data.select(\"bottom_price\").to_series(),\n            name=\"Bottom Price\",\n            line=dict(color=\"green\"),\n        )\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_data.select(\"date\").to_series(),\n            y=filtered_data.select(\"recent_price\").to_series(),\n            name=\"Recent Price\",\n            line=dict(color=\"blue\"),\n        )\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_data.select(\"date\").to_series(),\n            y=filtered_data.select(\"top_price\").to_series(),\n            name=\"Top Price\",\n            line=dict(color=\"red\"),\n        )\n    )\n    fig.update_layout(\n        title=f\"Historical Mandelbrot Channel for {symbol}\",\n        xaxis_title=\"Date\",\n        yaxis_title=\"Price\",\n        template=template,\n    )\n    return fig\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.view.create_current_plot","title":"humbldata.toolbox.technical.mandelbrot_channel.view.create_current_plot","text":"<pre><code>create_current_plot(data: DataFrame, equity_data: DataFrame, symbol: str, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate a current plot for a given symbol from the provided data and equity data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing historical data including top and bottom prices.</p> required <code>equity_data</code> <code>DataFrame</code> <p>The dataframe containing current equity data including dates and close prices.</p> required <code>symbol</code> <code>str</code> <p>The symbol for which the current plot is to be generated.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the current data of the given symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def create_current_plot(\n    data: pl.DataFrame,\n    equity_data: pl.DataFrame,\n    symbol: str,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate a current plot for a given symbol from the provided data and equity data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing historical data including top and bottom prices.\n    equity_data : pl.DataFrame\n        The dataframe containing current equity data including dates and close prices.\n    symbol : str\n        The symbol for which the current plot is to be generated.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the current data of the given symbol.\n    \"\"\"\n    filtered_data = data.filter(pl.col(\"symbol\") == symbol)\n    equity_data = equity_data.filter(pl.col(\"symbol\") == symbol)\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=equity_data.select(\"date\").to_series(),\n            y=equity_data.select(\"close\").to_series(),\n            name=\"Recent Price\",\n            line=dict(color=\"blue\"),\n        )\n    )\n    fig.add_hline(\n        y=filtered_data.select(\"top_price\").row(0)[0],\n        line=dict(color=\"red\", width=2),\n        name=\"Top Price\",\n    )\n    fig.add_hline(\n        y=filtered_data.select(\"bottom_price\").row(0)[0],\n        line=dict(color=\"green\", width=2),\n        name=\"Bottom Price\",\n    )\n    fig.update_layout(\n        title=f\"Current Mandelbrot Channel for {symbol}\",\n        xaxis_title=\"Date\",\n        yaxis_title=\"Price\",\n        template=template,\n    )\n    return fig\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.view.is_historical_data","title":"humbldata.toolbox.technical.mandelbrot_channel.view.is_historical_data","text":"<pre><code>is_historical_data(data: DataFrame) -&gt; bool\n</code></pre> <p>Check if the provided dataframe contains historical data based on the uniqueness of dates.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe to check for historical data presence.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Returns True if the dataframe contains historical data (more than one unique date), otherwise False.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def is_historical_data(data: pl.DataFrame) -&gt; bool:\n    \"\"\"\n    Check if the provided dataframe contains historical data based on the uniqueness of dates.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe to check for historical data presence.\n\n    Returns\n    -------\n    bool\n        Returns True if the dataframe contains historical data (more than one unique date), otherwise False.\n    \"\"\"\n    return data.select(\"date\").to_series().unique().shape[0] &gt; 1\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.view.generate_plot_for_symbol","title":"humbldata.toolbox.technical.mandelbrot_channel.view.generate_plot_for_symbol","text":"<pre><code>generate_plot_for_symbol(data: DataFrame, equity_data: DataFrame, symbol: str, template: ChartTemplate = ChartTemplate.plotly) -&gt; Chart\n</code></pre> <p>Generate a plot for a specific symbol that is filtered from the original DF.</p> <p>This function will check if the data provided is a Historical or Current Mandelbrot Channel data. If it is historical, it will generate a historical plot. If it is current, it will generate a current plot.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing Mandelbrot channel data for all symbols.</p> required <code>equity_data</code> <code>DataFrame</code> <p>The dataframe containing equity data for all symbols.</p> required <code>symbol</code> <code>str</code> <p>The symbol for which to generate the plot.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure. Options are: \"humbl_light\", \"humbl_dark\", \"plotly_light\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Chart</code> <p>A Chart object containing the generated plot for the specified symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def generate_plot_for_symbol(\n    data: pl.DataFrame,\n    equity_data: pl.DataFrame,\n    symbol: str,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; Chart:\n    \"\"\"\n    Generate a plot for a specific symbol that is filtered from the original DF.\n\n    This function will check if the data provided is a Historical or Current\n    Mandelbrot Channel data. If it is historical, it will generate a historical\n    plot. If it is current, it will generate a current plot.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing Mandelbrot channel data for all symbols.\n    equity_data : pl.DataFrame\n        The dataframe containing equity data for all symbols.\n    symbol : str\n        The symbol for which to generate the plot.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure. Options are:\n        \"humbl_light\", \"humbl_dark\", \"plotly_light\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\n\n    Returns\n    -------\n    Chart\n        A Chart object containing the generated plot for the specified symbol.\n\n    \"\"\"\n    if is_historical_data(data):\n        out = create_historical_plot(data, symbol, template)\n    else:\n        out = create_current_plot(data, equity_data, symbol, template)\n\n    return Chart(\n        content=out.to_json(), fig=out\n    )  # TODO: use to_json() instead of to_plotly_json()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.view.generate_plots","title":"humbldata.toolbox.technical.mandelbrot_channel.view.generate_plots","text":"<pre><code>generate_plots(data: LazyFrame, equity_data: LazyFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; list[Chart]\n</code></pre> <p>Context: Toolbox || Category: Technical || Subcategory: Mandelbrot Channel || Command: generate_plots().</p> <p>Generate plots for each unique symbol in the given dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The LazyFrame containing the symbols and MandelbrotChannelData</p> required <code>equity_data</code> <code>LazyFrame</code> <p>The LazyFrame containing equity data for the symbols.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>list[Chart]</code> <p>A list of Chart objects, each representing a plot for a unique symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def generate_plots(\n    data: pl.LazyFrame,\n    equity_data: pl.LazyFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; list[Chart]:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Subcategory: Mandelbrot Channel || **Command: generate_plots()**.\n\n    Generate plots for each unique symbol in the given dataframes.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The LazyFrame containing the symbols and MandelbrotChannelData\n    equity_data : pl.LazyFrame\n        The LazyFrame containing equity data for the symbols.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure.\n\n    Returns\n    -------\n    list[Chart]\n        A list of Chart objects, each representing a plot for a unique symbol.\n\n    \"\"\"\n    symbols = data.select(\"symbol\").unique().collect().to_series()\n\n    plots = [\n        generate_plot_for_symbol(\n            data.collect(), equity_data.collect(), symbol, template\n        )\n        for symbol in symbols\n    ]\n    return plots\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility","title":"humbldata.toolbox.technical.volatility","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers.</p> <p>All of the volatility estimators used in <code>calc_realized_volatility()</code>. These are various methods to calculate the realized volatility of financial data.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.std","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.std","text":"<pre><code>std(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _std.</p> <p>This function computes the standard deviation of returns, which is a common measure of volatility.It calculates the rolling standard deviation for a given window size, optionally adjusting for the average number of trading days and scaling the result to an annualized volatility percentage.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data containing the returns. It can be a DataFrame, LazyFrame, or Series.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating the standard deviation. The default is \"1m\" (one month).</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for annualizing the volatility. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>If True, null values will be dropped from the result. The default is True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>If True, the average number of trading days will be used when calculating the window size. The default is True.</p> <code>False</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. This parameter is used when <code>data</code> is a DataFrame or LazyFrame. The default is \"log_returns\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data structure with an additional column for the rolling standard deviation of returns, or the modified Series with the rolling standard deviation values.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def std(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _std**.\n\n    This function computes the standard deviation of returns, which is a common\n    measure of volatility.It calculates the rolling standard deviation for a\n    given window size, optionally adjusting for the average number of trading\n    days and scaling the result to an annualized volatility percentage.\n\n    Parameters\n    ----------\n    data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data containing the returns. It can be a DataFrame, LazyFrame,\n        or Series.\n    window : str, optional\n        The rolling window size for calculating the standard deviation.\n        The default is \"1m\" (one month).\n    trading_periods : int, optional\n        The number of trading periods in a year, used for annualizing the\n        volatility. The default is 252.\n    _drop_nulls : bool, optional\n        If True, null values will be dropped from the result.\n        The default is True.\n    _avg_trading_days : bool, optional\n        If True, the average number of trading days will be used when\n        calculating the window size. The default is True.\n    _column_name_returns : str, optional\n        The name of the column containing the returns. This parameter is used\n        when `data` is a DataFrame or LazyFrame. The default is \"log_returns\".\n\n    Returns\n    -------\n    Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data structure with an additional column for the rolling\n        standard deviation of returns, or the modified Series with the rolling\n        standard deviation values.\n    \"\"\"\n    window_timedelta = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    )\n    if isinstance(data, pl.Series):\n        return data.rolling_std(\n            window_size=window_timedelta.days, min_periods=1\n        )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    # convert window_timedelta to days to use fixed window\n    result = data.lazy().with_columns(\n        (\n            pl.col(_column_name_returns).rolling_std_by(\n                window_size=window_timedelta,\n                min_periods=2,  # using min_periods=2, bc if min_periods=1, the first value will be 0.\n                by=\"date\",\n            )\n            * math.sqrt(trading_periods)\n            * 100\n        ).alias(f\"std_volatility_pct_{window_timedelta.days}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(\n            subset=f\"std_volatility_pct_{window_timedelta.days}D\"\n        )\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.parkinson","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.parkinson","text":"<pre><code>parkinson(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', *, _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate Parkinson's volatility over a specified window.</p> <p>Parkinson's volatility is a measure that uses the stock's high and low prices of the day rather than just close to close prices. It is particularly useful for capturing large price movements during the day.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the stock prices.</p> required <code>window</code> <code>int</code> <p>The rolling window size for calculating volatility, by default 30.</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, by default 252.</p> required <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The calculated Parkinson's volatility, with an additional column \"parkinson_volatility_pct_{window_int}D\" indicating the percentage volatility.</p> Notes <p>This function requires the input data to have 'high' and 'low' columns to calculate the logarithm of their ratio, which is squared and scaled by a constant to estimate volatility. The result is then annualized and expressed as a percentage.</p> Usage <p>If you pass <code>\"1m</code> as a <code>window</code> argument and  <code>_avg_trading_days=False</code>. The result will be <code>30</code>. If <code>_avg_trading_days=True</code>, the result will be <code>21</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n&gt;&gt;&gt; _parkinson(data)\nA DataFrame with the calculated Parkinson's volatility.\n</code></pre> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def parkinson(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    *,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate Parkinson's volatility over a specified window.\n\n    Parkinson's volatility is a measure that uses the stock's high and low prices\n    of the day rather than just close to close prices. It is particularly useful\n    for capturing large price movements during the day.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the stock prices.\n    window : int, optional\n        The rolling window size for calculating volatility, by default 30.\n    trading_periods : int, optional\n        The number of trading periods in a year, by default 252.\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The calculated Parkinson's volatility, with an additional column\n        \"parkinson_volatility_pct_{window_int}D\"\n        indicating the percentage volatility.\n\n    Notes\n    -----\n    This function requires the input data to have 'high' and 'low' columns to\n    calculate\n    the logarithm of their ratio, which is squared and scaled by a constant to\n    estimate\n    volatility. The result is then annualized and expressed as a percentage.\n\n    Usage\n    -----\n    If you pass `\"1m` as a `window` argument and  `_avg_trading_days=False`.\n    The result will be `30`. If `_avg_trading_days=True`, the result will be\n    `21`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n    &gt;&gt;&gt; _parkinson(data)\n    A DataFrame with the calculated Parkinson's volatility.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    var1 = 1.0 / (4.0 * math.log(2.0))\n    var2 = (\n        data.lazy()\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    rs = var1 * var2**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = data.lazy().with_columns(\n        (\n            rs.rolling_map(_annual_vol, window_size=window_int, min_periods=1)\n            * 100\n        ).alias(f\"parkinson_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(\n            subset=f\"parkinson_volatility_pct_{window_int}D\"\n        )\n\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.garman_klass","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.garman_klass","text":"<pre><code>garman_klass(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _garman_klass.</p> <p>Calculates the Garman-Klass volatility for a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for volatility calculation, by default \"1m\".</p> <code>'1m'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the opening prices, by default \"open\".</p> <code>'open'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the adjusted closing prices, by default \"close\".</p> <code>'close'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The calculated Garman-Klass volatility, with an additional column \"volatility_pct\" indicating the percentage volatility.</p> Notes <p>Garman-Klass volatility extends Parkinson\u2019s volatility by considering the opening and closing prices in addition to the high and low prices. This approach provides a more accurate estimation of volatility, especially in markets with significant activity at the opening and closing of trading sessions.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def garman_klass(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _garman_klass**.\n\n    Calculates the Garman-Klass volatility for a given dataset.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for volatility calculation, by default \"1m\".\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _column_name_open : str, optional\n        The name of the column containing the opening prices, by default \"open\".\n    _column_name_close : str, optional\n        The name of the column containing the adjusted closing prices, by\n        default \"close\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The calculated Garman-Klass volatility, with an additional column\n        \"volatility_pct\" indicating the percentage volatility.\n\n    Notes\n    -----\n    Garman-Klass volatility extends Parkinson\u2019s volatility by considering the\n    opening and closing prices in addition to the high and low prices. This\n    approach provides a more accurate estimation of volatility, especially in\n    markets with significant activity at the opening and closing of trading\n    sessions.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n    log_hi_lo = (\n        data.lazy()\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    log_close_open = (\n        data.lazy()\n        .select((pl.col(_column_name_close) / pl.col(_column_name_open)).log())\n        .collect()\n        .to_series()\n    )\n    rs: pl.Series = 0.5 * log_hi_lo**2 - (2 * np.log(2) - 1) * log_close_open**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = data.lazy().with_columns(\n        (\n            rs.rolling_map(_annual_vol, window_size=window_int, min_periods=1)\n            * 100\n        ).alias(f\"gk_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"gk_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.hodges_tompkins","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.hodges_tompkins","text":"<pre><code>hodges_tompkins(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _column_name_returns: str = 'log_returns', *, _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _hodges_tompkins.</p> <p>Hodges-Tompkins volatility is a bias correction for estimation using an overlapping data sample that produces unbiased estimates and a substantial gain in efficiency.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def hodges_tompkins(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _column_name_returns: str = \"log_returns\",\n    *,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _hodges_tompkins**.\n\n    Hodges-Tompkins volatility is a bias correction for estimation using an\n    overlapping data sample that produces unbiased estimates and a\n    substantial gain in efficiency.\n    \"\"\"\n    # When calculating rv_mean, need a different adjustment factor,\n    # so window doesn't influence the Volatility_mean\n    # RV_MEAN\n\n    # Define Window Size\n    window_timedelta = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    )\n    # Calculate STD, assigned to `vol`\n    if isinstance(data, pl.Series):\n        vol = data.rolling_std(window_size=window_timedelta.days, min_periods=1)\n    else:\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.lazy().sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        vol = data.lazy().select(\n            pl.col(_column_name_returns).rolling_std_by(\n                window_size=window_timedelta, min_periods=1, by=\"date\"\n            )\n            * np.sqrt(trading_periods)\n        )\n\n    # Assign window size to h for adjustment\n    h: int = window_timedelta.days\n\n    if isinstance(data, pl.Series):\n        count = data.len()\n    elif isinstance(data, pl.LazyFrame):\n        count = data.collect().shape[0]\n    else:\n        count = data.shape[0]\n\n    n = (count - h) + 1\n    adj_factor = 1.0 / (1.0 - (h / n) + ((h**2 - 1) / (3 * n**2)))\n\n    if isinstance(data, pl.Series):\n        return (vol * adj_factor) * 100\n    else:\n        result = data.lazy().with_columns(\n            ((vol.collect() * adj_factor) * 100)\n            .to_series()\n            .alias(f\"ht_volatility_pct_{h}D\")\n        )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"ht_volatility_pct_{h}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.rogers_satchell","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.rogers_satchell","text":"<pre><code>rogers_satchell(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _rogers_satchell.</p> <p>Rogers-Satchell is an estimator for measuring the volatility of securities with an average return not equal to zero. Unlike Parkinson and Garman-Klass estimators, Rogers-Satchell incorporates a drift term (mean return not equal to zero). This function calculates the Rogers-Satchell volatility estimator over a specified window and optionally drops null values from the result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data for which to calculate the Rogers-Satchell volatility estimator. This can be either a DataFrame or a LazyFrame. There need to be OHLC columns present in the data.</p> required <code>window</code> <code>str</code> <p>The window over which to calculate the volatility estimator. The window is specified as a string, such as \"1m\" for one month.</p> <code>\"1m\"</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column representing the high prices in the data.</p> <code>\"high\"</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column representing the low prices in the data.</p> <code>\"low\"</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column representing the opening prices in the data.</p> <code>\"open\"</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column representing the adjusted closing prices in the data.</p> <code>\"close\"</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. If True, rows with null values in the calculated volatility column will be removed from the output.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Indicates whether to use the average number of trading days per window. This affects how the window size is interpreted. i.e instead of \"1mo\" returning <code>timedelta(days=31)</code>, it will return <code>timedelta(days=21)</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data with an additional column containing the calculated Rogers-Satchell volatility estimator. The return type matches the input type (DataFrame or LazyFrame).</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def rogers_satchell(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _rogers_satchell**.\n\n    Rogers-Satchell is an estimator for measuring the volatility of\n    securities with an average return not equal to zero. Unlike Parkinson\n    and Garman-Klass estimators, Rogers-Satchell incorporates a drift term\n    (mean return not equal to zero). This function calculates the\n    Rogers-Satchell volatility estimator over a specified window and optionally\n    drops null values from the result.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data for which to calculate the Rogers-Satchell volatility\n        estimator. This can be either a DataFrame or a LazyFrame. There need to\n        be OHLC columns present in the data.\n    window : str, default \"1m\"\n        The window over which to calculate the volatility estimator. The\n        window is specified as a string, such as \"1m\" for one month.\n    _column_name_high : str, default \"high\"\n        The name of the column representing the high prices in the data.\n    _column_name_low : str, default \"low\"\n        The name of the column representing the low prices in the data.\n    _column_name_open : str, default \"open\"\n        The name of the column representing the opening prices in the data.\n    _column_name_close : str, default \"close\"\n        The name of the column representing the adjusted closing prices in the\n        data.\n    _drop_nulls : bool, default True\n        Whether to drop null values from the result. If True, rows with null\n        values in the calculated volatility column will be removed from the\n        output.\n    _avg_trading_days : bool, default True\n        Indicates whether to use the average number of trading days per window.\n        This affects how the window size is interpreted. i.e instead of \"1mo\"\n        returning `timedelta(days=31)`, it will return `timedelta(days=21)`.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data with an additional column containing the calculated\n        Rogers-Satchell volatility estimator. The return type matches the input\n        type (DataFrame or LazyFrame).\n    \"\"\"\n    # Check if all required columns are present in the DataFrame\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n            ]\n        )\n        .with_columns(\n            (\n                pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n            ).alias(\"rs\")\n        )\n    )\n    result = data.lazy().with_columns(\n        (\n            pl.col(\"rs\").rolling_map(\n                _annual_vol, window_size=window_int, min_periods=1\n            )\n            * 100\n        ).alias(f\"rs_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"rs_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.yang_zhang","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.yang_zhang","text":"<pre><code>yang_zhang(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'close', _avg_trading_days: bool = False, _drop_nulls: bool = True, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _yang_zhang.</p> <p>Yang-Zhang volatility is the combination of the overnight (close-to-open volatility), a weighted average of the Rogers-Satchell volatility and the day\u2019s open-to-close volatility.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def yang_zhang(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"close\",\n    _avg_trading_days: bool = False,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _yang_zhang**.\n\n    Yang-Zhang volatility is the combination of the overnight\n    (close-to-open volatility), a weighted average of the Rogers-Satchell\n    volatility and the day\u2019s open-to-close volatility.\n    \"\"\"\n    # check required columns\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n                (pl.col(_column_name_open) / pl.col(_column_name_close).shift())\n                .log()\n                .alias(\"log_oc\"),\n                (\n                    pl.col(_column_name_close)\n                    / pl.col(_column_name_close).shift()\n                )\n                .log()\n                .alias(\"log_cc\"),\n            ]\n        )\n        .with_columns(\n            [\n                (pl.col(\"log_oc\") ** 2).alias(\"log_oc_sq\"),\n                (pl.col(\"log_cc\") ** 2).alias(\"log_cc_sq\"),\n                (\n                    pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                    + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n                ).alias(\"rs\"),\n            ]\n        )\n    )\n\n    k = 0.34 / (1.34 + (window_int + 1) / (window_int - 1))\n    data = _yang_zhang_engine(data=data, window=window_int)\n    result = (\n        data.lazy()\n        .with_columns(\n            (\n                (\n                    pl.col(\"open_vol\")\n                    + k * pl.col(\"close_vol\")\n                    + (1 - k) * pl.col(\"window_rs\")\n                ).sqrt()\n                * np.sqrt(trading_periods)\n                * 100\n            ).alias(f\"yz_volatility_pct_{window_int}D\")\n        )\n        .select(\n            pl.exclude(\n                [\n                    \"log_ho\",\n                    \"log_lo\",\n                    \"log_co\",\n                    \"log_oc\",\n                    \"log_cc\",\n                    \"log_oc_sq\",\n                    \"log_cc_sq\",\n                    \"rs\",\n                    \"close_vol\",\n                    \"open_vol\",\n                    \"window_rs\",\n                ]\n            )\n        )\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"yz_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.squared_returns","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.squared_returns","text":"<pre><code>squared_returns(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate squared returns over a rolling window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating squared returns, by default \"1m\".</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for scaling the result. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the price data, by default \"close\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data structure with an additional column for the rolling squared returns.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def squared_returns(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate squared returns over a rolling window.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for calculating squared returns, by default \"1m\".\n    trading_periods : int, optional\n        The number of trading periods in a year, used for scaling the result.\n        The default is 252.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _column_name_returns : str, optional\n        The name of the column containing the price data, by default \"close\".\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data structure with an additional column for the rolling\n        squared returns.\n    \"\"\"\n    _check_required_columns(data, _column_name_returns)\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = data.lazy().with_columns(\n        ((pl.col(_column_name_returns) * 100) ** 2).alias(\"sq_log_returns_pct\")\n    )\n    # Calculate rolling squared returns\n    result = (\n        data.lazy()\n        .with_columns(\n            pl.col(\"sq_log_returns_pct\")\n            .rolling_mean(window_size=window_int, min_periods=1)\n            .alias(f\"sq_volatility_pct_{window_int}D\")\n        )\n        .drop(\"sq_log_returns_pct\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"sq_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_model","title":"humbldata.toolbox.technical.volatility.realized_volatility_model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>A command to generate Realized Volatility for any time series. A complete set of volatility estimators based on Euan Sinclair's Volatility Trading</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_model.calc_realized_volatility","title":"humbldata.toolbox.technical.volatility.realized_volatility_model.calc_realized_volatility","text":"<pre><code>calc_realized_volatility(data: DataFrame | LazyFrame, window: str = '1m', method: Literal['std', 'parkinson', 'garman_klass', 'gk', 'hodges_tompkins', 'ht', 'rogers_satchell', 'rs', 'yang_zhang', 'yz', 'squared_returns', 'sq'] = 'std', grouped_mean: list[int] | None = None, _trading_periods: int = 252, _column_name_returns: str = 'log_returns', _column_name_close: str = 'close', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', *, _sort: bool = True) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>Calculates the Realized Volatility for a given time series based on the provided standard and extra parameters. This function adds ONE rolling volatility column to the input DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Realized Volatility.</p> required <code>window</code> <code>str</code> <p>The window size for a rolling volatility calculation, default is <code>\"1m\"</code> (1 month).</p> <code>'1m'</code> <code>method</code> <code>Literal['std', 'parkinson', 'garman_klass', 'hodges_tompkins', 'rogers_satchell', 'yang_zhang', 'squared_returns']</code> <p>The volatility estimator to use. You can also use abbreviations to access the same methods. The abbreviations are: <code>gk</code> for <code>garman_klass</code>, <code>ht</code> for <code>hodges_tompkins</code>, <code>rs</code> for <code>rogers_satchell</code>, <code>yz</code> for <code>yang_zhang</code>, <code>sq</code> for <code>squared_returns</code>.</p> <code>'std'</code> <code>grouped_mean</code> <code>list[int] | None</code> <p>A list of window sizes to use for calculating volatility. If provided, the volatility method will be calculated across these various windows, and then an averaged value of all the windows will be returned. If <code>None</code>, a single window size specified by <code>window</code> parameter will be used.</p> <code>None</code> <code>_sort</code> <code>bool</code> <p>If True, the data will be sorted before calculation. Default is True.</p> <code>True</code> <code>_trading_periods</code> <code>int</code> <p>The number of trading periods in a year, default is 252 (the typical number of trading days in a year).</p> <code>252</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. Default is \"log_returns\".</p> <code>'log_returns'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the close prices. Default is \"close\".</p> <code>'close'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices. Default is \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices. Default is \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the open prices. Default is \"open\".</p> <code>'open'</code> <p>Returns:</p> Type Description <code>VolatilityData</code> <p>The calculated Realized Volatility data for the given time series.</p> Notes <ul> <li> <p>Rolling calculations are used to show a time series of recent volatility that captures only a certain number of data points. The window size is used to determine the number of data points to use in the calculation. We do this because when looking at the volatility of a stock, you get a better insight (more granular) into the characteristics of the volatility seeing how 1-month or 3-month rolling volatility looked over time.</p> </li> <li> <p>This function does not accept <code>pl.Series</code> because the methods used to calculate volatility require, high, low, close, open columns for the data. It would be too cumbersome to pass each series needed for the calculation as a separate argument. Therefore, the function only accepts <code>pl.DataFrame</code> or <code>pl.LazyFrame</code> as input.</p> </li> </ul> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_model.py</code> <pre><code>def calc_realized_volatility(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    method: Literal[  # used to be rvol_method\n        \"std\",\n        \"parkinson\",\n        \"garman_klass\",\n        \"gk\",\n        \"hodges_tompkins\",\n        \"ht\",\n        \"rogers_satchell\",\n        \"rs\",\n        \"yang_zhang\",\n        \"yz\",\n        \"squared_returns\",\n        \"sq\",\n    ] = \"std\",\n    grouped_mean: list[int] | None = None,  # used to be rv_mean\n    _trading_periods: int = 252,\n    _column_name_returns: str = \"log_returns\",\n    _column_name_close: str = \"close\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: calc_realized_volatility**.\n\n    Calculates the Realized Volatility for a given time series based on the\n    provided standard and extra parameters. This function adds ONE rolling\n    volatility column to the input DataFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Realized Volatility.\n    window : str\n        The window size for a rolling volatility calculation, default is `\"1m\"`\n        (1 month).\n    method : Literal[\"std\", \"parkinson\", \"garman_klass\", \"hodges_tompkins\",\"rogers_satchell\", \"yang_zhang\", \"squared_returns\"]\n        The volatility estimator to use. You can also use abbreviations to\n        access the same methods. The abbreviations are: `gk` for `garman_klass`,\n        `ht` for `hodges_tompkins`, `rs` for `rogers_satchell`, `yz` for\n        `yang_zhang`, `sq` for `squared_returns`.\n    grouped_mean : list[int] | None\n        A list of window sizes to use for calculating volatility. If provided,\n        the volatility method will be calculated across these various windows,\n        and then an averaged value of all the windows will be returned. If `None`,\n        a single window size specified by `window` parameter will be used.\n    _sort : bool\n        If True, the data will be sorted before calculation. Default is True.\n    _trading_periods : int\n        The number of trading periods in a year, default is 252 (the typical\n        number of trading days in a year).\n    _column_name_returns : str\n        The name of the column containing the returns. Default is \"log_returns\".\n    _column_name_close : str\n        The name of the column containing the close prices. Default is \"close\".\n    _column_name_high : str\n        The name of the column containing the high prices. Default is \"high\".\n    _column_name_low : str\n        The name of the column containing the low prices. Default is \"low\".\n    _column_name_open : str\n        The name of the column containing the open prices. Default is \"open\".\n\n    Returns\n    -------\n    VolatilityData\n        The calculated Realized Volatility data for the given time series.\n\n    Notes\n    -----\n    - Rolling calculations are used to show a time series of recent volatility\n    that captures only a certain number of data points. The window size is\n    used to determine the number of data points to use in the calculation. We do\n    this because when looking at the volatility of a stock, you get a better\n    insight (more granular) into the characteristics of the volatility seeing how 1-month or\n    3-month rolling volatility looked over time.\n\n    - This function does not accept `pl.Series` because the methods used to\n    calculate volatility require, high, low, close, open columns for the data.\n    It would be too cumbersome to pass each series needed for the calculation\n    as a separate argument. Therefore, the function only accepts `pl.DataFrame`\n    or `pl.LazyFrame` as input.\n    \"\"\"  # noqa: W505\n    # Step 1: Get the correct realized volatility function =====================\n    func = VOLATILITY_METHODS.get(method)\n    if not func:\n        msg = f\"Volatility method: '{method}' is not supported.\"\n        raise HumblDataError(msg)\n\n    # Step 2: Get the names of the parameters that the function accepts ========\n    func_params = inspect.signature(func).parameters\n\n    # Step 3: Filter out the parameters not accepted by the function ===========\n    args_to_pass = {\n        key: value for key, value in locals().items() if key in func_params\n    }\n\n    # Step 4: Calculate Realized Volatility ====================================\n    if grouped_mean:\n        # calculate volatility over multiple windows and average the result, add to a new column\n        print(\"\ud83d\udea7 WIP!\")\n    else:\n        out = func(**args_to_pass)\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.quantitative","title":"humbldata.toolbox.quantitative","text":"<p>Context: Toolbox || Category: Quantitative.</p> <p>Quantitative indicators rely on statistical transformations of time series data.</p>"},{"location":"code_documentation/api_reference/#humbldata.core","title":"humbldata.core","text":"<p>The <code>core</code> module to contain logic &amp; functions used in controllers.</p> <p>This module is intended to contain sub-modules and functions that are not directly utilized from the package, but rather used in building the package itself. This means that the core module should not contain any code that is specific to the package's use case, but rather should be generic and reusable in other contexts.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models","title":"humbldata.core.standard_models","text":"<p>Models to represent core data structures of the Standardization Framework.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract","title":"humbldata.core.standard_models.abstract","text":"<p>Abstract core DATA MODELS to be inherited by other models.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.errors","title":"humbldata.core.standard_models.abstract.errors","text":"<p>An ABSTRACT DATA MODEL to be inherited by custom errors.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.errors.HumblDataError","title":"humbldata.core.standard_models.abstract.errors.HumblDataError","text":"<p>             Bases: <code>BaseException</code></p> <p>Base Error for HumblData logic.</p> Source code in <code>src/humbldata/core/standard_models/abstract/errors.py</code> <pre><code>class HumblDataError(BaseException):\n    \"\"\"Base Error for HumblData logic.\"\"\"\n\n    def __init__(self, original: str | Exception | None = None):\n        self.original = original\n        super().__init__(str(original))\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.query_params","title":"humbldata.core.standard_models.abstract.query_params","text":"<p>A wrapper around OpenBB QueryParams Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.query_params.QueryParams","title":"humbldata.core.standard_models.abstract.query_params.QueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>An abstract standard_model to represent a base QueryParams Data.</p> <p>QueryParams model should be used to define the query parameters for a <code>context.category.command</code> call.</p> <p>This QueryParams model is meant to be inherited and built upon by other standard_models for a specific context.</p> <p>Examples:</p> <pre><code>class EquityHistoricalQueryParams(QueryParams):\n\n    symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n    interval: Optional[str] = Field(\n        default=\"1d\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n    )\n    end_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n    )\n\n    @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n        if isinstance(v, str):\n            return v.upper()\n        return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre> <p>This would create a class that would be used to query historical price data for equities from any given command.</p> <p>This could then be used to create a <code>MandelbrotChannelEquityHistoricalQueryParams</code> that would define what query parameters are needed for the Mandelbrot Channel command.</p> Source code in <code>src/humbldata/core/standard_models/abstract/query_params.py</code> <pre><code>class QueryParams(OpenBBQueryParams):\n    \"\"\"\n    An abstract standard_model to represent a base QueryParams Data.\n\n    QueryParams model should be used to define the query parameters for a\n    `context.category.command` call.\n\n    This QueryParams model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Examples\n    --------\n    ```py\n    class EquityHistoricalQueryParams(QueryParams):\n\n        symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n        interval: Optional[str] = Field(\n            default=\"1d\",\n            description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n        )\n        start_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n        )\n        end_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n        )\n\n        @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n        @classmethod\n        def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n            if isinstance(v, str):\n                return v.upper()\n            return \",\".join([symbol.upper() for symbol in list(v)])\n    ```\n\n    This would create a class that would be used to query historical price data\n    for equities from any given command.\n\n    This could then be used to create a\n    `MandelbrotChannelEquityHistoricalQueryParams` that would define what query\n    parameters are needed for the Mandelbrot Channel command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.singleton","title":"humbldata.core.standard_models.abstract.singleton","text":"<p>An ABSTRACT DATA MODEL, Singleton, to represent a class that should only have one instance.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.singleton.SingletonMeta","title":"humbldata.core.standard_models.abstract.singleton.SingletonMeta","text":"<p>             Bases: <code>type</code>, <code>Generic[T]</code></p> <p>SingletonMeta is a metaclass that creates a Singleton instance of a class.</p> <p>Singleton design pattern restricts the instantiation of a class to a single instance. This is useful when exactly one object is needed to coordinate actions across the system.</p> Source code in <code>src/humbldata/core/standard_models/abstract/singleton.py</code> <pre><code>class SingletonMeta(type, Generic[T]):\n    \"\"\"\n    SingletonMeta is a metaclass that creates a Singleton instance of a class.\n\n    Singleton design pattern restricts the instantiation of a class to a single\n    instance. This is useful when exactly one object is needed to coordinate\n    actions across the system.\n    \"\"\"\n\n    _instances: ClassVar[dict[T, T]] = {}  # type: ignore  # noqa: PGH003\n\n    def __call__(cls, *args, **kwargs) -&gt; T:\n        \"\"\"\n        Override the __call__ method.\n\n        If the class exists, otherwise creates a new instance and stores it in\n        the _instances dictionary.\n        \"\"\"\n        if cls not in cls._instances:\n            instance = super().__call__(*args, **kwargs)\n            cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n        return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre> <code></code> humbldata.core.standard_models.abstract.singleton.SingletonMeta.__call__ \u00a4 <pre><code>__call__(*args, **kwargs) -&gt; T\n</code></pre> <p>Override the call method.</p> <p>If the class exists, otherwise creates a new instance and stores it in the _instances dictionary.</p> Source code in <code>src/humbldata/core/standard_models/abstract/singleton.py</code> <pre><code>def __call__(cls, *args, **kwargs) -&gt; T:\n    \"\"\"\n    Override the __call__ method.\n\n    If the class exists, otherwise creates a new instance and stores it in\n    the _instances dictionary.\n    \"\"\"\n    if cls not in cls._instances:\n        instance = super().__call__(*args, **kwargs)\n        cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n    return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.chart","title":"humbldata.core.standard_models.abstract.chart","text":""},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.chart.ChartTemplate","title":"humbldata.core.standard_models.abstract.chart.ChartTemplate","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Chart format.</p> <p>Available options: - plotly - humbl_light - humbl_dark - plotly_light - plotly_dark - ggplot2 - seaborn - simple_white - presentation - xgridoff - ygridoff - gridon - none</p> Source code in <code>src/humbldata/core/standard_models/abstract/chart.py</code> <pre><code>class ChartTemplate(str, Enum):\n    \"\"\"\n    Chart format.\n\n    Available options:\n    - plotly\n    - humbl_light\n    - humbl_dark\n    - plotly_light\n    - plotly_dark\n    - ggplot2\n    - seaborn\n    - simple_white\n    - presentation\n    - xgridoff\n    - ygridoff\n    - gridon\n    - none\n    \"\"\"\n\n    plotly = \"plotly\"\n    humbl_light = \"humbl_light\"\n    humbl_dark = \"humbl_dark\"\n    plotly_light = \"plotly_light\"\n    plotly_dark = \"plotly_dark\"\n    ggplot2 = \"ggplot2\"\n    seaborn = \"seaborn\"\n    simple_white = \"simple_white\"\n    presentation = \"presentation\"\n    xgridoff = \"xgridoff\"\n    ygridoff = \"ygridoff\"\n    gridon = \"gridon\"\n    none = \"none\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.chart.Chart","title":"humbldata.core.standard_models.abstract.chart.Chart","text":"<p>             Bases: <code>BaseModel</code></p> <p>a Chart Object that is returned from a View.</p> Source code in <code>src/humbldata/core/standard_models/abstract/chart.py</code> <pre><code>class Chart(BaseModel):\n    \"\"\"a Chart Object that is returned from a View.\"\"\"\n\n    content: str | None = Field(\n        default=None,\n        description=\"Raw textual representation of the chart.\",\n    )\n    theme: ChartTemplate | None = Field(\n        default=ChartTemplate.plotly,\n        description=\"Complementary attribute to the `content` attribute. It specifies the format of the chart.\",\n    )\n    fig: Any | None = Field(\n        default=None,\n        description=\"The figure object.\",\n        # json_schema_extra={\"exclude_from_api\": True},\n    )\n    model_config = ConfigDict(validate_assignment=True)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Human readable representation of the object.\"\"\"\n        items = [\n            f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n            for k, v in self.model_dump().items()\n        ]\n\n        return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n</code></pre> <code></code> humbldata.core.standard_models.abstract.chart.Chart.__repr__ \u00a4 <pre><code>__repr__() -&gt; str\n</code></pre> <p>Human readable representation of the object.</p> Source code in <code>src/humbldata/core/standard_models/abstract/chart.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Human readable representation of the object.\"\"\"\n    items = [\n        f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n        for k, v in self.model_dump().items()\n    ]\n\n    return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.data","title":"humbldata.core.standard_models.abstract.data","text":"<p>A wrapper around OpenBB Data Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.data.Data","title":"humbldata.core.standard_models.abstract.data.Data","text":"<p>             Bases: <code>DataFrameModel</code></p> <p>An abstract standard_model to represent a base Data Model.</p> <p>The Data Model should be used to define the data that is being collected and analyzed in a <code>context.category.command</code> call.</p> <p>This Data model is meant to be inherited and built upon by other standard_models for a specific context.</p> Example <pre><code>class EquityHistoricalData(Data):\n\ndate: Union[dateType, datetime] = Field(\n    description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n)\nopen: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\nhigh: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\nlow: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\nclose: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\nvolume: Optional[Union[float, int]] = Field(\n    default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n)\n\n@field_validator(\"date\", mode=\"before\", check_fields=False)\ndef date_validate(cls, v):  # pylint: disable=E0213\n    v = parser.isoparse(str(v))\n    if v.hour == 0 and v.minute == 0:\n        return v.date()\n    return v\n</code></pre> Source code in <code>src/humbldata/core/standard_models/abstract/data.py</code> <pre><code>class Data(pa.DataFrameModel):\n    \"\"\"\n    An abstract standard_model to represent a base Data Model.\n\n    The Data Model should be used to define the data that is being\n    collected and analyzed in a `context.category.command` call.\n\n    This Data model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Example\n    -------\n    ```py\n    class EquityHistoricalData(Data):\n\n    date: Union[dateType, datetime] = Field(\n        description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n    )\n    open: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\n    high: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\n    low: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\n    close: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\n    volume: Optional[Union[float, int]] = Field(\n        default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n    )\n\n    @field_validator(\"date\", mode=\"before\", check_fields=False)\n    def date_validate(cls, v):  # pylint: disable=E0213\n        v = parser.isoparse(str(v))\n        if v.hour == 0 and v.minute == 0:\n            return v.date()\n        return v\n\n    ```\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.humblobject","title":"humbldata.core.standard_models.abstract.humblobject","text":""},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.humblobject.extract_subclass_dict","title":"humbldata.core.standard_models.abstract.humblobject.extract_subclass_dict","text":"<pre><code>extract_subclass_dict(self, attribute_name: str, items: list)\n</code></pre> <p>Extract the dictionary representation of the specified attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attribute_name</code> <code>str</code> <p>The name of the attribute to update in the items list.</p> required Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def extract_subclass_dict(self, attribute_name: str, items: list):\n    \"\"\"\n    Extract the dictionary representation of the specified attribute.\n\n    Parameters\n    ----------\n    attribute_name : str\n        The name of the attribute to update in the items list.\n    \"\"\"\n    # Check if the attribute exists and has a value\n    attribute_value = getattr(self, attribute_name, None)\n    if attribute_value:\n        # Assuming the attribute has a method called 'model_dump' to get its dictionary representation\n        add_item = attribute_value.model_dump()\n        add_item_str = str(add_item)\n        if len(add_item_str) &gt; 80:\n            add_item_str = add_item_str[:80] + \"...\"\n        for i, item in enumerate(items):\n            if item.startswith(f\"{attribute_name}:\"):\n                items[i] = f\"{attribute_name}: {add_item_str}\"\n                break\n\n    return items\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.humblobject.HumblObject","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject","text":"<p>             Bases: <code>Tagged</code>, <code>Generic[T]</code></p> <p>HumblObject is the base class for all dta returned from the Toolbox.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>class HumblObject(Tagged, Generic[T]):\n    \"\"\"HumblObject is the base class for all dta returned from the Toolbox.\"\"\"\n\n    _user_settings: ClassVar[BaseModel | None] = None\n    _system_settings: ClassVar[BaseModel | None] = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    results: T | None = Field(\n        default=None,\n        description=\"Serializable Logical Plan of the pl.LazyFrame results.\",\n    )\n    equity_data: T | None = Field(\n        default=None,\n        description=\"Serialized raw data used in the command calculations.\",\n    )\n    provider: str | None = Field(\n        default=None,\n        description=\"Provider name.\",\n    )\n    warnings: list[Warning_] | None = Field(\n        default=None,\n        description=\"List of warnings.\",\n    )\n    chart: Chart | list[Chart] | None = Field(\n        default=None,\n        description=\"Chart object.\",\n    )\n    extra: dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Extra info.\",\n    )\n    context_params: ToolboxQueryParams | PortfolioQueryParams | None = Field(\n        default_factory=ToolboxQueryParams,\n        title=\"Context Parameters\",\n        description=\"Context parameters.\",\n    )\n    command_params: SerializeAsAny[QueryParams] | None = Field(\n        default=QueryParams,\n        title=\"Command Parameters\",\n        description=\"Command-specific parameters.\",\n    )\n\n    # @field_validator(\"command_params\")\n    # def validate_command_params(cls, v):\n    #     class_name = v.__class__.__name__\n    #     if \"QueryParams\" in class_name:\n    #         return v\n    #     msg = \"Wrong type for 'command_params', must be subclass of QueryParams\"\n    #     raise TypeError(msg)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Human readable representation of the object.\"\"\"\n        items = [\n            f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n            for k, v in self.model_dump().items()\n        ]\n\n        # Needed to extract subclass dict correctly\n        # items = extract_subclass_dict(self, \"command_params\", items)\n\n        return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n\n    def to_polars(\n        self, collect: bool = True, equity_data: bool = False\n    ) -&gt; pl.LazyFrame | pl.DataFrame:\n        \"\"\"\n        Deserialize the stored results or return the LazyFrame, and optionally collect them into a Polars DataFrame.\n\n        Parameters\n        ----------\n        collect : bool, optional\n            If True, collects the deserialized LazyFrame into a DataFrame.\n            Default is True.\n        equity_data : bool, optional\n            If True, processes equity_data instead of results.\n            Default is False.\n\n        Returns\n        -------\n        pl.LazyFrame | pl.DataFrame\n            The results as a Polars LazyFrame or DataFrame,\n            depending on the collect parameter.\n\n        Raises\n        ------\n        HumblDataError\n            If no results or equity data are found to process\n        \"\"\"\n        data = self.equity_data if equity_data else self.results\n\n        if data is None:\n            raise HumblDataError(\"No data found.\")\n\n        if isinstance(data, pl.LazyFrame):\n            out = data\n        elif isinstance(data, str):\n            with io.StringIO(data) as data_io:\n                out = pl.LazyFrame.deserialize(data_io, format=\"json\")\n        elif isinstance(data, bytes):\n            with io.BytesIO(data) as data_io:\n                out = pl.LazyFrame.deserialize(data_io, format=\"binary\")\n        else:\n            raise HumblDataError(\n                \"Invalid data type. Expected LazyFrame or serialized string.\"\n            )\n\n        if collect:\n            out = out.collect()\n\n        return out\n\n    def to_df(\n        self, collect: bool = True, equity_data: bool = False\n    ) -&gt; pl.LazyFrame | pl.DataFrame:\n        \"\"\"\n        Alias for the `to_polars` method.\n\n        Parameters\n        ----------\n        collect : bool, optional\n            If True, collects the deserialized LazyFrame into a DataFrame.\n            Default is True.\n\n        Returns\n        -------\n        pl.LazyFrame | pl.DataFrame\n            The deserialized results as a Polars LazyFrame or DataFrame,\n            depending on the collect parameter.\n        \"\"\"\n        return self.to_polars(collect=collect, equity_data=equity_data)\n\n    def to_pandas(self, equity_data: bool = False) -&gt; pd.DataFrame:\n        \"\"\"\n        Convert the results to a Pandas DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The results as a Pandas DataFrame.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_pandas()\n\n    def to_numpy(self, equity_data: bool = False) -&gt; np.ndarray:\n        \"\"\"\n        Convert the results to a NumPy array.\n\n        Returns\n        -------\n        np.ndarray\n            The results as a NumPy array.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_numpy()\n\n    def to_dict(\n        self,\n        row_wise: bool = False,\n        equity_data: bool = False,\n        as_series: bool = True,\n    ) -&gt; dict | list[dict]:\n        \"\"\"\n        Transform the stored data into a dictionary or a list of dictionaries.\n\n        This method allows for the conversion of the internal data\n        representation into a more universally accessible format, either\n        aggregating the entire dataset into a single dictionary (column-wise)\n        or breaking it down into a list of dictionaries, each representing a\n        row in the dataset.\n\n        Parameters\n        ----------\n        row_wise : bool, optional\n            Determines the format of the output. If set to True, the method\n            returns a list of dictionaries, with each dictionary representing a\n            row and its corresponding data as key-value pairs. If set to False,\n            the method returns a single dictionary, with column names as keys\n            and lists of column data as values. Default is False.\n\n        equity_data : bool, optional\n            A flag to specify whether to use equity-specific data for the\n            conversion. This parameter allows for flexibility in handling\n            different types of data stored within the object. Default is\n            False.\n        as_series : bool, optional\n            If True, the method returns a pl.Series with values as Series. If\n            False, the method returns a dict with values as List[Any].\n            Default is True.\n\n        Returns\n        -------\n        dict | list[dict]\n            Depending on the `row_wise` parameter, either a dictionary mapping column names to lists of values (if `row_wise` is False) or a list of dictionaries, each representing a row in the dataset (if `row_wise` is True).\n        \"\"\"\n        if row_wise:\n            return self.to_polars(\n                collect=True, equity_data=equity_data\n            ).to_dicts()\n        return self.to_polars(collect=True, equity_data=equity_data).to_dict(\n            as_series=as_series\n        )\n\n    def to_arrow(self, equity_data: bool = False) -&gt; pa.Table:\n        \"\"\"\n        Convert the results to an Arrow Table.\n\n        Returns\n        -------\n        pa.Table\n            The results as an Arrow Table.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_arrow()\n\n    def to_struct(\n        self, name: str = \"results\", equity_data: bool = False\n    ) -&gt; pl.Series:\n        \"\"\"\n        Convert the results to a struct.\n\n        Parameters\n        ----------\n        name : str, optional\n            The name of the struct. Default is \"results\".\n\n        Returns\n        -------\n        pl.Struct\n            The results as a struct.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_struct(\n            name=name\n        )\n\n    def to_json(\n        self, equity_data: bool = False, chart: bool = False\n    ) -&gt; str | list[str]:\n        \"\"\"\n        Convert the results to a JSON string.\n\n        Parameters\n        ----------\n        equity_data : bool, optional\n            A flag to specify whether to use equity-specific data for the\n            conversion. Default is False.\n        chart : bool, optional\n            If True, return all generated charts as a JSON string instead of\n            returning the results. Default is False.\n\n        Returns\n        -------\n        str\n            The results or charts as a JSON string.\n\n        Raises\n        ------\n        HumblDataError\n            If chart is True but no charts are available.\n        \"\"\"\n        import json\n        from datetime import date, datetime\n\n        from humbldata.core.standard_models.abstract.errors import (\n            HumblDataError,\n        )\n\n        def json_serial(obj):\n            \"\"\"JSON serializer for objects not serializable by default json code.\"\"\"\n            if isinstance(obj, (datetime, date)):\n                return obj.isoformat()\n            msg = f\"Type {type(obj)} not serializable\"\n            raise TypeError(msg)\n\n        if chart:\n            if self.chart is None:\n                msg = f\"You set `.to_json(chart=True)` but there were no charts. Make sure `chart=True` in {self.command_params.__class__.__name__}\"\n                raise HumblDataError(msg)\n\n            if isinstance(self.chart, list):\n                return [\n                    chart.content\n                    for chart in self.chart\n                    if chart and chart.content\n                ]\n            else:\n                return self.chart.content\n        else:\n            data = self.to_polars(\n                collect=True, equity_data=equity_data\n            ).to_dict(as_series=False)\n            return json.dumps(data, default=json_serial)\n\n    def is_empty(self, equity_data: bool = False) -&gt; bool:\n        \"\"\"\n        Check if the results are empty.\n\n        Returns\n        -------\n        bool\n            True if the results are empty, False otherwise.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).is_empty()\n\n    def show(self) -&gt; None:\n        \"\"\"Show the chart.\"\"\"\n        if isinstance(self.chart, list):\n            for chart in self.chart:\n                if chart and chart.fig:\n                    chart.fig.show()\n                else:\n                    msg = \"Chart object is missing or incomplete.\"\n                    raise HumblDataError(msg)\n        elif not self.chart or not self.chart.fig:\n            msg = \"Chart not found.\"\n            raise HumblDataError(msg)\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.__repr__ \u00a4 <pre><code>__repr__() -&gt; str\n</code></pre> <p>Human readable representation of the object.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Human readable representation of the object.\"\"\"\n    items = [\n        f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n        for k, v in self.model_dump().items()\n    ]\n\n    # Needed to extract subclass dict correctly\n    # items = extract_subclass_dict(self, \"command_params\", items)\n\n    return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_polars \u00a4 <pre><code>to_polars(collect: bool = True, equity_data: bool = False) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Deserialize the stored results or return the LazyFrame, and optionally collect them into a Polars DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>collect</code> <code>bool</code> <p>If True, collects the deserialized LazyFrame into a DataFrame. Default is True.</p> <code>True</code> <code>equity_data</code> <code>bool</code> <p>If True, processes equity_data instead of results. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The results as a Polars LazyFrame or DataFrame, depending on the collect parameter.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If no results or equity data are found to process</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_polars(\n    self, collect: bool = True, equity_data: bool = False\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Deserialize the stored results or return the LazyFrame, and optionally collect them into a Polars DataFrame.\n\n    Parameters\n    ----------\n    collect : bool, optional\n        If True, collects the deserialized LazyFrame into a DataFrame.\n        Default is True.\n    equity_data : bool, optional\n        If True, processes equity_data instead of results.\n        Default is False.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The results as a Polars LazyFrame or DataFrame,\n        depending on the collect parameter.\n\n    Raises\n    ------\n    HumblDataError\n        If no results or equity data are found to process\n    \"\"\"\n    data = self.equity_data if equity_data else self.results\n\n    if data is None:\n        raise HumblDataError(\"No data found.\")\n\n    if isinstance(data, pl.LazyFrame):\n        out = data\n    elif isinstance(data, str):\n        with io.StringIO(data) as data_io:\n            out = pl.LazyFrame.deserialize(data_io, format=\"json\")\n    elif isinstance(data, bytes):\n        with io.BytesIO(data) as data_io:\n            out = pl.LazyFrame.deserialize(data_io, format=\"binary\")\n    else:\n        raise HumblDataError(\n            \"Invalid data type. Expected LazyFrame or serialized string.\"\n        )\n\n    if collect:\n        out = out.collect()\n\n    return out\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_df \u00a4 <pre><code>to_df(collect: bool = True, equity_data: bool = False) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Alias for the <code>to_polars</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>collect</code> <code>bool</code> <p>If True, collects the deserialized LazyFrame into a DataFrame. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The deserialized results as a Polars LazyFrame or DataFrame, depending on the collect parameter.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_df(\n    self, collect: bool = True, equity_data: bool = False\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Alias for the `to_polars` method.\n\n    Parameters\n    ----------\n    collect : bool, optional\n        If True, collects the deserialized LazyFrame into a DataFrame.\n        Default is True.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The deserialized results as a Polars LazyFrame or DataFrame,\n        depending on the collect parameter.\n    \"\"\"\n    return self.to_polars(collect=collect, equity_data=equity_data)\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_pandas \u00a4 <pre><code>to_pandas(equity_data: bool = False) -&gt; DataFrame\n</code></pre> <p>Convert the results to a Pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The results as a Pandas DataFrame.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_pandas(self, equity_data: bool = False) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert the results to a Pandas DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The results as a Pandas DataFrame.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_pandas()\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_numpy \u00a4 <pre><code>to_numpy(equity_data: bool = False) -&gt; ndarray\n</code></pre> <p>Convert the results to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The results as a NumPy array.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_numpy(self, equity_data: bool = False) -&gt; np.ndarray:\n    \"\"\"\n    Convert the results to a NumPy array.\n\n    Returns\n    -------\n    np.ndarray\n        The results as a NumPy array.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_numpy()\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_dict \u00a4 <pre><code>to_dict(row_wise: bool = False, equity_data: bool = False, as_series: bool = True) -&gt; dict | list[dict]\n</code></pre> <p>Transform the stored data into a dictionary or a list of dictionaries.</p> <p>This method allows for the conversion of the internal data representation into a more universally accessible format, either aggregating the entire dataset into a single dictionary (column-wise) or breaking it down into a list of dictionaries, each representing a row in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>row_wise</code> <code>bool</code> <p>Determines the format of the output. If set to True, the method returns a list of dictionaries, with each dictionary representing a row and its corresponding data as key-value pairs. If set to False, the method returns a single dictionary, with column names as keys and lists of column data as values. Default is False.</p> <code>False</code> <code>equity_data</code> <code>bool</code> <p>A flag to specify whether to use equity-specific data for the conversion. This parameter allows for flexibility in handling different types of data stored within the object. Default is False.</p> <code>False</code> <code>as_series</code> <code>bool</code> <p>If True, the method returns a pl.Series with values as Series. If False, the method returns a dict with values as List[Any]. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict | list[dict]</code> <p>Depending on the <code>row_wise</code> parameter, either a dictionary mapping column names to lists of values (if <code>row_wise</code> is False) or a list of dictionaries, each representing a row in the dataset (if <code>row_wise</code> is True).</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_dict(\n    self,\n    row_wise: bool = False,\n    equity_data: bool = False,\n    as_series: bool = True,\n) -&gt; dict | list[dict]:\n    \"\"\"\n    Transform the stored data into a dictionary or a list of dictionaries.\n\n    This method allows for the conversion of the internal data\n    representation into a more universally accessible format, either\n    aggregating the entire dataset into a single dictionary (column-wise)\n    or breaking it down into a list of dictionaries, each representing a\n    row in the dataset.\n\n    Parameters\n    ----------\n    row_wise : bool, optional\n        Determines the format of the output. If set to True, the method\n        returns a list of dictionaries, with each dictionary representing a\n        row and its corresponding data as key-value pairs. If set to False,\n        the method returns a single dictionary, with column names as keys\n        and lists of column data as values. Default is False.\n\n    equity_data : bool, optional\n        A flag to specify whether to use equity-specific data for the\n        conversion. This parameter allows for flexibility in handling\n        different types of data stored within the object. Default is\n        False.\n    as_series : bool, optional\n        If True, the method returns a pl.Series with values as Series. If\n        False, the method returns a dict with values as List[Any].\n        Default is True.\n\n    Returns\n    -------\n    dict | list[dict]\n        Depending on the `row_wise` parameter, either a dictionary mapping column names to lists of values (if `row_wise` is False) or a list of dictionaries, each representing a row in the dataset (if `row_wise` is True).\n    \"\"\"\n    if row_wise:\n        return self.to_polars(\n            collect=True, equity_data=equity_data\n        ).to_dicts()\n    return self.to_polars(collect=True, equity_data=equity_data).to_dict(\n        as_series=as_series\n    )\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_arrow \u00a4 <pre><code>to_arrow(equity_data: bool = False) -&gt; Table\n</code></pre> <p>Convert the results to an Arrow Table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>The results as an Arrow Table.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_arrow(self, equity_data: bool = False) -&gt; pa.Table:\n    \"\"\"\n    Convert the results to an Arrow Table.\n\n    Returns\n    -------\n    pa.Table\n        The results as an Arrow Table.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_arrow()\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_struct \u00a4 <pre><code>to_struct(name: str = 'results', equity_data: bool = False) -&gt; Series\n</code></pre> <p>Convert the results to a struct.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the struct. Default is \"results\".</p> <code>'results'</code> <p>Returns:</p> Type Description <code>Struct</code> <p>The results as a struct.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_struct(\n    self, name: str = \"results\", equity_data: bool = False\n) -&gt; pl.Series:\n    \"\"\"\n    Convert the results to a struct.\n\n    Parameters\n    ----------\n    name : str, optional\n        The name of the struct. Default is \"results\".\n\n    Returns\n    -------\n    pl.Struct\n        The results as a struct.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_struct(\n        name=name\n    )\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.to_json \u00a4 <pre><code>to_json(equity_data: bool = False, chart: bool = False) -&gt; str | list[str]\n</code></pre> <p>Convert the results to a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>equity_data</code> <code>bool</code> <p>A flag to specify whether to use equity-specific data for the conversion. Default is False.</p> <code>False</code> <code>chart</code> <code>bool</code> <p>If True, return all generated charts as a JSON string instead of returning the results. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The results or charts as a JSON string.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If chart is True but no charts are available.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_json(\n    self, equity_data: bool = False, chart: bool = False\n) -&gt; str | list[str]:\n    \"\"\"\n    Convert the results to a JSON string.\n\n    Parameters\n    ----------\n    equity_data : bool, optional\n        A flag to specify whether to use equity-specific data for the\n        conversion. Default is False.\n    chart : bool, optional\n        If True, return all generated charts as a JSON string instead of\n        returning the results. Default is False.\n\n    Returns\n    -------\n    str\n        The results or charts as a JSON string.\n\n    Raises\n    ------\n    HumblDataError\n        If chart is True but no charts are available.\n    \"\"\"\n    import json\n    from datetime import date, datetime\n\n    from humbldata.core.standard_models.abstract.errors import (\n        HumblDataError,\n    )\n\n    def json_serial(obj):\n        \"\"\"JSON serializer for objects not serializable by default json code.\"\"\"\n        if isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n        msg = f\"Type {type(obj)} not serializable\"\n        raise TypeError(msg)\n\n    if chart:\n        if self.chart is None:\n            msg = f\"You set `.to_json(chart=True)` but there were no charts. Make sure `chart=True` in {self.command_params.__class__.__name__}\"\n            raise HumblDataError(msg)\n\n        if isinstance(self.chart, list):\n            return [\n                chart.content\n                for chart in self.chart\n                if chart and chart.content\n            ]\n        else:\n            return self.chart.content\n    else:\n        data = self.to_polars(\n            collect=True, equity_data=equity_data\n        ).to_dict(as_series=False)\n        return json.dumps(data, default=json_serial)\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.is_empty \u00a4 <pre><code>is_empty(equity_data: bool = False) -&gt; bool\n</code></pre> <p>Check if the results are empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the results are empty, False otherwise.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def is_empty(self, equity_data: bool = False) -&gt; bool:\n    \"\"\"\n    Check if the results are empty.\n\n    Returns\n    -------\n    bool\n        True if the results are empty, False otherwise.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).is_empty()\n</code></pre> <code></code> humbldata.core.standard_models.abstract.humblobject.HumblObject.show \u00a4 <pre><code>show() -&gt; None\n</code></pre> <p>Show the chart.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Show the chart.\"\"\"\n    if isinstance(self.chart, list):\n        for chart in self.chart:\n            if chart and chart.fig:\n                chart.fig.show()\n            else:\n                msg = \"Chart object is missing or incomplete.\"\n                raise HumblDataError(msg)\n    elif not self.chart or not self.chart.fig:\n        msg = \"Chart not found.\"\n        raise HumblDataError(msg)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.tagged","title":"humbldata.core.standard_models.abstract.tagged","text":"<p>An ABSTRACT DATA MODEL, Tagged, to be inherited by other models as identifier.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.tagged.Tagged","title":"humbldata.core.standard_models.abstract.tagged.Tagged","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class to represent an object tagged with a uuid7.</p> Source code in <code>src/humbldata/core/standard_models/abstract/tagged.py</code> <pre><code>class Tagged(BaseModel):\n    \"\"\"A class to represent an object tagged with a uuid7.\"\"\"\n\n    id: str = Field(default_factory=uuid7str, alias=\"_id\")\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio","title":"humbldata.core.standard_models.portfolio","text":"<p>Context: Portfolio || Category: Analytics.</p> <p>This module defines the QueryParams and Data classes for the Portfolio context.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio.analytics","title":"humbldata.core.standard_models.portfolio.analytics","text":""},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio.analytics.etf_category","title":"humbldata.core.standard_models.portfolio.analytics.etf_category","text":"<p>UserTable Standard Model.</p> <p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>This module is used to define the QueryParams and Data model for the UserTable command.</p> humbldata.core.standard_models.portfolio.analytics.etf_category.ETFCategoryData \u00a4 <p>             Bases: <code>Data</code></p> <p>Data model for the etf_category command, a Pandera.Polars Model.</p> <p>Used for simple validation of ETF category data for the UserTableFetcher internal logic <code>aggregate_user_table_data()</code></p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/etf_category.py</code> <pre><code>class ETFCategoryData(Data):\n    \"\"\"\n    Data model for the etf_category command, a Pandera.Polars Model.\n\n    Used for simple validation of ETF category data for the UserTableFetcher\n    internal logic `aggregate_user_table_data()`\n    \"\"\"\n\n    symbol: str = pa.Field(\n        default=None,\n        title=\"Symbol\",\n        description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"),\n    )\n    category: pl.Utf8 | None = pa.Field(\n        default=None,\n        title=\"Category/Sector\",\n        description=QUERY_DESCRIPTIONS.get(\"category\", \"\"),\n        nullable=True,\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio.analytics.user_table","title":"humbldata.core.standard_models.portfolio.analytics.user_table","text":"<p>UserTable Standard Model.</p> <p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>This module is used to define the QueryParams and Data model for the UserTable command.</p> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableQueryParams \u00a4 <p>             Bases: <code>QueryParams</code></p> <p>QueryParams model for the UserTable command, a Pydantic v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | set[str]</code> <p>The symbol or ticker of the stock(s). Can be a single symbol, a comma-separated string, or a list/set of symbols. Default is \"AAPL\". Examples: \"AAPL\", \"AAPL,MSFT\", [\"AAPL\", \"MSFT\"] All inputs will be converted to uppercase.</p> required Notes <p>The <code>symbols</code> input will be processed to ensure all symbols are uppercase and properly formatted, regardless of the input format.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>class UserTableQueryParams(QueryParams):\n    \"\"\"\n    QueryParams model for the UserTable command, a Pydantic v2 model.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | set[str]\n        The symbol or ticker of the stock(s). Can be a single symbol, a comma-separated string,\n        or a list/set of symbols. Default is \"AAPL\".\n        Examples: \"AAPL\", \"AAPL,MSFT\", [\"AAPL\", \"MSFT\"]\n        All inputs will be converted to uppercase.\n\n    Notes\n    -----\n    The `symbols` input will be processed to ensure all symbols are uppercase\n    and properly formatted, regardless of the input format.\n    \"\"\"\n\n    symbols: str | list[str] | set[str] = pa.Field(\n        default=\"AAPL\",\n        title=\"Symbol\",\n        description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"),\n    )\n\n    @field_validator(\"symbols\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n        \"\"\"\n        Convert the stock symbol to uppercase.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        Union[str, List[str]]\n            The uppercase stock symbol or a comma-separated string of uppercase\n            symbols.\n        \"\"\"\n        # Handle empty inputs\n        if not v:\n            return []\n        # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n        v = v.split(\",\") if isinstance(v, str) else v\n\n        # Trim whitespace and check if all elements in the list are strings\n        if not all(isinstance(item.strip(), str) for item in v):\n            msg = \"Every element in `symbol` list must be a `str`\"\n            raise ValueError(msg)\n\n        # Convert all elements to uppercase, trim whitespace, and join them with a comma\n        return [symbol.strip().upper() for symbol in v]\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableQueryParams.upper_symbol <code>classmethod</code> \u00a4 <pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; str | list[str]\n</code></pre> <p>Convert the stock symbol to uppercase.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>Union[str, List[str]]</code> <p>The uppercase stock symbol or a comma-separated string of uppercase symbols.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>@field_validator(\"symbols\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n    \"\"\"\n    Convert the stock symbol to uppercase.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    Union[str, List[str]]\n        The uppercase stock symbol or a comma-separated string of uppercase\n        symbols.\n    \"\"\"\n    # Handle empty inputs\n    if not v:\n        return []\n    # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n    v = v.split(\",\") if isinstance(v, str) else v\n\n    # Trim whitespace and check if all elements in the list are strings\n    if not all(isinstance(item.strip(), str) for item in v):\n        msg = \"Every element in `symbol` list must be a `str`\"\n        raise ValueError(msg)\n\n    # Convert all elements to uppercase, trim whitespace, and join them with a comma\n    return [symbol.strip().upper() for symbol in v]\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableData \u00a4 <p>             Bases: <code>Data</code></p> <p>Data model for the user_table command, a Pandera.Polars Model.</p> <p>This Data model is used to validate data in the <code>.transform_data()</code> method of the <code>UserTableFetcher</code> class.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>Utf8</code> <p>The stock symbol.</p> <code>last_price</code> <code>Float64</code> <p>The last known price of the stock.</p> <code>buy_price</code> <code>Float64</code> <p>The recommended buy price for the stock.</p> <code>sell_price</code> <code>Float64</code> <p>The recommended sell price for the stock.</p> <code>ud_pct</code> <code>Utf8</code> <p>The upside/downside percentage.</p> <code>ud_ratio</code> <code>Float64</code> <p>The upside/downside ratio.</p> <code>asset_class</code> <code>Utf8</code> <p>The asset class of the stock.</p> <code>sector</code> <code>Utf8</code> <p>The sector of the stock.</p> <code>humbl_suggestion</code> <code>Utf8 | None</code> <p>The suggestion provided by HUMBL.</p> <p>Methods:</p> Name Description <code>None</code> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>class UserTableData(Data):\n    \"\"\"\n    Data model for the user_table command, a Pandera.Polars Model.\n\n    This Data model is used to validate data in the `.transform_data()` method of the `UserTableFetcher` class.\n\n    Attributes\n    ----------\n    symbol : pl.Utf8\n        The stock symbol.\n    last_price : pl.Float64\n        The last known price of the stock.\n    buy_price : pl.Float64\n        The recommended buy price for the stock.\n    sell_price : pl.Float64\n        The recommended sell price for the stock.\n    ud_pct : pl.Utf8\n        The upside/downside percentage.\n    ud_ratio : pl.Float64\n        The upside/downside ratio.\n    asset_class : pl.Utf8\n        The asset class of the stock.\n    sector : pl.Utf8\n        The sector of the stock.\n    humbl_suggestion : pl.Utf8 | None\n        The suggestion provided by HUMBL.\n\n    Methods\n    -------\n    None\n\n    \"\"\"\n\n    symbol: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Symbol\",\n        description=DATA_DESCRIPTIONS.get(\"symbol\", \"\"),\n        alias=\"(symbols|symbol)\",\n        regex=True,\n    )\n    last_price: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Last Price\",\n        description=DATA_DESCRIPTIONS.get(\"last_price\", \"\"),\n    )\n    buy_price: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Buy Price\",\n        description=DATA_DESCRIPTIONS.get(\"buy_price\", \"\"),\n    )\n    sell_price: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Sell Price\",\n        description=DATA_DESCRIPTIONS.get(\"sell_price\", \"\"),\n    )\n    ud_pct: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Upside/Downside Percentage\",\n        description=DATA_DESCRIPTIONS.get(\"ud_pct\", \"\"),\n    )\n    ud_ratio: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Upside/Downside Ratio\",\n        description=DATA_DESCRIPTIONS.get(\"ud_ratio\", \"\"),\n    )\n    asset_class: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Asset Class\",\n        description=DATA_DESCRIPTIONS.get(\"asset_class\", \"\"),\n    )\n    sector: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Sector\",\n        description=DATA_DESCRIPTIONS.get(\"sector\", \"\"),\n        nullable=True,\n    )\n    humbl_suggestion: pl.Utf8 | None = pa.Field(\n        default=None,\n        title=\"humblSuggestion\",\n        description=QUERY_DESCRIPTIONS.get(\"humbl_suggestion\", \"\"),\n    )\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher \u00a4 <p>Fetcher for the UserTable command.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>PortfolioQueryParams</code> <p>The context parameters for the Portfolio query.</p> required <code>command_params</code> <code>UserTableQueryParams</code> <p>The command-specific parameters for the UserTable query.</p> required <p>Attributes:</p> Name Type Description <code>context_params</code> <code>PortfolioQueryParams</code> <p>Stores the context parameters passed during initialization.</p> <code>command_params</code> <code>UserTableQueryParams</code> <p>Stores the command-specific parameters passed during initialization.</p> <code>data</code> <code>DataFrame</code> <p>The raw data extracted from the data provider, before transformation.</p> <p>Methods:</p> Name Description <code>transform_query</code> <p>Transform the command-specific parameters into a query.</p> <code>extract_data</code> <p>Extracts the data from the provider and returns it as a Polars DataFrame.</p> <code>transform_data</code> <p>Transforms the command-specific data according to the UserTable logic.</p> <code>fetch_data</code> <p>Execute TET Pattern.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>results : UserTableData     Serializable results. provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']     Provider name. warnings : Optional[List[Warning_]]     List of warnings. chart : Optional[Chart]     Chart object. context_params : PortfolioQueryParams     Context-specific parameters. command_params : UserTableQueryParams     Command-specific parameters.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>class UserTableFetcher:\n    \"\"\"\n    Fetcher for the UserTable command.\n\n    Parameters\n    ----------\n    context_params : PortfolioQueryParams\n        The context parameters for the Portfolio query.\n    command_params : UserTableQueryParams\n        The command-specific parameters for the UserTable query.\n\n    Attributes\n    ----------\n    context_params : PortfolioQueryParams\n        Stores the context parameters passed during initialization.\n    command_params : UserTableQueryParams\n        Stores the command-specific parameters passed during initialization.\n    data : pl.DataFrame\n        The raw data extracted from the data provider, before transformation.\n\n    Methods\n    -------\n    transform_query()\n        Transform the command-specific parameters into a query.\n    extract_data()\n        Extracts the data from the provider and returns it as a Polars DataFrame.\n    transform_data()\n        Transforms the command-specific data according to the UserTable logic.\n    fetch_data()\n        Execute TET Pattern.\n\n    Returns\n    -------\n    HumblObject\n        results : UserTableData\n            Serializable results.\n        provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']\n            Provider name.\n        warnings : Optional[List[Warning_]]\n            List of warnings.\n        chart : Optional[Chart]\n            Chart object.\n        context_params : PortfolioQueryParams\n            Context-specific parameters.\n        command_params : UserTableQueryParams\n            Command-specific parameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: PortfolioQueryParams,\n        command_params: UserTableQueryParams,\n    ):\n        \"\"\"\n        Initialize the UserTableFetcher with context and command parameters.\n\n        Parameters\n        ----------\n        context_params : PortfolioQueryParams\n            The context parameters for the Portfolio query.\n        command_params : UserTableQueryParams\n            The command-specific parameters for the UserTable query.\n        \"\"\"\n        self.context_params = context_params\n        self.command_params = command_params\n\n    def transform_query(self):\n        \"\"\"\n        Transform the command-specific parameters into a query.\n\n        If command_params is not provided, it initializes a default UserTableQueryParams object.\n        \"\"\"\n        if not self.command_params:\n            self.command_params = None\n            # Set Default Arguments\n            self.command_params: UserTableQueryParams = UserTableQueryParams()\n        else:\n            self.command_params: UserTableQueryParams = UserTableQueryParams(\n                **self.command_params\n            )\n\n    async def extract_data(self):\n        \"\"\"\n        Extract the data from the provider and returns it as a Polars DataFrame.\n\n        Returns\n        -------\n        pl.DataFrame\n            The extracted data as a Polars DataFrame.\n\n        \"\"\"\n        self.etf_data = await aget_etf_category(self.context_params.symbols)\n\n        # Dates are automatically selected based on membership\n        self.toolbox = Toolbox(\n            symbols=self.context_params.symbols,\n            membership=self.context_params.membership,\n            interval=\"1d\",\n        )\n        self.mandelbrot = self.toolbox.technical.mandelbrot_channel().to_polars(\n            collect=False\n        )\n        return self\n\n    async def transform_data(self):\n        \"\"\"\n        Transform the command-specific data according to the user_table logic.\n\n        Returns\n        -------\n        pl.DataFrame\n            The transformed data as a Polars DataFrame\n        \"\"\"\n        # Implement data transformation logic here\n        transformed_data: pl.LazyFrame = await user_table_engine(\n            symbols=self.context_params.symbols,\n            etf_data=self.etf_data,\n            mandelbrot_data=self.mandelbrot,\n            toolbox=self.toolbox,\n        )\n        self.transformed_data = UserTableData(transformed_data.collect()).lazy()\n        self.transformed_data = self.transformed_data.with_columns(\n            pl.col(pl.Float64).round(2)\n        )\n        return self\n\n    @log_start_end(logger=logger)\n    async def fetch_data(self):\n        \"\"\"\n        Execute TET Pattern.\n\n        This method executes the query transformation, data fetching and\n        transformation process by first calling `transform_query` to prepare the query parameters, then\n        extracting the raw data using `extract_data` method, and finally\n        transforming the raw data using `transform_data` method.\n\n        Returns\n        -------\n        HumblObject\n            The HumblObject containing the transformed data and metadata.\n        \"\"\"\n        logger.debug(\"Running .transform_query()\")\n        self.transform_query()\n        logger.debug(\"Running .extract_data()\")\n        await self.extract_data()\n        logger.debug(\"Running .transform_data()\")\n        await self.transform_data()\n\n        return HumblObject(\n            results=self.transformed_data,\n            provider=self.context_params.provider,\n            warnings=None,\n            chart=None,\n            context_params=self.context_params,\n            command_params=self.command_params,\n        )\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.__init__ \u00a4 <pre><code>__init__(context_params: PortfolioQueryParams, command_params: UserTableQueryParams)\n</code></pre> <p>Initialize the UserTableFetcher with context and command parameters.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>PortfolioQueryParams</code> <p>The context parameters for the Portfolio query.</p> required <code>command_params</code> <code>UserTableQueryParams</code> <p>The command-specific parameters for the UserTable query.</p> required Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>def __init__(\n    self,\n    context_params: PortfolioQueryParams,\n    command_params: UserTableQueryParams,\n):\n    \"\"\"\n    Initialize the UserTableFetcher with context and command parameters.\n\n    Parameters\n    ----------\n    context_params : PortfolioQueryParams\n        The context parameters for the Portfolio query.\n    command_params : UserTableQueryParams\n        The command-specific parameters for the UserTable query.\n    \"\"\"\n    self.context_params = context_params\n    self.command_params = command_params\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the command-specific parameters into a query.</p> <p>If command_params is not provided, it initializes a default UserTableQueryParams object.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>def transform_query(self):\n    \"\"\"\n    Transform the command-specific parameters into a query.\n\n    If command_params is not provided, it initializes a default UserTableQueryParams object.\n    \"\"\"\n    if not self.command_params:\n        self.command_params = None\n        # Set Default Arguments\n        self.command_params: UserTableQueryParams = UserTableQueryParams()\n    else:\n        self.command_params: UserTableQueryParams = UserTableQueryParams(\n            **self.command_params\n        )\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.extract_data <code>async</code> \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider and returns it as a Polars DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The extracted data as a Polars DataFrame.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>async def extract_data(self):\n    \"\"\"\n    Extract the data from the provider and returns it as a Polars DataFrame.\n\n    Returns\n    -------\n    pl.DataFrame\n        The extracted data as a Polars DataFrame.\n\n    \"\"\"\n    self.etf_data = await aget_etf_category(self.context_params.symbols)\n\n    # Dates are automatically selected based on membership\n    self.toolbox = Toolbox(\n        symbols=self.context_params.symbols,\n        membership=self.context_params.membership,\n        interval=\"1d\",\n    )\n    self.mandelbrot = self.toolbox.technical.mandelbrot_channel().to_polars(\n        collect=False\n    )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.transform_data <code>async</code> \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data according to the user_table logic.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed data as a Polars DataFrame</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>async def transform_data(self):\n    \"\"\"\n    Transform the command-specific data according to the user_table logic.\n\n    Returns\n    -------\n    pl.DataFrame\n        The transformed data as a Polars DataFrame\n    \"\"\"\n    # Implement data transformation logic here\n    transformed_data: pl.LazyFrame = await user_table_engine(\n        symbols=self.context_params.symbols,\n        etf_data=self.etf_data,\n        mandelbrot_data=self.mandelbrot,\n        toolbox=self.toolbox,\n    )\n    self.transformed_data = UserTableData(transformed_data.collect()).lazy()\n    self.transformed_data = self.transformed_data.with_columns(\n        pl.col(pl.Float64).round(2)\n    )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.fetch_data <code>async</code> \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute TET Pattern.</p> <p>This method executes the query transformation, data fetching and transformation process by first calling <code>transform_query</code> to prepare the query parameters, then extracting the raw data using <code>extract_data</code> method, and finally transforming the raw data using <code>transform_data</code> method.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>The HumblObject containing the transformed data and metadata.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>@log_start_end(logger=logger)\nasync def fetch_data(self):\n    \"\"\"\n    Execute TET Pattern.\n\n    This method executes the query transformation, data fetching and\n    transformation process by first calling `transform_query` to prepare the query parameters, then\n    extracting the raw data using `extract_data` method, and finally\n    transforming the raw data using `transform_data` method.\n\n    Returns\n    -------\n    HumblObject\n        The HumblObject containing the transformed data and metadata.\n    \"\"\"\n    logger.debug(\"Running .transform_query()\")\n    self.transform_query()\n    logger.debug(\"Running .extract_data()\")\n    await self.extract_data()\n    logger.debug(\"Running .transform_data()\")\n    await self.transform_data()\n\n    return HumblObject(\n        results=self.transformed_data,\n        provider=self.context_params.provider,\n        warnings=None,\n        chart=None,\n        context_params=self.context_params,\n        command_params=self.command_params,\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio.PortfolioQueryParams","title":"humbldata.core.standard_models.portfolio.PortfolioQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>Query parameters for the PortfolioController.</p> <p>This class defines the query parameters used by the PortfolioController.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str or list of str</code> <p>The stock symbol(s) to query. Default is \"AAPL\".</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider for historical price data. Default is \"yahoo\".</p> required <code>membership</code> <code>Literal['anonymous', 'humblPEON', 'humblPREMIUM', 'humblPOWER', 'humblPERMANENT', 'admin']</code> <p>The membership level of the user accessing the data. Default is \"anonymous\".</p> required <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str or list of str</code> <p>The stock symbol(s) to query.</p> <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider for historical price data.</p> <code>membership</code> <code>Literal['anonymous', 'humblPEON', 'humblPREMIUM', 'humblPOWER', 'humblPERMANENT', 'admin']</code> <p>The membership level of the user.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/__init__.py</code> <pre><code>class PortfolioQueryParams(QueryParams):\n    \"\"\"\n    Query parameters for the PortfolioController.\n\n    This class defines the query parameters used by the PortfolioController.\n\n    Parameters\n    ----------\n    symbol : str or list of str\n        The stock symbol(s) to query. Default is \"AAPL\".\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS\n        The data provider for historical price data. Default is \"yahoo\".\n    membership : Literal[\"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"humblPERMANENT\", \"admin\"]\n        The membership level of the user accessing the data. Default is \"anonymous\".\n\n    Attributes\n    ----------\n    symbol : str or list of str\n        The stock symbol(s) to query.\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS\n        The data provider for historical price data.\n    membership : Literal[\"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"humblPERMANENT\", \"admin\"]\n        The membership level of the user.\n    \"\"\"\n\n    symbols: str | list[str] = Field(\n        default=[\"AAPL\"],\n        title=\"Symbols\",\n        description=QUERY_DESCRIPTIONS.get(\"symbols\", \"\"),\n    )\n    provider: OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS = Field(\n        default=\"yfinance\",\n        title=\"Provider\",\n        description=QUERY_DESCRIPTIONS.get(\"provider\", \"\"),\n    )\n    membership: Literal[\n        \"anonymous\",\n        \"humblPEON\",\n        \"humblPREMIUM\",\n        \"humblPOWER\",\n        \"humblPERMANENT\",\n        \"admin\",\n    ] = Field(\n        default=\"anonymous\",\n        title=\"Membership\",\n        description=QUERY_DESCRIPTIONS.get(\"membership\", \"\"),\n    )\n\n    @field_validator(\"symbols\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n        \"\"\"\n        Convert the stock symbols to uppercase and remove empty strings.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        List[str]\n            A list of uppercase stock symbols with empty strings removed.\n        \"\"\"\n        # Handle empty inputs\n        if not v:\n            return []\n\n        # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n        v = v.split(\",\") if isinstance(v, str) else list(v)\n\n        # Convert all elements to uppercase, trim whitespace, and remove empty strings\n        valid_symbols = [\n            symbol.strip().upper() for symbol in v if symbol.strip()\n        ]\n\n        if not valid_symbols:\n            msg = \"At least one valid symbol (str) must be provided\"\n            raise ValueError(msg)\n\n        return valid_symbols\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio.PortfolioQueryParams.upper_symbol","title":"humbldata.core.standard_models.portfolio.PortfolioQueryParams.upper_symbol  <code>classmethod</code>","text":"<pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; list[str]\n</code></pre> <p>Convert the stock symbols to uppercase and remove empty strings.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of uppercase stock symbols with empty strings removed.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/__init__.py</code> <pre><code>@field_validator(\"symbols\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n    \"\"\"\n    Convert the stock symbols to uppercase and remove empty strings.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    List[str]\n        A list of uppercase stock symbols with empty strings removed.\n    \"\"\"\n    # Handle empty inputs\n    if not v:\n        return []\n\n    # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n    v = v.split(\",\") if isinstance(v, str) else list(v)\n\n    # Convert all elements to uppercase, trim whitespace, and remove empty strings\n    valid_symbols = [\n        symbol.strip().upper() for symbol in v if symbol.strip()\n    ]\n\n    if not valid_symbols:\n        msg = \"At least one valid symbol (str) must be provided\"\n        raise ValueError(msg)\n\n    return valid_symbols\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.portfolio.PortfolioData","title":"humbldata.core.standard_models.portfolio.PortfolioData","text":"<p>             Bases: <code>Data</code></p> <p>The Data for the PortfolioController.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/__init__.py</code> <pre><code>class PortfolioData(Data):\n    \"\"\"\n    The Data for the PortfolioController.\n    \"\"\"\n\n    # Add your data model fields here\n    pass\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox","title":"humbldata.core.standard_models.toolbox","text":"<p>Context: Toolbox || Category: Standardized Framework Model.</p> <p>This module defines the QueryParams and Data classes for the Toolbox context. THis is where all of the context(s) of your project go. The STANDARD MODELS for categories and subsequent commands are nested here.</p> <p>Classes:</p> Name Description <code>ToolboxQueryParams</code> <p>Query parameters for the ToolboxController.</p> <code>ToolboxData</code> <p>A Pydantic model that defines the data returned by the ToolboxController.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>The symbol/ticker of the stock.</p> <code>interval</code> <code>Optional[str]</code> <p>The interval of the data. Defaults to '1d'.</p> <code>start_date</code> <code>str</code> <p>The start date of the data.</p> <code>end_date</code> <code>str</code> <p>The end date of the data.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.fundamental","title":"humbldata.core.standard_models.toolbox.fundamental","text":""},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass","text":"<p>HumblCompass Standard Model.</p> <p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>This module is used to define the QueryParams and Data model for the HumblCompass command.</p> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.AssetRecommendation \u00a4 <p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Asset recommendation categories.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class AssetRecommendation(str, Enum):\n    \"\"\"Asset recommendation categories.\"\"\"\n\n    EQUITIES = \"Equities\"\n    CREDIT = \"Credit\"\n    COMMODITIES = \"Commodities\"\n    FX = \"FX\"\n    FIXED_INCOME = \"Fixed Income\"\n    USD = \"USD\"\n    GOLD = \"Gold\"\n    TECHNOLOGY = \"Technology\"\n    CONSUMER_DISCRETIONARY = \"Consumer Discretionary\"\n    MATERIALS = \"Materials\"\n    INDUSTRIALS = \"Industrials\"\n    UTILITIES = \"Utilities\"\n    REITS = \"REITs\"\n    CONSUMER_STAPLES = \"Consumer Staples\"\n    FINANCIALS = \"Financials\"\n    ENERGY = \"Energy\"\n    HEALTH_CARE = \"Health Care\"\n    TELECOM = \"Telecom\"\n    HIGH_BETA = \"High Beta\"\n    MOMENTUM = \"Momentum\"\n    CYCLICALS = \"Cyclicals\"\n    SECULAR_GROWTH = \"Secular Growth\"\n    LOW_BETA = \"Low Beta\"\n    DEFENSIVES = \"Defensives\"\n    VALUE = \"Value\"\n    DIVIDEND_YIELD = \"Dividend Yield\"\n    QUALITY = \"Quality\"\n    CYCLICAL_GROWTH = \"Cyclical Growth\"\n    SMALL_CAPS = \"Small Caps\"\n    MID_CAPS = \"Mid Caps\"\n    BDCS = \"BDCs\"\n    CONVERTIBLES = \"Convertibles\"\n    HY_CREDIT = \"HY Credit\"\n    EM_DEBT = \"EM Debt\"\n    TIPS = \"TIPS\"\n    SHORT_DURATION_TREASURIES = \"Short Duration Treasuries\"\n    MORTGAGE_BACKED_SECURITIES = \"Mortgage Backed Securities\"\n    MEDIUM_DURATION_TREASURIES = \"Medium Duration Treasuries\"\n    LONG_DURATION_TREASURIES = \"Long Duration Treasuries\"\n    IG_CREDIT = \"Investment Grade Credit\"\n    MUNIS = \"Municipal Bonds\"\n    PREFERREDS = \"Preferreds\"\n    EM_LOCAL_CURRENCY = \"Emerging Market Local Currency\"\n    LEVERAGED_LOANS = \"Leveraged Loans\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.RecommendationCategory \u00a4 <p>             Bases: <code>BaseModel</code></p> <p>Category-specific recommendations with rationale.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class RecommendationCategory(BaseModel):\n    \"\"\"Category-specific recommendations with rationale.\"\"\"\n\n    best: list[AssetRecommendation]\n    worst: list[AssetRecommendation]\n    rationale: str\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.RegimeRecommendations \u00a4 <p>             Bases: <code>BaseModel</code></p> <p>Complete set of recommendations for a specific regime.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class RegimeRecommendations(BaseModel):\n    \"\"\"Complete set of recommendations for a specific regime.\"\"\"\n\n    asset_classes: RecommendationCategory\n    equity_sectors: RecommendationCategory\n    equity_factors: RecommendationCategory\n    fixed_income: RecommendationCategory\n    regime_description: str\n    key_risks: list[str]\n    last_updated: datetime = Field(default_factory=datetime.utcnow)\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassQueryParams \u00a4 <p>             Bases: <code>QueryParams</code></p> <p>QueryParams model for the HumblCompass command, a Pydantic v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>country</code> <code>Literal</code> <p>The country or group of countries to collect humblCOMPASS data for.</p> required <code>cli_start_date</code> <code>str</code> <p>The adjusted start date for CLI data collection.</p> required <code>cpi_start_date</code> <code>str</code> <p>The adjusted start date for CPI data collection.</p> required <code>z_score</code> <code>Optional[str]</code> <p>The time window for z-score calculation (e.g., \"1 year\", \"18 months\").</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object.</p> required <code>template</code> <code>Literal</code> <p>The template/theme to use for the plotly figure.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class HumblCompassQueryParams(QueryParams):\n    \"\"\"\n    QueryParams model for the HumblCompass command, a Pydantic v2 model.\n\n    Parameters\n    ----------\n    country : Literal\n        The country or group of countries to collect humblCOMPASS data for.\n    cli_start_date : str\n        The adjusted start date for CLI data collection.\n    cpi_start_date : str\n        The adjusted start date for CPI data collection.\n    z_score : Optional[str]\n        The time window for z-score calculation (e.g., \"1 year\", \"18 months\").\n    chart : bool\n        Whether to return a chart object.\n    template : Literal\n        The template/theme to use for the plotly figure.\n    \"\"\"\n\n    country: Literal[\n        \"g20\",\n        \"g7\",\n        \"asia5\",\n        \"north_america\",\n        \"europe4\",\n        \"australia\",\n        \"brazil\",\n        \"canada\",\n        \"china\",\n        \"france\",\n        \"germany\",\n        \"india\",\n        \"indonesia\",\n        \"italy\",\n        \"japan\",\n        \"mexico\",\n        \"south_africa\",\n        \"south_korea\",\n        \"spain\",\n        \"turkey\",\n        \"united_kingdom\",\n        \"united_states\",\n        \"all\",\n    ] = Field(\n        default=\"united_states\",\n        title=\"Country for humblCOMPASS data\",\n        description=HUMBLCOMPASS_QUERY_DESCRIPTIONS.get(\"country\", \"\"),\n    )\n    cli_start_date: str = Field(\n        default=None,\n        title=\"Adjusted start date for CLI data\",\n        description=\"The adjusted start date for CLI data collection.\",\n    )\n    cpi_start_date: str = Field(\n        default=None,\n        title=\"Adjusted start date for CPI data\",\n        description=\"The adjusted start date for CPI data collection.\",\n    )\n    z_score: str | None = Field(\n        default=None,\n        title=\"Z-score calculation window\",\n        description=\"The time window for z-score calculation (e.g., '1 year', '18 months').\",\n    )\n    chart: bool = Field(\n        default=False,\n        title=\"Results Chart\",\n        description=HUMBLCOMPASS_QUERY_DESCRIPTIONS.get(\"chart\", \"\"),\n    )\n    template: Literal[\n        \"humbl_dark\",\n        \"humbl_light\",\n        \"ggplot2\",\n        \"seaborn\",\n        \"simple_white\",\n        \"plotly\",\n        \"plotly_white\",\n        \"plotly_dark\",\n        \"presentation\",\n        \"xgridoff\",\n        \"ygridoff\",\n        \"gridon\",\n        \"none\",\n    ] = Field(\n        default=\"humbl_dark\",\n        title=\"Plotly Template\",\n        description=HUMBLCOMPASS_QUERY_DESCRIPTIONS.get(\"template\", \"\"),\n    )\n    recommendations: bool = Field(\n        default=False,\n        title=\"Investment Recommendations\",\n        description=\"Whether to include investment recommendations based on the HUMBL regime.\",\n    )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassData \u00a4 <p>             Bases: <code>Data</code></p> <p>Data model for the humbl_compass command, a Pandera.Polars Model.</p> <p>This Data model is used to validate data in the <code>.transform_data()</code> method of the <code>HumblCompassFetcher</code> class.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class HumblCompassData(Data):\n    \"\"\"\n    Data model for the humbl_compass command, a Pandera.Polars Model.\n\n    This Data model is used to validate data in the `.transform_data()` method of the `HumblCompassFetcher` class.\n    \"\"\"\n\n    date_month_start: pl.Date = pa.Field(\n        default=None,\n        title=\"Date\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"date\"],\n    )\n    country: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Country\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"country\"],\n    )\n    cpi: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Consumer Price Index (CPI)\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cpi\"],\n    )\n    cpi_3m_delta: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Consumer Price Index (CPI) 3-Month Delta\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cpi_3m_delta\"],\n    )\n    cpi_zscore: pl.Float64 | None = pa.Field(\n        default=None,\n        title=\"Consumer Price Index (CPI) 1-Year Z-Score\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cpi_1yr_zscore\"],\n    )\n    cli: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Composite Leading Indicator (CLI)\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cli\"],\n    )\n    cli_3m_delta: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Composite Leading Indicator (CLI) 3-Month Delta\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cli_3m_delta\"],\n    )\n    cli_zscore: pl.Float64 | None = pa.Field(\n        default=None,\n        title=\"Composite Leading Indicator (CLI) 1-Year Z-Score\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cli_1yr_zscore\"],\n    )\n    humbl_regime: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"HUMBL Regime\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"humbl_regime\"],\n    )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher \u00a4 <p>Fetcher for the HumblCompass command.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the Toolbox query.</p> required <code>command_params</code> <code>HumblCompassQueryParams</code> <p>The command-specific parameters for the HumblCompass query.</p> required <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>Stores the context parameters passed during initialization.</p> <code>command_params</code> <code>HumblCompassQueryParams</code> <p>Stores the command-specific parameters passed during initialization.</p> <code>data</code> <code>DataFrame</code> <p>The raw data extracted from the data provider, before transformation.</p> <p>Methods:</p> Name Description <code>transform_query</code> <p>Transform the command-specific parameters into a query.</p> <code>extract_data</code> <p>Extracts the data from the provider and returns it as a Polars DataFrame.</p> <code>transform_data</code> <p>Transforms the command-specific data according to the HumblCompass logic.</p> <code>fetch_data</code> <p>Execute TET Pattern.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>results : HumblCompassData     Serializable results. provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']     Provider name. warnings : Optional[List[Warning_]]     List of warnings. chart : Optional[Chart]     Chart object. context_params : ToolboxQueryParams     Context-specific parameters. command_params : HumblCompassQueryParams     Command-specific parameters.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class HumblCompassFetcher:\n    \"\"\"\n    Fetcher for the HumblCompass command.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the Toolbox query.\n    command_params : HumblCompassQueryParams\n        The command-specific parameters for the HumblCompass query.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        Stores the context parameters passed during initialization.\n    command_params : HumblCompassQueryParams\n        Stores the command-specific parameters passed during initialization.\n    data : pl.DataFrame\n        The raw data extracted from the data provider, before transformation.\n\n    Methods\n    -------\n    transform_query()\n        Transform the command-specific parameters into a query.\n    extract_data()\n        Extracts the data from the provider and returns it as a Polars DataFrame.\n    transform_data()\n        Transforms the command-specific data according to the HumblCompass logic.\n    fetch_data()\n        Execute TET Pattern.\n\n    Returns\n    -------\n    HumblObject\n        results : HumblCompassData\n            Serializable results.\n        provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']\n            Provider name.\n        warnings : Optional[List[Warning_]]\n            List of warnings.\n        chart : Optional[Chart]\n            Chart object.\n        context_params : ToolboxQueryParams\n            Context-specific parameters.\n        command_params : HumblCompassQueryParams\n            Command-specific parameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: HumblCompassQueryParams,\n    ):\n        \"\"\"\n        Initialize the HumblCompassFetcher with context and command parameters.\n\n        Parameters\n        ----------\n        context_params : ToolboxQueryParams\n            The context parameters for the Toolbox query.\n        command_params : HumblCompassQueryParams\n            The command-specific parameters for the HumblCompass query.\n        \"\"\"\n        self.context_params = context_params\n        self.command_params = command_params\n\n    def transform_query(self):\n        \"\"\"\n        Transform the command-specific parameters into a query.\n\n        If command_params is not provided, it initializes a default HumblCompassQueryParams object.\n        Calculates adjusted start dates for CLI and CPI data collection.\n        \"\"\"\n        if not self.command_params:\n            self.command_params = HumblCompassQueryParams()\n        elif isinstance(self.command_params, dict):\n            self.command_params = HumblCompassQueryParams(**self.command_params)\n\n        # Calculate adjusted start dates\n        if isinstance(self.context_params.start_date, str):\n            start_date = pl.Series(\n                [datetime.strptime(self.context_params.start_date, \"%Y-%m-%d\")]\n            )\n        else:\n            start_date = pl.Series([self.context_params.start_date])\n\n        # Calculate z-score window in months\n        self.z_score_months = 0\n        if (\n            self.command_params.z_score is not None\n            and self.context_params.membership != \"humblPEON\"\n        ):\n            z_score_months_str = _window_format(\n                self.command_params.z_score, _return_timedelta=False\n            )\n            self.z_score_months = _window_format_monthly(z_score_months_str)\n        elif self.context_params.membership == \"humblPEON\":\n            logger.warning(\n                \"Z-score is not calculated for humblPEON membership level.\"\n            )\n\n        cli_start_date = start_date.dt.offset_by(\n            f\"-{4 + self.z_score_months}mo\"\n        ).dt.strftime(\"%Y-%m-%d\")[0]\n        cpi_start_date = start_date.dt.offset_by(\n            f\"-{3 + self.z_score_months}mo\"\n        ).dt.strftime(\"%Y-%m-%d\")[0]\n\n        # Update the command_params with the new start dates\n        self.command_params = self.command_params.model_copy(\n            update={\n                \"cli_start_date\": cli_start_date,\n                \"cpi_start_date\": cpi_start_date,\n            }\n        )\n\n        logger.info(\n            f\"CLI start date: {self.command_params.cli_start_date} and CPI start date: {self.command_params.cpi_start_date}. \"\n            f\"Dates are adjusted to account for CLI data release lag and z-score calculation window.\"\n        )\n\n    def extract_data(self):\n        \"\"\"\n        Extract the data from the provider and returns it as a Polars DataFrame.\n\n        Returns\n        -------\n        self\n            The HumblCompassFetcher instance with extracted data.\n        \"\"\"\n        # Collect CLI Data\n        self.oecd_cli_data = (\n            obb.economy.composite_leading_indicator(\n                start_date=self.command_params.cli_start_date,\n                end_date=self.context_params.end_date,\n                provider=\"oecd\",\n                country=self.command_params.country,\n            )\n            .to_polars()\n            .lazy()\n            .rename({\"value\": \"cli\"})\n            .with_columns(\n                [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n            )\n        )\n\n        # Collect YoY CPI Data\n        self.oecd_cpi_data = (\n            obb.economy.cpi(\n                start_date=self.command_params.cpi_start_date,\n                end_date=self.context_params.end_date,\n                frequency=\"monthly\",\n                country=self.command_params.country,\n                transform=\"yoy\",\n                provider=\"oecd\",\n                harmonized=False,\n                expenditure=\"total\",\n            )\n            .to_polars()\n            .lazy()\n            .rename({\"value\": \"cpi\"})\n            .with_columns(\n                [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n            )\n        )\n        return self\n\n    def transform_data(self):\n        \"\"\"\n        Transform the command-specific data according to the humbl_compass logic.\n\n        Returns\n        -------\n        self\n            The HumblCompassFetcher instance with transformed data.\n        \"\"\"\n        # Combine CLI and CPI data\n        # CLI data is released before CPI data, so we use a left join\n        combined_data = (\n            self.oecd_cli_data.join(\n                self.oecd_cpi_data,\n                on=[\"date_month_start\", \"country\"],\n                how=\"left\",\n                suffix=\"_cpi\",\n            )\n            .sort(\"date_month_start\")\n            .with_columns(\n                [\n                    pl.col(\"country\").cast(pl.Utf8),\n                    pl.col(\"cli\").cast(pl.Float64),\n                    pl.col(\"cpi\").cast(pl.Float64)\n                    * 100,  # Convert CPI to percentage\n                ]\n            )\n            .rename(\n                {\n                    \"date\": \"date_cli\",\n                }\n            )\n            .select(\n                [\n                    \"date_month_start\",\n                    \"date_cli\",\n                    \"date_cpi\",\n                    \"country\",\n                    \"cli\",\n                    \"cpi\",\n                ]\n            )\n        )\n\n        # Calculate 3-month deltas\n        delta_window = 3\n        transformed_data = combined_data.with_columns(\n            [\n                (pl.col(\"cli\") - pl.col(\"cli\").shift(delta_window)).alias(\n                    \"cli_3m_delta\"\n                ),\n                (pl.col(\"cpi\") - pl.col(\"cpi\").shift(delta_window)).alias(\n                    \"cpi_3m_delta\"\n                ),\n            ]\n        )\n\n        # Add this after calculating 3-month deltas in transform_data()\n        transformed_data = transformed_data.with_columns(\n            [\n                pl.when(\n                    (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n                )\n                .then(pl.lit(\"humblBLOAT\"))\n                .when(\n                    (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n                )\n                .then(pl.lit(\"humblBOUNCE\"))\n                .when(\n                    (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n                )\n                .then(pl.lit(\"humblBOOM\"))\n                .when(\n                    (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n                )\n                .then(pl.lit(\"humblBUST\"))\n                .otherwise(None)\n                .alias(\"humbl_regime\")\n            ]\n        )\n\n        # Calculate z-scores only if self.z_score_months is greater than 0 and membership is not humblPEON\n        if (\n            self.z_score_months &gt; 0\n            and self.context_params.membership != \"humblPEON\"\n        ):\n            transformed_data = transformed_data.with_columns(\n                [\n                    pl.when(\n                        pl.col(\"cli\").count().over(\"country\")\n                        &gt;= self.z_score_months\n                    )\n                    .then(\n                        (\n                            pl.col(\"cli\")\n                            - pl.col(\"cli\").rolling_mean(self.z_score_months)\n                        )\n                        / pl.col(\"cli\").rolling_std(self.z_score_months)\n                    )\n                    .alias(\"cli_zscore\"),\n                    pl.when(\n                        pl.col(\"cpi\").count().over(\"country\")\n                        &gt;= self.z_score_months\n                    )\n                    .then(\n                        (\n                            pl.col(\"cpi\")\n                            - pl.col(\"cpi\").rolling_mean(self.z_score_months)\n                        )\n                        / pl.col(\"cpi\").rolling_std(self.z_score_months)\n                    )\n                    .alias(\"cpi_zscore\"),\n                ]\n            )\n\n        # Select columns based on whether z-scores were calculated\n        columns_to_select = [\n            pl.col(\"date_month_start\"),\n            pl.col(\"country\"),\n            pl.col(\"cpi\").round(2),\n            pl.col(\"cpi_3m_delta\").round(2),\n            pl.col(\"cli\").round(2),\n            pl.col(\"cli_3m_delta\").round(2),\n            pl.col(\"humbl_regime\"),\n        ]\n\n        if (\n            self.z_score_months &gt; 0\n            and self.context_params.membership != \"humblPEON\"\n        ):\n            columns_to_select.extend(\n                [\n                    pl.col(\"cpi_zscore\").round(2),\n                    pl.col(\"cli_zscore\").round(2),\n                ]\n            )\n\n        self.transformed_data = transformed_data.select(columns_to_select)\n\n        # Validate the data using HumblCompassData\n        self.transformed_data = HumblCompassData(\n            self.transformed_data.collect().drop_nulls()  # removes preceding 3 months used for delta calculations\n        ).lazy()\n\n        # Generate chart if requested\n        self.chart = None\n        if self.command_params.chart:\n            self.chart = generate_plots(\n                self.transformed_data,\n                template=ChartTemplate(self.command_params.template),\n            )\n\n        # Add warning if z_score is None\n        if self.command_params.z_score is None:\n            if not hasattr(self, \"warnings\"):\n                self.warnings = []\n            self.warnings.append(\n                HumblDataWarning(\n                    category=\"HumblCompassFetcher\",\n                    message=\"Z-score defaulted to None. No z-score data will be calculated.\",\n                )\n            )\n\n        # Add recommendations if requested\n        if self.command_params.recommendations:\n            latest_regime = (\n                self.transformed_data.select(pl.col(\"humbl_regime\"))\n                .collect()\n                .row(-1)[0]\n            )\n\n            if latest_regime not in REGIME_RECOMMENDATIONS:\n                if not hasattr(self, \"warnings\"):\n                    self.warnings = []\n                self.warnings.append(\n                    HumblDataWarning(\n                        category=\"HumblCompassFetcher\",\n                        message=f\"No recommendations available for regime: {latest_regime}\",\n                    )\n                )\n            else:\n                recommendations = REGIME_RECOMMENDATIONS[latest_regime]\n                if not hasattr(self, \"extra\"):\n                    self.extra = {}\n                self.extra[\"humbl_regime_recommendations\"] = (\n                    recommendations.model_dump()\n                )\n\n        self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n        return self\n\n    @log_start_end(logger=logger)\n    def fetch_data(self):\n        \"\"\"\n        Execute TET Pattern.\n\n        This method executes the query transformation, data fetching and\n        transformation process by first calling `transform_query` to prepare the query parameters, then\n        extracting the raw data using `extract_data` method, and finally\n        transforming the raw data using `transform_data` method.\n\n        Returns\n        -------\n        HumblObject\n            The HumblObject containing the transformed data and metadata.\n        \"\"\"\n        self.transform_query()\n        self.extract_data()\n        self.transform_data()\n\n        # Initialize warnings list if it doesn't exist\n        if not hasattr(self.context_params, \"warnings\"):\n            self.context_params.warnings = []\n\n        # Initialize fetcher warnings if they don't exist\n        if not hasattr(self, \"warnings\"):\n            self.warnings = []\n\n        # Initialize extra dict if it doesn't exist\n        if not hasattr(self, \"extra\"):\n            self.extra = {}\n\n        # Combine warnings from both sources\n        all_warnings = self.context_params.warnings + self.warnings\n\n        return HumblObject(\n            results=self.transformed_data,\n            provider=self.context_params.provider,\n            warnings=all_warnings,  # Use combined warnings\n            chart=self.chart,\n            context_params=self.context_params,\n            command_params=self.command_params,\n            extra=self.extra,  # pipe in extra from transform_data()\n        )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.__init__ \u00a4 <pre><code>__init__(context_params: ToolboxQueryParams, command_params: HumblCompassQueryParams)\n</code></pre> <p>Initialize the HumblCompassFetcher with context and command parameters.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the Toolbox query.</p> required <code>command_params</code> <code>HumblCompassQueryParams</code> <p>The command-specific parameters for the HumblCompass query.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def __init__(\n    self,\n    context_params: ToolboxQueryParams,\n    command_params: HumblCompassQueryParams,\n):\n    \"\"\"\n    Initialize the HumblCompassFetcher with context and command parameters.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the Toolbox query.\n    command_params : HumblCompassQueryParams\n        The command-specific parameters for the HumblCompass query.\n    \"\"\"\n    self.context_params = context_params\n    self.command_params = command_params\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the command-specific parameters into a query.</p> <p>If command_params is not provided, it initializes a default HumblCompassQueryParams object. Calculates adjusted start dates for CLI and CPI data collection.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def transform_query(self):\n    \"\"\"\n    Transform the command-specific parameters into a query.\n\n    If command_params is not provided, it initializes a default HumblCompassQueryParams object.\n    Calculates adjusted start dates for CLI and CPI data collection.\n    \"\"\"\n    if not self.command_params:\n        self.command_params = HumblCompassQueryParams()\n    elif isinstance(self.command_params, dict):\n        self.command_params = HumblCompassQueryParams(**self.command_params)\n\n    # Calculate adjusted start dates\n    if isinstance(self.context_params.start_date, str):\n        start_date = pl.Series(\n            [datetime.strptime(self.context_params.start_date, \"%Y-%m-%d\")]\n        )\n    else:\n        start_date = pl.Series([self.context_params.start_date])\n\n    # Calculate z-score window in months\n    self.z_score_months = 0\n    if (\n        self.command_params.z_score is not None\n        and self.context_params.membership != \"humblPEON\"\n    ):\n        z_score_months_str = _window_format(\n            self.command_params.z_score, _return_timedelta=False\n        )\n        self.z_score_months = _window_format_monthly(z_score_months_str)\n    elif self.context_params.membership == \"humblPEON\":\n        logger.warning(\n            \"Z-score is not calculated for humblPEON membership level.\"\n        )\n\n    cli_start_date = start_date.dt.offset_by(\n        f\"-{4 + self.z_score_months}mo\"\n    ).dt.strftime(\"%Y-%m-%d\")[0]\n    cpi_start_date = start_date.dt.offset_by(\n        f\"-{3 + self.z_score_months}mo\"\n    ).dt.strftime(\"%Y-%m-%d\")[0]\n\n    # Update the command_params with the new start dates\n    self.command_params = self.command_params.model_copy(\n        update={\n            \"cli_start_date\": cli_start_date,\n            \"cpi_start_date\": cpi_start_date,\n        }\n    )\n\n    logger.info(\n        f\"CLI start date: {self.command_params.cli_start_date} and CPI start date: {self.command_params.cpi_start_date}. \"\n        f\"Dates are adjusted to account for CLI data release lag and z-score calculation window.\"\n    )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.extract_data \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider and returns it as a Polars DataFrame.</p> <p>Returns:</p> Type Description <code>self</code> <p>The HumblCompassFetcher instance with extracted data.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def extract_data(self):\n    \"\"\"\n    Extract the data from the provider and returns it as a Polars DataFrame.\n\n    Returns\n    -------\n    self\n        The HumblCompassFetcher instance with extracted data.\n    \"\"\"\n    # Collect CLI Data\n    self.oecd_cli_data = (\n        obb.economy.composite_leading_indicator(\n            start_date=self.command_params.cli_start_date,\n            end_date=self.context_params.end_date,\n            provider=\"oecd\",\n            country=self.command_params.country,\n        )\n        .to_polars()\n        .lazy()\n        .rename({\"value\": \"cli\"})\n        .with_columns(\n            [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n        )\n    )\n\n    # Collect YoY CPI Data\n    self.oecd_cpi_data = (\n        obb.economy.cpi(\n            start_date=self.command_params.cpi_start_date,\n            end_date=self.context_params.end_date,\n            frequency=\"monthly\",\n            country=self.command_params.country,\n            transform=\"yoy\",\n            provider=\"oecd\",\n            harmonized=False,\n            expenditure=\"total\",\n        )\n        .to_polars()\n        .lazy()\n        .rename({\"value\": \"cpi\"})\n        .with_columns(\n            [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n        )\n    )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.transform_data \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data according to the humbl_compass logic.</p> <p>Returns:</p> Type Description <code>self</code> <p>The HumblCompassFetcher instance with transformed data.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def transform_data(self):\n    \"\"\"\n    Transform the command-specific data according to the humbl_compass logic.\n\n    Returns\n    -------\n    self\n        The HumblCompassFetcher instance with transformed data.\n    \"\"\"\n    # Combine CLI and CPI data\n    # CLI data is released before CPI data, so we use a left join\n    combined_data = (\n        self.oecd_cli_data.join(\n            self.oecd_cpi_data,\n            on=[\"date_month_start\", \"country\"],\n            how=\"left\",\n            suffix=\"_cpi\",\n        )\n        .sort(\"date_month_start\")\n        .with_columns(\n            [\n                pl.col(\"country\").cast(pl.Utf8),\n                pl.col(\"cli\").cast(pl.Float64),\n                pl.col(\"cpi\").cast(pl.Float64)\n                * 100,  # Convert CPI to percentage\n            ]\n        )\n        .rename(\n            {\n                \"date\": \"date_cli\",\n            }\n        )\n        .select(\n            [\n                \"date_month_start\",\n                \"date_cli\",\n                \"date_cpi\",\n                \"country\",\n                \"cli\",\n                \"cpi\",\n            ]\n        )\n    )\n\n    # Calculate 3-month deltas\n    delta_window = 3\n    transformed_data = combined_data.with_columns(\n        [\n            (pl.col(\"cli\") - pl.col(\"cli\").shift(delta_window)).alias(\n                \"cli_3m_delta\"\n            ),\n            (pl.col(\"cpi\") - pl.col(\"cpi\").shift(delta_window)).alias(\n                \"cpi_3m_delta\"\n            ),\n        ]\n    )\n\n    # Add this after calculating 3-month deltas in transform_data()\n    transformed_data = transformed_data.with_columns(\n        [\n            pl.when(\n                (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n            )\n            .then(pl.lit(\"humblBLOAT\"))\n            .when(\n                (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n            )\n            .then(pl.lit(\"humblBOUNCE\"))\n            .when(\n                (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n            )\n            .then(pl.lit(\"humblBOOM\"))\n            .when(\n                (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n            )\n            .then(pl.lit(\"humblBUST\"))\n            .otherwise(None)\n            .alias(\"humbl_regime\")\n        ]\n    )\n\n    # Calculate z-scores only if self.z_score_months is greater than 0 and membership is not humblPEON\n    if (\n        self.z_score_months &gt; 0\n        and self.context_params.membership != \"humblPEON\"\n    ):\n        transformed_data = transformed_data.with_columns(\n            [\n                pl.when(\n                    pl.col(\"cli\").count().over(\"country\")\n                    &gt;= self.z_score_months\n                )\n                .then(\n                    (\n                        pl.col(\"cli\")\n                        - pl.col(\"cli\").rolling_mean(self.z_score_months)\n                    )\n                    / pl.col(\"cli\").rolling_std(self.z_score_months)\n                )\n                .alias(\"cli_zscore\"),\n                pl.when(\n                    pl.col(\"cpi\").count().over(\"country\")\n                    &gt;= self.z_score_months\n                )\n                .then(\n                    (\n                        pl.col(\"cpi\")\n                        - pl.col(\"cpi\").rolling_mean(self.z_score_months)\n                    )\n                    / pl.col(\"cpi\").rolling_std(self.z_score_months)\n                )\n                .alias(\"cpi_zscore\"),\n            ]\n        )\n\n    # Select columns based on whether z-scores were calculated\n    columns_to_select = [\n        pl.col(\"date_month_start\"),\n        pl.col(\"country\"),\n        pl.col(\"cpi\").round(2),\n        pl.col(\"cpi_3m_delta\").round(2),\n        pl.col(\"cli\").round(2),\n        pl.col(\"cli_3m_delta\").round(2),\n        pl.col(\"humbl_regime\"),\n    ]\n\n    if (\n        self.z_score_months &gt; 0\n        and self.context_params.membership != \"humblPEON\"\n    ):\n        columns_to_select.extend(\n            [\n                pl.col(\"cpi_zscore\").round(2),\n                pl.col(\"cli_zscore\").round(2),\n            ]\n        )\n\n    self.transformed_data = transformed_data.select(columns_to_select)\n\n    # Validate the data using HumblCompassData\n    self.transformed_data = HumblCompassData(\n        self.transformed_data.collect().drop_nulls()  # removes preceding 3 months used for delta calculations\n    ).lazy()\n\n    # Generate chart if requested\n    self.chart = None\n    if self.command_params.chart:\n        self.chart = generate_plots(\n            self.transformed_data,\n            template=ChartTemplate(self.command_params.template),\n        )\n\n    # Add warning if z_score is None\n    if self.command_params.z_score is None:\n        if not hasattr(self, \"warnings\"):\n            self.warnings = []\n        self.warnings.append(\n            HumblDataWarning(\n                category=\"HumblCompassFetcher\",\n                message=\"Z-score defaulted to None. No z-score data will be calculated.\",\n            )\n        )\n\n    # Add recommendations if requested\n    if self.command_params.recommendations:\n        latest_regime = (\n            self.transformed_data.select(pl.col(\"humbl_regime\"))\n            .collect()\n            .row(-1)[0]\n        )\n\n        if latest_regime not in REGIME_RECOMMENDATIONS:\n            if not hasattr(self, \"warnings\"):\n                self.warnings = []\n            self.warnings.append(\n                HumblDataWarning(\n                    category=\"HumblCompassFetcher\",\n                    message=f\"No recommendations available for regime: {latest_regime}\",\n                )\n            )\n        else:\n            recommendations = REGIME_RECOMMENDATIONS[latest_regime]\n            if not hasattr(self, \"extra\"):\n                self.extra = {}\n            self.extra[\"humbl_regime_recommendations\"] = (\n                recommendations.model_dump()\n            )\n\n    self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.fetch_data \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute TET Pattern.</p> <p>This method executes the query transformation, data fetching and transformation process by first calling <code>transform_query</code> to prepare the query parameters, then extracting the raw data using <code>extract_data</code> method, and finally transforming the raw data using <code>transform_data</code> method.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>The HumblObject containing the transformed data and metadata.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>@log_start_end(logger=logger)\ndef fetch_data(self):\n    \"\"\"\n    Execute TET Pattern.\n\n    This method executes the query transformation, data fetching and\n    transformation process by first calling `transform_query` to prepare the query parameters, then\n    extracting the raw data using `extract_data` method, and finally\n    transforming the raw data using `transform_data` method.\n\n    Returns\n    -------\n    HumblObject\n        The HumblObject containing the transformed data and metadata.\n    \"\"\"\n    self.transform_query()\n    self.extract_data()\n    self.transform_data()\n\n    # Initialize warnings list if it doesn't exist\n    if not hasattr(self.context_params, \"warnings\"):\n        self.context_params.warnings = []\n\n    # Initialize fetcher warnings if they don't exist\n    if not hasattr(self, \"warnings\"):\n        self.warnings = []\n\n    # Initialize extra dict if it doesn't exist\n    if not hasattr(self, \"extra\"):\n        self.extra = {}\n\n    # Combine warnings from both sources\n    all_warnings = self.context_params.warnings + self.warnings\n\n    return HumblObject(\n        results=self.transformed_data,\n        provider=self.context_params.provider,\n        warnings=all_warnings,  # Use combined warnings\n        chart=self.chart,\n        context_params=self.context_params,\n        command_params=self.command_params,\n        extra=self.extra,  # pipe in extra from transform_data()\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.technical","title":"humbldata.core.standard_models.toolbox.technical","text":"<p>Context: Toolbox || Category: Technical.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.technical.realized_volatility","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility","text":"<p>Volatility Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Volatility.</p> <p>This module is used to define the QueryParams and Data model for the Volatility command.</p> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityQueryParams \u00a4 <p>             Bases: <code>QueryParams</code></p> <p>QueryParams for the Realized Volatility command.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>class RealizedVolatilityQueryParams(QueryParams):\n    \"\"\"\n    QueryParams for the Realized Volatility command.\n    \"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityData \u00a4 <p>             Bases: <code>Data</code></p> <p>Data model for the Realized Volatility command.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>class RealizedVolatilityData(Data):\n    \"\"\"\n    Data model for the Realized Volatility command.\n    \"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher \u00a4 <p>             Bases: <code>RealizedVolatilityQueryParams</code></p> <p>Fetcher for the Realized Volatility command.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>class RealizedVolatilityFetcher(RealizedVolatilityQueryParams):\n    \"\"\"\n    Fetcher for the Realized Volatility command.\n    \"\"\"\n\n    data_list: ClassVar[list[RealizedVolatilityData]] = []\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: RealizedVolatilityQueryParams,\n    ):\n        self._context_params = context_params\n        self._command_params = command_params\n\n    def transform_query(self):\n        \"\"\"Transform the params to the command-specific query.\"\"\"\n\n    def extract_data(self):\n        \"\"\"Extract the data from the provider.\"\"\"\n        # Assuming 'obb' is a predefined object in your context\n        df = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbol,\n                start_date=str(self.context_params.start_date),\n                end_date=str(self.context_params.end_date),\n                provider=self.command_params.provider,\n                verbose=not self.command_params.kwargs.get(\"silent\", False),\n                **self.command_params.kwargs,\n            )\n            .to_df()\n            .reset_index()\n        )\n        return df\n\n    def transform_data(self):\n        \"\"\"Transform the command-specific data.\"\"\"\n        # Placeholder for data transformation logic\n\n    def fetch_data(self):\n        \"\"\"Execute the TET pattern.\"\"\"\n        # Call the methods in the desired order\n        query = self.transform_query()\n        raw_data = (\n            self.extract_data()\n        )  # This should use 'query' to fetch the data\n        transformed_data = (\n            self.transform_data()\n        )  # This should transform 'raw_data'\n\n        # Validate with VolatilityData, unpack dict into pydantic row by row\n        return transformed_data\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the params to the command-specific query.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def transform_query(self):\n    \"\"\"Transform the params to the command-specific query.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.extract_data \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def extract_data(self):\n    \"\"\"Extract the data from the provider.\"\"\"\n    # Assuming 'obb' is a predefined object in your context\n    df = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbol,\n            start_date=str(self.context_params.start_date),\n            end_date=str(self.context_params.end_date),\n            provider=self.command_params.provider,\n            verbose=not self.command_params.kwargs.get(\"silent\", False),\n            **self.command_params.kwargs,\n        )\n        .to_df()\n        .reset_index()\n    )\n    return df\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_data \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def transform_data(self):\n    \"\"\"Transform the command-specific data.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.fetch_data \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute the TET pattern.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def fetch_data(self):\n    \"\"\"Execute the TET pattern.\"\"\"\n    # Call the methods in the desired order\n    query = self.transform_query()\n    raw_data = (\n        self.extract_data()\n    )  # This should use 'query' to fetch the data\n    transformed_data = (\n        self.transform_data()\n    )  # This should transform 'raw_data'\n\n    # Validate with VolatilityData, unpack dict into pydantic row by row\n    return transformed_data\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.technical.mandelbrot_channel","title":"humbldata.core.standard_models.toolbox.technical.mandelbrot_channel","text":"<p>Mandelbrot Channel Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Mandelbrot Channel.</p> <p>This module is used to define the QueryParams and Data model for the Mandelbrot Channel command.</p> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelQueryParams \u00a4 <p>             Bases: <code>QueryParams</code></p> <p>QueryParams model for the Mandelbrot Channel command, a Pydantic v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>str</code> <p>The width of the window used for splitting the data into sections for detrending. Defaults to \"1m\".</p> required <code>rv_adjustment</code> <code>bool</code> <p>Whether to adjust the calculation for realized volatility. If True, the data is filtered to only include observations in the same volatility bucket that the stock is currently in. Defaults to True.</p> required <code>rv_method</code> <code>str</code> <p>The method to calculate the realized volatility. Only need to define when rv_adjustment is True. Defaults to \"std\".</p> required <code>rs_method</code> <code>Literal['RS', 'RS_min', 'RS_max', 'RS_mean']</code> <p>The method to use for Range/STD calculation. This is either, min, max or mean of all RS ranges per window. If not defined, just used the most recent RS window. Defaults to \"RS\".</p> required <code>rv_grouped_mean</code> <code>bool</code> <p>Whether to calculate the mean value of realized volatility over multiple window lengths. Defaults to False.</p> required <code>live_price</code> <code>bool</code> <p>Whether to calculate the ranges using the current live price, or the most recent 'close' observation. Defaults to False.</p> required <code>historical</code> <code>bool</code> <p>Whether to calculate the Historical Mandelbrot Channel (over-time), and return a time-series of channels from the start to the end date. If False, the Mandelbrot Channel calculation is done aggregating all of the data into one observation. If True, then it will enable daily observations over-time. Defaults to False.</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object. Defaults to False.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>class MandelbrotChannelQueryParams(QueryParams):\n    \"\"\"\n    QueryParams model for the Mandelbrot Channel command, a Pydantic v2 model.\n\n    Parameters\n    ----------\n    window : str\n        The width of the window used for splitting the data into sections for\n        detrending. Defaults to \"1m\".\n    rv_adjustment : bool\n        Whether to adjust the calculation for realized volatility. If True, the\n        data is filtered\n        to only include observations in the same volatility bucket that the\n        stock is currently in. Defaults to True.\n    rv_method : str\n        The method to calculate the realized volatility. Only need to define\n        when rv_adjustment is True. Defaults to \"std\".\n    rs_method : Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"]\n        The method to use for Range/STD calculation. This is either, min, max\n        or mean of all RS ranges\n        per window. If not defined, just used the most recent RS window.\n        Defaults to \"RS\".\n    rv_grouped_mean : bool\n        Whether to calculate the mean value of realized volatility over\n        multiple window lengths. Defaults to False.\n    live_price : bool\n        Whether to calculate the ranges using the current live price, or the\n        most recent 'close' observation. Defaults to False.\n    historical : bool\n        Whether to calculate the Historical Mandelbrot Channel (over-time), and\n        return a time-series of channels from the start to the end date. If\n        False, the Mandelbrot Channel calculation is done aggregating all of the\n        data into one observation. If True, then it will enable daily\n        observations over-time. Defaults to False.\n    chart : bool\n        Whether to return a chart object. Defaults to False.\n    \"\"\"\n\n    window: str = Field(\n        default=\"1mo\",\n        title=\"Window\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"window\", \"\"),\n    )\n    rv_adjustment: bool = Field(\n        default=True,\n        title=\"Realized Volatility Adjustment\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rv_adjustment\", \"\"),\n    )\n    rv_method: Literal[\n        \"std\",\n        \"parkinson\",\n        \"garman_klass\",\n        \"gk\",\n        \"hodges_tompkins\",\n        \"ht\",\n        \"rogers_satchell\",\n        \"rs\",\n        \"yang_zhang\",\n        \"yz\",\n        \"squared_returns\",\n        \"sq\",\n    ] = Field(\n        default=\"std\",\n        title=\"Realized Volatility Method\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rv_method\", \"\"),\n    )\n    rs_method: Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"] = Field(\n        default=\"RS\",\n        title=\"R/S Method\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rs_method\", \"\"),\n    )\n    rv_grouped_mean: bool = Field(\n        default=False,\n        title=\"Realized Volatility Grouped Mean\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rv_grouped_mean\", \"\"),\n    )\n    live_price: bool = Field(\n        default=False,\n        title=\"Live Price\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"live_price\", \"\"),\n    )\n    historical: bool = Field(\n        default=False,\n        title=\"Historical Mandelbrot Channel\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"historical\", \"\"),\n    )\n    chart: bool = Field(\n        default=False,\n        title=\"Results Chart\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"chart\", \"\"),\n    )\n    template: Literal[\n        \"humbl_dark\",\n        \"humbl_light\",\n        \"ggplot2\",\n        \"seaborn\",\n        \"simple_white\",\n        \"plotly\",\n        \"plotly_white\",\n        \"plotly_dark\",\n        \"presentation\",\n        \"xgridoff\",\n        \"ygridoff\",\n        \"gridon\",\n        \"none\",\n    ] = Field(\n        default=\"humbl_dark\",\n        title=\"Plotly Template\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"template\", \"\"),\n    )\n\n    @field_validator(\"window\", mode=\"after\", check_fields=False)\n    @classmethod\n    def window_format(cls, v: str) -&gt; str:\n        \"\"\"\n        Format the window string into a standardized format.\n\n        Parameters\n        ----------\n        v : str\n            The window size as a string.\n\n        Returns\n        -------\n        str\n            The window string in a standardized format.\n\n        Raises\n        ------\n        ValueError\n            If the input is not a string.\n        \"\"\"\n        if isinstance(v, str):\n            return _window_format(v, _return_timedelta=False)\n        else:\n            msg = \"Window must be a string.\"\n            raise ValueError(msg)\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelQueryParams.window_format <code>classmethod</code> \u00a4 <pre><code>window_format(v: str) -&gt; str\n</code></pre> <p>Format the window string into a standardized format.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str</code> <p>The window size as a string.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The window string in a standardized format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input is not a string.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>@field_validator(\"window\", mode=\"after\", check_fields=False)\n@classmethod\ndef window_format(cls, v: str) -&gt; str:\n    \"\"\"\n    Format the window string into a standardized format.\n\n    Parameters\n    ----------\n    v : str\n        The window size as a string.\n\n    Returns\n    -------\n    str\n        The window string in a standardized format.\n\n    Raises\n    ------\n    ValueError\n        If the input is not a string.\n    \"\"\"\n    if isinstance(v, str):\n        return _window_format(v, _return_timedelta=False)\n    else:\n        msg = \"Window must be a string.\"\n        raise ValueError(msg)\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelData \u00a4 <p>             Bases: <code>Data</code></p> <p>Data model for the Mandelbrot Channel command, a Pandera.Polars Model.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>Union[date, datetime]</code> <p>The date of the data point. Defaults to None.</p> required <code>symbol</code> <code>str</code> <p>The stock symbol. Defaults to None.</p> required <code>bottom_price</code> <code>float</code> <p>The bottom price in the Mandelbrot Channel. Defaults to None.</p> required <code>recent_price</code> <code>float</code> <p>The most recent price within the Mandelbrot Channel. Defaults to None.</p> required <code>top_price</code> <code>float</code> <p>The top price in the Mandelbrot Channel. Defaults to None.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>class MandelbrotChannelData(Data):\n    \"\"\"\n    Data model for the Mandelbrot Channel command, a Pandera.Polars Model.\n\n    Parameters\n    ----------\n    date : Union[dt.date, dt.datetime], optional\n        The date of the data point. Defaults to None.\n    symbol : str, optional\n        The stock symbol. Defaults to None.\n    bottom_price : float, optional\n        The bottom price in the Mandelbrot Channel. Defaults to None.\n    recent_price : float, optional\n        The most recent price within the Mandelbrot Channel. Defaults to None.\n    top_price : float, optional\n        The top price in the Mandelbrot Channel. Defaults to None.\n    \"\"\"\n\n    date: pl.Date = pa.Field(\n        default=None,\n        title=\"Date\",\n        description=\"The date of the data point.\",\n    )\n    symbol: str = pa.Field(\n        default=None,\n        title=\"Symbol\",\n        description=\"The stock symbol.\",\n    )\n    bottom_price: float = pa.Field(\n        default=None,\n        title=\"Bottom Price\",\n        description=\"The bottom price in the Mandelbrot Channel.\",\n    )\n    recent_price: float = pa.Field(\n        default=None,\n        title=\"Recent Price\",\n        description=\"The most recent price within the Mandelbrot Channel.\",\n        alias=\"(close_price|recent_price|last_price)\",\n        regex=True,\n    )\n    top_price: float = pa.Field(\n        default=None,\n        title=\"Top Price\",\n        description=\"The top price in the Mandelbrot Channel.\",\n    )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher \u00a4 <p>Fetcher for the Mandelbrot Channel command.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the toolbox query.</p> required <code>command_params</code> <code>MandelbrotChannelQueryParams</code> <p>The command-specific parameters for the Mandelbrot Channel query.</p> required <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>Stores the context parameters passed during initialization.</p> <code>command_params</code> <code>MandelbrotChannelQueryParams</code> <p>Stores the command-specific parameters passed during initialization.</p> <code>equity_historical_data</code> <code>DataFrame</code> <p>The raw data extracted from the data provider, before transformation.</p> <p>Methods:</p> Name Description <code>transform_query</code> <p>Transform the command-specific parameters into a query.</p> <code>extract_data</code> <p>Extracts the data from the provider and returns it as a Polars DataFrame.</p> <code>transform_data</code> <p>Transforms the command-specific data according to the Mandelbrot Channel logic.</p> <code>fetch_data</code> <p>Execute TET Pattern.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>results : MandelbrotChannelData     Serializable results. provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']     Provider name. warnings : Optional[List[Warning_]]     List of warnings. chart : Optional[Chart]     Chart object. context_params : ToolboxQueryParams     Context-specific parameters. command_params : MandelbrotChannelQueryParams     Command-specific parameters.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>class MandelbrotChannelFetcher:\n    \"\"\"\n    Fetcher for the Mandelbrot Channel command.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the toolbox query.\n    command_params : MandelbrotChannelQueryParams\n        The command-specific parameters for the Mandelbrot Channel query.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        Stores the context parameters passed during initialization.\n    command_params : MandelbrotChannelQueryParams\n        Stores the command-specific parameters passed during initialization.\n    equity_historical_data : pl.DataFrame\n        The raw data extracted from the data provider, before transformation.\n\n    Methods\n    -------\n    transform_query()\n        Transform the command-specific parameters into a query.\n    extract_data()\n        Extracts the data from the provider and returns it as a Polars DataFrame.\n    transform_data()\n        Transforms the command-specific data according to the Mandelbrot Channel logic.\n    fetch_data()\n        Execute TET Pattern.\n\n    Returns\n    -------\n    HumblObject\n        results : MandelbrotChannelData\n            Serializable results.\n        provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']\n            Provider name.\n        warnings : Optional[List[Warning_]]\n            List of warnings.\n        chart : Optional[Chart]\n            Chart object.\n        context_params : ToolboxQueryParams\n            Context-specific parameters.\n        command_params : MandelbrotChannelQueryParams\n            Command-specific parameters.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: MandelbrotChannelQueryParams,\n    ):\n        \"\"\"\n        Initialize the MandelbrotChannelFetcher with context and command parameters.\n\n        Parameters\n        ----------\n        context_params : ToolboxQueryParams\n            The context parameters for the toolbox query.\n        command_params : MandelbrotChannelQueryParams\n            The command-specific parameters for the Mandelbrot Channel query.\n        \"\"\"\n        self.context_params = context_params\n        self.command_params = command_params\n\n    def transform_query(self):\n        \"\"\"\n        Transform the command-specific parameters into a query.\n\n        If command_params is not provided, it initializes a default MandelbrotChannelQueryParams object.\n        \"\"\"\n        if not self.command_params:\n            self.command_params = None\n            # Set Default Arguments\n            self.command_params: MandelbrotChannelQueryParams = (\n                MandelbrotChannelQueryParams()\n            )\n        else:\n            self.command_params: MandelbrotChannelQueryParams = (\n                MandelbrotChannelQueryParams(**self.command_params)\n            )\n\n    def extract_data(self):\n        \"\"\"\n        Extract the data from the provider and returns it as a Polars DataFrame.\n\n        Drops unnecessary columns like dividends and stock splits from the data.\n\n        Returns\n        -------\n        pl.DataFrame\n            The extracted data as a Polars DataFrame.\n        \"\"\"\n        self.equity_historical_data: pl.LazyFrame = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbols,\n                start_date=self.context_params.start_date,\n                end_date=self.context_params.end_date,\n                provider=self.context_params.provider,\n                adjustment=\"splits_and_dividends\",\n                # add kwargs\n            )\n            .to_polars()\n            .lazy()\n        ).drop([\"dividend\", \"split_ratio\"])  # TODO: drop `capital_gains` col\n\n        if len(self.context_params.symbols) == 1:\n            self.equity_historical_data = (\n                self.equity_historical_data.with_columns(\n                    symbol=pl.lit(self.context_params.symbols[0])\n                )\n            )\n        return self\n\n    def transform_data(self):\n        \"\"\"\n        Transform the command-specific data according to the Mandelbrot Channel logic.\n\n        Returns\n        -------\n        pl.DataFrame\n            The transformed data as a Polars DataFrame\n        \"\"\"\n        if self.command_params.historical is False:\n            transformed_data = calc_mandelbrot_channel(\n                data=self.equity_historical_data,\n                window=self.command_params.window,\n                rv_adjustment=self.command_params.rv_adjustment,\n                rv_method=self.command_params.rv_method,\n                rv_grouped_mean=self.command_params.rv_grouped_mean,\n                rs_method=self.command_params.rs_method,\n                live_price=self.command_params.live_price,\n            )\n        else:\n            transformed_data = calc_mandelbrot_channel_historical_concurrent(\n                data=self.equity_historical_data,\n                window=self.command_params.window,\n                rv_adjustment=self.command_params.rv_adjustment,\n                rv_method=self.command_params.rv_method,\n                rv_grouped_mean=self.command_params.rv_grouped_mean,\n                rs_method=self.command_params.rs_method,\n                live_price=self.command_params.live_price,\n                use_processes=False,\n            )\n\n        self.transformed_data = MandelbrotChannelData(\n            transformed_data.collect().drop_nulls()  ## HOTFIX - need to trace where coming from w/ unequal data\n        ).lazy()\n\n        if self.command_params.chart:\n            self.chart = generate_plots(\n                self.transformed_data,\n                self.equity_historical_data,\n                template=self.command_params.template,\n            )\n        else:\n            self.chart = None\n\n        self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n        return self\n\n    @log_start_end(logger=logger)\n    def fetch_data(self):\n        \"\"\"\n        Execute TET Pattern.\n\n        This method executes the query transformation, data fetching and\n        transformation process by first calling `transform_query` to prepare the query parameters, then\n        extracting the raw data using `extract_data` method, and finally\n        transforming the raw data using `transform_data` method.\n\n        Returns\n        -------\n        pl.DataFrame\n            The transformed data as a Polars DataFrame, ready for further analysis\n            or visualization.\n        \"\"\"\n        self.transform_query()\n        self.extract_data()\n        self.transform_data()\n\n        if not hasattr(self.context_params, \"warnings\"):\n            self.context_params.warnings = []\n\n        return HumblObject(\n            results=self.transformed_data,\n            provider=self.context_params.provider,\n            equity_data=self.equity_historical_data.serialize(),\n            warnings=self.context_params.warnings,\n            chart=self.chart,\n            context_params=self.context_params,\n            command_params=self.command_params,\n        )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.__init__ \u00a4 <pre><code>__init__(context_params: ToolboxQueryParams, command_params: MandelbrotChannelQueryParams)\n</code></pre> <p>Initialize the MandelbrotChannelFetcher with context and command parameters.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the toolbox query.</p> required <code>command_params</code> <code>MandelbrotChannelQueryParams</code> <p>The command-specific parameters for the Mandelbrot Channel query.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def __init__(\n    self,\n    context_params: ToolboxQueryParams,\n    command_params: MandelbrotChannelQueryParams,\n):\n    \"\"\"\n    Initialize the MandelbrotChannelFetcher with context and command parameters.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the toolbox query.\n    command_params : MandelbrotChannelQueryParams\n        The command-specific parameters for the Mandelbrot Channel query.\n    \"\"\"\n    self.context_params = context_params\n    self.command_params = command_params\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the command-specific parameters into a query.</p> <p>If command_params is not provided, it initializes a default MandelbrotChannelQueryParams object.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def transform_query(self):\n    \"\"\"\n    Transform the command-specific parameters into a query.\n\n    If command_params is not provided, it initializes a default MandelbrotChannelQueryParams object.\n    \"\"\"\n    if not self.command_params:\n        self.command_params = None\n        # Set Default Arguments\n        self.command_params: MandelbrotChannelQueryParams = (\n            MandelbrotChannelQueryParams()\n        )\n    else:\n        self.command_params: MandelbrotChannelQueryParams = (\n            MandelbrotChannelQueryParams(**self.command_params)\n        )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.extract_data \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider and returns it as a Polars DataFrame.</p> <p>Drops unnecessary columns like dividends and stock splits from the data.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The extracted data as a Polars DataFrame.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def extract_data(self):\n    \"\"\"\n    Extract the data from the provider and returns it as a Polars DataFrame.\n\n    Drops unnecessary columns like dividends and stock splits from the data.\n\n    Returns\n    -------\n    pl.DataFrame\n        The extracted data as a Polars DataFrame.\n    \"\"\"\n    self.equity_historical_data: pl.LazyFrame = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbols,\n            start_date=self.context_params.start_date,\n            end_date=self.context_params.end_date,\n            provider=self.context_params.provider,\n            adjustment=\"splits_and_dividends\",\n            # add kwargs\n        )\n        .to_polars()\n        .lazy()\n    ).drop([\"dividend\", \"split_ratio\"])  # TODO: drop `capital_gains` col\n\n    if len(self.context_params.symbols) == 1:\n        self.equity_historical_data = (\n            self.equity_historical_data.with_columns(\n                symbol=pl.lit(self.context_params.symbols[0])\n            )\n        )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.transform_data \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data according to the Mandelbrot Channel logic.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed data as a Polars DataFrame</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def transform_data(self):\n    \"\"\"\n    Transform the command-specific data according to the Mandelbrot Channel logic.\n\n    Returns\n    -------\n    pl.DataFrame\n        The transformed data as a Polars DataFrame\n    \"\"\"\n    if self.command_params.historical is False:\n        transformed_data = calc_mandelbrot_channel(\n            data=self.equity_historical_data,\n            window=self.command_params.window,\n            rv_adjustment=self.command_params.rv_adjustment,\n            rv_method=self.command_params.rv_method,\n            rv_grouped_mean=self.command_params.rv_grouped_mean,\n            rs_method=self.command_params.rs_method,\n            live_price=self.command_params.live_price,\n        )\n    else:\n        transformed_data = calc_mandelbrot_channel_historical_concurrent(\n            data=self.equity_historical_data,\n            window=self.command_params.window,\n            rv_adjustment=self.command_params.rv_adjustment,\n            rv_method=self.command_params.rv_method,\n            rv_grouped_mean=self.command_params.rv_grouped_mean,\n            rs_method=self.command_params.rs_method,\n            live_price=self.command_params.live_price,\n            use_processes=False,\n        )\n\n    self.transformed_data = MandelbrotChannelData(\n        transformed_data.collect().drop_nulls()  ## HOTFIX - need to trace where coming from w/ unequal data\n    ).lazy()\n\n    if self.command_params.chart:\n        self.chart = generate_plots(\n            self.transformed_data,\n            self.equity_historical_data,\n            template=self.command_params.template,\n        )\n    else:\n        self.chart = None\n\n    self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.fetch_data \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute TET Pattern.</p> <p>This method executes the query transformation, data fetching and transformation process by first calling <code>transform_query</code> to prepare the query parameters, then extracting the raw data using <code>extract_data</code> method, and finally transforming the raw data using <code>transform_data</code> method.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed data as a Polars DataFrame, ready for further analysis or visualization.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>@log_start_end(logger=logger)\ndef fetch_data(self):\n    \"\"\"\n    Execute TET Pattern.\n\n    This method executes the query transformation, data fetching and\n    transformation process by first calling `transform_query` to prepare the query parameters, then\n    extracting the raw data using `extract_data` method, and finally\n    transforming the raw data using `transform_data` method.\n\n    Returns\n    -------\n    pl.DataFrame\n        The transformed data as a Polars DataFrame, ready for further analysis\n        or visualization.\n    \"\"\"\n    self.transform_query()\n    self.extract_data()\n    self.transform_data()\n\n    if not hasattr(self.context_params, \"warnings\"):\n        self.context_params.warnings = []\n\n    return HumblObject(\n        results=self.transformed_data,\n        provider=self.context_params.provider,\n        equity_data=self.equity_historical_data.serialize(),\n        warnings=self.context_params.warnings,\n        chart=self.chart,\n        context_params=self.context_params,\n        command_params=self.command_params,\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxQueryParams","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>Query parameters for the ToolboxController.</p> <p>This class defines the query parameters used by the ToolboxController, including the stock symbol, data interval, start date, and end date. It also includes a method to ensure the stock symbol is in uppercase. If no dates constraints are given, it will collect the MAX amount of data available.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str | list[str] | set[str]</code> <p>The symbol or ticker of the stock. You can pass multiple tickers like: \"AAPL\", \"AAPL, MSFT\" or [\"AAPL\", \"MSFT\"]. The input will be converted to uppercase.</p> <code>\"\"</code> <code>interval</code> <code>str | None</code> <p>The interval of the data. Can be None.</p> <code>\"1d\"</code> <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> <code>\"\"</code> <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> <code>\"\"</code> <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider to be used for the query.</p> <code>\"yfinance\"</code> <code>membership</code> <code>str</code> <p>The membership level of the user.</p> <code>\"anonymous\"</code> <p>Methods:</p> Name Description <code>upper_symbol</code> <p>A Pydantic <code>@field_validator()</code> that converts the stock symbol to uppercase. If a list or set of symbols is provided, each symbol in the collection is converted to uppercase and returned as a comma-separated string.</p> <code>validate_interval</code> <p>A Pydantic <code>@field_validator()</code> that validates the interval format. Ensures the interval is a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.</p> <code>validate_date_format</code> <p>A Pydantic <code>@field_validator()</code> that validates the date format to ensure it is YYYY-MM-DD.</p> <code>validate_start_date</code> <p>A Pydantic <code>@model_validator()</code> that validates and adjusts the start date based on membership level.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>symbol</code> parameter is a list and not all elements are strings, or if <code>symbol</code> is not a string, list, or set. If the <code>interval</code> format is invalid. If the <code>date</code> format is invalid.</p> Notes <p>A Pydantic v2 Model</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>class ToolboxQueryParams(QueryParams):\n    \"\"\"\n    Query parameters for the ToolboxController.\n\n    This class defines the query parameters used by the ToolboxController,\n    including the stock symbol, data interval, start date, and end date. It also\n    includes a method to ensure the stock symbol is in uppercase.\n    If no dates constraints are given, it will collect the MAX amount of data\n    available.\n\n    Parameters\n    ----------\n    symbol : str | list[str] | set[str], default=\"\"\n        The symbol or ticker of the stock. You can pass multiple tickers like:\n        \"AAPL\", \"AAPL, MSFT\" or [\"AAPL\", \"MSFT\"]. The input will be converted\n        to uppercase.\n    interval : str | None, default=\"1d\"\n        The interval of the data. Can be None.\n    start_date : str, default=\"\"\n        The start date for the data query.\n    end_date : str, default=\"\"\n        The end date for the data query.\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS, default=\"yfinance\"\n        The data provider to be used for the query.\n    membership : str, default=\"anonymous\"\n        The membership level of the user.\n\n    Methods\n    -------\n    upper_symbol(cls, v: Union[str, list[str], set[str]]) -&gt; Union[str, list[str]]\n        A Pydantic `@field_validator()` that converts the stock symbol to\n        uppercase. If a list or set of symbols is provided, each symbol in the\n        collection is converted to uppercase and returned as a comma-separated\n        string.\n    validate_interval(cls, v: str) -&gt; str\n        A Pydantic `@field_validator()` that validates the interval format.\n        Ensures the interval is a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.\n    validate_date_format(cls, v: str | date) -&gt; date\n        A Pydantic `@field_validator()` that validates the date format to ensure it is YYYY-MM-DD.\n    validate_start_date(self) -&gt; 'ToolboxQueryParams'\n        A Pydantic `@model_validator()` that validates and adjusts the start date based on membership level.\n\n    Raises\n    ------\n    ValueError\n        If the `symbol` parameter is a list and not all elements are strings, or\n        if `symbol` is not a string, list, or set.\n        If the `interval` format is invalid.\n        If the `date` format is invalid.\n\n    Notes\n    -----\n    A Pydantic v2 Model\n\n    \"\"\"\n\n    symbols: str | list[str] | None = Field(\n        default=None,\n        title=\"Symbols/Tickers\",\n        description=QUERY_DESCRIPTIONS.get(\"symbols\", \"\"),\n    )\n    interval: str | None = Field(\n        default=\"1d\",\n        title=\"Interval\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: dt.date | str = Field(\n        default_factory=lambda: dt.date(1950, 1, 1),\n        title=\"Start Date\",\n        description=\"The starting date for the data query.\",\n    )\n    end_date: dt.date | str = Field(\n        default_factory=lambda: dt.datetime.now(\n            tz=pytz.timezone(\"America/New_York\")\n        ).date(),\n        title=\"End Date\",\n        description=\"The ending date for the data query.\",\n    )\n    provider: OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS = Field(\n        default=\"yfinance\",\n        title=\"Provider\",\n        description=QUERY_DESCRIPTIONS.get(\"provider\", \"\"),\n    )\n    membership: Literal[\n        \"anonymous\",\n        \"humblPEON\",\n        \"humblPREMIUM\",\n        \"humblPOWER\",\n        \"humblPERMANENT\",\n        \"admin\",\n    ] = Field(\n        default=\"anonymous\",\n        title=\"Membership\",\n        description=QUERY_DESCRIPTIONS.get(\"membership\", \"\"),\n    )\n\n    @field_validator(\"symbols\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n        \"\"\"\n        Convert the stock symbols to uppercase and remove empty strings.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        List[str]\n            A list of uppercase stock symbols with empty strings removed.\n        \"\"\"\n        # Handle empty inputs\n        if not v:\n            return []\n\n        # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n        v = v.split(\",\") if isinstance(v, str) else list(v)\n\n        # Convert all elements to uppercase, trim whitespace, and remove empty strings\n        valid_symbols = [\n            symbol.strip().upper() for symbol in v if symbol.strip()\n        ]\n\n        if not valid_symbols:\n            msg = \"At least one valid symbol (str) must be provided\"\n            raise ValueError(msg)\n\n        return valid_symbols\n\n    @field_validator(\"interval\", mode=\"before\", check_fields=False)\n    @classmethod\n    def validate_interval(cls, v: str) -&gt; str:\n        \"\"\"\n        Validate the interval format.\n\n        Parameters\n        ----------\n        v : str\n            The interval string to be validated.\n\n        Returns\n        -------\n        str\n            The validated interval string.\n\n        Raises\n        ------\n        ValueError\n            If the interval format is invalid.\n        \"\"\"\n        if not re.match(r\"^\\d*[smhdWMQY]$\", v):\n            msg = \"Invalid interval format. Must be a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.\"\n            raise ValueError(msg)\n        return v\n\n    @field_validator(\"start_date\", \"end_date\", mode=\"before\")\n    @classmethod\n    def validate_date_format(cls, v: str | dt.date) -&gt; dt.date:\n        \"\"\"\n        Validate and convert the input date to a datetime.date object.\n\n        This method accepts either a string in 'YYYY-MM-DD' format or a datetime.date object.\n        It converts the input to a datetime.date object, ensuring it's in the correct format.\n\n        Parameters\n        ----------\n        v : str | dt.date\n            The input date to validate and convert.\n\n        Returns\n        -------\n        dt.date\n            The validated and converted date.\n\n        Raises\n        ------\n        ValueError\n            If the input string is not in the correct format.\n        TypeError\n            If the input is neither a string nor a datetime.date object.\n        \"\"\"\n        if isinstance(v, str):\n            try:\n                date = datetime.strptime(v, \"%Y-%m-%d\").replace(\n                    tzinfo=pytz.timezone(\"America/New_York\")\n                )\n            except ValueError as e:\n                msg = f\"Invalid date format. Must be YYYY-MM-DD: {e}\"\n                raise ValueError(msg) from e\n        elif isinstance(v, dt.date):\n            date = datetime.combine(v, datetime.min.time()).replace(\n                tzinfo=pytz.timezone(\"America/New_York\")\n            )\n        else:\n            msg = f\"Expected str or date, got {type(v)}\"\n            raise TypeError(msg)\n\n        # Check if the date is in the correct format\n        if date.strftime(\"%Y-%m-%d\") != date.strftime(\"%Y-%m-%d\"):\n            msg = \"Date must be in YYYY-MM-DD format\"\n            raise ValueError(msg)\n        if date.date() &lt; dt.date(1950, 1, 1):\n            msg = \"Date must be after 1950-01-01\"\n            raise ValueError(msg)\n\n        return date.date()\n\n    @model_validator(mode=\"after\")\n    def validate_start_date(self) -&gt; \"ToolboxQueryParams\":\n        end_date: dt.date = self.end_date  # type: ignore  # noqa: PGH003 the date has already been converted to date\n\n        start_date_mapping = {\n            \"anonymous\": (end_date - timedelta(days=365), \"1Y\"),\n            \"humblPEON\": (end_date - timedelta(days=730), \"2Y\"),\n            \"humblPREMIUM\": (end_date - timedelta(days=1825), \"5Y\"),\n            \"humblPOWER\": (end_date - timedelta(days=7300), \"20Y\"),\n            \"humblPERMANENT\": (end_date - timedelta(days=10680), \"30Y\"),\n            \"admin\": (\n                datetime(\n                    1950, 1, 1, tzinfo=pytz.timezone(\"America/New_York\")\n                ).date(),\n                \"All\",\n            ),\n        }\n\n        allowed_start_date, data_length = start_date_mapping.get(\n            self.membership, (end_date - timedelta(days=365), \"1Y\")\n        )\n\n        if self.start_date &lt; allowed_start_date:  # type: ignore  # noqa: PGH003 the date has already been converted to date\n            warning_msg = f\"Start date adjusted to {allowed_start_date} based on {self.membership} membership ({data_length} of data).\"\n            logger.warning(warning_msg)\n            self.start_date = allowed_start_date\n            if not hasattr(self, \"warnings\"):\n                self.warnings = []\n            self.warnings.append(\n                HumblDataWarning(\n                    category=\"ToolboxQueryParams\",\n                    message=warning_msg,\n                )\n            )\n\n        return self\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol  <code>classmethod</code>","text":"<pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; list[str]\n</code></pre> <p>Convert the stock symbols to uppercase and remove empty strings.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of uppercase stock symbols with empty strings removed.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>@field_validator(\"symbols\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n    \"\"\"\n    Convert the stock symbols to uppercase and remove empty strings.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    List[str]\n        A list of uppercase stock symbols with empty strings removed.\n    \"\"\"\n    # Handle empty inputs\n    if not v:\n        return []\n\n    # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n    v = v.split(\",\") if isinstance(v, str) else list(v)\n\n    # Convert all elements to uppercase, trim whitespace, and remove empty strings\n    valid_symbols = [\n        symbol.strip().upper() for symbol in v if symbol.strip()\n    ]\n\n    if not valid_symbols:\n        msg = \"At least one valid symbol (str) must be provided\"\n        raise ValueError(msg)\n\n    return valid_symbols\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_interval","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_interval  <code>classmethod</code>","text":"<pre><code>validate_interval(v: str) -&gt; str\n</code></pre> <p>Validate the interval format.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str</code> <p>The interval string to be validated.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The validated interval string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the interval format is invalid.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>@field_validator(\"interval\", mode=\"before\", check_fields=False)\n@classmethod\ndef validate_interval(cls, v: str) -&gt; str:\n    \"\"\"\n    Validate the interval format.\n\n    Parameters\n    ----------\n    v : str\n        The interval string to be validated.\n\n    Returns\n    -------\n    str\n        The validated interval string.\n\n    Raises\n    ------\n    ValueError\n        If the interval format is invalid.\n    \"\"\"\n    if not re.match(r\"^\\d*[smhdWMQY]$\", v):\n        msg = \"Invalid interval format. Must be a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.\"\n        raise ValueError(msg)\n    return v\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_date_format","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_date_format  <code>classmethod</code>","text":"<pre><code>validate_date_format(v: str | date) -&gt; date\n</code></pre> <p>Validate and convert the input date to a datetime.date object.</p> <p>This method accepts either a string in 'YYYY-MM-DD' format or a datetime.date object. It converts the input to a datetime.date object, ensuring it's in the correct format.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str | date</code> <p>The input date to validate and convert.</p> required <p>Returns:</p> Type Description <code>date</code> <p>The validated and converted date.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input string is not in the correct format.</p> <code>TypeError</code> <p>If the input is neither a string nor a datetime.date object.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>@field_validator(\"start_date\", \"end_date\", mode=\"before\")\n@classmethod\ndef validate_date_format(cls, v: str | dt.date) -&gt; dt.date:\n    \"\"\"\n    Validate and convert the input date to a datetime.date object.\n\n    This method accepts either a string in 'YYYY-MM-DD' format or a datetime.date object.\n    It converts the input to a datetime.date object, ensuring it's in the correct format.\n\n    Parameters\n    ----------\n    v : str | dt.date\n        The input date to validate and convert.\n\n    Returns\n    -------\n    dt.date\n        The validated and converted date.\n\n    Raises\n    ------\n    ValueError\n        If the input string is not in the correct format.\n    TypeError\n        If the input is neither a string nor a datetime.date object.\n    \"\"\"\n    if isinstance(v, str):\n        try:\n            date = datetime.strptime(v, \"%Y-%m-%d\").replace(\n                tzinfo=pytz.timezone(\"America/New_York\")\n            )\n        except ValueError as e:\n            msg = f\"Invalid date format. Must be YYYY-MM-DD: {e}\"\n            raise ValueError(msg) from e\n    elif isinstance(v, dt.date):\n        date = datetime.combine(v, datetime.min.time()).replace(\n            tzinfo=pytz.timezone(\"America/New_York\")\n        )\n    else:\n        msg = f\"Expected str or date, got {type(v)}\"\n        raise TypeError(msg)\n\n    # Check if the date is in the correct format\n    if date.strftime(\"%Y-%m-%d\") != date.strftime(\"%Y-%m-%d\"):\n        msg = \"Date must be in YYYY-MM-DD format\"\n        raise ValueError(msg)\n    if date.date() &lt; dt.date(1950, 1, 1):\n        msg = \"Date must be after 1950-01-01\"\n        raise ValueError(msg)\n\n    return date.date()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxData","title":"humbldata.core.standard_models.toolbox.ToolboxData","text":"<p>             Bases: <code>Data</code></p> <p>The Data for the ToolboxController.</p> <p>WIP: I'm thinking that this is the final layer around which the HumblDataObject will be returned to the user, with all necessary information about the query, command, data and charts that they should want. This HumblDataObject will return values in json/dict format, with methods to allow transformation into polars_df, pandas_df, a list, a dict...</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>class ToolboxData(Data):\n    \"\"\"\n    The Data for the ToolboxController.\n\n    WIP: I'm thinking that this is the final layer around which the\n    HumblDataObject will be returned to the user, with all necessary information\n    about the query, command, data and charts that they should want.\n    This HumblDataObject will return values in json/dict format, with methods\n    to allow transformation into polars_df, pandas_df, a list, a dict...\n    \"\"\"\n\n    date: pl.Date = pa.Field(\n        default=None,\n        title=\"Date\",\n        description=DATA_DESCRIPTIONS.get(\"date\", \"\"),\n    )\n    open: float = pa.Field(\n        default=None,\n        title=\"Open\",\n        description=DATA_DESCRIPTIONS.get(\"open\", \"\"),\n    )\n    high: float = pa.Field(\n        default=None,\n        title=\"High\",\n        description=DATA_DESCRIPTIONS.get(\"high\", \"\"),\n    )\n    low: float = pa.Field(\n        default=None,\n        title=\"Low\",\n        description=DATA_DESCRIPTIONS.get(\"low\", \"\"),\n    )\n    close: float = pa.Field(\n        default=None,\n        title=\"Close\",\n        description=DATA_DESCRIPTIONS.get(\"close\", \"\"),\n    )\n    volume: int = pa.Field(\n        default=None,\n        title=\"Volume\",\n        description=DATA_DESCRIPTIONS.get(\"volume\", \"\"),\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils","title":"humbldata.core.utils","text":"<p>humbldata core utils.</p> <p>Utils is used to keep; helpers, descriptions, constants, and other useful tools.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env","title":"humbldata.core.utils.env","text":"<p>The Env Module, to control a single instance of environment variables.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env","title":"humbldata.core.utils.env.Env","text":"<p>A singleton environment to hold all Environment variables.</p> Source code in <code>src/humbldata/core/utils/env.py</code> <pre><code>class Env(metaclass=SingletonMeta):\n    \"\"\"A singleton environment to hold all Environment variables.\"\"\"\n\n    _environ: dict[str, str]\n\n    def __init__(self) -&gt; None:\n        env_path = dotenv.find_dotenv()\n        dotenv.load_dotenv(Path(env_path))\n\n        self._environ = os.environ.copy()\n\n    @property\n    def OBB_PAT(self) -&gt; str | None:  # noqa: N802\n        \"\"\"OpenBB Personal Access Token.\"\"\"\n        return self._environ.get(\"OBB_PAT\", None)\n\n    @property\n    def LOGGER_LEVEL(self) -&gt; int:\n        \"\"\"\n        Get the global logger level.\n\n        Returns\n        -------\n        int\n            The numeric logging level (default: 20 for INFO).\n\n        Notes\n        -----\n        Mapping of string levels to numeric values:\n        DEBUG: 10, INFO: 20, WARNING: 30, ERROR: 40, CRITICAL: 50\n        \"\"\"\n        level_map = {\n            \"DEBUG\": 10,\n            \"INFO\": 20,\n            \"WARNING\": 30,\n            \"ERROR\": 40,\n            \"CRITICAL\": 50,\n        }\n        return level_map.get(\n            self._environ.get(\"LOGGER_LEVEL\", \"INFO\").upper(), 20\n        )\n\n    @property\n    def OBB_LOGGED_IN(self) -&gt; bool:\n        return self.str2bool(self._environ.get(\"OBB_LOGGED_IN\", False))\n\n    @staticmethod\n    def str2bool(value: str | bool) -&gt; bool:\n        \"\"\"Match a value to its boolean correspondent.\n\n        Args:\n            value (str): The string value to be converted to a boolean.\n\n        Returns\n        -------\n            bool: The boolean value corresponding to the input string.\n\n        Raises\n        ------\n            ValueError: If the input string does not correspond to a boolean\n            value.\n        \"\"\"\n        if isinstance(value, bool):\n            return value\n        if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n            return False\n        if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n            return True\n        msg = f\"Failed to cast '{value}' to bool.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env.OBB_PAT","title":"humbldata.core.utils.env.Env.OBB_PAT  <code>property</code>","text":"<pre><code>OBB_PAT: str | None\n</code></pre> <p>OpenBB Personal Access Token.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env.LOGGER_LEVEL","title":"humbldata.core.utils.env.Env.LOGGER_LEVEL  <code>property</code>","text":"<pre><code>LOGGER_LEVEL: int\n</code></pre> <p>Get the global logger level.</p> <p>Returns:</p> Type Description <code>int</code> <p>The numeric logging level (default: 20 for INFO).</p> Notes <p>Mapping of string levels to numeric values: DEBUG: 10, INFO: 20, WARNING: 30, ERROR: 40, CRITICAL: 50</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env.str2bool","title":"humbldata.core.utils.env.Env.str2bool  <code>staticmethod</code>","text":"<pre><code>str2bool(value: str | bool) -&gt; bool\n</code></pre> <p>Match a value to its boolean correspondent.</p> <p>Args:     value (str): The string value to be converted to a boolean.</p> <p>Returns:</p> Type Description <code>    bool: The boolean value corresponding to the input string.</code> <p>Raises:</p> Type Description <code>    ValueError: If the input string does not correspond to a boolean</code> <p>value.</p> Source code in <code>src/humbldata/core/utils/env.py</code> <pre><code>@staticmethod\ndef str2bool(value: str | bool) -&gt; bool:\n    \"\"\"Match a value to its boolean correspondent.\n\n    Args:\n        value (str): The string value to be converted to a boolean.\n\n    Returns\n    -------\n        bool: The boolean value corresponding to the input string.\n\n    Raises\n    ------\n        ValueError: If the input string does not correspond to a boolean\n        value.\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n    if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n        return False\n    if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n        return True\n    msg = f\"Failed to cast '{value}' to bool.\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.descriptions","title":"humbldata.core.utils.descriptions","text":"<p>Common descriptions for model fields.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.constants","title":"humbldata.core.utils.constants","text":"<p>A module to contain all project-wide constants.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.logger","title":"humbldata.core.utils.logger","text":""},{"location":"code_documentation/api_reference/#humbldata.core.utils.logger.setup_logger","title":"humbldata.core.utils.logger.setup_logger","text":"<pre><code>setup_logger(name: str, level: int = logging.INFO) -&gt; Logger\n</code></pre> <p>Set up a logger with the specified name and logging level.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>int</code> <p>The logging level, by default logging.INFO.</p> <code>INFO</code> <p>Returns:</p> Type Description <code>Logger</code> <p>A configured logger instance.</p> Notes <p>This function creates a logger with a StreamHandler that outputs to sys.stdout. It uses a formatter that includes timestamp, logger name, log level, and message. If the logger already has handlers, it skips the setup to avoid duplicate logging. The logger is configured not to propagate messages to the root logger.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; logger = setup_logger(\"my_logger\", logging.DEBUG)\n&gt;&gt;&gt; logger.debug(\"This is a debug message\")\n2023-05-20 10:30:45,123 - my_logger - DEBUG - This is a debug message\n</code></pre> Source code in <code>src/humbldata/core/utils/logger.py</code> <pre><code>def setup_logger(name: str, level: int = logging.INFO) -&gt; logging.Logger:\n    \"\"\"\n    Set up a logger with the specified name and logging level.\n\n    Parameters\n    ----------\n    name : str\n        The name of the logger.\n    level : int, optional\n        The logging level, by default logging.INFO.\n\n    Returns\n    -------\n    logging.Logger\n        A configured logger instance.\n\n    Notes\n    -----\n    This function creates a logger with a StreamHandler that outputs to sys.stdout.\n    It uses a formatter that includes timestamp, logger name, log level, and message.\n    If the logger already has handlers, it skips the setup to avoid duplicate logging.\n    The logger is configured not to propagate messages to the root logger.\n\n    Examples\n    --------\n    &gt;&gt;&gt; logger = setup_logger(\"my_logger\", logging.DEBUG)\n    &gt;&gt;&gt; logger.debug(\"This is a debug message\")\n    2023-05-20 10:30:45,123 - my_logger - DEBUG - This is a debug message\n    \"\"\"\n    logger = logging.getLogger(name)\n\n    # Check if the logger already has handlers to avoid duplicate logging\n    if not logger.handlers:\n        logger.setLevel(level)\n\n        # Install coloredlogs\n        coloredlogs.install(\n            level=level,\n            logger=logger,\n            fmt=\"%(levelname)s: %(name)s || %(message)s\",\n            level_styles={\n                \"debug\": {\"color\": \"green\"},\n                \"info\": {\"color\": \"blue\"},\n                \"warning\": {\"color\": \"yellow\", \"bold\": True},\n                \"error\": {\"color\": \"red\", \"bold\": True},\n                \"critical\": {\n                    \"color\": \"red\",\n                    \"bold\": True,\n                    \"background\": \"white\",\n                },\n            },\n            field_styles={\n                \"asctime\": {\"color\": \"blue\"},\n                \"levelname\": {\"color\": \"magenta\", \"bold\": True},\n                \"name\": {\"color\": \"cyan\"},\n            },\n        )\n\n    # Prevent the logger from propagating messages to the root logger\n    logger.propagate = False\n\n    return logger\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.logger.log_start_end","title":"humbldata.core.utils.logger.log_start_end","text":"<pre><code>log_start_end(func: Callable | None = None, *, logger: Logger | None = None) -&gt; Callable\n</code></pre> <p>Log the start and end of any function, including time tracking.</p> <p>This decorator works with both synchronous and asynchronous functions. It logs the start and end of the function execution, as well as the total execution time. If an exception occurs, it logs the exception details.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable | None</code> <p>The function to be decorated. If None, the decorator can be used with parameters.</p> <code>None</code> <code>logger</code> <code>Logger | None</code> <p>The logger to use. If None, a logger will be created using the function's module name.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable</code> <p>The wrapped function.</p> Notes <ul> <li>For asynchronous functions, the decorator uses an async wrapper.</li> <li>For synchronous functions, it uses a sync wrapper.</li> <li>If a KeyboardInterrupt occurs, it logs the interruption and returns an empty list.</li> <li>If any other exception occurs, it logs the exception and re-raises it.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @log_start_end\n... def example_function():\n...     print(\"This is an example function\")\n...\n&gt;&gt;&gt; example_function()\nSTART: example_function (sync)\nThis is an example function\nEND: example_function (sync) - Total time: 0.0001s\n</code></pre> <pre><code>&gt;&gt;&gt; @log_start_end(logger=custom_logger)\n... async def async_example():\n...     await asyncio.sleep(1)\n...\n&gt;&gt;&gt; asyncio.run(async_example())\nSTART: async_example (async)\nEND: async_example (async) - Total time: 1.0012s\n</code></pre> Source code in <code>src/humbldata/core/utils/logger.py</code> <pre><code>def log_start_end(\n    func: Callable | None = None, *, logger: logging.Logger | None = None\n) -&gt; Callable:\n    \"\"\"\n    Log the start and end of any function, including time tracking.\n\n    This decorator works with both synchronous and asynchronous functions.\n    It logs the start and end of the function execution, as well as the total\n    execution time. If an exception occurs, it logs the exception details.\n\n    Parameters\n    ----------\n    func : Callable | None, optional\n        The function to be decorated. If None, the decorator can be used with parameters.\n    logger : logging.Logger | None, optional\n        The logger to use. If None, a logger will be created using the function's module name.\n\n    Returns\n    -------\n    Callable\n        The wrapped function.\n\n    Notes\n    -----\n    - For asynchronous functions, the decorator uses an async wrapper.\n    - For synchronous functions, it uses a sync wrapper.\n    - If a KeyboardInterrupt occurs, it logs the interruption and returns an empty list.\n    - If any other exception occurs, it logs the exception and re-raises it.\n\n    Examples\n    --------\n    &gt;&gt;&gt; @log_start_end\n    ... def example_function():\n    ...     print(\"This is an example function\")\n    ...\n    &gt;&gt;&gt; example_function()\n    START: example_function (sync)\n    This is an example function\n    END: example_function (sync) - Total time: 0.0001s\n\n    &gt;&gt;&gt; @log_start_end(logger=custom_logger)\n    ... async def async_example():\n    ...     await asyncio.sleep(1)\n    ...\n    &gt;&gt;&gt; asyncio.run(async_example())\n    START: async_example (async)\n    END: async_example (async) - Total time: 1.0012s\n    \"\"\"\n    assert callable(func) or func is None\n\n    def decorator(func: Callable) -&gt; Callable:\n        @functools.wraps(func)\n        async def async_wrapper(*args, **kwargs) -&gt; Any:\n            nonlocal logger\n            if logger is None:\n                logger = logging.getLogger(func.__module__)\n\n            start_time = time.time()\n            logger.info(f\"START: {func.__name__} (async)\")\n\n            try:\n                result = await func(*args, **kwargs)\n            except KeyboardInterrupt:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"INTERRUPTED: {func.__name__} (async) - Total time: {total_time:.4f}s\"\n                )\n                return []\n            except Exception as e:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.exception(\n                    f\"EXCEPTION in {func.__name__} (async) - Total time: {total_time:.4f}s\"\n                )\n                raise\n            else:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"END: {func.__name__} (async) - Total time: {total_time:.4f}s\"\n                )\n                return result\n\n        @functools.wraps(func)\n        def sync_wrapper(*args, **kwargs) -&gt; Any:\n            nonlocal logger\n            if logger is None:\n                logger = logging.getLogger(func.__module__)\n\n            start_time = time.time()\n            logger.info(f\"START: {func.__name__} (sync)\")\n\n            try:\n                result = func(*args, **kwargs)\n            except KeyboardInterrupt:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"INTERRUPTED: {func.__name__} (sync) - Total time: {total_time:.4f}s\"\n                )\n                return []\n            except Exception as e:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.exception(\n                    f\"EXCEPTION in {func.__name__} (sync) - Total time: {total_time:.4f}s\"\n                )\n                raise\n            else:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"END: {func.__name__} (sync) - Total time: {total_time:.4f}s\"\n                )\n                return result\n\n        if asyncio.iscoroutinefunction(func):\n            return async_wrapper\n        else:\n            return sync_wrapper\n\n    return decorator(func) if callable(func) else decorator\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers","title":"humbldata.core.utils.openbb_helpers","text":"<p>Core Module - OpenBB Helpers.</p> <p>This module contains functions used to interact with OpenBB, or wrap commands to have specific data outputs.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.obb_login","title":"humbldata.core.utils.openbb_helpers.obb_login","text":"<pre><code>obb_login(pat: str | None = None) -&gt; bool\n</code></pre> <p>Log into the OpenBB Hub using a Personal Access Token (PAT).</p> <p>This function wraps the <code>obb.account.login</code> method to provide a simplified interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT is provided, it attempts to use the PAT stored in the environment variable <code>OBB_PAT</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pat</code> <code>str | None</code> <p>The personal access token for authentication. If None, the token is retrieved from the environment variable <code>OBB_PAT</code>. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if login is successful, False otherwise.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If an error occurs during the login process.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\nTrue\n</code></pre> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>def obb_login(pat: str | None = None) -&gt; bool:\n    \"\"\"\n    Log into the OpenBB Hub using a Personal Access Token (PAT).\n\n    This function wraps the `obb.account.login` method to provide a simplified\n    interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT\n    is provided, it attempts to use the PAT stored in the environment variable\n    `OBB_PAT`.\n\n    Parameters\n    ----------\n    pat : str | None, optional\n        The personal access token for authentication. If None, the token is\n        retrieved from the environment variable `OBB_PAT`. Default is None.\n\n    Returns\n    -------\n    bool\n        True if login is successful, False otherwise.\n\n    Raises\n    ------\n    HumblDataError\n        If an error occurs during the login process.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\n    True\n\n    &gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\n    True\n\n    \"\"\"\n    if pat is None:\n        pat = Env().OBB_PAT\n    try:\n        obb.account.login(pat=pat, remember_me=True)\n        # obb.account.save()\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"true\")\n\n        return True\n    except Exception as e:\n        from humbldata.core.standard_models.abstract.warnings import (\n            HumblDataWarning,\n        )\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"false\")\n\n        warnings.warn(\n            \"An error occurred while logging into OpenBB. Details below:\\n\"\n            + repr(e),\n            category=HumblDataWarning,\n            stacklevel=1,\n        )\n        return False\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.get_latest_price","title":"humbldata.core.utils.openbb_helpers.get_latest_price","text":"<pre><code>get_latest_price(symbol: str | list[str] | Series, provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_latest_price.</p> <p>Queries the latest stock price data for the given symbol(s) using the specified provider. Defaults to YahooFinance (<code>yfinance</code>) if no provider is specified. Returns a LazyFrame with the stock symbols and their latest prices.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str | list[str] | Series</code> <p>The stock symbol(s) to query for the latest price. Accepts a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_QUOTE_PROVIDERS</code> <p>The data provider for fetching stock prices. Defaults is <code>yfinance</code>, in which case a default provider is used.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their latest prices ('last_price').</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>def get_latest_price(\n    symbol: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_latest_price**.\n\n    Queries the latest stock price data for the given symbol(s) using the\n    specified provider. Defaults to YahooFinance (`yfinance`) if no provider is\n    specified. Returns a LazyFrame with the stock symbols and their latest prices.\n\n    Parameters\n    ----------\n    symbol : str | list[str] | pl.Series\n        The stock symbol(s) to query for the latest price. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n    provider : OBB_EQUITY_PRICE_QUOTE_PROVIDERS, optional\n        The data provider for fetching stock prices. Defaults is `yfinance`,\n        in which case a default provider is used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their latest prices ('last_price').\n    \"\"\"\n    logging.getLogger(\"openbb_terminal.stocks.stocks_model\").setLevel(\n        logging.CRITICAL\n    )\n\n    return (\n        obb.equity.price.quote(symbol, provider=provider)\n        .to_polars()\n        .lazy()\n        .select([\"symbol\", \"last_price\"])\n        .rename({\"last_price\": \"recent_price\"})\n    )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.aget_latest_price","title":"humbldata.core.utils.openbb_helpers.aget_latest_price  <code>async</code>","text":"<pre><code>aget_latest_price(symbols: str | list[str] | Series, provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Asynchronous version of get_latest_price.</p> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_latest_price_async.</p> <p>Queries the latest stock price data for the given symbol(s) using the specified provider asynchronously. This functions collects the latest prices for ETF's and Equities, but not futures or options. Defaults to YahooFinance (<code>yfinance</code>) if no provider is specified. Returns a LazyFrame with the stock symbols and their latest prices.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | List[str] | Series</code> <p>The stock symbol(s) to query for the latest price. Accepts a single symbol, a list of symbols, or a Polars Series of symbols. You can pass multiple symbols as a string; <code>'AAPL,XLE'</code>, and it will split the string into a list of symbols.</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_QUOTE_PROVIDERS</code> <p>The data provider for fetching stock prices. Default is <code>yfinance</code>.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their latest prices ('recent_price').</p> Notes <p>If entering symbols as a string, DO NOT include spaces between the symbols.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_latest_price(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Asynchronous version of get_latest_price.\n\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_latest_price_async**.\n\n    Queries the latest stock price data for the given symbol(s) using the\n    specified provider asynchronously. This functions collects the latest prices\n    for ETF's and Equities, but not futures or options. Defaults to YahooFinance\n    (`yfinance`) if no provider is specified. Returns a LazyFrame with the stock\n    symbols and their latest prices.\n\n    Parameters\n    ----------\n    symbols : str | List[str] | pl.Series\n        The stock symbol(s) to query for the latest price. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n        You can pass multiple symbols as a string; `'AAPL,XLE'`, and it will\n        split the string into a list of symbols.\n    provider : OBB_EQUITY_PRICE_QUOTE_PROVIDERS, optional\n        The data provider for fetching stock prices. Default is `yfinance`.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their latest prices ('recent_price').\n\n    Notes\n    -----\n    If entering symbols as a string, DO NOT include spaces between the symbols.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    result = await loop.run_in_executor(\n        None, lambda: obb.equity.price.quote(symbols, provider=provider)\n    )\n    out = result.to_polars().lazy()\n    if {\"last_price\", \"prev_close\"}.issubset(out.collect_schema().names()):\n        out = out.select(\n            [\n                pl.when(pl.col(\"asset_type\") == \"ETF\")\n                .then(pl.col(\"prev_close\"))\n                .otherwise(pl.col(\"last_price\"))\n                .alias(\"last_price\"),\n                pl.col(\"symbol\"),\n            ]\n        )\n    elif \"last_price\" not in out.collect_schema().names():\n        out = out.select(\n            pl.col(\"symbol\"), pl.col(\"prev_close\").alias(\"last_price\")\n        )\n    else:\n        out = out.select(pl.col(\"symbol\"), pl.col(\"last_price\"))\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.aget_last_close","title":"humbldata.core.utils.openbb_helpers.aget_last_close  <code>async</code>","text":"<pre><code>aget_last_close(symbols: str | list[str] | Series, provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: aget_last_close.</p> <p>Asynchronously retrieves the last closing price for the given stock symbol(s) using OpenBB's equity price quote data.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | List[str] | Series</code> <p>The stock symbol(s) to query for the last closing price. Accepts a single symbol, a list of symbols, or a Polars Series of symbols. You can pass multiple symbols as a string; <code>'AAPL,XLE'</code>, and it will split the string into a list of symbols.</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_QUOTE_PROVIDERS</code> <p>The data provider for fetching stock prices. Default is <code>yfinance</code>.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their last closing prices ('prev_close').</p> Notes <p>This function uses OpenBB's equity price quote data to fetch the last closing price. It returns a lazy frame for efficient processing, especially with large datasets.</p> <p>If entering symbols as a string, DO NOT include spaces between the symbols.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_last_close(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: aget_last_close**.\n\n    Asynchronously retrieves the last closing price for the given stock symbol(s) using OpenBB's equity price quote data.\n\n    Parameters\n    ----------\n    symbols : str | List[str] | pl.Series\n        The stock symbol(s) to query for the last closing price. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols. You can pass\n        multiple symbols as a string; `'AAPL,XLE'`, and it will split the string\n        into a list of symbols.\n    provider : OBB_EQUITY_PRICE_QUOTE_PROVIDERS, optional\n        The data provider for fetching stock prices. Default is `yfinance`.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their last closing prices ('prev_close').\n\n    Notes\n    -----\n    This function uses OpenBB's equity price quote data to fetch the last closing price.\n    It returns a lazy frame for efficient processing, especially with large datasets.\n\n    If entering symbols as a string, DO NOT include spaces between the symbols.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    result = await loop.run_in_executor(\n        None, lambda: obb.equity.price.quote(symbols, provider=provider)\n    )\n    out = result.to_polars().lazy()\n\n    return out.select(pl.col(\"symbol\"), pl.col(\"prev_close\"))\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.get_equity_sector","title":"humbldata.core.utils.openbb_helpers.get_equity_sector","text":"<pre><code>get_equity_sector(symbols: str | list[str] | Series, provider: OBB_EQUITY_PROFILE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_sector.</p> <p>Retrieves the sector information for the given stock symbol(s) using OpenBB's equity profile data.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | Series</code> <p>The stock symbol(s) to query for sector information. Accepts a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>str | None</code> <p>The data provider to use for fetching sector information. If None, the default provider will be used.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their corresponding sectors ('sector').</p> Notes <p>This function uses OpenBB's equity profile data to fetch sector information. It returns a lazy frame for efficient processing, especially with large datasets.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>def get_equity_sector(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PROFILE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_sector**.\n\n    Retrieves the sector information for the given stock symbol(s) using OpenBB's equity profile data.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | pl.Series\n        The stock symbol(s) to query for sector information. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n    provider : str | None, optional\n        The data provider to use for fetching sector information. If None, the default\n        provider will be used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their corresponding sectors ('sector').\n\n    Notes\n    -----\n    This function uses OpenBB's equity profile data to fetch sector information.\n    It returns a lazy frame for efficient processing, especially with large datasets.\n    \"\"\"\n    try:\n        result = obb.equity.profile(symbols, provider=provider)\n        return result.to_polars().select([\"symbol\", \"sector\"]).lazy()\n    except pl.exceptions.ColumnNotFoundError:\n        # If an error occurs, return a LazyFrame with symbol and null sector\n        if isinstance(symbols, str):\n            symbols = [symbols]\n        elif isinstance(symbols, pl.Series):\n            symbols = symbols.to_list()\n        return pl.LazyFrame(\n            {\"symbol\": symbols, \"sector\": [None] * len(symbols)}\n        )\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.aget_equity_sector","title":"humbldata.core.utils.openbb_helpers.aget_equity_sector  <code>async</code>","text":"<pre><code>aget_equity_sector(symbols: str | list[str] | Series, provider: OBB_EQUITY_PROFILE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Asynchronous version of get_sector.</p> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_sector_async.</p> <p>Retrieves the sector information for the given stock symbol(s) using OpenBB's equity profile data asynchronously. If an ETF is passed, it will return a NULL sector for the symbol. The sector returned hasn't been normalized to GICS_SECTORS, it is the raw OpenBB sector output. Sectors are normalized to GICS_SECTORS in the <code>aet_sector_filter</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | List[str] | Series</code> <p>The stock symbol(s) to query for sector information. Accepts a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>str | None</code> <p>The data provider to use for fetching sector information. If None, the default provider will be used.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their corresponding sectors ('sector').</p> Notes <p>This function uses OpenBB's equity profile data to fetch sector information. It returns a lazy frame for efficient processing, especially with large datasets.</p> <p>If you just pass an ETF to the <code>obb.equity.profile</code> function, it will throw return data without the NULL columns (sector column included) and only returns columns where there is data, so we need to handle that edge case. If an ETF is included with an equity, it will return a NULL sector column, so we can select the sector column from the ETF data and return it as a NULL sector for the equity.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_equity_sector(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PROFILE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Asynchronous version of get_sector.\n\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_sector_async**.\n\n    Retrieves the sector information for the given stock symbol(s) using\n    OpenBB's equity profile data asynchronously. If an ETF is passed, it will\n    return a NULL sector for the symbol. The sector returned hasn't been\n    normalized to GICS_SECTORS, it is the raw OpenBB sector output.\n    Sectors are normalized to GICS_SECTORS in the `aet_sector_filter` function.\n\n    Parameters\n    ----------\n    symbols : str | List[str] | pl.Series\n        The stock symbol(s) to query for sector information. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n    provider : str | None, optional\n        The data provider to use for fetching sector information. If None, the default\n        provider will be used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their corresponding sectors ('sector').\n\n    Notes\n    -----\n    This function uses OpenBB's equity profile data to fetch sector information.\n    It returns a lazy frame for efficient processing, especially with large datasets.\n\n    If you just pass an ETF to the `obb.equity.profile` function, it will throw\n    return data without the NULL columns (sector column included) and only\n    returns columns where there is data, so we need to handle that edge case.\n    If an ETF is included with an equity, it will return a NULL sector column,\n    so we can select the sector column from the ETF data and return it as a\n    NULL sector for the equity.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    try:\n        result = await loop.run_in_executor(\n            None, lambda: obb.equity.profile(symbols, provider=provider)\n        )\n        return result.to_polars().select([\"symbol\", \"sector\"]).lazy()\n    except pl.exceptions.ColumnNotFoundError:\n        # If an error occurs, return a LazyFrame with symbol and null sector\n        if isinstance(symbols, str):\n            symbols = [symbols]\n        elif isinstance(symbols, pl.Series):\n            symbols = symbols.to_list()\n        return pl.LazyFrame(\n            {\"symbol\": symbols, \"sector\": [None] * len(symbols)}\n        ).cast(pl.Utf8)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.aget_etf_category","title":"humbldata.core.utils.openbb_helpers.aget_etf_category  <code>async</code>","text":"<pre><code>aget_etf_category(symbols: str | list[str] | Series, provider: OBB_ETF_INFO_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Asynchronously retrieves the category information for the given ETF symbol(s).</p> <p>This function uses the <code>obb.etf.info</code> function and selects the <code>category</code> column to get the sector information. This function handles EQUITY symbols that are not ETF's the same way that <code>aget_equity_sector</code> does. The sector returned (under the OpenBB column name <code>category</code>) hasn't been normalized to GICS_SECTORS, it is the raw OpenBB category output. Sectors are normalized to GICS_SECTORS in the <code>aget_sector_filter</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | Series</code> <p>The ETF symbol(s) to query for category information.</p> required <code>provider</code> <code>OBB_EQUITY_PROFILE_PROVIDERS | None</code> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the ETF symbols ('symbol') and their corresponding categories ('category').</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_etf_category(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_ETF_INFO_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Asynchronously retrieves the category information for the given ETF symbol(s).\n\n    This function uses the `obb.etf.info` function and selects the `category`\n    column to get the sector information. This function handles EQUITY\n    symbols that are not ETF's the same way that `aget_equity_sector` does.\n    The sector returned (under the OpenBB column name `category`) hasn't been\n    normalized to GICS_SECTORS, it is the raw OpenBB category output.\n    Sectors are normalized to GICS_SECTORS in the `aget_sector_filter` function.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | pl.Series\n        The ETF symbol(s) to query for category information.\n    provider : OBB_EQUITY_PROFILE_PROVIDERS | None, optional\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the ETF symbols ('symbol') and\n        their corresponding categories ('category').\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    try:\n        result = await loop.run_in_executor(\n            None, lambda: obb.etf.info(symbols, provider=provider)\n        )\n        out = result.to_polars().lazy().select([\"symbol\", \"category\"])\n        # Create a LazyFrame with all input symbols\n        all_symbols = pl.LazyFrame({\"symbol\": symbols})\n\n        # Left join to include all input symbols, filling missing sectors with null\n        out = all_symbols.join(out, on=\"symbol\", how=\"left\").with_columns(\n            [\n                pl.when(pl.col(\"category\").is_null())\n                .then(None)\n                .otherwise(pl.col(\"category\"))\n                .alias(\"category\")\n            ]\n        )\n    except OpenBBError:\n        if isinstance(symbols, str):\n            symbols = [symbols]\n        elif isinstance(symbols, pl.Series):\n            symbols = symbols.to_list()\n        return pl.LazyFrame(\n            {\"symbol\": symbols, \"category\": [None] * len(symbols)}\n        ).cast(pl.Utf8)\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.core_helpers","title":"humbldata.core.utils.core_helpers","text":"<p>A module to contain core helper functions for the program.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.core_helpers.is_debug_mode","title":"humbldata.core.utils.core_helpers.is_debug_mode","text":"<pre><code>is_debug_mode() -&gt; bool\n</code></pre> <p>Check if the current system is in debug mode.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the system is in debug mode, False otherwise.</p> Source code in <code>src/humbldata/core/utils/core_helpers.py</code> <pre><code>def is_debug_mode() -&gt; bool:\n    \"\"\"\n    Check if the current system is in debug mode.\n\n    Returns\n    -------\n    bool\n        True if the system is in debug mode, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.core_helpers.run_async","title":"humbldata.core.utils.core_helpers.run_async","text":"<pre><code>run_async(coro)\n</code></pre> <p>Run an async function in a new thread and return the result.</p> Source code in <code>src/humbldata/core/utils/core_helpers.py</code> <pre><code>def run_async(coro):\n    \"\"\"Run an async function in a new thread and return the result.\"\"\"\n    with ThreadPoolExecutor() as executor:\n        future = executor.submit(lambda: asyncio.run(coro))\n        return future.result()\n</code></pre>"},{"location":"code_documentation/category/","title":"\ud83d\udcda Category","text":""},{"location":"code_documentation/command/","title":"\ud83c\udfc3\ud83c\udffc\u200d\u2642\ufe0f Command","text":""},{"location":"code_documentation/core/","title":"\ud83d\udd78\ufe0f Core","text":"<p>The <code>core</code> module to contain logic &amp; functions used in controllers.</p> <p>This module is intended to contain sub-modules and functions that are not directly utilized from the package, but rather used in building the package itself. This means that the core module should not contain any code that is specific to the package's use case, but rather should be generic and reusable in other contexts.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models","title":"humbldata.core.standard_models","text":"<p>Models to represent core data structures of the Standardization Framework.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract","title":"humbldata.core.standard_models.abstract","text":"<p>Abstract core DATA MODELS to be inherited by other models.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.errors","title":"humbldata.core.standard_models.abstract.errors","text":"<p>An ABSTRACT DATA MODEL to be inherited by custom errors.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.errors.HumblDataError","title":"humbldata.core.standard_models.abstract.errors.HumblDataError","text":"<p>             Bases: <code>BaseException</code></p> <p>Base Error for HumblData logic.</p> Source code in <code>src/humbldata/core/standard_models/abstract/errors.py</code> <pre><code>class HumblDataError(BaseException):\n    \"\"\"Base Error for HumblData logic.\"\"\"\n\n    def __init__(self, original: str | Exception | None = None):\n        self.original = original\n        super().__init__(str(original))\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.query_params","title":"humbldata.core.standard_models.abstract.query_params","text":"<p>A wrapper around OpenBB QueryParams Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.query_params.QueryParams","title":"humbldata.core.standard_models.abstract.query_params.QueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>An abstract standard_model to represent a base QueryParams Data.</p> <p>QueryParams model should be used to define the query parameters for a <code>context.category.command</code> call.</p> <p>This QueryParams model is meant to be inherited and built upon by other standard_models for a specific context.</p> <p>Examples:</p> <pre><code>class EquityHistoricalQueryParams(QueryParams):\n\n    symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n    interval: Optional[str] = Field(\n        default=\"1d\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n    )\n    end_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n    )\n\n    @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n        if isinstance(v, str):\n            return v.upper()\n        return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre> <p>This would create a class that would be used to query historical price data for equities from any given command.</p> <p>This could then be used to create a <code>MandelbrotChannelEquityHistoricalQueryParams</code> that would define what query parameters are needed for the Mandelbrot Channel command.</p> Source code in <code>src/humbldata/core/standard_models/abstract/query_params.py</code> <pre><code>class QueryParams(OpenBBQueryParams):\n    \"\"\"\n    An abstract standard_model to represent a base QueryParams Data.\n\n    QueryParams model should be used to define the query parameters for a\n    `context.category.command` call.\n\n    This QueryParams model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Examples\n    --------\n    ```py\n    class EquityHistoricalQueryParams(QueryParams):\n\n        symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n        interval: Optional[str] = Field(\n            default=\"1d\",\n            description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n        )\n        start_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n        )\n        end_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n        )\n\n        @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n        @classmethod\n        def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n            if isinstance(v, str):\n                return v.upper()\n            return \",\".join([symbol.upper() for symbol in list(v)])\n    ```\n\n    This would create a class that would be used to query historical price data\n    for equities from any given command.\n\n    This could then be used to create a\n    `MandelbrotChannelEquityHistoricalQueryParams` that would define what query\n    parameters are needed for the Mandelbrot Channel command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.singleton","title":"humbldata.core.standard_models.abstract.singleton","text":"<p>An ABSTRACT DATA MODEL, Singleton, to represent a class that should only have one instance.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.singleton.SingletonMeta","title":"humbldata.core.standard_models.abstract.singleton.SingletonMeta","text":"<p>             Bases: <code>type</code>, <code>Generic[T]</code></p> <p>SingletonMeta is a metaclass that creates a Singleton instance of a class.</p> <p>Singleton design pattern restricts the instantiation of a class to a single instance. This is useful when exactly one object is needed to coordinate actions across the system.</p> Source code in <code>src/humbldata/core/standard_models/abstract/singleton.py</code> <pre><code>class SingletonMeta(type, Generic[T]):\n    \"\"\"\n    SingletonMeta is a metaclass that creates a Singleton instance of a class.\n\n    Singleton design pattern restricts the instantiation of a class to a single\n    instance. This is useful when exactly one object is needed to coordinate\n    actions across the system.\n    \"\"\"\n\n    _instances: ClassVar[dict[T, T]] = {}  # type: ignore  # noqa: PGH003\n\n    def __call__(cls, *args, **kwargs) -&gt; T:\n        \"\"\"\n        Override the __call__ method.\n\n        If the class exists, otherwise creates a new instance and stores it in\n        the _instances dictionary.\n        \"\"\"\n        if cls not in cls._instances:\n            instance = super().__call__(*args, **kwargs)\n            cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n        return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.singleton.SingletonMeta.__call__","title":"humbldata.core.standard_models.abstract.singleton.SingletonMeta.__call__","text":"<pre><code>__call__(*args, **kwargs) -&gt; T\n</code></pre> <p>Override the call method.</p> <p>If the class exists, otherwise creates a new instance and stores it in the _instances dictionary.</p> Source code in <code>src/humbldata/core/standard_models/abstract/singleton.py</code> <pre><code>def __call__(cls, *args, **kwargs) -&gt; T:\n    \"\"\"\n    Override the __call__ method.\n\n    If the class exists, otherwise creates a new instance and stores it in\n    the _instances dictionary.\n    \"\"\"\n    if cls not in cls._instances:\n        instance = super().__call__(*args, **kwargs)\n        cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n    return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.chart","title":"humbldata.core.standard_models.abstract.chart","text":""},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.chart.ChartTemplate","title":"humbldata.core.standard_models.abstract.chart.ChartTemplate","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Chart format.</p> <p>Available options: - plotly - humbl_light - humbl_dark - plotly_light - plotly_dark - ggplot2 - seaborn - simple_white - presentation - xgridoff - ygridoff - gridon - none</p> Source code in <code>src/humbldata/core/standard_models/abstract/chart.py</code> <pre><code>class ChartTemplate(str, Enum):\n    \"\"\"\n    Chart format.\n\n    Available options:\n    - plotly\n    - humbl_light\n    - humbl_dark\n    - plotly_light\n    - plotly_dark\n    - ggplot2\n    - seaborn\n    - simple_white\n    - presentation\n    - xgridoff\n    - ygridoff\n    - gridon\n    - none\n    \"\"\"\n\n    plotly = \"plotly\"\n    humbl_light = \"humbl_light\"\n    humbl_dark = \"humbl_dark\"\n    plotly_light = \"plotly_light\"\n    plotly_dark = \"plotly_dark\"\n    ggplot2 = \"ggplot2\"\n    seaborn = \"seaborn\"\n    simple_white = \"simple_white\"\n    presentation = \"presentation\"\n    xgridoff = \"xgridoff\"\n    ygridoff = \"ygridoff\"\n    gridon = \"gridon\"\n    none = \"none\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.chart.Chart","title":"humbldata.core.standard_models.abstract.chart.Chart","text":"<p>             Bases: <code>BaseModel</code></p> <p>a Chart Object that is returned from a View.</p> Source code in <code>src/humbldata/core/standard_models/abstract/chart.py</code> <pre><code>class Chart(BaseModel):\n    \"\"\"a Chart Object that is returned from a View.\"\"\"\n\n    content: str | None = Field(\n        default=None,\n        description=\"Raw textual representation of the chart.\",\n    )\n    theme: ChartTemplate | None = Field(\n        default=ChartTemplate.plotly,\n        description=\"Complementary attribute to the `content` attribute. It specifies the format of the chart.\",\n    )\n    fig: Any | None = Field(\n        default=None,\n        description=\"The figure object.\",\n        # json_schema_extra={\"exclude_from_api\": True},\n    )\n    model_config = ConfigDict(validate_assignment=True)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Human readable representation of the object.\"\"\"\n        items = [\n            f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n            for k, v in self.model_dump().items()\n        ]\n\n        return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.chart.Chart.__repr__","title":"humbldata.core.standard_models.abstract.chart.Chart.__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Human readable representation of the object.</p> Source code in <code>src/humbldata/core/standard_models/abstract/chart.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Human readable representation of the object.\"\"\"\n    items = [\n        f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n        for k, v in self.model_dump().items()\n    ]\n\n    return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.data","title":"humbldata.core.standard_models.abstract.data","text":"<p>A wrapper around OpenBB Data Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.data.Data","title":"humbldata.core.standard_models.abstract.data.Data","text":"<p>             Bases: <code>DataFrameModel</code></p> <p>An abstract standard_model to represent a base Data Model.</p> <p>The Data Model should be used to define the data that is being collected and analyzed in a <code>context.category.command</code> call.</p> <p>This Data model is meant to be inherited and built upon by other standard_models for a specific context.</p> Example <pre><code>class EquityHistoricalData(Data):\n\ndate: Union[dateType, datetime] = Field(\n    description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n)\nopen: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\nhigh: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\nlow: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\nclose: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\nvolume: Optional[Union[float, int]] = Field(\n    default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n)\n\n@field_validator(\"date\", mode=\"before\", check_fields=False)\ndef date_validate(cls, v):  # pylint: disable=E0213\n    v = parser.isoparse(str(v))\n    if v.hour == 0 and v.minute == 0:\n        return v.date()\n    return v\n</code></pre> Source code in <code>src/humbldata/core/standard_models/abstract/data.py</code> <pre><code>class Data(pa.DataFrameModel):\n    \"\"\"\n    An abstract standard_model to represent a base Data Model.\n\n    The Data Model should be used to define the data that is being\n    collected and analyzed in a `context.category.command` call.\n\n    This Data model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Example\n    -------\n    ```py\n    class EquityHistoricalData(Data):\n\n    date: Union[dateType, datetime] = Field(\n        description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n    )\n    open: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\n    high: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\n    low: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\n    close: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\n    volume: Optional[Union[float, int]] = Field(\n        default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n    )\n\n    @field_validator(\"date\", mode=\"before\", check_fields=False)\n    def date_validate(cls, v):  # pylint: disable=E0213\n        v = parser.isoparse(str(v))\n        if v.hour == 0 and v.minute == 0:\n            return v.date()\n        return v\n\n    ```\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject","title":"humbldata.core.standard_models.abstract.humblobject","text":""},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.extract_subclass_dict","title":"humbldata.core.standard_models.abstract.humblobject.extract_subclass_dict","text":"<pre><code>extract_subclass_dict(self, attribute_name: str, items: list)\n</code></pre> <p>Extract the dictionary representation of the specified attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attribute_name</code> <code>str</code> <p>The name of the attribute to update in the items list.</p> required Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def extract_subclass_dict(self, attribute_name: str, items: list):\n    \"\"\"\n    Extract the dictionary representation of the specified attribute.\n\n    Parameters\n    ----------\n    attribute_name : str\n        The name of the attribute to update in the items list.\n    \"\"\"\n    # Check if the attribute exists and has a value\n    attribute_value = getattr(self, attribute_name, None)\n    if attribute_value:\n        # Assuming the attribute has a method called 'model_dump' to get its dictionary representation\n        add_item = attribute_value.model_dump()\n        add_item_str = str(add_item)\n        if len(add_item_str) &gt; 80:\n            add_item_str = add_item_str[:80] + \"...\"\n        for i, item in enumerate(items):\n            if item.startswith(f\"{attribute_name}:\"):\n                items[i] = f\"{attribute_name}: {add_item_str}\"\n                break\n\n    return items\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject","text":"<p>             Bases: <code>Tagged</code>, <code>Generic[T]</code></p> <p>HumblObject is the base class for all dta returned from the Toolbox.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>class HumblObject(Tagged, Generic[T]):\n    \"\"\"HumblObject is the base class for all dta returned from the Toolbox.\"\"\"\n\n    _user_settings: ClassVar[BaseModel | None] = None\n    _system_settings: ClassVar[BaseModel | None] = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    results: T | None = Field(\n        default=None,\n        description=\"Serializable Logical Plan of the pl.LazyFrame results.\",\n    )\n    equity_data: T | None = Field(\n        default=None,\n        description=\"Serialized raw data used in the command calculations.\",\n    )\n    provider: str | None = Field(\n        default=None,\n        description=\"Provider name.\",\n    )\n    warnings: list[Warning_] | None = Field(\n        default=None,\n        description=\"List of warnings.\",\n    )\n    chart: Chart | list[Chart] | None = Field(\n        default=None,\n        description=\"Chart object.\",\n    )\n    extra: dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Extra info.\",\n    )\n    context_params: ToolboxQueryParams | PortfolioQueryParams | None = Field(\n        default_factory=ToolboxQueryParams,\n        title=\"Context Parameters\",\n        description=\"Context parameters.\",\n    )\n    command_params: SerializeAsAny[QueryParams] | None = Field(\n        default=QueryParams,\n        title=\"Command Parameters\",\n        description=\"Command-specific parameters.\",\n    )\n\n    # @field_validator(\"command_params\")\n    # def validate_command_params(cls, v):\n    #     class_name = v.__class__.__name__\n    #     if \"QueryParams\" in class_name:\n    #         return v\n    #     msg = \"Wrong type for 'command_params', must be subclass of QueryParams\"\n    #     raise TypeError(msg)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Human readable representation of the object.\"\"\"\n        items = [\n            f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n            for k, v in self.model_dump().items()\n        ]\n\n        # Needed to extract subclass dict correctly\n        # items = extract_subclass_dict(self, \"command_params\", items)\n\n        return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n\n    def to_polars(\n        self, collect: bool = True, equity_data: bool = False\n    ) -&gt; pl.LazyFrame | pl.DataFrame:\n        \"\"\"\n        Deserialize the stored results or return the LazyFrame, and optionally collect them into a Polars DataFrame.\n\n        Parameters\n        ----------\n        collect : bool, optional\n            If True, collects the deserialized LazyFrame into a DataFrame.\n            Default is True.\n        equity_data : bool, optional\n            If True, processes equity_data instead of results.\n            Default is False.\n\n        Returns\n        -------\n        pl.LazyFrame | pl.DataFrame\n            The results as a Polars LazyFrame or DataFrame,\n            depending on the collect parameter.\n\n        Raises\n        ------\n        HumblDataError\n            If no results or equity data are found to process\n        \"\"\"\n        data = self.equity_data if equity_data else self.results\n\n        if data is None:\n            raise HumblDataError(\"No data found.\")\n\n        if isinstance(data, pl.LazyFrame):\n            out = data\n        elif isinstance(data, str):\n            with io.StringIO(data) as data_io:\n                out = pl.LazyFrame.deserialize(data_io, format=\"json\")\n        elif isinstance(data, bytes):\n            with io.BytesIO(data) as data_io:\n                out = pl.LazyFrame.deserialize(data_io, format=\"binary\")\n        else:\n            raise HumblDataError(\n                \"Invalid data type. Expected LazyFrame or serialized string.\"\n            )\n\n        if collect:\n            out = out.collect()\n\n        return out\n\n    def to_df(\n        self, collect: bool = True, equity_data: bool = False\n    ) -&gt; pl.LazyFrame | pl.DataFrame:\n        \"\"\"\n        Alias for the `to_polars` method.\n\n        Parameters\n        ----------\n        collect : bool, optional\n            If True, collects the deserialized LazyFrame into a DataFrame.\n            Default is True.\n\n        Returns\n        -------\n        pl.LazyFrame | pl.DataFrame\n            The deserialized results as a Polars LazyFrame or DataFrame,\n            depending on the collect parameter.\n        \"\"\"\n        return self.to_polars(collect=collect, equity_data=equity_data)\n\n    def to_pandas(self, equity_data: bool = False) -&gt; pd.DataFrame:\n        \"\"\"\n        Convert the results to a Pandas DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The results as a Pandas DataFrame.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_pandas()\n\n    def to_numpy(self, equity_data: bool = False) -&gt; np.ndarray:\n        \"\"\"\n        Convert the results to a NumPy array.\n\n        Returns\n        -------\n        np.ndarray\n            The results as a NumPy array.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_numpy()\n\n    def to_dict(\n        self,\n        row_wise: bool = False,\n        equity_data: bool = False,\n        as_series: bool = True,\n    ) -&gt; dict | list[dict]:\n        \"\"\"\n        Transform the stored data into a dictionary or a list of dictionaries.\n\n        This method allows for the conversion of the internal data\n        representation into a more universally accessible format, either\n        aggregating the entire dataset into a single dictionary (column-wise)\n        or breaking it down into a list of dictionaries, each representing a\n        row in the dataset.\n\n        Parameters\n        ----------\n        row_wise : bool, optional\n            Determines the format of the output. If set to True, the method\n            returns a list of dictionaries, with each dictionary representing a\n            row and its corresponding data as key-value pairs. If set to False,\n            the method returns a single dictionary, with column names as keys\n            and lists of column data as values. Default is False.\n\n        equity_data : bool, optional\n            A flag to specify whether to use equity-specific data for the\n            conversion. This parameter allows for flexibility in handling\n            different types of data stored within the object. Default is\n            False.\n        as_series : bool, optional\n            If True, the method returns a pl.Series with values as Series. If\n            False, the method returns a dict with values as List[Any].\n            Default is True.\n\n        Returns\n        -------\n        dict | list[dict]\n            Depending on the `row_wise` parameter, either a dictionary mapping column names to lists of values (if `row_wise` is False) or a list of dictionaries, each representing a row in the dataset (if `row_wise` is True).\n        \"\"\"\n        if row_wise:\n            return self.to_polars(\n                collect=True, equity_data=equity_data\n            ).to_dicts()\n        return self.to_polars(collect=True, equity_data=equity_data).to_dict(\n            as_series=as_series\n        )\n\n    def to_arrow(self, equity_data: bool = False) -&gt; pa.Table:\n        \"\"\"\n        Convert the results to an Arrow Table.\n\n        Returns\n        -------\n        pa.Table\n            The results as an Arrow Table.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_arrow()\n\n    def to_struct(\n        self, name: str = \"results\", equity_data: bool = False\n    ) -&gt; pl.Series:\n        \"\"\"\n        Convert the results to a struct.\n\n        Parameters\n        ----------\n        name : str, optional\n            The name of the struct. Default is \"results\".\n\n        Returns\n        -------\n        pl.Struct\n            The results as a struct.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).to_struct(\n            name=name\n        )\n\n    def to_json(\n        self, equity_data: bool = False, chart: bool = False\n    ) -&gt; str | list[str]:\n        \"\"\"\n        Convert the results to a JSON string.\n\n        Parameters\n        ----------\n        equity_data : bool, optional\n            A flag to specify whether to use equity-specific data for the\n            conversion. Default is False.\n        chart : bool, optional\n            If True, return all generated charts as a JSON string instead of\n            returning the results. Default is False.\n\n        Returns\n        -------\n        str\n            The results or charts as a JSON string.\n\n        Raises\n        ------\n        HumblDataError\n            If chart is True but no charts are available.\n        \"\"\"\n        import json\n        from datetime import date, datetime\n\n        from humbldata.core.standard_models.abstract.errors import (\n            HumblDataError,\n        )\n\n        def json_serial(obj):\n            \"\"\"JSON serializer for objects not serializable by default json code.\"\"\"\n            if isinstance(obj, (datetime, date)):\n                return obj.isoformat()\n            msg = f\"Type {type(obj)} not serializable\"\n            raise TypeError(msg)\n\n        if chart:\n            if self.chart is None:\n                msg = f\"You set `.to_json(chart=True)` but there were no charts. Make sure `chart=True` in {self.command_params.__class__.__name__}\"\n                raise HumblDataError(msg)\n\n            if isinstance(self.chart, list):\n                return [\n                    chart.content\n                    for chart in self.chart\n                    if chart and chart.content\n                ]\n            else:\n                return self.chart.content\n        else:\n            data = self.to_polars(\n                collect=True, equity_data=equity_data\n            ).to_dict(as_series=False)\n            return json.dumps(data, default=json_serial)\n\n    def is_empty(self, equity_data: bool = False) -&gt; bool:\n        \"\"\"\n        Check if the results are empty.\n\n        Returns\n        -------\n        bool\n            True if the results are empty, False otherwise.\n        \"\"\"\n        return self.to_polars(collect=True, equity_data=equity_data).is_empty()\n\n    def show(self) -&gt; None:\n        \"\"\"Show the chart.\"\"\"\n        if isinstance(self.chart, list):\n            for chart in self.chart:\n                if chart and chart.fig:\n                    chart.fig.show()\n                else:\n                    msg = \"Chart object is missing or incomplete.\"\n                    raise HumblDataError(msg)\n        elif not self.chart or not self.chart.fig:\n            msg = \"Chart not found.\"\n            raise HumblDataError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.__repr__","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Human readable representation of the object.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Human readable representation of the object.\"\"\"\n    items = [\n        f\"{k}: {v}\"[:83] + (\"...\" if len(f\"{k}: {v}\") &gt; 83 else \"\")\n        for k, v in self.model_dump().items()\n    ]\n\n    # Needed to extract subclass dict correctly\n    # items = extract_subclass_dict(self, \"command_params\", items)\n\n    return f\"{self.__class__.__name__}\\n\\n\" + \"\\n\".join(items)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_polars","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_polars","text":"<pre><code>to_polars(collect: bool = True, equity_data: bool = False) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Deserialize the stored results or return the LazyFrame, and optionally collect them into a Polars DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>collect</code> <code>bool</code> <p>If True, collects the deserialized LazyFrame into a DataFrame. Default is True.</p> <code>True</code> <code>equity_data</code> <code>bool</code> <p>If True, processes equity_data instead of results. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The results as a Polars LazyFrame or DataFrame, depending on the collect parameter.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If no results or equity data are found to process</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_polars(\n    self, collect: bool = True, equity_data: bool = False\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Deserialize the stored results or return the LazyFrame, and optionally collect them into a Polars DataFrame.\n\n    Parameters\n    ----------\n    collect : bool, optional\n        If True, collects the deserialized LazyFrame into a DataFrame.\n        Default is True.\n    equity_data : bool, optional\n        If True, processes equity_data instead of results.\n        Default is False.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The results as a Polars LazyFrame or DataFrame,\n        depending on the collect parameter.\n\n    Raises\n    ------\n    HumblDataError\n        If no results or equity data are found to process\n    \"\"\"\n    data = self.equity_data if equity_data else self.results\n\n    if data is None:\n        raise HumblDataError(\"No data found.\")\n\n    if isinstance(data, pl.LazyFrame):\n        out = data\n    elif isinstance(data, str):\n        with io.StringIO(data) as data_io:\n            out = pl.LazyFrame.deserialize(data_io, format=\"json\")\n    elif isinstance(data, bytes):\n        with io.BytesIO(data) as data_io:\n            out = pl.LazyFrame.deserialize(data_io, format=\"binary\")\n    else:\n        raise HumblDataError(\n            \"Invalid data type. Expected LazyFrame or serialized string.\"\n        )\n\n    if collect:\n        out = out.collect()\n\n    return out\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_df","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_df","text":"<pre><code>to_df(collect: bool = True, equity_data: bool = False) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Alias for the <code>to_polars</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>collect</code> <code>bool</code> <p>If True, collects the deserialized LazyFrame into a DataFrame. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The deserialized results as a Polars LazyFrame or DataFrame, depending on the collect parameter.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_df(\n    self, collect: bool = True, equity_data: bool = False\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Alias for the `to_polars` method.\n\n    Parameters\n    ----------\n    collect : bool, optional\n        If True, collects the deserialized LazyFrame into a DataFrame.\n        Default is True.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The deserialized results as a Polars LazyFrame or DataFrame,\n        depending on the collect parameter.\n    \"\"\"\n    return self.to_polars(collect=collect, equity_data=equity_data)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_pandas","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_pandas","text":"<pre><code>to_pandas(equity_data: bool = False) -&gt; DataFrame\n</code></pre> <p>Convert the results to a Pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The results as a Pandas DataFrame.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_pandas(self, equity_data: bool = False) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert the results to a Pandas DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The results as a Pandas DataFrame.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_pandas()\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_numpy","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_numpy","text":"<pre><code>to_numpy(equity_data: bool = False) -&gt; ndarray\n</code></pre> <p>Convert the results to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The results as a NumPy array.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_numpy(self, equity_data: bool = False) -&gt; np.ndarray:\n    \"\"\"\n    Convert the results to a NumPy array.\n\n    Returns\n    -------\n    np.ndarray\n        The results as a NumPy array.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_numpy()\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_dict","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_dict","text":"<pre><code>to_dict(row_wise: bool = False, equity_data: bool = False, as_series: bool = True) -&gt; dict | list[dict]\n</code></pre> <p>Transform the stored data into a dictionary or a list of dictionaries.</p> <p>This method allows for the conversion of the internal data representation into a more universally accessible format, either aggregating the entire dataset into a single dictionary (column-wise) or breaking it down into a list of dictionaries, each representing a row in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>row_wise</code> <code>bool</code> <p>Determines the format of the output. If set to True, the method returns a list of dictionaries, with each dictionary representing a row and its corresponding data as key-value pairs. If set to False, the method returns a single dictionary, with column names as keys and lists of column data as values. Default is False.</p> <code>False</code> <code>equity_data</code> <code>bool</code> <p>A flag to specify whether to use equity-specific data for the conversion. This parameter allows for flexibility in handling different types of data stored within the object. Default is False.</p> <code>False</code> <code>as_series</code> <code>bool</code> <p>If True, the method returns a pl.Series with values as Series. If False, the method returns a dict with values as List[Any]. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict | list[dict]</code> <p>Depending on the <code>row_wise</code> parameter, either a dictionary mapping column names to lists of values (if <code>row_wise</code> is False) or a list of dictionaries, each representing a row in the dataset (if <code>row_wise</code> is True).</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_dict(\n    self,\n    row_wise: bool = False,\n    equity_data: bool = False,\n    as_series: bool = True,\n) -&gt; dict | list[dict]:\n    \"\"\"\n    Transform the stored data into a dictionary or a list of dictionaries.\n\n    This method allows for the conversion of the internal data\n    representation into a more universally accessible format, either\n    aggregating the entire dataset into a single dictionary (column-wise)\n    or breaking it down into a list of dictionaries, each representing a\n    row in the dataset.\n\n    Parameters\n    ----------\n    row_wise : bool, optional\n        Determines the format of the output. If set to True, the method\n        returns a list of dictionaries, with each dictionary representing a\n        row and its corresponding data as key-value pairs. If set to False,\n        the method returns a single dictionary, with column names as keys\n        and lists of column data as values. Default is False.\n\n    equity_data : bool, optional\n        A flag to specify whether to use equity-specific data for the\n        conversion. This parameter allows for flexibility in handling\n        different types of data stored within the object. Default is\n        False.\n    as_series : bool, optional\n        If True, the method returns a pl.Series with values as Series. If\n        False, the method returns a dict with values as List[Any].\n        Default is True.\n\n    Returns\n    -------\n    dict | list[dict]\n        Depending on the `row_wise` parameter, either a dictionary mapping column names to lists of values (if `row_wise` is False) or a list of dictionaries, each representing a row in the dataset (if `row_wise` is True).\n    \"\"\"\n    if row_wise:\n        return self.to_polars(\n            collect=True, equity_data=equity_data\n        ).to_dicts()\n    return self.to_polars(collect=True, equity_data=equity_data).to_dict(\n        as_series=as_series\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_arrow","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_arrow","text":"<pre><code>to_arrow(equity_data: bool = False) -&gt; Table\n</code></pre> <p>Convert the results to an Arrow Table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>The results as an Arrow Table.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_arrow(self, equity_data: bool = False) -&gt; pa.Table:\n    \"\"\"\n    Convert the results to an Arrow Table.\n\n    Returns\n    -------\n    pa.Table\n        The results as an Arrow Table.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_arrow()\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_struct","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_struct","text":"<pre><code>to_struct(name: str = 'results', equity_data: bool = False) -&gt; Series\n</code></pre> <p>Convert the results to a struct.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the struct. Default is \"results\".</p> <code>'results'</code> <p>Returns:</p> Type Description <code>Struct</code> <p>The results as a struct.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_struct(\n    self, name: str = \"results\", equity_data: bool = False\n) -&gt; pl.Series:\n    \"\"\"\n    Convert the results to a struct.\n\n    Parameters\n    ----------\n    name : str, optional\n        The name of the struct. Default is \"results\".\n\n    Returns\n    -------\n    pl.Struct\n        The results as a struct.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).to_struct(\n        name=name\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.to_json","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.to_json","text":"<pre><code>to_json(equity_data: bool = False, chart: bool = False) -&gt; str | list[str]\n</code></pre> <p>Convert the results to a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>equity_data</code> <code>bool</code> <p>A flag to specify whether to use equity-specific data for the conversion. Default is False.</p> <code>False</code> <code>chart</code> <code>bool</code> <p>If True, return all generated charts as a JSON string instead of returning the results. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The results or charts as a JSON string.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If chart is True but no charts are available.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def to_json(\n    self, equity_data: bool = False, chart: bool = False\n) -&gt; str | list[str]:\n    \"\"\"\n    Convert the results to a JSON string.\n\n    Parameters\n    ----------\n    equity_data : bool, optional\n        A flag to specify whether to use equity-specific data for the\n        conversion. Default is False.\n    chart : bool, optional\n        If True, return all generated charts as a JSON string instead of\n        returning the results. Default is False.\n\n    Returns\n    -------\n    str\n        The results or charts as a JSON string.\n\n    Raises\n    ------\n    HumblDataError\n        If chart is True but no charts are available.\n    \"\"\"\n    import json\n    from datetime import date, datetime\n\n    from humbldata.core.standard_models.abstract.errors import (\n        HumblDataError,\n    )\n\n    def json_serial(obj):\n        \"\"\"JSON serializer for objects not serializable by default json code.\"\"\"\n        if isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n        msg = f\"Type {type(obj)} not serializable\"\n        raise TypeError(msg)\n\n    if chart:\n        if self.chart is None:\n            msg = f\"You set `.to_json(chart=True)` but there were no charts. Make sure `chart=True` in {self.command_params.__class__.__name__}\"\n            raise HumblDataError(msg)\n\n        if isinstance(self.chart, list):\n            return [\n                chart.content\n                for chart in self.chart\n                if chart and chart.content\n            ]\n        else:\n            return self.chart.content\n    else:\n        data = self.to_polars(\n            collect=True, equity_data=equity_data\n        ).to_dict(as_series=False)\n        return json.dumps(data, default=json_serial)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.is_empty","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.is_empty","text":"<pre><code>is_empty(equity_data: bool = False) -&gt; bool\n</code></pre> <p>Check if the results are empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the results are empty, False otherwise.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def is_empty(self, equity_data: bool = False) -&gt; bool:\n    \"\"\"\n    Check if the results are empty.\n\n    Returns\n    -------\n    bool\n        True if the results are empty, False otherwise.\n    \"\"\"\n    return self.to_polars(collect=True, equity_data=equity_data).is_empty()\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.humblobject.HumblObject.show","title":"humbldata.core.standard_models.abstract.humblobject.HumblObject.show","text":"<pre><code>show() -&gt; None\n</code></pre> <p>Show the chart.</p> Source code in <code>src/humbldata/core/standard_models/abstract/humblobject.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Show the chart.\"\"\"\n    if isinstance(self.chart, list):\n        for chart in self.chart:\n            if chart and chart.fig:\n                chart.fig.show()\n            else:\n                msg = \"Chart object is missing or incomplete.\"\n                raise HumblDataError(msg)\n    elif not self.chart or not self.chart.fig:\n        msg = \"Chart not found.\"\n        raise HumblDataError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.tagged","title":"humbldata.core.standard_models.abstract.tagged","text":"<p>An ABSTRACT DATA MODEL, Tagged, to be inherited by other models as identifier.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.tagged.Tagged","title":"humbldata.core.standard_models.abstract.tagged.Tagged","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class to represent an object tagged with a uuid7.</p> Source code in <code>src/humbldata/core/standard_models/abstract/tagged.py</code> <pre><code>class Tagged(BaseModel):\n    \"\"\"A class to represent an object tagged with a uuid7.\"\"\"\n\n    id: str = Field(default_factory=uuid7str, alias=\"_id\")\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio","title":"humbldata.core.standard_models.portfolio","text":"<p>Context: Portfolio || Category: Analytics.</p> <p>This module defines the QueryParams and Data classes for the Portfolio context.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics","title":"humbldata.core.standard_models.portfolio.analytics","text":""},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics.etf_category","title":"humbldata.core.standard_models.portfolio.analytics.etf_category","text":"<p>UserTable Standard Model.</p> <p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>This module is used to define the QueryParams and Data model for the UserTable command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics.etf_category.ETFCategoryData","title":"humbldata.core.standard_models.portfolio.analytics.etf_category.ETFCategoryData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the etf_category command, a Pandera.Polars Model.</p> <p>Used for simple validation of ETF category data for the UserTableFetcher internal logic <code>aggregate_user_table_data()</code></p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/etf_category.py</code> <pre><code>class ETFCategoryData(Data):\n    \"\"\"\n    Data model for the etf_category command, a Pandera.Polars Model.\n\n    Used for simple validation of ETF category data for the UserTableFetcher\n    internal logic `aggregate_user_table_data()`\n    \"\"\"\n\n    symbol: str = pa.Field(\n        default=None,\n        title=\"Symbol\",\n        description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"),\n    )\n    category: pl.Utf8 | None = pa.Field(\n        default=None,\n        title=\"Category/Sector\",\n        description=QUERY_DESCRIPTIONS.get(\"category\", \"\"),\n        nullable=True,\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics.user_table","title":"humbldata.core.standard_models.portfolio.analytics.user_table","text":"<p>UserTable Standard Model.</p> <p>Context: Portfolio || Category: Analytics || Command: user_table.</p> <p>This module is used to define the QueryParams and Data model for the UserTable command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics.user_table.UserTableQueryParams","title":"humbldata.core.standard_models.portfolio.analytics.user_table.UserTableQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>QueryParams model for the UserTable command, a Pydantic v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | set[str]</code> <p>The symbol or ticker of the stock(s). Can be a single symbol, a comma-separated string, or a list/set of symbols. Default is \"AAPL\". Examples: \"AAPL\", \"AAPL,MSFT\", [\"AAPL\", \"MSFT\"] All inputs will be converted to uppercase.</p> required Notes <p>The <code>symbols</code> input will be processed to ensure all symbols are uppercase and properly formatted, regardless of the input format.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>class UserTableQueryParams(QueryParams):\n    \"\"\"\n    QueryParams model for the UserTable command, a Pydantic v2 model.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | set[str]\n        The symbol or ticker of the stock(s). Can be a single symbol, a comma-separated string,\n        or a list/set of symbols. Default is \"AAPL\".\n        Examples: \"AAPL\", \"AAPL,MSFT\", [\"AAPL\", \"MSFT\"]\n        All inputs will be converted to uppercase.\n\n    Notes\n    -----\n    The `symbols` input will be processed to ensure all symbols are uppercase\n    and properly formatted, regardless of the input format.\n    \"\"\"\n\n    symbols: str | list[str] | set[str] = pa.Field(\n        default=\"AAPL\",\n        title=\"Symbol\",\n        description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"),\n    )\n\n    @field_validator(\"symbols\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n        \"\"\"\n        Convert the stock symbol to uppercase.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        Union[str, List[str]]\n            The uppercase stock symbol or a comma-separated string of uppercase\n            symbols.\n        \"\"\"\n        # Handle empty inputs\n        if not v:\n            return []\n        # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n        v = v.split(\",\") if isinstance(v, str) else v\n\n        # Trim whitespace and check if all elements in the list are strings\n        if not all(isinstance(item.strip(), str) for item in v):\n            msg = \"Every element in `symbol` list must be a `str`\"\n            raise ValueError(msg)\n\n        # Convert all elements to uppercase, trim whitespace, and join them with a comma\n        return [symbol.strip().upper() for symbol in v]\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableQueryParams.upper_symbol <code>classmethod</code> \u00a4 <pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; str | list[str]\n</code></pre> <p>Convert the stock symbol to uppercase.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>Union[str, List[str]]</code> <p>The uppercase stock symbol or a comma-separated string of uppercase symbols.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>@field_validator(\"symbols\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n    \"\"\"\n    Convert the stock symbol to uppercase.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    Union[str, List[str]]\n        The uppercase stock symbol or a comma-separated string of uppercase\n        symbols.\n    \"\"\"\n    # Handle empty inputs\n    if not v:\n        return []\n    # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n    v = v.split(\",\") if isinstance(v, str) else v\n\n    # Trim whitespace and check if all elements in the list are strings\n    if not all(isinstance(item.strip(), str) for item in v):\n        msg = \"Every element in `symbol` list must be a `str`\"\n        raise ValueError(msg)\n\n    # Convert all elements to uppercase, trim whitespace, and join them with a comma\n    return [symbol.strip().upper() for symbol in v]\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics.user_table.UserTableData","title":"humbldata.core.standard_models.portfolio.analytics.user_table.UserTableData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the user_table command, a Pandera.Polars Model.</p> <p>This Data model is used to validate data in the <code>.transform_data()</code> method of the <code>UserTableFetcher</code> class.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>Utf8</code> <p>The stock symbol.</p> <code>last_price</code> <code>Float64</code> <p>The last known price of the stock.</p> <code>buy_price</code> <code>Float64</code> <p>The recommended buy price for the stock.</p> <code>sell_price</code> <code>Float64</code> <p>The recommended sell price for the stock.</p> <code>ud_pct</code> <code>Utf8</code> <p>The upside/downside percentage.</p> <code>ud_ratio</code> <code>Float64</code> <p>The upside/downside ratio.</p> <code>asset_class</code> <code>Utf8</code> <p>The asset class of the stock.</p> <code>sector</code> <code>Utf8</code> <p>The sector of the stock.</p> <code>humbl_suggestion</code> <code>Utf8 | None</code> <p>The suggestion provided by HUMBL.</p> <p>Methods:</p> Name Description <code>None</code> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>class UserTableData(Data):\n    \"\"\"\n    Data model for the user_table command, a Pandera.Polars Model.\n\n    This Data model is used to validate data in the `.transform_data()` method of the `UserTableFetcher` class.\n\n    Attributes\n    ----------\n    symbol : pl.Utf8\n        The stock symbol.\n    last_price : pl.Float64\n        The last known price of the stock.\n    buy_price : pl.Float64\n        The recommended buy price for the stock.\n    sell_price : pl.Float64\n        The recommended sell price for the stock.\n    ud_pct : pl.Utf8\n        The upside/downside percentage.\n    ud_ratio : pl.Float64\n        The upside/downside ratio.\n    asset_class : pl.Utf8\n        The asset class of the stock.\n    sector : pl.Utf8\n        The sector of the stock.\n    humbl_suggestion : pl.Utf8 | None\n        The suggestion provided by HUMBL.\n\n    Methods\n    -------\n    None\n\n    \"\"\"\n\n    symbol: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Symbol\",\n        description=DATA_DESCRIPTIONS.get(\"symbol\", \"\"),\n        alias=\"(symbols|symbol)\",\n        regex=True,\n    )\n    last_price: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Last Price\",\n        description=DATA_DESCRIPTIONS.get(\"last_price\", \"\"),\n    )\n    buy_price: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Buy Price\",\n        description=DATA_DESCRIPTIONS.get(\"buy_price\", \"\"),\n    )\n    sell_price: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Sell Price\",\n        description=DATA_DESCRIPTIONS.get(\"sell_price\", \"\"),\n    )\n    ud_pct: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Upside/Downside Percentage\",\n        description=DATA_DESCRIPTIONS.get(\"ud_pct\", \"\"),\n    )\n    ud_ratio: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Upside/Downside Ratio\",\n        description=DATA_DESCRIPTIONS.get(\"ud_ratio\", \"\"),\n    )\n    asset_class: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Asset Class\",\n        description=DATA_DESCRIPTIONS.get(\"asset_class\", \"\"),\n    )\n    sector: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Sector\",\n        description=DATA_DESCRIPTIONS.get(\"sector\", \"\"),\n        nullable=True,\n    )\n    humbl_suggestion: pl.Utf8 | None = pa.Field(\n        default=None,\n        title=\"humblSuggestion\",\n        description=QUERY_DESCRIPTIONS.get(\"humbl_suggestion\", \"\"),\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher","title":"humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher","text":"<p>Fetcher for the UserTable command.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>PortfolioQueryParams</code> <p>The context parameters for the Portfolio query.</p> required <code>command_params</code> <code>UserTableQueryParams</code> <p>The command-specific parameters for the UserTable query.</p> required <p>Attributes:</p> Name Type Description <code>context_params</code> <code>PortfolioQueryParams</code> <p>Stores the context parameters passed during initialization.</p> <code>command_params</code> <code>UserTableQueryParams</code> <p>Stores the command-specific parameters passed during initialization.</p> <code>data</code> <code>DataFrame</code> <p>The raw data extracted from the data provider, before transformation.</p> <p>Methods:</p> Name Description <code>transform_query</code> <p>Transform the command-specific parameters into a query.</p> <code>extract_data</code> <p>Extracts the data from the provider and returns it as a Polars DataFrame.</p> <code>transform_data</code> <p>Transforms the command-specific data according to the UserTable logic.</p> <code>fetch_data</code> <p>Execute TET Pattern.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>results : UserTableData     Serializable results. provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']     Provider name. warnings : Optional[List[Warning_]]     List of warnings. chart : Optional[Chart]     Chart object. context_params : PortfolioQueryParams     Context-specific parameters. command_params : UserTableQueryParams     Command-specific parameters.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>class UserTableFetcher:\n    \"\"\"\n    Fetcher for the UserTable command.\n\n    Parameters\n    ----------\n    context_params : PortfolioQueryParams\n        The context parameters for the Portfolio query.\n    command_params : UserTableQueryParams\n        The command-specific parameters for the UserTable query.\n\n    Attributes\n    ----------\n    context_params : PortfolioQueryParams\n        Stores the context parameters passed during initialization.\n    command_params : UserTableQueryParams\n        Stores the command-specific parameters passed during initialization.\n    data : pl.DataFrame\n        The raw data extracted from the data provider, before transformation.\n\n    Methods\n    -------\n    transform_query()\n        Transform the command-specific parameters into a query.\n    extract_data()\n        Extracts the data from the provider and returns it as a Polars DataFrame.\n    transform_data()\n        Transforms the command-specific data according to the UserTable logic.\n    fetch_data()\n        Execute TET Pattern.\n\n    Returns\n    -------\n    HumblObject\n        results : UserTableData\n            Serializable results.\n        provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']\n            Provider name.\n        warnings : Optional[List[Warning_]]\n            List of warnings.\n        chart : Optional[Chart]\n            Chart object.\n        context_params : PortfolioQueryParams\n            Context-specific parameters.\n        command_params : UserTableQueryParams\n            Command-specific parameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: PortfolioQueryParams,\n        command_params: UserTableQueryParams,\n    ):\n        \"\"\"\n        Initialize the UserTableFetcher with context and command parameters.\n\n        Parameters\n        ----------\n        context_params : PortfolioQueryParams\n            The context parameters for the Portfolio query.\n        command_params : UserTableQueryParams\n            The command-specific parameters for the UserTable query.\n        \"\"\"\n        self.context_params = context_params\n        self.command_params = command_params\n\n    def transform_query(self):\n        \"\"\"\n        Transform the command-specific parameters into a query.\n\n        If command_params is not provided, it initializes a default UserTableQueryParams object.\n        \"\"\"\n        if not self.command_params:\n            self.command_params = None\n            # Set Default Arguments\n            self.command_params: UserTableQueryParams = UserTableQueryParams()\n        else:\n            self.command_params: UserTableQueryParams = UserTableQueryParams(\n                **self.command_params\n            )\n\n    async def extract_data(self):\n        \"\"\"\n        Extract the data from the provider and returns it as a Polars DataFrame.\n\n        Returns\n        -------\n        pl.DataFrame\n            The extracted data as a Polars DataFrame.\n\n        \"\"\"\n        self.etf_data = await aget_etf_category(self.context_params.symbols)\n\n        # Dates are automatically selected based on membership\n        self.toolbox = Toolbox(\n            symbols=self.context_params.symbols,\n            membership=self.context_params.membership,\n            interval=\"1d\",\n        )\n        self.mandelbrot = self.toolbox.technical.mandelbrot_channel().to_polars(\n            collect=False\n        )\n        return self\n\n    async def transform_data(self):\n        \"\"\"\n        Transform the command-specific data according to the user_table logic.\n\n        Returns\n        -------\n        pl.DataFrame\n            The transformed data as a Polars DataFrame\n        \"\"\"\n        # Implement data transformation logic here\n        transformed_data: pl.LazyFrame = await user_table_engine(\n            symbols=self.context_params.symbols,\n            etf_data=self.etf_data,\n            mandelbrot_data=self.mandelbrot,\n            toolbox=self.toolbox,\n        )\n        self.transformed_data = UserTableData(transformed_data.collect()).lazy()\n        self.transformed_data = self.transformed_data.with_columns(\n            pl.col(pl.Float64).round(2)\n        )\n        return self\n\n    @log_start_end(logger=logger)\n    async def fetch_data(self):\n        \"\"\"\n        Execute TET Pattern.\n\n        This method executes the query transformation, data fetching and\n        transformation process by first calling `transform_query` to prepare the query parameters, then\n        extracting the raw data using `extract_data` method, and finally\n        transforming the raw data using `transform_data` method.\n\n        Returns\n        -------\n        HumblObject\n            The HumblObject containing the transformed data and metadata.\n        \"\"\"\n        logger.debug(\"Running .transform_query()\")\n        self.transform_query()\n        logger.debug(\"Running .extract_data()\")\n        await self.extract_data()\n        logger.debug(\"Running .transform_data()\")\n        await self.transform_data()\n\n        return HumblObject(\n            results=self.transformed_data,\n            provider=self.context_params.provider,\n            warnings=None,\n            chart=None,\n            context_params=self.context_params,\n            command_params=self.command_params,\n        )\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.__init__ \u00a4 <pre><code>__init__(context_params: PortfolioQueryParams, command_params: UserTableQueryParams)\n</code></pre> <p>Initialize the UserTableFetcher with context and command parameters.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>PortfolioQueryParams</code> <p>The context parameters for the Portfolio query.</p> required <code>command_params</code> <code>UserTableQueryParams</code> <p>The command-specific parameters for the UserTable query.</p> required Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>def __init__(\n    self,\n    context_params: PortfolioQueryParams,\n    command_params: UserTableQueryParams,\n):\n    \"\"\"\n    Initialize the UserTableFetcher with context and command parameters.\n\n    Parameters\n    ----------\n    context_params : PortfolioQueryParams\n        The context parameters for the Portfolio query.\n    command_params : UserTableQueryParams\n        The command-specific parameters for the UserTable query.\n    \"\"\"\n    self.context_params = context_params\n    self.command_params = command_params\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the command-specific parameters into a query.</p> <p>If command_params is not provided, it initializes a default UserTableQueryParams object.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>def transform_query(self):\n    \"\"\"\n    Transform the command-specific parameters into a query.\n\n    If command_params is not provided, it initializes a default UserTableQueryParams object.\n    \"\"\"\n    if not self.command_params:\n        self.command_params = None\n        # Set Default Arguments\n        self.command_params: UserTableQueryParams = UserTableQueryParams()\n    else:\n        self.command_params: UserTableQueryParams = UserTableQueryParams(\n            **self.command_params\n        )\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.extract_data <code>async</code> \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider and returns it as a Polars DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The extracted data as a Polars DataFrame.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>async def extract_data(self):\n    \"\"\"\n    Extract the data from the provider and returns it as a Polars DataFrame.\n\n    Returns\n    -------\n    pl.DataFrame\n        The extracted data as a Polars DataFrame.\n\n    \"\"\"\n    self.etf_data = await aget_etf_category(self.context_params.symbols)\n\n    # Dates are automatically selected based on membership\n    self.toolbox = Toolbox(\n        symbols=self.context_params.symbols,\n        membership=self.context_params.membership,\n        interval=\"1d\",\n    )\n    self.mandelbrot = self.toolbox.technical.mandelbrot_channel().to_polars(\n        collect=False\n    )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.transform_data <code>async</code> \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data according to the user_table logic.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed data as a Polars DataFrame</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>async def transform_data(self):\n    \"\"\"\n    Transform the command-specific data according to the user_table logic.\n\n    Returns\n    -------\n    pl.DataFrame\n        The transformed data as a Polars DataFrame\n    \"\"\"\n    # Implement data transformation logic here\n    transformed_data: pl.LazyFrame = await user_table_engine(\n        symbols=self.context_params.symbols,\n        etf_data=self.etf_data,\n        mandelbrot_data=self.mandelbrot,\n        toolbox=self.toolbox,\n    )\n    self.transformed_data = UserTableData(transformed_data.collect()).lazy()\n    self.transformed_data = self.transformed_data.with_columns(\n        pl.col(pl.Float64).round(2)\n    )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.portfolio.analytics.user_table.UserTableFetcher.fetch_data <code>async</code> \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute TET Pattern.</p> <p>This method executes the query transformation, data fetching and transformation process by first calling <code>transform_query</code> to prepare the query parameters, then extracting the raw data using <code>extract_data</code> method, and finally transforming the raw data using <code>transform_data</code> method.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>The HumblObject containing the transformed data and metadata.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/analytics/user_table.py</code> <pre><code>@log_start_end(logger=logger)\nasync def fetch_data(self):\n    \"\"\"\n    Execute TET Pattern.\n\n    This method executes the query transformation, data fetching and\n    transformation process by first calling `transform_query` to prepare the query parameters, then\n    extracting the raw data using `extract_data` method, and finally\n    transforming the raw data using `transform_data` method.\n\n    Returns\n    -------\n    HumblObject\n        The HumblObject containing the transformed data and metadata.\n    \"\"\"\n    logger.debug(\"Running .transform_query()\")\n    self.transform_query()\n    logger.debug(\"Running .extract_data()\")\n    await self.extract_data()\n    logger.debug(\"Running .transform_data()\")\n    await self.transform_data()\n\n    return HumblObject(\n        results=self.transformed_data,\n        provider=self.context_params.provider,\n        warnings=None,\n        chart=None,\n        context_params=self.context_params,\n        command_params=self.command_params,\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.PortfolioQueryParams","title":"humbldata.core.standard_models.portfolio.PortfolioQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>Query parameters for the PortfolioController.</p> <p>This class defines the query parameters used by the PortfolioController.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str or list of str</code> <p>The stock symbol(s) to query. Default is \"AAPL\".</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider for historical price data. Default is \"yahoo\".</p> required <code>membership</code> <code>Literal['anonymous', 'humblPEON', 'humblPREMIUM', 'humblPOWER', 'humblPERMANENT', 'admin']</code> <p>The membership level of the user accessing the data. Default is \"anonymous\".</p> required <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str or list of str</code> <p>The stock symbol(s) to query.</p> <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider for historical price data.</p> <code>membership</code> <code>Literal['anonymous', 'humblPEON', 'humblPREMIUM', 'humblPOWER', 'humblPERMANENT', 'admin']</code> <p>The membership level of the user.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/__init__.py</code> <pre><code>class PortfolioQueryParams(QueryParams):\n    \"\"\"\n    Query parameters for the PortfolioController.\n\n    This class defines the query parameters used by the PortfolioController.\n\n    Parameters\n    ----------\n    symbol : str or list of str\n        The stock symbol(s) to query. Default is \"AAPL\".\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS\n        The data provider for historical price data. Default is \"yahoo\".\n    membership : Literal[\"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"humblPERMANENT\", \"admin\"]\n        The membership level of the user accessing the data. Default is \"anonymous\".\n\n    Attributes\n    ----------\n    symbol : str or list of str\n        The stock symbol(s) to query.\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS\n        The data provider for historical price data.\n    membership : Literal[\"anonymous\", \"humblPEON\", \"humblPREMIUM\", \"humblPOWER\", \"humblPERMANENT\", \"admin\"]\n        The membership level of the user.\n    \"\"\"\n\n    symbols: str | list[str] = Field(\n        default=[\"AAPL\"],\n        title=\"Symbols\",\n        description=QUERY_DESCRIPTIONS.get(\"symbols\", \"\"),\n    )\n    provider: OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS = Field(\n        default=\"yfinance\",\n        title=\"Provider\",\n        description=QUERY_DESCRIPTIONS.get(\"provider\", \"\"),\n    )\n    membership: Literal[\n        \"anonymous\",\n        \"humblPEON\",\n        \"humblPREMIUM\",\n        \"humblPOWER\",\n        \"humblPERMANENT\",\n        \"admin\",\n    ] = Field(\n        default=\"anonymous\",\n        title=\"Membership\",\n        description=QUERY_DESCRIPTIONS.get(\"membership\", \"\"),\n    )\n\n    @field_validator(\"symbols\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n        \"\"\"\n        Convert the stock symbols to uppercase and remove empty strings.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        List[str]\n            A list of uppercase stock symbols with empty strings removed.\n        \"\"\"\n        # Handle empty inputs\n        if not v:\n            return []\n\n        # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n        v = v.split(\",\") if isinstance(v, str) else list(v)\n\n        # Convert all elements to uppercase, trim whitespace, and remove empty strings\n        valid_symbols = [\n            symbol.strip().upper() for symbol in v if symbol.strip()\n        ]\n\n        if not valid_symbols:\n            msg = \"At least one valid symbol (str) must be provided\"\n            raise ValueError(msg)\n\n        return valid_symbols\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.PortfolioQueryParams.upper_symbol","title":"humbldata.core.standard_models.portfolio.PortfolioQueryParams.upper_symbol  <code>classmethod</code>","text":"<pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; list[str]\n</code></pre> <p>Convert the stock symbols to uppercase and remove empty strings.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of uppercase stock symbols with empty strings removed.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/__init__.py</code> <pre><code>@field_validator(\"symbols\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n    \"\"\"\n    Convert the stock symbols to uppercase and remove empty strings.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    List[str]\n        A list of uppercase stock symbols with empty strings removed.\n    \"\"\"\n    # Handle empty inputs\n    if not v:\n        return []\n\n    # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n    v = v.split(\",\") if isinstance(v, str) else list(v)\n\n    # Convert all elements to uppercase, trim whitespace, and remove empty strings\n    valid_symbols = [\n        symbol.strip().upper() for symbol in v if symbol.strip()\n    ]\n\n    if not valid_symbols:\n        msg = \"At least one valid symbol (str) must be provided\"\n        raise ValueError(msg)\n\n    return valid_symbols\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.portfolio.PortfolioData","title":"humbldata.core.standard_models.portfolio.PortfolioData","text":"<p>             Bases: <code>Data</code></p> <p>The Data for the PortfolioController.</p> Source code in <code>src/humbldata/core/standard_models/portfolio/__init__.py</code> <pre><code>class PortfolioData(Data):\n    \"\"\"\n    The Data for the PortfolioController.\n    \"\"\"\n\n    # Add your data model fields here\n    pass\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox","title":"humbldata.core.standard_models.toolbox","text":"<p>Context: Toolbox || Category: Standardized Framework Model.</p> <p>This module defines the QueryParams and Data classes for the Toolbox context. THis is where all of the context(s) of your project go. The STANDARD MODELS for categories and subsequent commands are nested here.</p> <p>Classes:</p> Name Description <code>ToolboxQueryParams</code> <p>Query parameters for the ToolboxController.</p> <code>ToolboxData</code> <p>A Pydantic model that defines the data returned by the ToolboxController.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>The symbol/ticker of the stock.</p> <code>interval</code> <code>Optional[str]</code> <p>The interval of the data. Defaults to '1d'.</p> <code>start_date</code> <code>str</code> <p>The start date of the data.</p> <code>end_date</code> <code>str</code> <p>The end date of the data.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental","title":"humbldata.core.standard_models.toolbox.fundamental","text":""},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass","text":"<p>HumblCompass Standard Model.</p> <p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>This module is used to define the QueryParams and Data model for the HumblCompass command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass.AssetRecommendation","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass.AssetRecommendation","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Asset recommendation categories.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class AssetRecommendation(str, Enum):\n    \"\"\"Asset recommendation categories.\"\"\"\n\n    EQUITIES = \"Equities\"\n    CREDIT = \"Credit\"\n    COMMODITIES = \"Commodities\"\n    FX = \"FX\"\n    FIXED_INCOME = \"Fixed Income\"\n    USD = \"USD\"\n    GOLD = \"Gold\"\n    TECHNOLOGY = \"Technology\"\n    CONSUMER_DISCRETIONARY = \"Consumer Discretionary\"\n    MATERIALS = \"Materials\"\n    INDUSTRIALS = \"Industrials\"\n    UTILITIES = \"Utilities\"\n    REITS = \"REITs\"\n    CONSUMER_STAPLES = \"Consumer Staples\"\n    FINANCIALS = \"Financials\"\n    ENERGY = \"Energy\"\n    HEALTH_CARE = \"Health Care\"\n    TELECOM = \"Telecom\"\n    HIGH_BETA = \"High Beta\"\n    MOMENTUM = \"Momentum\"\n    CYCLICALS = \"Cyclicals\"\n    SECULAR_GROWTH = \"Secular Growth\"\n    LOW_BETA = \"Low Beta\"\n    DEFENSIVES = \"Defensives\"\n    VALUE = \"Value\"\n    DIVIDEND_YIELD = \"Dividend Yield\"\n    QUALITY = \"Quality\"\n    CYCLICAL_GROWTH = \"Cyclical Growth\"\n    SMALL_CAPS = \"Small Caps\"\n    MID_CAPS = \"Mid Caps\"\n    BDCS = \"BDCs\"\n    CONVERTIBLES = \"Convertibles\"\n    HY_CREDIT = \"HY Credit\"\n    EM_DEBT = \"EM Debt\"\n    TIPS = \"TIPS\"\n    SHORT_DURATION_TREASURIES = \"Short Duration Treasuries\"\n    MORTGAGE_BACKED_SECURITIES = \"Mortgage Backed Securities\"\n    MEDIUM_DURATION_TREASURIES = \"Medium Duration Treasuries\"\n    LONG_DURATION_TREASURIES = \"Long Duration Treasuries\"\n    IG_CREDIT = \"Investment Grade Credit\"\n    MUNIS = \"Municipal Bonds\"\n    PREFERREDS = \"Preferreds\"\n    EM_LOCAL_CURRENCY = \"Emerging Market Local Currency\"\n    LEVERAGED_LOANS = \"Leveraged Loans\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass.RecommendationCategory","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass.RecommendationCategory","text":"<p>             Bases: <code>BaseModel</code></p> <p>Category-specific recommendations with rationale.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class RecommendationCategory(BaseModel):\n    \"\"\"Category-specific recommendations with rationale.\"\"\"\n\n    best: list[AssetRecommendation]\n    worst: list[AssetRecommendation]\n    rationale: str\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass.RegimeRecommendations","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass.RegimeRecommendations","text":"<p>             Bases: <code>BaseModel</code></p> <p>Complete set of recommendations for a specific regime.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class RegimeRecommendations(BaseModel):\n    \"\"\"Complete set of recommendations for a specific regime.\"\"\"\n\n    asset_classes: RecommendationCategory\n    equity_sectors: RecommendationCategory\n    equity_factors: RecommendationCategory\n    fixed_income: RecommendationCategory\n    regime_description: str\n    key_risks: list[str]\n    last_updated: datetime = Field(default_factory=datetime.utcnow)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassQueryParams","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>QueryParams model for the HumblCompass command, a Pydantic v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>country</code> <code>Literal</code> <p>The country or group of countries to collect humblCOMPASS data for.</p> required <code>cli_start_date</code> <code>str</code> <p>The adjusted start date for CLI data collection.</p> required <code>cpi_start_date</code> <code>str</code> <p>The adjusted start date for CPI data collection.</p> required <code>z_score</code> <code>Optional[str]</code> <p>The time window for z-score calculation (e.g., \"1 year\", \"18 months\").</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object.</p> required <code>template</code> <code>Literal</code> <p>The template/theme to use for the plotly figure.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class HumblCompassQueryParams(QueryParams):\n    \"\"\"\n    QueryParams model for the HumblCompass command, a Pydantic v2 model.\n\n    Parameters\n    ----------\n    country : Literal\n        The country or group of countries to collect humblCOMPASS data for.\n    cli_start_date : str\n        The adjusted start date for CLI data collection.\n    cpi_start_date : str\n        The adjusted start date for CPI data collection.\n    z_score : Optional[str]\n        The time window for z-score calculation (e.g., \"1 year\", \"18 months\").\n    chart : bool\n        Whether to return a chart object.\n    template : Literal\n        The template/theme to use for the plotly figure.\n    \"\"\"\n\n    country: Literal[\n        \"g20\",\n        \"g7\",\n        \"asia5\",\n        \"north_america\",\n        \"europe4\",\n        \"australia\",\n        \"brazil\",\n        \"canada\",\n        \"china\",\n        \"france\",\n        \"germany\",\n        \"india\",\n        \"indonesia\",\n        \"italy\",\n        \"japan\",\n        \"mexico\",\n        \"south_africa\",\n        \"south_korea\",\n        \"spain\",\n        \"turkey\",\n        \"united_kingdom\",\n        \"united_states\",\n        \"all\",\n    ] = Field(\n        default=\"united_states\",\n        title=\"Country for humblCOMPASS data\",\n        description=HUMBLCOMPASS_QUERY_DESCRIPTIONS.get(\"country\", \"\"),\n    )\n    cli_start_date: str = Field(\n        default=None,\n        title=\"Adjusted start date for CLI data\",\n        description=\"The adjusted start date for CLI data collection.\",\n    )\n    cpi_start_date: str = Field(\n        default=None,\n        title=\"Adjusted start date for CPI data\",\n        description=\"The adjusted start date for CPI data collection.\",\n    )\n    z_score: str | None = Field(\n        default=None,\n        title=\"Z-score calculation window\",\n        description=\"The time window for z-score calculation (e.g., '1 year', '18 months').\",\n    )\n    chart: bool = Field(\n        default=False,\n        title=\"Results Chart\",\n        description=HUMBLCOMPASS_QUERY_DESCRIPTIONS.get(\"chart\", \"\"),\n    )\n    template: Literal[\n        \"humbl_dark\",\n        \"humbl_light\",\n        \"ggplot2\",\n        \"seaborn\",\n        \"simple_white\",\n        \"plotly\",\n        \"plotly_white\",\n        \"plotly_dark\",\n        \"presentation\",\n        \"xgridoff\",\n        \"ygridoff\",\n        \"gridon\",\n        \"none\",\n    ] = Field(\n        default=\"humbl_dark\",\n        title=\"Plotly Template\",\n        description=HUMBLCOMPASS_QUERY_DESCRIPTIONS.get(\"template\", \"\"),\n    )\n    recommendations: bool = Field(\n        default=False,\n        title=\"Investment Recommendations\",\n        description=\"Whether to include investment recommendations based on the HUMBL regime.\",\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassData","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the humbl_compass command, a Pandera.Polars Model.</p> <p>This Data model is used to validate data in the <code>.transform_data()</code> method of the <code>HumblCompassFetcher</code> class.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class HumblCompassData(Data):\n    \"\"\"\n    Data model for the humbl_compass command, a Pandera.Polars Model.\n\n    This Data model is used to validate data in the `.transform_data()` method of the `HumblCompassFetcher` class.\n    \"\"\"\n\n    date_month_start: pl.Date = pa.Field(\n        default=None,\n        title=\"Date\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"date\"],\n    )\n    country: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"Country\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"country\"],\n    )\n    cpi: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Consumer Price Index (CPI)\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cpi\"],\n    )\n    cpi_3m_delta: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Consumer Price Index (CPI) 3-Month Delta\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cpi_3m_delta\"],\n    )\n    cpi_zscore: pl.Float64 | None = pa.Field(\n        default=None,\n        title=\"Consumer Price Index (CPI) 1-Year Z-Score\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cpi_1yr_zscore\"],\n    )\n    cli: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Composite Leading Indicator (CLI)\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cli\"],\n    )\n    cli_3m_delta: pl.Float64 = pa.Field(\n        default=None,\n        title=\"Composite Leading Indicator (CLI) 3-Month Delta\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cli_3m_delta\"],\n    )\n    cli_zscore: pl.Float64 | None = pa.Field(\n        default=None,\n        title=\"Composite Leading Indicator (CLI) 1-Year Z-Score\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"cli_1yr_zscore\"],\n    )\n    humbl_regime: pl.Utf8 = pa.Field(\n        default=None,\n        title=\"HUMBL Regime\",\n        description=HUMBLCOMPASS_DATA_DESCRIPTIONS[\"humbl_regime\"],\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher","title":"humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher","text":"<p>Fetcher for the HumblCompass command.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the Toolbox query.</p> required <code>command_params</code> <code>HumblCompassQueryParams</code> <p>The command-specific parameters for the HumblCompass query.</p> required <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>Stores the context parameters passed during initialization.</p> <code>command_params</code> <code>HumblCompassQueryParams</code> <p>Stores the command-specific parameters passed during initialization.</p> <code>data</code> <code>DataFrame</code> <p>The raw data extracted from the data provider, before transformation.</p> <p>Methods:</p> Name Description <code>transform_query</code> <p>Transform the command-specific parameters into a query.</p> <code>extract_data</code> <p>Extracts the data from the provider and returns it as a Polars DataFrame.</p> <code>transform_data</code> <p>Transforms the command-specific data according to the HumblCompass logic.</p> <code>fetch_data</code> <p>Execute TET Pattern.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>results : HumblCompassData     Serializable results. provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']     Provider name. warnings : Optional[List[Warning_]]     List of warnings. chart : Optional[Chart]     Chart object. context_params : ToolboxQueryParams     Context-specific parameters. command_params : HumblCompassQueryParams     Command-specific parameters.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>class HumblCompassFetcher:\n    \"\"\"\n    Fetcher for the HumblCompass command.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the Toolbox query.\n    command_params : HumblCompassQueryParams\n        The command-specific parameters for the HumblCompass query.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        Stores the context parameters passed during initialization.\n    command_params : HumblCompassQueryParams\n        Stores the command-specific parameters passed during initialization.\n    data : pl.DataFrame\n        The raw data extracted from the data provider, before transformation.\n\n    Methods\n    -------\n    transform_query()\n        Transform the command-specific parameters into a query.\n    extract_data()\n        Extracts the data from the provider and returns it as a Polars DataFrame.\n    transform_data()\n        Transforms the command-specific data according to the HumblCompass logic.\n    fetch_data()\n        Execute TET Pattern.\n\n    Returns\n    -------\n    HumblObject\n        results : HumblCompassData\n            Serializable results.\n        provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']\n            Provider name.\n        warnings : Optional[List[Warning_]]\n            List of warnings.\n        chart : Optional[Chart]\n            Chart object.\n        context_params : ToolboxQueryParams\n            Context-specific parameters.\n        command_params : HumblCompassQueryParams\n            Command-specific parameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: HumblCompassQueryParams,\n    ):\n        \"\"\"\n        Initialize the HumblCompassFetcher with context and command parameters.\n\n        Parameters\n        ----------\n        context_params : ToolboxQueryParams\n            The context parameters for the Toolbox query.\n        command_params : HumblCompassQueryParams\n            The command-specific parameters for the HumblCompass query.\n        \"\"\"\n        self.context_params = context_params\n        self.command_params = command_params\n\n    def transform_query(self):\n        \"\"\"\n        Transform the command-specific parameters into a query.\n\n        If command_params is not provided, it initializes a default HumblCompassQueryParams object.\n        Calculates adjusted start dates for CLI and CPI data collection.\n        \"\"\"\n        if not self.command_params:\n            self.command_params = HumblCompassQueryParams()\n        elif isinstance(self.command_params, dict):\n            self.command_params = HumblCompassQueryParams(**self.command_params)\n\n        # Calculate adjusted start dates\n        if isinstance(self.context_params.start_date, str):\n            start_date = pl.Series(\n                [datetime.strptime(self.context_params.start_date, \"%Y-%m-%d\")]\n            )\n        else:\n            start_date = pl.Series([self.context_params.start_date])\n\n        # Calculate z-score window in months\n        self.z_score_months = 0\n        if (\n            self.command_params.z_score is not None\n            and self.context_params.membership != \"humblPEON\"\n        ):\n            z_score_months_str = _window_format(\n                self.command_params.z_score, _return_timedelta=False\n            )\n            self.z_score_months = _window_format_monthly(z_score_months_str)\n        elif self.context_params.membership == \"humblPEON\":\n            logger.warning(\n                \"Z-score is not calculated for humblPEON membership level.\"\n            )\n\n        cli_start_date = start_date.dt.offset_by(\n            f\"-{4 + self.z_score_months}mo\"\n        ).dt.strftime(\"%Y-%m-%d\")[0]\n        cpi_start_date = start_date.dt.offset_by(\n            f\"-{3 + self.z_score_months}mo\"\n        ).dt.strftime(\"%Y-%m-%d\")[0]\n\n        # Update the command_params with the new start dates\n        self.command_params = self.command_params.model_copy(\n            update={\n                \"cli_start_date\": cli_start_date,\n                \"cpi_start_date\": cpi_start_date,\n            }\n        )\n\n        logger.info(\n            f\"CLI start date: {self.command_params.cli_start_date} and CPI start date: {self.command_params.cpi_start_date}. \"\n            f\"Dates are adjusted to account for CLI data release lag and z-score calculation window.\"\n        )\n\n    def extract_data(self):\n        \"\"\"\n        Extract the data from the provider and returns it as a Polars DataFrame.\n\n        Returns\n        -------\n        self\n            The HumblCompassFetcher instance with extracted data.\n        \"\"\"\n        # Collect CLI Data\n        self.oecd_cli_data = (\n            obb.economy.composite_leading_indicator(\n                start_date=self.command_params.cli_start_date,\n                end_date=self.context_params.end_date,\n                provider=\"oecd\",\n                country=self.command_params.country,\n            )\n            .to_polars()\n            .lazy()\n            .rename({\"value\": \"cli\"})\n            .with_columns(\n                [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n            )\n        )\n\n        # Collect YoY CPI Data\n        self.oecd_cpi_data = (\n            obb.economy.cpi(\n                start_date=self.command_params.cpi_start_date,\n                end_date=self.context_params.end_date,\n                frequency=\"monthly\",\n                country=self.command_params.country,\n                transform=\"yoy\",\n                provider=\"oecd\",\n                harmonized=False,\n                expenditure=\"total\",\n            )\n            .to_polars()\n            .lazy()\n            .rename({\"value\": \"cpi\"})\n            .with_columns(\n                [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n            )\n        )\n        return self\n\n    def transform_data(self):\n        \"\"\"\n        Transform the command-specific data according to the humbl_compass logic.\n\n        Returns\n        -------\n        self\n            The HumblCompassFetcher instance with transformed data.\n        \"\"\"\n        # Combine CLI and CPI data\n        # CLI data is released before CPI data, so we use a left join\n        combined_data = (\n            self.oecd_cli_data.join(\n                self.oecd_cpi_data,\n                on=[\"date_month_start\", \"country\"],\n                how=\"left\",\n                suffix=\"_cpi\",\n            )\n            .sort(\"date_month_start\")\n            .with_columns(\n                [\n                    pl.col(\"country\").cast(pl.Utf8),\n                    pl.col(\"cli\").cast(pl.Float64),\n                    pl.col(\"cpi\").cast(pl.Float64)\n                    * 100,  # Convert CPI to percentage\n                ]\n            )\n            .rename(\n                {\n                    \"date\": \"date_cli\",\n                }\n            )\n            .select(\n                [\n                    \"date_month_start\",\n                    \"date_cli\",\n                    \"date_cpi\",\n                    \"country\",\n                    \"cli\",\n                    \"cpi\",\n                ]\n            )\n        )\n\n        # Calculate 3-month deltas\n        delta_window = 3\n        transformed_data = combined_data.with_columns(\n            [\n                (pl.col(\"cli\") - pl.col(\"cli\").shift(delta_window)).alias(\n                    \"cli_3m_delta\"\n                ),\n                (pl.col(\"cpi\") - pl.col(\"cpi\").shift(delta_window)).alias(\n                    \"cpi_3m_delta\"\n                ),\n            ]\n        )\n\n        # Add this after calculating 3-month deltas in transform_data()\n        transformed_data = transformed_data.with_columns(\n            [\n                pl.when(\n                    (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n                )\n                .then(pl.lit(\"humblBLOAT\"))\n                .when(\n                    (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n                )\n                .then(pl.lit(\"humblBOUNCE\"))\n                .when(\n                    (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n                )\n                .then(pl.lit(\"humblBOOM\"))\n                .when(\n                    (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n                )\n                .then(pl.lit(\"humblBUST\"))\n                .otherwise(None)\n                .alias(\"humbl_regime\")\n            ]\n        )\n\n        # Calculate z-scores only if self.z_score_months is greater than 0 and membership is not humblPEON\n        if (\n            self.z_score_months &gt; 0\n            and self.context_params.membership != \"humblPEON\"\n        ):\n            transformed_data = transformed_data.with_columns(\n                [\n                    pl.when(\n                        pl.col(\"cli\").count().over(\"country\")\n                        &gt;= self.z_score_months\n                    )\n                    .then(\n                        (\n                            pl.col(\"cli\")\n                            - pl.col(\"cli\").rolling_mean(self.z_score_months)\n                        )\n                        / pl.col(\"cli\").rolling_std(self.z_score_months)\n                    )\n                    .alias(\"cli_zscore\"),\n                    pl.when(\n                        pl.col(\"cpi\").count().over(\"country\")\n                        &gt;= self.z_score_months\n                    )\n                    .then(\n                        (\n                            pl.col(\"cpi\")\n                            - pl.col(\"cpi\").rolling_mean(self.z_score_months)\n                        )\n                        / pl.col(\"cpi\").rolling_std(self.z_score_months)\n                    )\n                    .alias(\"cpi_zscore\"),\n                ]\n            )\n\n        # Select columns based on whether z-scores were calculated\n        columns_to_select = [\n            pl.col(\"date_month_start\"),\n            pl.col(\"country\"),\n            pl.col(\"cpi\").round(2),\n            pl.col(\"cpi_3m_delta\").round(2),\n            pl.col(\"cli\").round(2),\n            pl.col(\"cli_3m_delta\").round(2),\n            pl.col(\"humbl_regime\"),\n        ]\n\n        if (\n            self.z_score_months &gt; 0\n            and self.context_params.membership != \"humblPEON\"\n        ):\n            columns_to_select.extend(\n                [\n                    pl.col(\"cpi_zscore\").round(2),\n                    pl.col(\"cli_zscore\").round(2),\n                ]\n            )\n\n        self.transformed_data = transformed_data.select(columns_to_select)\n\n        # Validate the data using HumblCompassData\n        self.transformed_data = HumblCompassData(\n            self.transformed_data.collect().drop_nulls()  # removes preceding 3 months used for delta calculations\n        ).lazy()\n\n        # Generate chart if requested\n        self.chart = None\n        if self.command_params.chart:\n            self.chart = generate_plots(\n                self.transformed_data,\n                template=ChartTemplate(self.command_params.template),\n            )\n\n        # Add warning if z_score is None\n        if self.command_params.z_score is None:\n            if not hasattr(self, \"warnings\"):\n                self.warnings = []\n            self.warnings.append(\n                HumblDataWarning(\n                    category=\"HumblCompassFetcher\",\n                    message=\"Z-score defaulted to None. No z-score data will be calculated.\",\n                )\n            )\n\n        # Add recommendations if requested\n        if self.command_params.recommendations:\n            latest_regime = (\n                self.transformed_data.select(pl.col(\"humbl_regime\"))\n                .collect()\n                .row(-1)[0]\n            )\n\n            if latest_regime not in REGIME_RECOMMENDATIONS:\n                if not hasattr(self, \"warnings\"):\n                    self.warnings = []\n                self.warnings.append(\n                    HumblDataWarning(\n                        category=\"HumblCompassFetcher\",\n                        message=f\"No recommendations available for regime: {latest_regime}\",\n                    )\n                )\n            else:\n                recommendations = REGIME_RECOMMENDATIONS[latest_regime]\n                if not hasattr(self, \"extra\"):\n                    self.extra = {}\n                self.extra[\"humbl_regime_recommendations\"] = (\n                    recommendations.model_dump()\n                )\n\n        self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n        return self\n\n    @log_start_end(logger=logger)\n    def fetch_data(self):\n        \"\"\"\n        Execute TET Pattern.\n\n        This method executes the query transformation, data fetching and\n        transformation process by first calling `transform_query` to prepare the query parameters, then\n        extracting the raw data using `extract_data` method, and finally\n        transforming the raw data using `transform_data` method.\n\n        Returns\n        -------\n        HumblObject\n            The HumblObject containing the transformed data and metadata.\n        \"\"\"\n        self.transform_query()\n        self.extract_data()\n        self.transform_data()\n\n        # Initialize warnings list if it doesn't exist\n        if not hasattr(self.context_params, \"warnings\"):\n            self.context_params.warnings = []\n\n        # Initialize fetcher warnings if they don't exist\n        if not hasattr(self, \"warnings\"):\n            self.warnings = []\n\n        # Initialize extra dict if it doesn't exist\n        if not hasattr(self, \"extra\"):\n            self.extra = {}\n\n        # Combine warnings from both sources\n        all_warnings = self.context_params.warnings + self.warnings\n\n        return HumblObject(\n            results=self.transformed_data,\n            provider=self.context_params.provider,\n            warnings=all_warnings,  # Use combined warnings\n            chart=self.chart,\n            context_params=self.context_params,\n            command_params=self.command_params,\n            extra=self.extra,  # pipe in extra from transform_data()\n        )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.__init__ \u00a4 <pre><code>__init__(context_params: ToolboxQueryParams, command_params: HumblCompassQueryParams)\n</code></pre> <p>Initialize the HumblCompassFetcher with context and command parameters.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the Toolbox query.</p> required <code>command_params</code> <code>HumblCompassQueryParams</code> <p>The command-specific parameters for the HumblCompass query.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def __init__(\n    self,\n    context_params: ToolboxQueryParams,\n    command_params: HumblCompassQueryParams,\n):\n    \"\"\"\n    Initialize the HumblCompassFetcher with context and command parameters.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the Toolbox query.\n    command_params : HumblCompassQueryParams\n        The command-specific parameters for the HumblCompass query.\n    \"\"\"\n    self.context_params = context_params\n    self.command_params = command_params\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the command-specific parameters into a query.</p> <p>If command_params is not provided, it initializes a default HumblCompassQueryParams object. Calculates adjusted start dates for CLI and CPI data collection.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def transform_query(self):\n    \"\"\"\n    Transform the command-specific parameters into a query.\n\n    If command_params is not provided, it initializes a default HumblCompassQueryParams object.\n    Calculates adjusted start dates for CLI and CPI data collection.\n    \"\"\"\n    if not self.command_params:\n        self.command_params = HumblCompassQueryParams()\n    elif isinstance(self.command_params, dict):\n        self.command_params = HumblCompassQueryParams(**self.command_params)\n\n    # Calculate adjusted start dates\n    if isinstance(self.context_params.start_date, str):\n        start_date = pl.Series(\n            [datetime.strptime(self.context_params.start_date, \"%Y-%m-%d\")]\n        )\n    else:\n        start_date = pl.Series([self.context_params.start_date])\n\n    # Calculate z-score window in months\n    self.z_score_months = 0\n    if (\n        self.command_params.z_score is not None\n        and self.context_params.membership != \"humblPEON\"\n    ):\n        z_score_months_str = _window_format(\n            self.command_params.z_score, _return_timedelta=False\n        )\n        self.z_score_months = _window_format_monthly(z_score_months_str)\n    elif self.context_params.membership == \"humblPEON\":\n        logger.warning(\n            \"Z-score is not calculated for humblPEON membership level.\"\n        )\n\n    cli_start_date = start_date.dt.offset_by(\n        f\"-{4 + self.z_score_months}mo\"\n    ).dt.strftime(\"%Y-%m-%d\")[0]\n    cpi_start_date = start_date.dt.offset_by(\n        f\"-{3 + self.z_score_months}mo\"\n    ).dt.strftime(\"%Y-%m-%d\")[0]\n\n    # Update the command_params with the new start dates\n    self.command_params = self.command_params.model_copy(\n        update={\n            \"cli_start_date\": cli_start_date,\n            \"cpi_start_date\": cpi_start_date,\n        }\n    )\n\n    logger.info(\n        f\"CLI start date: {self.command_params.cli_start_date} and CPI start date: {self.command_params.cpi_start_date}. \"\n        f\"Dates are adjusted to account for CLI data release lag and z-score calculation window.\"\n    )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.extract_data \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider and returns it as a Polars DataFrame.</p> <p>Returns:</p> Type Description <code>self</code> <p>The HumblCompassFetcher instance with extracted data.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def extract_data(self):\n    \"\"\"\n    Extract the data from the provider and returns it as a Polars DataFrame.\n\n    Returns\n    -------\n    self\n        The HumblCompassFetcher instance with extracted data.\n    \"\"\"\n    # Collect CLI Data\n    self.oecd_cli_data = (\n        obb.economy.composite_leading_indicator(\n            start_date=self.command_params.cli_start_date,\n            end_date=self.context_params.end_date,\n            provider=\"oecd\",\n            country=self.command_params.country,\n        )\n        .to_polars()\n        .lazy()\n        .rename({\"value\": \"cli\"})\n        .with_columns(\n            [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n        )\n    )\n\n    # Collect YoY CPI Data\n    self.oecd_cpi_data = (\n        obb.economy.cpi(\n            start_date=self.command_params.cpi_start_date,\n            end_date=self.context_params.end_date,\n            frequency=\"monthly\",\n            country=self.command_params.country,\n            transform=\"yoy\",\n            provider=\"oecd\",\n            harmonized=False,\n            expenditure=\"total\",\n        )\n        .to_polars()\n        .lazy()\n        .rename({\"value\": \"cpi\"})\n        .with_columns(\n            [pl.col(\"date\").dt.month_start().alias(\"date_month_start\")]\n        )\n    )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.transform_data \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data according to the humbl_compass logic.</p> <p>Returns:</p> Type Description <code>self</code> <p>The HumblCompassFetcher instance with transformed data.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>def transform_data(self):\n    \"\"\"\n    Transform the command-specific data according to the humbl_compass logic.\n\n    Returns\n    -------\n    self\n        The HumblCompassFetcher instance with transformed data.\n    \"\"\"\n    # Combine CLI and CPI data\n    # CLI data is released before CPI data, so we use a left join\n    combined_data = (\n        self.oecd_cli_data.join(\n            self.oecd_cpi_data,\n            on=[\"date_month_start\", \"country\"],\n            how=\"left\",\n            suffix=\"_cpi\",\n        )\n        .sort(\"date_month_start\")\n        .with_columns(\n            [\n                pl.col(\"country\").cast(pl.Utf8),\n                pl.col(\"cli\").cast(pl.Float64),\n                pl.col(\"cpi\").cast(pl.Float64)\n                * 100,  # Convert CPI to percentage\n            ]\n        )\n        .rename(\n            {\n                \"date\": \"date_cli\",\n            }\n        )\n        .select(\n            [\n                \"date_month_start\",\n                \"date_cli\",\n                \"date_cpi\",\n                \"country\",\n                \"cli\",\n                \"cpi\",\n            ]\n        )\n    )\n\n    # Calculate 3-month deltas\n    delta_window = 3\n    transformed_data = combined_data.with_columns(\n        [\n            (pl.col(\"cli\") - pl.col(\"cli\").shift(delta_window)).alias(\n                \"cli_3m_delta\"\n            ),\n            (pl.col(\"cpi\") - pl.col(\"cpi\").shift(delta_window)).alias(\n                \"cpi_3m_delta\"\n            ),\n        ]\n    )\n\n    # Add this after calculating 3-month deltas in transform_data()\n    transformed_data = transformed_data.with_columns(\n        [\n            pl.when(\n                (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n            )\n            .then(pl.lit(\"humblBLOAT\"))\n            .when(\n                (pl.col(\"cpi_3m_delta\") &gt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n            )\n            .then(pl.lit(\"humblBOUNCE\"))\n            .when(\n                (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &gt; 0)\n            )\n            .then(pl.lit(\"humblBOOM\"))\n            .when(\n                (pl.col(\"cpi_3m_delta\") &lt; 0) &amp; (pl.col(\"cli_3m_delta\") &lt; 0)\n            )\n            .then(pl.lit(\"humblBUST\"))\n            .otherwise(None)\n            .alias(\"humbl_regime\")\n        ]\n    )\n\n    # Calculate z-scores only if self.z_score_months is greater than 0 and membership is not humblPEON\n    if (\n        self.z_score_months &gt; 0\n        and self.context_params.membership != \"humblPEON\"\n    ):\n        transformed_data = transformed_data.with_columns(\n            [\n                pl.when(\n                    pl.col(\"cli\").count().over(\"country\")\n                    &gt;= self.z_score_months\n                )\n                .then(\n                    (\n                        pl.col(\"cli\")\n                        - pl.col(\"cli\").rolling_mean(self.z_score_months)\n                    )\n                    / pl.col(\"cli\").rolling_std(self.z_score_months)\n                )\n                .alias(\"cli_zscore\"),\n                pl.when(\n                    pl.col(\"cpi\").count().over(\"country\")\n                    &gt;= self.z_score_months\n                )\n                .then(\n                    (\n                        pl.col(\"cpi\")\n                        - pl.col(\"cpi\").rolling_mean(self.z_score_months)\n                    )\n                    / pl.col(\"cpi\").rolling_std(self.z_score_months)\n                )\n                .alias(\"cpi_zscore\"),\n            ]\n        )\n\n    # Select columns based on whether z-scores were calculated\n    columns_to_select = [\n        pl.col(\"date_month_start\"),\n        pl.col(\"country\"),\n        pl.col(\"cpi\").round(2),\n        pl.col(\"cpi_3m_delta\").round(2),\n        pl.col(\"cli\").round(2),\n        pl.col(\"cli_3m_delta\").round(2),\n        pl.col(\"humbl_regime\"),\n    ]\n\n    if (\n        self.z_score_months &gt; 0\n        and self.context_params.membership != \"humblPEON\"\n    ):\n        columns_to_select.extend(\n            [\n                pl.col(\"cpi_zscore\").round(2),\n                pl.col(\"cli_zscore\").round(2),\n            ]\n        )\n\n    self.transformed_data = transformed_data.select(columns_to_select)\n\n    # Validate the data using HumblCompassData\n    self.transformed_data = HumblCompassData(\n        self.transformed_data.collect().drop_nulls()  # removes preceding 3 months used for delta calculations\n    ).lazy()\n\n    # Generate chart if requested\n    self.chart = None\n    if self.command_params.chart:\n        self.chart = generate_plots(\n            self.transformed_data,\n            template=ChartTemplate(self.command_params.template),\n        )\n\n    # Add warning if z_score is None\n    if self.command_params.z_score is None:\n        if not hasattr(self, \"warnings\"):\n            self.warnings = []\n        self.warnings.append(\n            HumblDataWarning(\n                category=\"HumblCompassFetcher\",\n                message=\"Z-score defaulted to None. No z-score data will be calculated.\",\n            )\n        )\n\n    # Add recommendations if requested\n    if self.command_params.recommendations:\n        latest_regime = (\n            self.transformed_data.select(pl.col(\"humbl_regime\"))\n            .collect()\n            .row(-1)[0]\n        )\n\n        if latest_regime not in REGIME_RECOMMENDATIONS:\n            if not hasattr(self, \"warnings\"):\n                self.warnings = []\n            self.warnings.append(\n                HumblDataWarning(\n                    category=\"HumblCompassFetcher\",\n                    message=f\"No recommendations available for regime: {latest_regime}\",\n                )\n            )\n        else:\n            recommendations = REGIME_RECOMMENDATIONS[latest_regime]\n            if not hasattr(self, \"extra\"):\n                self.extra = {}\n            self.extra[\"humbl_regime_recommendations\"] = (\n                recommendations.model_dump()\n            )\n\n    self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.fundamental.humbl_compass.HumblCompassFetcher.fetch_data \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute TET Pattern.</p> <p>This method executes the query transformation, data fetching and transformation process by first calling <code>transform_query</code> to prepare the query parameters, then extracting the raw data using <code>extract_data</code> method, and finally transforming the raw data using <code>transform_data</code> method.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>The HumblObject containing the transformed data and metadata.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/fundamental/humbl_compass.py</code> <pre><code>@log_start_end(logger=logger)\ndef fetch_data(self):\n    \"\"\"\n    Execute TET Pattern.\n\n    This method executes the query transformation, data fetching and\n    transformation process by first calling `transform_query` to prepare the query parameters, then\n    extracting the raw data using `extract_data` method, and finally\n    transforming the raw data using `transform_data` method.\n\n    Returns\n    -------\n    HumblObject\n        The HumblObject containing the transformed data and metadata.\n    \"\"\"\n    self.transform_query()\n    self.extract_data()\n    self.transform_data()\n\n    # Initialize warnings list if it doesn't exist\n    if not hasattr(self.context_params, \"warnings\"):\n        self.context_params.warnings = []\n\n    # Initialize fetcher warnings if they don't exist\n    if not hasattr(self, \"warnings\"):\n        self.warnings = []\n\n    # Initialize extra dict if it doesn't exist\n    if not hasattr(self, \"extra\"):\n        self.extra = {}\n\n    # Combine warnings from both sources\n    all_warnings = self.context_params.warnings + self.warnings\n\n    return HumblObject(\n        results=self.transformed_data,\n        provider=self.context_params.provider,\n        warnings=all_warnings,  # Use combined warnings\n        chart=self.chart,\n        context_params=self.context_params,\n        command_params=self.command_params,\n        extra=self.extra,  # pipe in extra from transform_data()\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical","title":"humbldata.core.standard_models.toolbox.technical","text":"<p>Context: Toolbox || Category: Technical.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility","text":"<p>Volatility Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Volatility.</p> <p>This module is used to define the QueryParams and Data model for the Volatility command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityQueryParams","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>QueryParams for the Realized Volatility command.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>class RealizedVolatilityQueryParams(QueryParams):\n    \"\"\"\n    QueryParams for the Realized Volatility command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityData","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the Realized Volatility command.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>class RealizedVolatilityData(Data):\n    \"\"\"\n    Data model for the Realized Volatility command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher","text":"<p>             Bases: <code>RealizedVolatilityQueryParams</code></p> <p>Fetcher for the Realized Volatility command.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>class RealizedVolatilityFetcher(RealizedVolatilityQueryParams):\n    \"\"\"\n    Fetcher for the Realized Volatility command.\n    \"\"\"\n\n    data_list: ClassVar[list[RealizedVolatilityData]] = []\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: RealizedVolatilityQueryParams,\n    ):\n        self._context_params = context_params\n        self._command_params = command_params\n\n    def transform_query(self):\n        \"\"\"Transform the params to the command-specific query.\"\"\"\n\n    def extract_data(self):\n        \"\"\"Extract the data from the provider.\"\"\"\n        # Assuming 'obb' is a predefined object in your context\n        df = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbol,\n                start_date=str(self.context_params.start_date),\n                end_date=str(self.context_params.end_date),\n                provider=self.command_params.provider,\n                verbose=not self.command_params.kwargs.get(\"silent\", False),\n                **self.command_params.kwargs,\n            )\n            .to_df()\n            .reset_index()\n        )\n        return df\n\n    def transform_data(self):\n        \"\"\"Transform the command-specific data.\"\"\"\n        # Placeholder for data transformation logic\n\n    def fetch_data(self):\n        \"\"\"Execute the TET pattern.\"\"\"\n        # Call the methods in the desired order\n        query = self.transform_query()\n        raw_data = (\n            self.extract_data()\n        )  # This should use 'query' to fetch the data\n        transformed_data = (\n            self.transform_data()\n        )  # This should transform 'raw_data'\n\n        # Validate with VolatilityData, unpack dict into pydantic row by row\n        return transformed_data\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the params to the command-specific query.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def transform_query(self):\n    \"\"\"Transform the params to the command-specific query.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.extract_data \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def extract_data(self):\n    \"\"\"Extract the data from the provider.\"\"\"\n    # Assuming 'obb' is a predefined object in your context\n    df = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbol,\n            start_date=str(self.context_params.start_date),\n            end_date=str(self.context_params.end_date),\n            provider=self.command_params.provider,\n            verbose=not self.command_params.kwargs.get(\"silent\", False),\n            **self.command_params.kwargs,\n        )\n        .to_df()\n        .reset_index()\n    )\n    return df\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_data \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def transform_data(self):\n    \"\"\"Transform the command-specific data.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.fetch_data \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute the TET pattern.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/realized_volatility.py</code> <pre><code>def fetch_data(self):\n    \"\"\"Execute the TET pattern.\"\"\"\n    # Call the methods in the desired order\n    query = self.transform_query()\n    raw_data = (\n        self.extract_data()\n    )  # This should use 'query' to fetch the data\n    transformed_data = (\n        self.transform_data()\n    )  # This should transform 'raw_data'\n\n    # Validate with VolatilityData, unpack dict into pydantic row by row\n    return transformed_data\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrot_channel","title":"humbldata.core.standard_models.toolbox.technical.mandelbrot_channel","text":"<p>Mandelbrot Channel Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Mandelbrot Channel.</p> <p>This module is used to define the QueryParams and Data model for the Mandelbrot Channel command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelQueryParams","title":"humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>QueryParams model for the Mandelbrot Channel command, a Pydantic v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>str</code> <p>The width of the window used for splitting the data into sections for detrending. Defaults to \"1m\".</p> required <code>rv_adjustment</code> <code>bool</code> <p>Whether to adjust the calculation for realized volatility. If True, the data is filtered to only include observations in the same volatility bucket that the stock is currently in. Defaults to True.</p> required <code>rv_method</code> <code>str</code> <p>The method to calculate the realized volatility. Only need to define when rv_adjustment is True. Defaults to \"std\".</p> required <code>rs_method</code> <code>Literal['RS', 'RS_min', 'RS_max', 'RS_mean']</code> <p>The method to use for Range/STD calculation. This is either, min, max or mean of all RS ranges per window. If not defined, just used the most recent RS window. Defaults to \"RS\".</p> required <code>rv_grouped_mean</code> <code>bool</code> <p>Whether to calculate the mean value of realized volatility over multiple window lengths. Defaults to False.</p> required <code>live_price</code> <code>bool</code> <p>Whether to calculate the ranges using the current live price, or the most recent 'close' observation. Defaults to False.</p> required <code>historical</code> <code>bool</code> <p>Whether to calculate the Historical Mandelbrot Channel (over-time), and return a time-series of channels from the start to the end date. If False, the Mandelbrot Channel calculation is done aggregating all of the data into one observation. If True, then it will enable daily observations over-time. Defaults to False.</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object. Defaults to False.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>class MandelbrotChannelQueryParams(QueryParams):\n    \"\"\"\n    QueryParams model for the Mandelbrot Channel command, a Pydantic v2 model.\n\n    Parameters\n    ----------\n    window : str\n        The width of the window used for splitting the data into sections for\n        detrending. Defaults to \"1m\".\n    rv_adjustment : bool\n        Whether to adjust the calculation for realized volatility. If True, the\n        data is filtered\n        to only include observations in the same volatility bucket that the\n        stock is currently in. Defaults to True.\n    rv_method : str\n        The method to calculate the realized volatility. Only need to define\n        when rv_adjustment is True. Defaults to \"std\".\n    rs_method : Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"]\n        The method to use for Range/STD calculation. This is either, min, max\n        or mean of all RS ranges\n        per window. If not defined, just used the most recent RS window.\n        Defaults to \"RS\".\n    rv_grouped_mean : bool\n        Whether to calculate the mean value of realized volatility over\n        multiple window lengths. Defaults to False.\n    live_price : bool\n        Whether to calculate the ranges using the current live price, or the\n        most recent 'close' observation. Defaults to False.\n    historical : bool\n        Whether to calculate the Historical Mandelbrot Channel (over-time), and\n        return a time-series of channels from the start to the end date. If\n        False, the Mandelbrot Channel calculation is done aggregating all of the\n        data into one observation. If True, then it will enable daily\n        observations over-time. Defaults to False.\n    chart : bool\n        Whether to return a chart object. Defaults to False.\n    \"\"\"\n\n    window: str = Field(\n        default=\"1mo\",\n        title=\"Window\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"window\", \"\"),\n    )\n    rv_adjustment: bool = Field(\n        default=True,\n        title=\"Realized Volatility Adjustment\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rv_adjustment\", \"\"),\n    )\n    rv_method: Literal[\n        \"std\",\n        \"parkinson\",\n        \"garman_klass\",\n        \"gk\",\n        \"hodges_tompkins\",\n        \"ht\",\n        \"rogers_satchell\",\n        \"rs\",\n        \"yang_zhang\",\n        \"yz\",\n        \"squared_returns\",\n        \"sq\",\n    ] = Field(\n        default=\"std\",\n        title=\"Realized Volatility Method\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rv_method\", \"\"),\n    )\n    rs_method: Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"] = Field(\n        default=\"RS\",\n        title=\"R/S Method\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rs_method\", \"\"),\n    )\n    rv_grouped_mean: bool = Field(\n        default=False,\n        title=\"Realized Volatility Grouped Mean\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"rv_grouped_mean\", \"\"),\n    )\n    live_price: bool = Field(\n        default=False,\n        title=\"Live Price\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"live_price\", \"\"),\n    )\n    historical: bool = Field(\n        default=False,\n        title=\"Historical Mandelbrot Channel\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"historical\", \"\"),\n    )\n    chart: bool = Field(\n        default=False,\n        title=\"Results Chart\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"chart\", \"\"),\n    )\n    template: Literal[\n        \"humbl_dark\",\n        \"humbl_light\",\n        \"ggplot2\",\n        \"seaborn\",\n        \"simple_white\",\n        \"plotly\",\n        \"plotly_white\",\n        \"plotly_dark\",\n        \"presentation\",\n        \"xgridoff\",\n        \"ygridoff\",\n        \"gridon\",\n        \"none\",\n    ] = Field(\n        default=\"humbl_dark\",\n        title=\"Plotly Template\",\n        description=MANDELBROT_QUERY_DESCRIPTIONS.get(\"template\", \"\"),\n    )\n\n    @field_validator(\"window\", mode=\"after\", check_fields=False)\n    @classmethod\n    def window_format(cls, v: str) -&gt; str:\n        \"\"\"\n        Format the window string into a standardized format.\n\n        Parameters\n        ----------\n        v : str\n            The window size as a string.\n\n        Returns\n        -------\n        str\n            The window string in a standardized format.\n\n        Raises\n        ------\n        ValueError\n            If the input is not a string.\n        \"\"\"\n        if isinstance(v, str):\n            return _window_format(v, _return_timedelta=False)\n        else:\n            msg = \"Window must be a string.\"\n            raise ValueError(msg)\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelQueryParams.window_format <code>classmethod</code> \u00a4 <pre><code>window_format(v: str) -&gt; str\n</code></pre> <p>Format the window string into a standardized format.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str</code> <p>The window size as a string.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The window string in a standardized format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input is not a string.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>@field_validator(\"window\", mode=\"after\", check_fields=False)\n@classmethod\ndef window_format(cls, v: str) -&gt; str:\n    \"\"\"\n    Format the window string into a standardized format.\n\n    Parameters\n    ----------\n    v : str\n        The window size as a string.\n\n    Returns\n    -------\n    str\n        The window string in a standardized format.\n\n    Raises\n    ------\n    ValueError\n        If the input is not a string.\n    \"\"\"\n    if isinstance(v, str):\n        return _window_format(v, _return_timedelta=False)\n    else:\n        msg = \"Window must be a string.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelData","title":"humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the Mandelbrot Channel command, a Pandera.Polars Model.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>Union[date, datetime]</code> <p>The date of the data point. Defaults to None.</p> required <code>symbol</code> <code>str</code> <p>The stock symbol. Defaults to None.</p> required <code>bottom_price</code> <code>float</code> <p>The bottom price in the Mandelbrot Channel. Defaults to None.</p> required <code>recent_price</code> <code>float</code> <p>The most recent price within the Mandelbrot Channel. Defaults to None.</p> required <code>top_price</code> <code>float</code> <p>The top price in the Mandelbrot Channel. Defaults to None.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>class MandelbrotChannelData(Data):\n    \"\"\"\n    Data model for the Mandelbrot Channel command, a Pandera.Polars Model.\n\n    Parameters\n    ----------\n    date : Union[dt.date, dt.datetime], optional\n        The date of the data point. Defaults to None.\n    symbol : str, optional\n        The stock symbol. Defaults to None.\n    bottom_price : float, optional\n        The bottom price in the Mandelbrot Channel. Defaults to None.\n    recent_price : float, optional\n        The most recent price within the Mandelbrot Channel. Defaults to None.\n    top_price : float, optional\n        The top price in the Mandelbrot Channel. Defaults to None.\n    \"\"\"\n\n    date: pl.Date = pa.Field(\n        default=None,\n        title=\"Date\",\n        description=\"The date of the data point.\",\n    )\n    symbol: str = pa.Field(\n        default=None,\n        title=\"Symbol\",\n        description=\"The stock symbol.\",\n    )\n    bottom_price: float = pa.Field(\n        default=None,\n        title=\"Bottom Price\",\n        description=\"The bottom price in the Mandelbrot Channel.\",\n    )\n    recent_price: float = pa.Field(\n        default=None,\n        title=\"Recent Price\",\n        description=\"The most recent price within the Mandelbrot Channel.\",\n        alias=\"(close_price|recent_price|last_price)\",\n        regex=True,\n    )\n    top_price: float = pa.Field(\n        default=None,\n        title=\"Top Price\",\n        description=\"The top price in the Mandelbrot Channel.\",\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher","title":"humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher","text":"<p>Fetcher for the Mandelbrot Channel command.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the toolbox query.</p> required <code>command_params</code> <code>MandelbrotChannelQueryParams</code> <p>The command-specific parameters for the Mandelbrot Channel query.</p> required <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>Stores the context parameters passed during initialization.</p> <code>command_params</code> <code>MandelbrotChannelQueryParams</code> <p>Stores the command-specific parameters passed during initialization.</p> <code>equity_historical_data</code> <code>DataFrame</code> <p>The raw data extracted from the data provider, before transformation.</p> <p>Methods:</p> Name Description <code>transform_query</code> <p>Transform the command-specific parameters into a query.</p> <code>extract_data</code> <p>Extracts the data from the provider and returns it as a Polars DataFrame.</p> <code>transform_data</code> <p>Transforms the command-specific data according to the Mandelbrot Channel logic.</p> <code>fetch_data</code> <p>Execute TET Pattern.</p> <p>Returns:</p> Type Description <code>HumblObject</code> <p>results : MandelbrotChannelData     Serializable results. provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']     Provider name. warnings : Optional[List[Warning_]]     List of warnings. chart : Optional[Chart]     Chart object. context_params : ToolboxQueryParams     Context-specific parameters. command_params : MandelbrotChannelQueryParams     Command-specific parameters.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>class MandelbrotChannelFetcher:\n    \"\"\"\n    Fetcher for the Mandelbrot Channel command.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the toolbox query.\n    command_params : MandelbrotChannelQueryParams\n        The command-specific parameters for the Mandelbrot Channel query.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        Stores the context parameters passed during initialization.\n    command_params : MandelbrotChannelQueryParams\n        Stores the command-specific parameters passed during initialization.\n    equity_historical_data : pl.DataFrame\n        The raw data extracted from the data provider, before transformation.\n\n    Methods\n    -------\n    transform_query()\n        Transform the command-specific parameters into a query.\n    extract_data()\n        Extracts the data from the provider and returns it as a Polars DataFrame.\n    transform_data()\n        Transforms the command-specific data according to the Mandelbrot Channel logic.\n    fetch_data()\n        Execute TET Pattern.\n\n    Returns\n    -------\n    HumblObject\n        results : MandelbrotChannelData\n            Serializable results.\n        provider : Literal['fmp', 'intrinio', 'polygon', 'tiingo', 'yfinance']\n            Provider name.\n        warnings : Optional[List[Warning_]]\n            List of warnings.\n        chart : Optional[Chart]\n            Chart object.\n        context_params : ToolboxQueryParams\n            Context-specific parameters.\n        command_params : MandelbrotChannelQueryParams\n            Command-specific parameters.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: MandelbrotChannelQueryParams,\n    ):\n        \"\"\"\n        Initialize the MandelbrotChannelFetcher with context and command parameters.\n\n        Parameters\n        ----------\n        context_params : ToolboxQueryParams\n            The context parameters for the toolbox query.\n        command_params : MandelbrotChannelQueryParams\n            The command-specific parameters for the Mandelbrot Channel query.\n        \"\"\"\n        self.context_params = context_params\n        self.command_params = command_params\n\n    def transform_query(self):\n        \"\"\"\n        Transform the command-specific parameters into a query.\n\n        If command_params is not provided, it initializes a default MandelbrotChannelQueryParams object.\n        \"\"\"\n        if not self.command_params:\n            self.command_params = None\n            # Set Default Arguments\n            self.command_params: MandelbrotChannelQueryParams = (\n                MandelbrotChannelQueryParams()\n            )\n        else:\n            self.command_params: MandelbrotChannelQueryParams = (\n                MandelbrotChannelQueryParams(**self.command_params)\n            )\n\n    def extract_data(self):\n        \"\"\"\n        Extract the data from the provider and returns it as a Polars DataFrame.\n\n        Drops unnecessary columns like dividends and stock splits from the data.\n\n        Returns\n        -------\n        pl.DataFrame\n            The extracted data as a Polars DataFrame.\n        \"\"\"\n        self.equity_historical_data: pl.LazyFrame = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbols,\n                start_date=self.context_params.start_date,\n                end_date=self.context_params.end_date,\n                provider=self.context_params.provider,\n                adjustment=\"splits_and_dividends\",\n                # add kwargs\n            )\n            .to_polars()\n            .lazy()\n        ).drop([\"dividend\", \"split_ratio\"])  # TODO: drop `capital_gains` col\n\n        if len(self.context_params.symbols) == 1:\n            self.equity_historical_data = (\n                self.equity_historical_data.with_columns(\n                    symbol=pl.lit(self.context_params.symbols[0])\n                )\n            )\n        return self\n\n    def transform_data(self):\n        \"\"\"\n        Transform the command-specific data according to the Mandelbrot Channel logic.\n\n        Returns\n        -------\n        pl.DataFrame\n            The transformed data as a Polars DataFrame\n        \"\"\"\n        if self.command_params.historical is False:\n            transformed_data = calc_mandelbrot_channel(\n                data=self.equity_historical_data,\n                window=self.command_params.window,\n                rv_adjustment=self.command_params.rv_adjustment,\n                rv_method=self.command_params.rv_method,\n                rv_grouped_mean=self.command_params.rv_grouped_mean,\n                rs_method=self.command_params.rs_method,\n                live_price=self.command_params.live_price,\n            )\n        else:\n            transformed_data = calc_mandelbrot_channel_historical_concurrent(\n                data=self.equity_historical_data,\n                window=self.command_params.window,\n                rv_adjustment=self.command_params.rv_adjustment,\n                rv_method=self.command_params.rv_method,\n                rv_grouped_mean=self.command_params.rv_grouped_mean,\n                rs_method=self.command_params.rs_method,\n                live_price=self.command_params.live_price,\n                use_processes=False,\n            )\n\n        self.transformed_data = MandelbrotChannelData(\n            transformed_data.collect().drop_nulls()  ## HOTFIX - need to trace where coming from w/ unequal data\n        ).lazy()\n\n        if self.command_params.chart:\n            self.chart = generate_plots(\n                self.transformed_data,\n                self.equity_historical_data,\n                template=self.command_params.template,\n            )\n        else:\n            self.chart = None\n\n        self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n        return self\n\n    @log_start_end(logger=logger)\n    def fetch_data(self):\n        \"\"\"\n        Execute TET Pattern.\n\n        This method executes the query transformation, data fetching and\n        transformation process by first calling `transform_query` to prepare the query parameters, then\n        extracting the raw data using `extract_data` method, and finally\n        transforming the raw data using `transform_data` method.\n\n        Returns\n        -------\n        pl.DataFrame\n            The transformed data as a Polars DataFrame, ready for further analysis\n            or visualization.\n        \"\"\"\n        self.transform_query()\n        self.extract_data()\n        self.transform_data()\n\n        if not hasattr(self.context_params, \"warnings\"):\n            self.context_params.warnings = []\n\n        return HumblObject(\n            results=self.transformed_data,\n            provider=self.context_params.provider,\n            equity_data=self.equity_historical_data.serialize(),\n            warnings=self.context_params.warnings,\n            chart=self.chart,\n            context_params=self.context_params,\n            command_params=self.command_params,\n        )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.__init__ \u00a4 <pre><code>__init__(context_params: ToolboxQueryParams, command_params: MandelbrotChannelQueryParams)\n</code></pre> <p>Initialize the MandelbrotChannelFetcher with context and command parameters.</p> <p>Parameters:</p> Name Type Description Default <code>context_params</code> <code>ToolboxQueryParams</code> <p>The context parameters for the toolbox query.</p> required <code>command_params</code> <code>MandelbrotChannelQueryParams</code> <p>The command-specific parameters for the Mandelbrot Channel query.</p> required Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def __init__(\n    self,\n    context_params: ToolboxQueryParams,\n    command_params: MandelbrotChannelQueryParams,\n):\n    \"\"\"\n    Initialize the MandelbrotChannelFetcher with context and command parameters.\n\n    Parameters\n    ----------\n    context_params : ToolboxQueryParams\n        The context parameters for the toolbox query.\n    command_params : MandelbrotChannelQueryParams\n        The command-specific parameters for the Mandelbrot Channel query.\n    \"\"\"\n    self.context_params = context_params\n    self.command_params = command_params\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.transform_query \u00a4 <pre><code>transform_query()\n</code></pre> <p>Transform the command-specific parameters into a query.</p> <p>If command_params is not provided, it initializes a default MandelbrotChannelQueryParams object.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def transform_query(self):\n    \"\"\"\n    Transform the command-specific parameters into a query.\n\n    If command_params is not provided, it initializes a default MandelbrotChannelQueryParams object.\n    \"\"\"\n    if not self.command_params:\n        self.command_params = None\n        # Set Default Arguments\n        self.command_params: MandelbrotChannelQueryParams = (\n            MandelbrotChannelQueryParams()\n        )\n    else:\n        self.command_params: MandelbrotChannelQueryParams = (\n            MandelbrotChannelQueryParams(**self.command_params)\n        )\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.extract_data \u00a4 <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider and returns it as a Polars DataFrame.</p> <p>Drops unnecessary columns like dividends and stock splits from the data.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The extracted data as a Polars DataFrame.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def extract_data(self):\n    \"\"\"\n    Extract the data from the provider and returns it as a Polars DataFrame.\n\n    Drops unnecessary columns like dividends and stock splits from the data.\n\n    Returns\n    -------\n    pl.DataFrame\n        The extracted data as a Polars DataFrame.\n    \"\"\"\n    self.equity_historical_data: pl.LazyFrame = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbols,\n            start_date=self.context_params.start_date,\n            end_date=self.context_params.end_date,\n            provider=self.context_params.provider,\n            adjustment=\"splits_and_dividends\",\n            # add kwargs\n        )\n        .to_polars()\n        .lazy()\n    ).drop([\"dividend\", \"split_ratio\"])  # TODO: drop `capital_gains` col\n\n    if len(self.context_params.symbols) == 1:\n        self.equity_historical_data = (\n            self.equity_historical_data.with_columns(\n                symbol=pl.lit(self.context_params.symbols[0])\n            )\n        )\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.transform_data \u00a4 <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data according to the Mandelbrot Channel logic.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed data as a Polars DataFrame</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>def transform_data(self):\n    \"\"\"\n    Transform the command-specific data according to the Mandelbrot Channel logic.\n\n    Returns\n    -------\n    pl.DataFrame\n        The transformed data as a Polars DataFrame\n    \"\"\"\n    if self.command_params.historical is False:\n        transformed_data = calc_mandelbrot_channel(\n            data=self.equity_historical_data,\n            window=self.command_params.window,\n            rv_adjustment=self.command_params.rv_adjustment,\n            rv_method=self.command_params.rv_method,\n            rv_grouped_mean=self.command_params.rv_grouped_mean,\n            rs_method=self.command_params.rs_method,\n            live_price=self.command_params.live_price,\n        )\n    else:\n        transformed_data = calc_mandelbrot_channel_historical_concurrent(\n            data=self.equity_historical_data,\n            window=self.command_params.window,\n            rv_adjustment=self.command_params.rv_adjustment,\n            rv_method=self.command_params.rv_method,\n            rv_grouped_mean=self.command_params.rv_grouped_mean,\n            rs_method=self.command_params.rs_method,\n            live_price=self.command_params.live_price,\n            use_processes=False,\n        )\n\n    self.transformed_data = MandelbrotChannelData(\n        transformed_data.collect().drop_nulls()  ## HOTFIX - need to trace where coming from w/ unequal data\n    ).lazy()\n\n    if self.command_params.chart:\n        self.chart = generate_plots(\n            self.transformed_data,\n            self.equity_historical_data,\n            template=self.command_params.template,\n        )\n    else:\n        self.chart = None\n\n    self.transformed_data = self.transformed_data.serialize(format=\"binary\")\n    return self\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrot_channel.MandelbrotChannelFetcher.fetch_data \u00a4 <pre><code>fetch_data()\n</code></pre> <p>Execute TET Pattern.</p> <p>This method executes the query transformation, data fetching and transformation process by first calling <code>transform_query</code> to prepare the query parameters, then extracting the raw data using <code>extract_data</code> method, and finally transforming the raw data using <code>transform_data</code> method.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed data as a Polars DataFrame, ready for further analysis or visualization.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/technical/mandelbrot_channel.py</code> <pre><code>@log_start_end(logger=logger)\ndef fetch_data(self):\n    \"\"\"\n    Execute TET Pattern.\n\n    This method executes the query transformation, data fetching and\n    transformation process by first calling `transform_query` to prepare the query parameters, then\n    extracting the raw data using `extract_data` method, and finally\n    transforming the raw data using `transform_data` method.\n\n    Returns\n    -------\n    pl.DataFrame\n        The transformed data as a Polars DataFrame, ready for further analysis\n        or visualization.\n    \"\"\"\n    self.transform_query()\n    self.extract_data()\n    self.transform_data()\n\n    if not hasattr(self.context_params, \"warnings\"):\n        self.context_params.warnings = []\n\n    return HumblObject(\n        results=self.transformed_data,\n        provider=self.context_params.provider,\n        equity_data=self.equity_historical_data.serialize(),\n        warnings=self.context_params.warnings,\n        chart=self.chart,\n        context_params=self.context_params,\n        command_params=self.command_params,\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxQueryParams","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>Query parameters for the ToolboxController.</p> <p>This class defines the query parameters used by the ToolboxController, including the stock symbol, data interval, start date, and end date. It also includes a method to ensure the stock symbol is in uppercase. If no dates constraints are given, it will collect the MAX amount of data available.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str | list[str] | set[str]</code> <p>The symbol or ticker of the stock. You can pass multiple tickers like: \"AAPL\", \"AAPL, MSFT\" or [\"AAPL\", \"MSFT\"]. The input will be converted to uppercase.</p> <code>\"\"</code> <code>interval</code> <code>str | None</code> <p>The interval of the data. Can be None.</p> <code>\"1d\"</code> <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> <code>\"\"</code> <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> <code>\"\"</code> <code>provider</code> <code>OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS</code> <p>The data provider to be used for the query.</p> <code>\"yfinance\"</code> <code>membership</code> <code>str</code> <p>The membership level of the user.</p> <code>\"anonymous\"</code> <p>Methods:</p> Name Description <code>upper_symbol</code> <p>A Pydantic <code>@field_validator()</code> that converts the stock symbol to uppercase. If a list or set of symbols is provided, each symbol in the collection is converted to uppercase and returned as a comma-separated string.</p> <code>validate_interval</code> <p>A Pydantic <code>@field_validator()</code> that validates the interval format. Ensures the interval is a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.</p> <code>validate_date_format</code> <p>A Pydantic <code>@field_validator()</code> that validates the date format to ensure it is YYYY-MM-DD.</p> <code>validate_start_date</code> <p>A Pydantic <code>@model_validator()</code> that validates and adjusts the start date based on membership level.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>symbol</code> parameter is a list and not all elements are strings, or if <code>symbol</code> is not a string, list, or set. If the <code>interval</code> format is invalid. If the <code>date</code> format is invalid.</p> Notes <p>A Pydantic v2 Model</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>class ToolboxQueryParams(QueryParams):\n    \"\"\"\n    Query parameters for the ToolboxController.\n\n    This class defines the query parameters used by the ToolboxController,\n    including the stock symbol, data interval, start date, and end date. It also\n    includes a method to ensure the stock symbol is in uppercase.\n    If no dates constraints are given, it will collect the MAX amount of data\n    available.\n\n    Parameters\n    ----------\n    symbol : str | list[str] | set[str], default=\"\"\n        The symbol or ticker of the stock. You can pass multiple tickers like:\n        \"AAPL\", \"AAPL, MSFT\" or [\"AAPL\", \"MSFT\"]. The input will be converted\n        to uppercase.\n    interval : str | None, default=\"1d\"\n        The interval of the data. Can be None.\n    start_date : str, default=\"\"\n        The start date for the data query.\n    end_date : str, default=\"\"\n        The end date for the data query.\n    provider : OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS, default=\"yfinance\"\n        The data provider to be used for the query.\n    membership : str, default=\"anonymous\"\n        The membership level of the user.\n\n    Methods\n    -------\n    upper_symbol(cls, v: Union[str, list[str], set[str]]) -&gt; Union[str, list[str]]\n        A Pydantic `@field_validator()` that converts the stock symbol to\n        uppercase. If a list or set of symbols is provided, each symbol in the\n        collection is converted to uppercase and returned as a comma-separated\n        string.\n    validate_interval(cls, v: str) -&gt; str\n        A Pydantic `@field_validator()` that validates the interval format.\n        Ensures the interval is a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.\n    validate_date_format(cls, v: str | date) -&gt; date\n        A Pydantic `@field_validator()` that validates the date format to ensure it is YYYY-MM-DD.\n    validate_start_date(self) -&gt; 'ToolboxQueryParams'\n        A Pydantic `@model_validator()` that validates and adjusts the start date based on membership level.\n\n    Raises\n    ------\n    ValueError\n        If the `symbol` parameter is a list and not all elements are strings, or\n        if `symbol` is not a string, list, or set.\n        If the `interval` format is invalid.\n        If the `date` format is invalid.\n\n    Notes\n    -----\n    A Pydantic v2 Model\n\n    \"\"\"\n\n    symbols: str | list[str] | None = Field(\n        default=None,\n        title=\"Symbols/Tickers\",\n        description=QUERY_DESCRIPTIONS.get(\"symbols\", \"\"),\n    )\n    interval: str | None = Field(\n        default=\"1d\",\n        title=\"Interval\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: dt.date | str = Field(\n        default_factory=lambda: dt.date(1950, 1, 1),\n        title=\"Start Date\",\n        description=\"The starting date for the data query.\",\n    )\n    end_date: dt.date | str = Field(\n        default_factory=lambda: dt.datetime.now(\n            tz=pytz.timezone(\"America/New_York\")\n        ).date(),\n        title=\"End Date\",\n        description=\"The ending date for the data query.\",\n    )\n    provider: OBB_EQUITY_PRICE_HISTORICAL_PROVIDERS = Field(\n        default=\"yfinance\",\n        title=\"Provider\",\n        description=QUERY_DESCRIPTIONS.get(\"provider\", \"\"),\n    )\n    membership: Literal[\n        \"anonymous\",\n        \"humblPEON\",\n        \"humblPREMIUM\",\n        \"humblPOWER\",\n        \"humblPERMANENT\",\n        \"admin\",\n    ] = Field(\n        default=\"anonymous\",\n        title=\"Membership\",\n        description=QUERY_DESCRIPTIONS.get(\"membership\", \"\"),\n    )\n\n    @field_validator(\"symbols\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n        \"\"\"\n        Convert the stock symbols to uppercase and remove empty strings.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        List[str]\n            A list of uppercase stock symbols with empty strings removed.\n        \"\"\"\n        # Handle empty inputs\n        if not v:\n            return []\n\n        # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n        v = v.split(\",\") if isinstance(v, str) else list(v)\n\n        # Convert all elements to uppercase, trim whitespace, and remove empty strings\n        valid_symbols = [\n            symbol.strip().upper() for symbol in v if symbol.strip()\n        ]\n\n        if not valid_symbols:\n            msg = \"At least one valid symbol (str) must be provided\"\n            raise ValueError(msg)\n\n        return valid_symbols\n\n    @field_validator(\"interval\", mode=\"before\", check_fields=False)\n    @classmethod\n    def validate_interval(cls, v: str) -&gt; str:\n        \"\"\"\n        Validate the interval format.\n\n        Parameters\n        ----------\n        v : str\n            The interval string to be validated.\n\n        Returns\n        -------\n        str\n            The validated interval string.\n\n        Raises\n        ------\n        ValueError\n            If the interval format is invalid.\n        \"\"\"\n        if not re.match(r\"^\\d*[smhdWMQY]$\", v):\n            msg = \"Invalid interval format. Must be a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.\"\n            raise ValueError(msg)\n        return v\n\n    @field_validator(\"start_date\", \"end_date\", mode=\"before\")\n    @classmethod\n    def validate_date_format(cls, v: str | dt.date) -&gt; dt.date:\n        \"\"\"\n        Validate and convert the input date to a datetime.date object.\n\n        This method accepts either a string in 'YYYY-MM-DD' format or a datetime.date object.\n        It converts the input to a datetime.date object, ensuring it's in the correct format.\n\n        Parameters\n        ----------\n        v : str | dt.date\n            The input date to validate and convert.\n\n        Returns\n        -------\n        dt.date\n            The validated and converted date.\n\n        Raises\n        ------\n        ValueError\n            If the input string is not in the correct format.\n        TypeError\n            If the input is neither a string nor a datetime.date object.\n        \"\"\"\n        if isinstance(v, str):\n            try:\n                date = datetime.strptime(v, \"%Y-%m-%d\").replace(\n                    tzinfo=pytz.timezone(\"America/New_York\")\n                )\n            except ValueError as e:\n                msg = f\"Invalid date format. Must be YYYY-MM-DD: {e}\"\n                raise ValueError(msg) from e\n        elif isinstance(v, dt.date):\n            date = datetime.combine(v, datetime.min.time()).replace(\n                tzinfo=pytz.timezone(\"America/New_York\")\n            )\n        else:\n            msg = f\"Expected str or date, got {type(v)}\"\n            raise TypeError(msg)\n\n        # Check if the date is in the correct format\n        if date.strftime(\"%Y-%m-%d\") != date.strftime(\"%Y-%m-%d\"):\n            msg = \"Date must be in YYYY-MM-DD format\"\n            raise ValueError(msg)\n        if date.date() &lt; dt.date(1950, 1, 1):\n            msg = \"Date must be after 1950-01-01\"\n            raise ValueError(msg)\n\n        return date.date()\n\n    @model_validator(mode=\"after\")\n    def validate_start_date(self) -&gt; \"ToolboxQueryParams\":\n        end_date: dt.date = self.end_date  # type: ignore  # noqa: PGH003 the date has already been converted to date\n\n        start_date_mapping = {\n            \"anonymous\": (end_date - timedelta(days=365), \"1Y\"),\n            \"humblPEON\": (end_date - timedelta(days=730), \"2Y\"),\n            \"humblPREMIUM\": (end_date - timedelta(days=1825), \"5Y\"),\n            \"humblPOWER\": (end_date - timedelta(days=7300), \"20Y\"),\n            \"humblPERMANENT\": (end_date - timedelta(days=10680), \"30Y\"),\n            \"admin\": (\n                datetime(\n                    1950, 1, 1, tzinfo=pytz.timezone(\"America/New_York\")\n                ).date(),\n                \"All\",\n            ),\n        }\n\n        allowed_start_date, data_length = start_date_mapping.get(\n            self.membership, (end_date - timedelta(days=365), \"1Y\")\n        )\n\n        if self.start_date &lt; allowed_start_date:  # type: ignore  # noqa: PGH003 the date has already been converted to date\n            warning_msg = f\"Start date adjusted to {allowed_start_date} based on {self.membership} membership ({data_length} of data).\"\n            logger.warning(warning_msg)\n            self.start_date = allowed_start_date\n            if not hasattr(self, \"warnings\"):\n                self.warnings = []\n            self.warnings.append(\n                HumblDataWarning(\n                    category=\"ToolboxQueryParams\",\n                    message=warning_msg,\n                )\n            )\n\n        return self\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol  <code>classmethod</code>","text":"<pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; list[str]\n</code></pre> <p>Convert the stock symbols to uppercase and remove empty strings.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of uppercase stock symbols with empty strings removed.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>@field_validator(\"symbols\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; list[str]:\n    \"\"\"\n    Convert the stock symbols to uppercase and remove empty strings.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    List[str]\n        A list of uppercase stock symbols with empty strings removed.\n    \"\"\"\n    # Handle empty inputs\n    if not v:\n        return []\n\n    # If v is a string, split it by commas into a list. Otherwise, ensure it's a list.\n    v = v.split(\",\") if isinstance(v, str) else list(v)\n\n    # Convert all elements to uppercase, trim whitespace, and remove empty strings\n    valid_symbols = [\n        symbol.strip().upper() for symbol in v if symbol.strip()\n    ]\n\n    if not valid_symbols:\n        msg = \"At least one valid symbol (str) must be provided\"\n        raise ValueError(msg)\n\n    return valid_symbols\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_interval","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_interval  <code>classmethod</code>","text":"<pre><code>validate_interval(v: str) -&gt; str\n</code></pre> <p>Validate the interval format.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str</code> <p>The interval string to be validated.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The validated interval string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the interval format is invalid.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>@field_validator(\"interval\", mode=\"before\", check_fields=False)\n@classmethod\ndef validate_interval(cls, v: str) -&gt; str:\n    \"\"\"\n    Validate the interval format.\n\n    Parameters\n    ----------\n    v : str\n        The interval string to be validated.\n\n    Returns\n    -------\n    str\n        The validated interval string.\n\n    Raises\n    ------\n    ValueError\n        If the interval format is invalid.\n    \"\"\"\n    if not re.match(r\"^\\d*[smhdWMQY]$\", v):\n        msg = \"Invalid interval format. Must be a number followed by one of 's', 'm', 'h', 'd', 'W', 'M', 'Q', 'Y'.\"\n        raise ValueError(msg)\n    return v\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_date_format","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.validate_date_format  <code>classmethod</code>","text":"<pre><code>validate_date_format(v: str | date) -&gt; date\n</code></pre> <p>Validate and convert the input date to a datetime.date object.</p> <p>This method accepts either a string in 'YYYY-MM-DD' format or a datetime.date object. It converts the input to a datetime.date object, ensuring it's in the correct format.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str | date</code> <p>The input date to validate and convert.</p> required <p>Returns:</p> Type Description <code>date</code> <p>The validated and converted date.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input string is not in the correct format.</p> <code>TypeError</code> <p>If the input is neither a string nor a datetime.date object.</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>@field_validator(\"start_date\", \"end_date\", mode=\"before\")\n@classmethod\ndef validate_date_format(cls, v: str | dt.date) -&gt; dt.date:\n    \"\"\"\n    Validate and convert the input date to a datetime.date object.\n\n    This method accepts either a string in 'YYYY-MM-DD' format or a datetime.date object.\n    It converts the input to a datetime.date object, ensuring it's in the correct format.\n\n    Parameters\n    ----------\n    v : str | dt.date\n        The input date to validate and convert.\n\n    Returns\n    -------\n    dt.date\n        The validated and converted date.\n\n    Raises\n    ------\n    ValueError\n        If the input string is not in the correct format.\n    TypeError\n        If the input is neither a string nor a datetime.date object.\n    \"\"\"\n    if isinstance(v, str):\n        try:\n            date = datetime.strptime(v, \"%Y-%m-%d\").replace(\n                tzinfo=pytz.timezone(\"America/New_York\")\n            )\n        except ValueError as e:\n            msg = f\"Invalid date format. Must be YYYY-MM-DD: {e}\"\n            raise ValueError(msg) from e\n    elif isinstance(v, dt.date):\n        date = datetime.combine(v, datetime.min.time()).replace(\n            tzinfo=pytz.timezone(\"America/New_York\")\n        )\n    else:\n        msg = f\"Expected str or date, got {type(v)}\"\n        raise TypeError(msg)\n\n    # Check if the date is in the correct format\n    if date.strftime(\"%Y-%m-%d\") != date.strftime(\"%Y-%m-%d\"):\n        msg = \"Date must be in YYYY-MM-DD format\"\n        raise ValueError(msg)\n    if date.date() &lt; dt.date(1950, 1, 1):\n        msg = \"Date must be after 1950-01-01\"\n        raise ValueError(msg)\n\n    return date.date()\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxData","title":"humbldata.core.standard_models.toolbox.ToolboxData","text":"<p>             Bases: <code>Data</code></p> <p>The Data for the ToolboxController.</p> <p>WIP: I'm thinking that this is the final layer around which the HumblDataObject will be returned to the user, with all necessary information about the query, command, data and charts that they should want. This HumblDataObject will return values in json/dict format, with methods to allow transformation into polars_df, pandas_df, a list, a dict...</p> Source code in <code>src/humbldata/core/standard_models/toolbox/__init__.py</code> <pre><code>class ToolboxData(Data):\n    \"\"\"\n    The Data for the ToolboxController.\n\n    WIP: I'm thinking that this is the final layer around which the\n    HumblDataObject will be returned to the user, with all necessary information\n    about the query, command, data and charts that they should want.\n    This HumblDataObject will return values in json/dict format, with methods\n    to allow transformation into polars_df, pandas_df, a list, a dict...\n    \"\"\"\n\n    date: pl.Date = pa.Field(\n        default=None,\n        title=\"Date\",\n        description=DATA_DESCRIPTIONS.get(\"date\", \"\"),\n    )\n    open: float = pa.Field(\n        default=None,\n        title=\"Open\",\n        description=DATA_DESCRIPTIONS.get(\"open\", \"\"),\n    )\n    high: float = pa.Field(\n        default=None,\n        title=\"High\",\n        description=DATA_DESCRIPTIONS.get(\"high\", \"\"),\n    )\n    low: float = pa.Field(\n        default=None,\n        title=\"Low\",\n        description=DATA_DESCRIPTIONS.get(\"low\", \"\"),\n    )\n    close: float = pa.Field(\n        default=None,\n        title=\"Close\",\n        description=DATA_DESCRIPTIONS.get(\"close\", \"\"),\n    )\n    volume: int = pa.Field(\n        default=None,\n        title=\"Volume\",\n        description=DATA_DESCRIPTIONS.get(\"volume\", \"\"),\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils","title":"humbldata.core.utils","text":"<p>humbldata core utils.</p> <p>Utils is used to keep; helpers, descriptions, constants, and other useful tools.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env","title":"humbldata.core.utils.env","text":"<p>The Env Module, to control a single instance of environment variables.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env","title":"humbldata.core.utils.env.Env","text":"<p>A singleton environment to hold all Environment variables.</p> Source code in <code>src/humbldata/core/utils/env.py</code> <pre><code>class Env(metaclass=SingletonMeta):\n    \"\"\"A singleton environment to hold all Environment variables.\"\"\"\n\n    _environ: dict[str, str]\n\n    def __init__(self) -&gt; None:\n        env_path = dotenv.find_dotenv()\n        dotenv.load_dotenv(Path(env_path))\n\n        self._environ = os.environ.copy()\n\n    @property\n    def OBB_PAT(self) -&gt; str | None:  # noqa: N802\n        \"\"\"OpenBB Personal Access Token.\"\"\"\n        return self._environ.get(\"OBB_PAT\", None)\n\n    @property\n    def LOGGER_LEVEL(self) -&gt; int:\n        \"\"\"\n        Get the global logger level.\n\n        Returns\n        -------\n        int\n            The numeric logging level (default: 20 for INFO).\n\n        Notes\n        -----\n        Mapping of string levels to numeric values:\n        DEBUG: 10, INFO: 20, WARNING: 30, ERROR: 40, CRITICAL: 50\n        \"\"\"\n        level_map = {\n            \"DEBUG\": 10,\n            \"INFO\": 20,\n            \"WARNING\": 30,\n            \"ERROR\": 40,\n            \"CRITICAL\": 50,\n        }\n        return level_map.get(\n            self._environ.get(\"LOGGER_LEVEL\", \"INFO\").upper(), 20\n        )\n\n    @property\n    def OBB_LOGGED_IN(self) -&gt; bool:\n        return self.str2bool(self._environ.get(\"OBB_LOGGED_IN\", False))\n\n    @staticmethod\n    def str2bool(value: str | bool) -&gt; bool:\n        \"\"\"Match a value to its boolean correspondent.\n\n        Args:\n            value (str): The string value to be converted to a boolean.\n\n        Returns\n        -------\n            bool: The boolean value corresponding to the input string.\n\n        Raises\n        ------\n            ValueError: If the input string does not correspond to a boolean\n            value.\n        \"\"\"\n        if isinstance(value, bool):\n            return value\n        if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n            return False\n        if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n            return True\n        msg = f\"Failed to cast '{value}' to bool.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env.OBB_PAT","title":"humbldata.core.utils.env.Env.OBB_PAT  <code>property</code>","text":"<pre><code>OBB_PAT: str | None\n</code></pre> <p>OpenBB Personal Access Token.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env.LOGGER_LEVEL","title":"humbldata.core.utils.env.Env.LOGGER_LEVEL  <code>property</code>","text":"<pre><code>LOGGER_LEVEL: int\n</code></pre> <p>Get the global logger level.</p> <p>Returns:</p> Type Description <code>int</code> <p>The numeric logging level (default: 20 for INFO).</p> Notes <p>Mapping of string levels to numeric values: DEBUG: 10, INFO: 20, WARNING: 30, ERROR: 40, CRITICAL: 50</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env.str2bool","title":"humbldata.core.utils.env.Env.str2bool  <code>staticmethod</code>","text":"<pre><code>str2bool(value: str | bool) -&gt; bool\n</code></pre> <p>Match a value to its boolean correspondent.</p> <p>Args:     value (str): The string value to be converted to a boolean.</p> <p>Returns:</p> Type Description <code>    bool: The boolean value corresponding to the input string.</code> <p>Raises:</p> Type Description <code>    ValueError: If the input string does not correspond to a boolean</code> <p>value.</p> Source code in <code>src/humbldata/core/utils/env.py</code> <pre><code>@staticmethod\ndef str2bool(value: str | bool) -&gt; bool:\n    \"\"\"Match a value to its boolean correspondent.\n\n    Args:\n        value (str): The string value to be converted to a boolean.\n\n    Returns\n    -------\n        bool: The boolean value corresponding to the input string.\n\n    Raises\n    ------\n        ValueError: If the input string does not correspond to a boolean\n        value.\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n    if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n        return False\n    if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n        return True\n    msg = f\"Failed to cast '{value}' to bool.\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.descriptions","title":"humbldata.core.utils.descriptions","text":"<p>Common descriptions for model fields.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.constants","title":"humbldata.core.utils.constants","text":"<p>A module to contain all project-wide constants.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.logger","title":"humbldata.core.utils.logger","text":""},{"location":"code_documentation/core/#humbldata.core.utils.logger.setup_logger","title":"humbldata.core.utils.logger.setup_logger","text":"<pre><code>setup_logger(name: str, level: int = logging.INFO) -&gt; Logger\n</code></pre> <p>Set up a logger with the specified name and logging level.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>int</code> <p>The logging level, by default logging.INFO.</p> <code>INFO</code> <p>Returns:</p> Type Description <code>Logger</code> <p>A configured logger instance.</p> Notes <p>This function creates a logger with a StreamHandler that outputs to sys.stdout. It uses a formatter that includes timestamp, logger name, log level, and message. If the logger already has handlers, it skips the setup to avoid duplicate logging. The logger is configured not to propagate messages to the root logger.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; logger = setup_logger(\"my_logger\", logging.DEBUG)\n&gt;&gt;&gt; logger.debug(\"This is a debug message\")\n2023-05-20 10:30:45,123 - my_logger - DEBUG - This is a debug message\n</code></pre> Source code in <code>src/humbldata/core/utils/logger.py</code> <pre><code>def setup_logger(name: str, level: int = logging.INFO) -&gt; logging.Logger:\n    \"\"\"\n    Set up a logger with the specified name and logging level.\n\n    Parameters\n    ----------\n    name : str\n        The name of the logger.\n    level : int, optional\n        The logging level, by default logging.INFO.\n\n    Returns\n    -------\n    logging.Logger\n        A configured logger instance.\n\n    Notes\n    -----\n    This function creates a logger with a StreamHandler that outputs to sys.stdout.\n    It uses a formatter that includes timestamp, logger name, log level, and message.\n    If the logger already has handlers, it skips the setup to avoid duplicate logging.\n    The logger is configured not to propagate messages to the root logger.\n\n    Examples\n    --------\n    &gt;&gt;&gt; logger = setup_logger(\"my_logger\", logging.DEBUG)\n    &gt;&gt;&gt; logger.debug(\"This is a debug message\")\n    2023-05-20 10:30:45,123 - my_logger - DEBUG - This is a debug message\n    \"\"\"\n    logger = logging.getLogger(name)\n\n    # Check if the logger already has handlers to avoid duplicate logging\n    if not logger.handlers:\n        logger.setLevel(level)\n\n        # Install coloredlogs\n        coloredlogs.install(\n            level=level,\n            logger=logger,\n            fmt=\"%(levelname)s: %(name)s || %(message)s\",\n            level_styles={\n                \"debug\": {\"color\": \"green\"},\n                \"info\": {\"color\": \"blue\"},\n                \"warning\": {\"color\": \"yellow\", \"bold\": True},\n                \"error\": {\"color\": \"red\", \"bold\": True},\n                \"critical\": {\n                    \"color\": \"red\",\n                    \"bold\": True,\n                    \"background\": \"white\",\n                },\n            },\n            field_styles={\n                \"asctime\": {\"color\": \"blue\"},\n                \"levelname\": {\"color\": \"magenta\", \"bold\": True},\n                \"name\": {\"color\": \"cyan\"},\n            },\n        )\n\n    # Prevent the logger from propagating messages to the root logger\n    logger.propagate = False\n\n    return logger\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.logger.log_start_end","title":"humbldata.core.utils.logger.log_start_end","text":"<pre><code>log_start_end(func: Callable | None = None, *, logger: Logger | None = None) -&gt; Callable\n</code></pre> <p>Log the start and end of any function, including time tracking.</p> <p>This decorator works with both synchronous and asynchronous functions. It logs the start and end of the function execution, as well as the total execution time. If an exception occurs, it logs the exception details.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable | None</code> <p>The function to be decorated. If None, the decorator can be used with parameters.</p> <code>None</code> <code>logger</code> <code>Logger | None</code> <p>The logger to use. If None, a logger will be created using the function's module name.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable</code> <p>The wrapped function.</p> Notes <ul> <li>For asynchronous functions, the decorator uses an async wrapper.</li> <li>For synchronous functions, it uses a sync wrapper.</li> <li>If a KeyboardInterrupt occurs, it logs the interruption and returns an empty list.</li> <li>If any other exception occurs, it logs the exception and re-raises it.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @log_start_end\n... def example_function():\n...     print(\"This is an example function\")\n...\n&gt;&gt;&gt; example_function()\nSTART: example_function (sync)\nThis is an example function\nEND: example_function (sync) - Total time: 0.0001s\n</code></pre> <pre><code>&gt;&gt;&gt; @log_start_end(logger=custom_logger)\n... async def async_example():\n...     await asyncio.sleep(1)\n...\n&gt;&gt;&gt; asyncio.run(async_example())\nSTART: async_example (async)\nEND: async_example (async) - Total time: 1.0012s\n</code></pre> Source code in <code>src/humbldata/core/utils/logger.py</code> <pre><code>def log_start_end(\n    func: Callable | None = None, *, logger: logging.Logger | None = None\n) -&gt; Callable:\n    \"\"\"\n    Log the start and end of any function, including time tracking.\n\n    This decorator works with both synchronous and asynchronous functions.\n    It logs the start and end of the function execution, as well as the total\n    execution time. If an exception occurs, it logs the exception details.\n\n    Parameters\n    ----------\n    func : Callable | None, optional\n        The function to be decorated. If None, the decorator can be used with parameters.\n    logger : logging.Logger | None, optional\n        The logger to use. If None, a logger will be created using the function's module name.\n\n    Returns\n    -------\n    Callable\n        The wrapped function.\n\n    Notes\n    -----\n    - For asynchronous functions, the decorator uses an async wrapper.\n    - For synchronous functions, it uses a sync wrapper.\n    - If a KeyboardInterrupt occurs, it logs the interruption and returns an empty list.\n    - If any other exception occurs, it logs the exception and re-raises it.\n\n    Examples\n    --------\n    &gt;&gt;&gt; @log_start_end\n    ... def example_function():\n    ...     print(\"This is an example function\")\n    ...\n    &gt;&gt;&gt; example_function()\n    START: example_function (sync)\n    This is an example function\n    END: example_function (sync) - Total time: 0.0001s\n\n    &gt;&gt;&gt; @log_start_end(logger=custom_logger)\n    ... async def async_example():\n    ...     await asyncio.sleep(1)\n    ...\n    &gt;&gt;&gt; asyncio.run(async_example())\n    START: async_example (async)\n    END: async_example (async) - Total time: 1.0012s\n    \"\"\"\n    assert callable(func) or func is None\n\n    def decorator(func: Callable) -&gt; Callable:\n        @functools.wraps(func)\n        async def async_wrapper(*args, **kwargs) -&gt; Any:\n            nonlocal logger\n            if logger is None:\n                logger = logging.getLogger(func.__module__)\n\n            start_time = time.time()\n            logger.info(f\"START: {func.__name__} (async)\")\n\n            try:\n                result = await func(*args, **kwargs)\n            except KeyboardInterrupt:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"INTERRUPTED: {func.__name__} (async) - Total time: {total_time:.4f}s\"\n                )\n                return []\n            except Exception as e:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.exception(\n                    f\"EXCEPTION in {func.__name__} (async) - Total time: {total_time:.4f}s\"\n                )\n                raise\n            else:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"END: {func.__name__} (async) - Total time: {total_time:.4f}s\"\n                )\n                return result\n\n        @functools.wraps(func)\n        def sync_wrapper(*args, **kwargs) -&gt; Any:\n            nonlocal logger\n            if logger is None:\n                logger = logging.getLogger(func.__module__)\n\n            start_time = time.time()\n            logger.info(f\"START: {func.__name__} (sync)\")\n\n            try:\n                result = func(*args, **kwargs)\n            except KeyboardInterrupt:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"INTERRUPTED: {func.__name__} (sync) - Total time: {total_time:.4f}s\"\n                )\n                return []\n            except Exception as e:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.exception(\n                    f\"EXCEPTION in {func.__name__} (sync) - Total time: {total_time:.4f}s\"\n                )\n                raise\n            else:\n                end_time = time.time()\n                total_time = end_time - start_time\n                logger.info(\n                    f\"END: {func.__name__} (sync) - Total time: {total_time:.4f}s\"\n                )\n                return result\n\n        if asyncio.iscoroutinefunction(func):\n            return async_wrapper\n        else:\n            return sync_wrapper\n\n    return decorator(func) if callable(func) else decorator\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers","title":"humbldata.core.utils.openbb_helpers","text":"<p>Core Module - OpenBB Helpers.</p> <p>This module contains functions used to interact with OpenBB, or wrap commands to have specific data outputs.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.obb_login","title":"humbldata.core.utils.openbb_helpers.obb_login","text":"<pre><code>obb_login(pat: str | None = None) -&gt; bool\n</code></pre> <p>Log into the OpenBB Hub using a Personal Access Token (PAT).</p> <p>This function wraps the <code>obb.account.login</code> method to provide a simplified interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT is provided, it attempts to use the PAT stored in the environment variable <code>OBB_PAT</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pat</code> <code>str | None</code> <p>The personal access token for authentication. If None, the token is retrieved from the environment variable <code>OBB_PAT</code>. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if login is successful, False otherwise.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If an error occurs during the login process.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\nTrue\n</code></pre> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>def obb_login(pat: str | None = None) -&gt; bool:\n    \"\"\"\n    Log into the OpenBB Hub using a Personal Access Token (PAT).\n\n    This function wraps the `obb.account.login` method to provide a simplified\n    interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT\n    is provided, it attempts to use the PAT stored in the environment variable\n    `OBB_PAT`.\n\n    Parameters\n    ----------\n    pat : str | None, optional\n        The personal access token for authentication. If None, the token is\n        retrieved from the environment variable `OBB_PAT`. Default is None.\n\n    Returns\n    -------\n    bool\n        True if login is successful, False otherwise.\n\n    Raises\n    ------\n    HumblDataError\n        If an error occurs during the login process.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\n    True\n\n    &gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\n    True\n\n    \"\"\"\n    if pat is None:\n        pat = Env().OBB_PAT\n    try:\n        obb.account.login(pat=pat, remember_me=True)\n        # obb.account.save()\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"true\")\n\n        return True\n    except Exception as e:\n        from humbldata.core.standard_models.abstract.warnings import (\n            HumblDataWarning,\n        )\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"false\")\n\n        warnings.warn(\n            \"An error occurred while logging into OpenBB. Details below:\\n\"\n            + repr(e),\n            category=HumblDataWarning,\n            stacklevel=1,\n        )\n        return False\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.get_latest_price","title":"humbldata.core.utils.openbb_helpers.get_latest_price","text":"<pre><code>get_latest_price(symbol: str | list[str] | Series, provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_latest_price.</p> <p>Queries the latest stock price data for the given symbol(s) using the specified provider. Defaults to YahooFinance (<code>yfinance</code>) if no provider is specified. Returns a LazyFrame with the stock symbols and their latest prices.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str | list[str] | Series</code> <p>The stock symbol(s) to query for the latest price. Accepts a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_QUOTE_PROVIDERS</code> <p>The data provider for fetching stock prices. Defaults is <code>yfinance</code>, in which case a default provider is used.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their latest prices ('last_price').</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>def get_latest_price(\n    symbol: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_latest_price**.\n\n    Queries the latest stock price data for the given symbol(s) using the\n    specified provider. Defaults to YahooFinance (`yfinance`) if no provider is\n    specified. Returns a LazyFrame with the stock symbols and their latest prices.\n\n    Parameters\n    ----------\n    symbol : str | list[str] | pl.Series\n        The stock symbol(s) to query for the latest price. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n    provider : OBB_EQUITY_PRICE_QUOTE_PROVIDERS, optional\n        The data provider for fetching stock prices. Defaults is `yfinance`,\n        in which case a default provider is used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their latest prices ('last_price').\n    \"\"\"\n    logging.getLogger(\"openbb_terminal.stocks.stocks_model\").setLevel(\n        logging.CRITICAL\n    )\n\n    return (\n        obb.equity.price.quote(symbol, provider=provider)\n        .to_polars()\n        .lazy()\n        .select([\"symbol\", \"last_price\"])\n        .rename({\"last_price\": \"recent_price\"})\n    )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.aget_latest_price","title":"humbldata.core.utils.openbb_helpers.aget_latest_price  <code>async</code>","text":"<pre><code>aget_latest_price(symbols: str | list[str] | Series, provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Asynchronous version of get_latest_price.</p> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_latest_price_async.</p> <p>Queries the latest stock price data for the given symbol(s) using the specified provider asynchronously. This functions collects the latest prices for ETF's and Equities, but not futures or options. Defaults to YahooFinance (<code>yfinance</code>) if no provider is specified. Returns a LazyFrame with the stock symbols and their latest prices.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | List[str] | Series</code> <p>The stock symbol(s) to query for the latest price. Accepts a single symbol, a list of symbols, or a Polars Series of symbols. You can pass multiple symbols as a string; <code>'AAPL,XLE'</code>, and it will split the string into a list of symbols.</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_QUOTE_PROVIDERS</code> <p>The data provider for fetching stock prices. Default is <code>yfinance</code>.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their latest prices ('recent_price').</p> Notes <p>If entering symbols as a string, DO NOT include spaces between the symbols.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_latest_price(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Asynchronous version of get_latest_price.\n\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_latest_price_async**.\n\n    Queries the latest stock price data for the given symbol(s) using the\n    specified provider asynchronously. This functions collects the latest prices\n    for ETF's and Equities, but not futures or options. Defaults to YahooFinance\n    (`yfinance`) if no provider is specified. Returns a LazyFrame with the stock\n    symbols and their latest prices.\n\n    Parameters\n    ----------\n    symbols : str | List[str] | pl.Series\n        The stock symbol(s) to query for the latest price. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n        You can pass multiple symbols as a string; `'AAPL,XLE'`, and it will\n        split the string into a list of symbols.\n    provider : OBB_EQUITY_PRICE_QUOTE_PROVIDERS, optional\n        The data provider for fetching stock prices. Default is `yfinance`.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their latest prices ('recent_price').\n\n    Notes\n    -----\n    If entering symbols as a string, DO NOT include spaces between the symbols.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    result = await loop.run_in_executor(\n        None, lambda: obb.equity.price.quote(symbols, provider=provider)\n    )\n    out = result.to_polars().lazy()\n    if {\"last_price\", \"prev_close\"}.issubset(out.collect_schema().names()):\n        out = out.select(\n            [\n                pl.when(pl.col(\"asset_type\") == \"ETF\")\n                .then(pl.col(\"prev_close\"))\n                .otherwise(pl.col(\"last_price\"))\n                .alias(\"last_price\"),\n                pl.col(\"symbol\"),\n            ]\n        )\n    elif \"last_price\" not in out.collect_schema().names():\n        out = out.select(\n            pl.col(\"symbol\"), pl.col(\"prev_close\").alias(\"last_price\")\n        )\n    else:\n        out = out.select(pl.col(\"symbol\"), pl.col(\"last_price\"))\n\n    return out\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.aget_last_close","title":"humbldata.core.utils.openbb_helpers.aget_last_close  <code>async</code>","text":"<pre><code>aget_last_close(symbols: str | list[str] | Series, provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: aget_last_close.</p> <p>Asynchronously retrieves the last closing price for the given stock symbol(s) using OpenBB's equity price quote data.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | List[str] | Series</code> <p>The stock symbol(s) to query for the last closing price. Accepts a single symbol, a list of symbols, or a Polars Series of symbols. You can pass multiple symbols as a string; <code>'AAPL,XLE'</code>, and it will split the string into a list of symbols.</p> required <code>provider</code> <code>OBB_EQUITY_PRICE_QUOTE_PROVIDERS</code> <p>The data provider for fetching stock prices. Default is <code>yfinance</code>.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their last closing prices ('prev_close').</p> Notes <p>This function uses OpenBB's equity price quote data to fetch the last closing price. It returns a lazy frame for efficient processing, especially with large datasets.</p> <p>If entering symbols as a string, DO NOT include spaces between the symbols.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_last_close(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PRICE_QUOTE_PROVIDERS = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: aget_last_close**.\n\n    Asynchronously retrieves the last closing price for the given stock symbol(s) using OpenBB's equity price quote data.\n\n    Parameters\n    ----------\n    symbols : str | List[str] | pl.Series\n        The stock symbol(s) to query for the last closing price. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols. You can pass\n        multiple symbols as a string; `'AAPL,XLE'`, and it will split the string\n        into a list of symbols.\n    provider : OBB_EQUITY_PRICE_QUOTE_PROVIDERS, optional\n        The data provider for fetching stock prices. Default is `yfinance`.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their last closing prices ('prev_close').\n\n    Notes\n    -----\n    This function uses OpenBB's equity price quote data to fetch the last closing price.\n    It returns a lazy frame for efficient processing, especially with large datasets.\n\n    If entering symbols as a string, DO NOT include spaces between the symbols.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    result = await loop.run_in_executor(\n        None, lambda: obb.equity.price.quote(symbols, provider=provider)\n    )\n    out = result.to_polars().lazy()\n\n    return out.select(pl.col(\"symbol\"), pl.col(\"prev_close\"))\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.get_equity_sector","title":"humbldata.core.utils.openbb_helpers.get_equity_sector","text":"<pre><code>get_equity_sector(symbols: str | list[str] | Series, provider: OBB_EQUITY_PROFILE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_sector.</p> <p>Retrieves the sector information for the given stock symbol(s) using OpenBB's equity profile data.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | Series</code> <p>The stock symbol(s) to query for sector information. Accepts a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>str | None</code> <p>The data provider to use for fetching sector information. If None, the default provider will be used.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their corresponding sectors ('sector').</p> Notes <p>This function uses OpenBB's equity profile data to fetch sector information. It returns a lazy frame for efficient processing, especially with large datasets.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>def get_equity_sector(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PROFILE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_sector**.\n\n    Retrieves the sector information for the given stock symbol(s) using OpenBB's equity profile data.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | pl.Series\n        The stock symbol(s) to query for sector information. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n    provider : str | None, optional\n        The data provider to use for fetching sector information. If None, the default\n        provider will be used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their corresponding sectors ('sector').\n\n    Notes\n    -----\n    This function uses OpenBB's equity profile data to fetch sector information.\n    It returns a lazy frame for efficient processing, especially with large datasets.\n    \"\"\"\n    try:\n        result = obb.equity.profile(symbols, provider=provider)\n        return result.to_polars().select([\"symbol\", \"sector\"]).lazy()\n    except pl.exceptions.ColumnNotFoundError:\n        # If an error occurs, return a LazyFrame with symbol and null sector\n        if isinstance(symbols, str):\n            symbols = [symbols]\n        elif isinstance(symbols, pl.Series):\n            symbols = symbols.to_list()\n        return pl.LazyFrame(\n            {\"symbol\": symbols, \"sector\": [None] * len(symbols)}\n        )\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.aget_equity_sector","title":"humbldata.core.utils.openbb_helpers.aget_equity_sector  <code>async</code>","text":"<pre><code>aget_equity_sector(symbols: str | list[str] | Series, provider: OBB_EQUITY_PROFILE_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Asynchronous version of get_sector.</p> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_sector_async.</p> <p>Retrieves the sector information for the given stock symbol(s) using OpenBB's equity profile data asynchronously. If an ETF is passed, it will return a NULL sector for the symbol. The sector returned hasn't been normalized to GICS_SECTORS, it is the raw OpenBB sector output. Sectors are normalized to GICS_SECTORS in the <code>aet_sector_filter</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | List[str] | Series</code> <p>The stock symbol(s) to query for sector information. Accepts a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>str | None</code> <p>The data provider to use for fetching sector information. If None, the default provider will be used.</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the stock symbols ('symbol') and their corresponding sectors ('sector').</p> Notes <p>This function uses OpenBB's equity profile data to fetch sector information. It returns a lazy frame for efficient processing, especially with large datasets.</p> <p>If you just pass an ETF to the <code>obb.equity.profile</code> function, it will throw return data without the NULL columns (sector column included) and only returns columns where there is data, so we need to handle that edge case. If an ETF is included with an equity, it will return a NULL sector column, so we can select the sector column from the ETF data and return it as a NULL sector for the equity.</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_equity_sector(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_EQUITY_PROFILE_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Asynchronous version of get_sector.\n\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_sector_async**.\n\n    Retrieves the sector information for the given stock symbol(s) using\n    OpenBB's equity profile data asynchronously. If an ETF is passed, it will\n    return a NULL sector for the symbol. The sector returned hasn't been\n    normalized to GICS_SECTORS, it is the raw OpenBB sector output.\n    Sectors are normalized to GICS_SECTORS in the `aet_sector_filter` function.\n\n    Parameters\n    ----------\n    symbols : str | List[str] | pl.Series\n        The stock symbol(s) to query for sector information. Accepts a single\n        symbol, a list of symbols, or a Polars Series of symbols.\n    provider : str | None, optional\n        The data provider to use for fetching sector information. If None, the default\n        provider will be used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the stock symbols ('symbol') and\n        their corresponding sectors ('sector').\n\n    Notes\n    -----\n    This function uses OpenBB's equity profile data to fetch sector information.\n    It returns a lazy frame for efficient processing, especially with large datasets.\n\n    If you just pass an ETF to the `obb.equity.profile` function, it will throw\n    return data without the NULL columns (sector column included) and only\n    returns columns where there is data, so we need to handle that edge case.\n    If an ETF is included with an equity, it will return a NULL sector column,\n    so we can select the sector column from the ETF data and return it as a\n    NULL sector for the equity.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    try:\n        result = await loop.run_in_executor(\n            None, lambda: obb.equity.profile(symbols, provider=provider)\n        )\n        return result.to_polars().select([\"symbol\", \"sector\"]).lazy()\n    except pl.exceptions.ColumnNotFoundError:\n        # If an error occurs, return a LazyFrame with symbol and null sector\n        if isinstance(symbols, str):\n            symbols = [symbols]\n        elif isinstance(symbols, pl.Series):\n            symbols = symbols.to_list()\n        return pl.LazyFrame(\n            {\"symbol\": symbols, \"sector\": [None] * len(symbols)}\n        ).cast(pl.Utf8)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.aget_etf_category","title":"humbldata.core.utils.openbb_helpers.aget_etf_category  <code>async</code>","text":"<pre><code>aget_etf_category(symbols: str | list[str] | Series, provider: OBB_ETF_INFO_PROVIDERS | None = 'yfinance') -&gt; LazyFrame\n</code></pre> <p>Asynchronously retrieves the category information for the given ETF symbol(s).</p> <p>This function uses the <code>obb.etf.info</code> function and selects the <code>category</code> column to get the sector information. This function handles EQUITY symbols that are not ETF's the same way that <code>aget_equity_sector</code> does. The sector returned (under the OpenBB column name <code>category</code>) hasn't been normalized to GICS_SECTORS, it is the raw OpenBB category output. Sectors are normalized to GICS_SECTORS in the <code>aget_sector_filter</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>str | list[str] | Series</code> <p>The ETF symbol(s) to query for category information.</p> required <code>provider</code> <code>OBB_EQUITY_PROFILE_PROVIDERS | None</code> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with columns for the ETF symbols ('symbol') and their corresponding categories ('category').</p> Source code in <code>src/humbldata/core/utils/openbb_helpers.py</code> <pre><code>async def aget_etf_category(\n    symbols: str | list[str] | pl.Series,\n    provider: OBB_ETF_INFO_PROVIDERS | None = \"yfinance\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Asynchronously retrieves the category information for the given ETF symbol(s).\n\n    This function uses the `obb.etf.info` function and selects the `category`\n    column to get the sector information. This function handles EQUITY\n    symbols that are not ETF's the same way that `aget_equity_sector` does.\n    The sector returned (under the OpenBB column name `category`) hasn't been\n    normalized to GICS_SECTORS, it is the raw OpenBB category output.\n    Sectors are normalized to GICS_SECTORS in the `aget_sector_filter` function.\n\n    Parameters\n    ----------\n    symbols : str | list[str] | pl.Series\n        The ETF symbol(s) to query for category information.\n    provider : OBB_EQUITY_PROFILE_PROVIDERS | None, optional\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame with columns for the ETF symbols ('symbol') and\n        their corresponding categories ('category').\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    try:\n        result = await loop.run_in_executor(\n            None, lambda: obb.etf.info(symbols, provider=provider)\n        )\n        out = result.to_polars().lazy().select([\"symbol\", \"category\"])\n        # Create a LazyFrame with all input symbols\n        all_symbols = pl.LazyFrame({\"symbol\": symbols})\n\n        # Left join to include all input symbols, filling missing sectors with null\n        out = all_symbols.join(out, on=\"symbol\", how=\"left\").with_columns(\n            [\n                pl.when(pl.col(\"category\").is_null())\n                .then(None)\n                .otherwise(pl.col(\"category\"))\n                .alias(\"category\")\n            ]\n        )\n    except OpenBBError:\n        if isinstance(symbols, str):\n            symbols = [symbols]\n        elif isinstance(symbols, pl.Series):\n            symbols = symbols.to_list()\n        return pl.LazyFrame(\n            {\"symbol\": symbols, \"category\": [None] * len(symbols)}\n        ).cast(pl.Utf8)\n    return out\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.core_helpers","title":"humbldata.core.utils.core_helpers","text":"<p>A module to contain core helper functions for the program.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.core_helpers.is_debug_mode","title":"humbldata.core.utils.core_helpers.is_debug_mode","text":"<pre><code>is_debug_mode() -&gt; bool\n</code></pre> <p>Check if the current system is in debug mode.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the system is in debug mode, False otherwise.</p> Source code in <code>src/humbldata/core/utils/core_helpers.py</code> <pre><code>def is_debug_mode() -&gt; bool:\n    \"\"\"\n    Check if the current system is in debug mode.\n\n    Returns\n    -------\n    bool\n        True if the system is in debug mode, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.core_helpers.run_async","title":"humbldata.core.utils.core_helpers.run_async","text":"<pre><code>run_async(coro)\n</code></pre> <p>Run an async function in a new thread and return the result.</p> Source code in <code>src/humbldata/core/utils/core_helpers.py</code> <pre><code>def run_async(coro):\n    \"\"\"Run an async function in a new thread and return the result.\"\"\"\n    with ThreadPoolExecutor() as executor:\n        future = executor.submit(lambda: asyncio.run(coro))\n        return future.result()\n</code></pre>"},{"location":"code_documentation/context/","title":"\ud83d\udce5 Context","text":"<p>This tab holds all of the Contexts that have been defined for <code>humbldata</code>.</p> <p>You can have as many contexts as you would like in your package. Each context is a top-level directory</p>"},{"location":"code_documentation/context/#available-contexts","title":"Available Contexts","text":""},{"location":"code_documentation/context/#1-toolbox","title":"1. Toolbox","text":"<p>The Toolbox context provides a set of utilities and tools for various financial analyses.</p>"},{"location":"code_documentation/context/#2-portfolio","title":"2. Portfolio","text":"<p>The Portfolio context focuses on portfolio management and analysis.</p>"},{"location":"code_documentation/context/toolbox/","title":"\ud83e\uddf0 Toolbox","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox","title":"humbldata.toolbox","text":"<p>Context: Toolbox.</p> <p>A category to group all of the technical indicators available in the <code>Toolbox()</code></p> <p>Technical indicators rely on statistical transformations of time series data. These are raw math operations.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers","title":"toolbox_helpers","text":"<p>Context: Toolbox || Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.log_returns","title":"log_returns","text":"<pre><code>log_returns(data: Series | DataFrame | LazyFrame | None = None, _column_name: str = 'adj_close', *, _drop_nulls: bool = True, _sort: bool = True) -&gt; Series | DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: log_returns.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY. Calculates the logarithmic returns for a given Polars Series, DataFrame, or LazyFrame. Logarithmic returns are widely used in the financial industry to measure the rate of return on investments over time. This function supports calculations on both individual series and dataframes containing financial time series data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series | DataFrame | LazyFrame</code> <p>The input data for which to calculate the log returns. Default is None.</p> <code>None</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. Default is True.</p> <code>True</code> <code>_column_name</code> <code>str</code> <p>The column name to use for log return calculations in DataFrame or LazyFrame. Default is \"adj_close\".</p> <code>'adj_close'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by <code>date</code> and <code>symbol</code> before calculation. If you want a DUMB function, set to False. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Series | DataFrame | LazyFrame</code> <p>The original <code>data</code>, with an extra column of <code>log returns</code> of the input data. The return type matches the input type.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If neither a series, DataFrame, nor LazyFrame is provided as input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; series = pl.Series([100, 105, 103])\n&gt;&gt;&gt; log_returns(data=series)\nseries([-inf, 0.048790, -0.019418])\n</code></pre> <pre><code>&gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n&gt;&gt;&gt; log_returns(data=df)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 adj_close \u2506 log_returns\u2502\n\u2502 ---       \u2506 ---        \u2502\n\u2502 f64       \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 100.0     \u2506 NaN        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 105.0     \u2506 0.048790   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 103.0     \u2506 -0.019418  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Improvements <p>Add a parameter <code>_sort_cols: list[str] | None = None</code> to make the function even dumber. This way you could specify certain columns to sort by instead of using default <code>date</code> and <code>symbol</code>. If <code>_sort_cols=None</code> and <code>_sort=True</code>, then the function will use the default <code>date</code> and <code>symbol</code> columns for sorting.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def log_returns(\n    data: pl.Series | pl.DataFrame | pl.LazyFrame | None = None,\n    _column_name: str = \"adj_close\",\n    *,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.Series | pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: log_returns**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n    Calculates the logarithmic returns for a given Polars Series, DataFrame, or\n    LazyFrame. Logarithmic returns are widely used in the financial\n    industry to measure the rate of return on investments over time. This\n    function supports calculations on both individual series and dataframes\n    containing financial time series data.\n\n    Parameters\n    ----------\n    data : pl.Series | pl.DataFrame | pl.LazyFrame, optional\n        The input data for which to calculate the log returns. Default is None.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result. Default is True.\n    _column_name : str, optional\n        The column name to use for log return calculations in DataFrame or\n        LazyFrame. Default is \"adj_close\".\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by `date` and `symbol` before\n        calculation. If you want a DUMB function, set to False.\n        Default is True.\n\n    Returns\n    -------\n    pl.Series | pl.DataFrame | pl.LazyFrame\n        The original `data`, with an extra column of `log returns` of the input\n        data. The return type matches the input type.\n\n    Raises\n    ------\n    HumblDataError\n        If neither a series, DataFrame, nor LazyFrame is provided as input.\n\n    Examples\n    --------\n    &gt;&gt;&gt; series = pl.Series([100, 105, 103])\n    &gt;&gt;&gt; log_returns(data=series)\n    series([-inf, 0.048790, -0.019418])\n\n    &gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n    &gt;&gt;&gt; log_returns(data=df)\n    shape: (3, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 adj_close \u2506 log_returns\u2502\n    \u2502 ---       \u2506 ---        \u2502\n    \u2502 f64       \u2506 f64        \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 100.0     \u2506 NaN        \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 105.0     \u2506 0.048790   \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 103.0     \u2506 -0.019418  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    Improvements\n    -----------\n    Add a parameter `_sort_cols: list[str] | None = None` to make the function even\n    dumber. This way you could specify certain columns to sort by instead of\n    using default `date` and `symbol`. If `_sort_cols=None` and `_sort=True`,\n    then the function will use the default `date` and `symbol` columns for\n    sorting.\n\n    \"\"\"\n    # Calculation for Polars Series\n    if isinstance(data, pl.Series):\n        out = data.log().diff()\n        if _drop_nulls:\n            out = out.drop_nulls()\n    # Calculation for Polars DataFrame or LazyFrame\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n        if \"log_returns\" not in data.collect_schema().names():\n            out = data.with_columns(\n                pl.col(_column_name).log().diff().alias(\"log_returns\")\n            )\n        else:\n            out = data\n        if _drop_nulls:\n            out = out.drop_nulls(subset=\"log_returns\")\n    else:\n        msg = \"No valid data type was provided for `log_returns()` calculation.\"\n        raise HumblDataError(msg)\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.detrend","title":"detrend","text":"<pre><code>detrend(data: DataFrame | LazyFrame | Series, _detrend_col: str = 'log_returns', _detrend_value_col: str | Series | None = 'window_mean', *, _sort: bool = False) -&gt; DataFrame | LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: detrend.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>Detrends a column in a DataFrame, LazyFrame, or Series by subtracting the values of another column from it. Optionally sorts the data by 'symbol' and 'date' before detrending if _sort is True.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, LazyFrame, Series]</code> <p>The data structure containing the columns to be processed.</p> required <code>_detrend_col</code> <code>str</code> <p>The name of the column from which values will be subtracted.</p> <code>'log_returns'</code> <code>_detrend_value_col</code> <code>str | Series | None</code> <p>The name of the column whose values will be subtracted OR if you pass a pl.Series to the <code>data</code> parameter, then you can use this to pass a second <code>pl.Series</code> to subtract from the first.</p> <code>'window_mean'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the data by 'symbol' and 'date' before detrending. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, LazyFrame, Series]</code> <p>The detrended data structure with the same type as the input, with an added column named <code>f\"detrended_{_detrend_col}\"</code>.</p> Notes <p>Function doesn't use <code>.over()</code> in calculation. Once the data is sorted, subtracting _detrend_value_col from _detrend_col is a simple operation that doesn't need to be grouped, because the sorting has already aligned the rows for subtraction</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def detrend(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _detrend_col: str = \"log_returns\",\n    _detrend_value_col: str | pl.Series | None = \"window_mean\",\n    *,\n    _sort: bool = False,\n) -&gt; pl.DataFrame | pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: detrend**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    Detrends a column in a DataFrame, LazyFrame, or Series by subtracting the\n    values of another column from it. Optionally sorts the data by 'symbol' and\n    'date' before detrending if _sort is True.\n\n    Parameters\n    ----------\n    data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The data structure containing the columns to be processed.\n    _detrend_col : str\n        The name of the column from which values will be subtracted.\n    _detrend_value_col : str | pl.Series | None, optional\n        The name of the column whose values will be subtracted OR if you\n        pass a pl.Series to the `data` parameter, then you can use this to\n        pass a second `pl.Series` to subtract from the first.\n    _sort : bool, optional\n        If True, sorts the data by 'symbol' and 'date' before detrending.\n        Default is False.\n\n    Returns\n    -------\n    Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The detrended data structure with the same type as the input,\n        with an added column named `f\"detrended_{_detrend_col}\"`.\n\n    Notes\n    -----\n    Function doesn't use `.over()` in calculation. Once the data is sorted,\n    subtracting _detrend_value_col from _detrend_col is a simple operation\n    that doesn't need to be grouped, because the sorting has already aligned\n    the rows for subtraction\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        col_names = data.collect_schema().names()\n        if _detrend_value_col not in col_names or _detrend_col not in col_names:\n            msg = f\"Both {_detrend_value_col} and {_detrend_col} must be columns in the data.\"\n            raise HumblDataError(msg)\n        detrended = data.with_columns(\n            (pl.col(_detrend_col) - pl.col(_detrend_value_col)).alias(\n                f\"detrended_{_detrend_col}\"\n            )\n        )\n    elif isinstance(data, pl.Series):\n        if not isinstance(_detrend_value_col, pl.Series):\n            msg = \"When 'data' is a Series, '_detrend_value_col' must also be a Series.\"\n            raise HumblDataError(msg)\n        detrended = data - _detrend_value_col\n        detrended.rename(f\"detrended_{_detrend_col}\")\n\n    return detrended\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.cum_sum","title":"cum_sum","text":"<pre><code>cum_sum(data: DataFrame | LazyFrame | Series | None = None, _column_name: str = 'detrended_returns', *, _sort: bool = True, _mandelbrot_usage: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: cum_sum.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>Calculate the cumulative sum of a series or column in a DataFrame or LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame | Series | None</code> <p>The data to process.</p> <code>None</code> <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the cumulative sum on, applicable if df is provided.</p> <code>'detrended_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date and symbol before calculation. Default is True.</p> <code>True</code> <code>_mandelbrot_usage</code> <code>bool</code> <p>If True, performs additional checks specific to the Mandelbrot Channel calculation. This should be set to True when you have a cumulative deviate series, and False when not. Please check 'Notes' for more information. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The DataFrame or Series with the cumulative deviate series added as a new column or as itself.</p> Notes <p>This function is used to calculate the cumulative sum for the deviate series of detrended returns for the data in the pipeline for <code>calc_mandelbrot_channel</code>.</p> <p>So, although it is calculating a cumulative sum, it is known as a cumulative deviate because it is a cumulative sum on a deviate series, meaning that the cumulative sum should = 0 for each window. The _mandelbrot_usage parameter allows for checks to ensure the data is suitable for Mandelbrot Channel calculations, i.e that the deviate series was calculated correctly by the end of each series being 0, meaning the trend (the mean over the window_index) was successfully removed from the data.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def cum_sum(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series | None = None,\n    _column_name: str = \"detrended_returns\",\n    *,\n    _sort: bool = True,\n    _mandelbrot_usage: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: cum_sum**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    Calculate the cumulative sum of a series or column in a DataFrame or\n    LazyFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame | pl.Series | None\n        The data to process.\n    _column_name : str\n        The name of the column to calculate the cumulative sum on,\n        applicable if df is provided.\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by date and symbol before\n        calculation. Default is True.\n    _mandelbrot_usage : bool, optional\n        If True, performs additional checks specific to the Mandelbrot Channel\n        calculation. This should be set to True when you have a cumulative\n        deviate series, and False when not. Please check 'Notes' for more\n        information. Default is True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The DataFrame or Series with the cumulative deviate series added as a\n        new column or as itself.\n\n    Notes\n    -----\n    This function is used to calculate the cumulative sum for the deviate series\n    of detrended returns for the data in the pipeline for\n    `calc_mandelbrot_channel`.\n\n    So, although it is calculating a cumulative sum, it is known as a cumulative\n    deviate because it is a cumulative sum on a deviate series, meaning that the\n    cumulative sum should = 0 for each window. The _mandelbrot_usage parameter\n    allows for checks to ensure the data is suitable for Mandelbrot Channel\n    calculations, i.e that the deviate series was calculated correctly by the\n    end of each series being 0, meaning the trend (the mean over the\n    window_index) was successfully removed from the data.\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if over_cols:\n            out = data.with_columns(\n                pl.col(_column_name).cum_sum().over(over_cols).alias(\"cum_sum\")\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).cum_sum().alias(\"cum_sum\")\n            )\n    elif isinstance(data, pl.Series):\n        out = data.cum_sum().alias(\"cum_sum\")\n    else:\n        msg = \"No DataFrame/LazyFrame/Series was provided.\"\n        raise HumblDataError(msg)\n\n    if _mandelbrot_usage:\n        _cumsum_check(out, _column_name=\"cum_sum\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.std","title":"std","text":"<pre><code>std(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum', *, _sort: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: std.</p> <p>Calculate the standard deviation of the cumulative deviate series within each window of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>LazyFrame</code> <p>The LazyFrame from which to calculate the standard deviation.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column from which to calculate the standard deviation, with \"cumdev\" as the default value.</p> <code>'cum_sum'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date and symbol before calculation. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame with the standard deviation of the specified column for each window, added as a new column named \"S\".</p> Improvements <p>Just need to parametrize <code>.over()</code> call in the function if want an even dumber function, that doesn't calculate each <code>window_index</code>.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def std(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series,\n    _column_name: str = \"cum_sum\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: std**.\n\n    Calculate the standard deviation of the cumulative deviate series within\n    each window of the dataset.\n\n    Parameters\n    ----------\n    df : pl.LazyFrame\n        The LazyFrame from which to calculate the standard deviation.\n    _column_name : str, optional\n        The name of the column from which to calculate the standard deviation,\n        with \"cumdev\" as the default value.\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by date and symbol before\n        calculation. Default is True.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame with the standard deviation of the specified column for each\n        window, added as a new column named \"S\".\n\n    Improvements\n    -----------\n    Just need to parametrize `.over()` call in the function if want an even\n    dumber function, that doesn't calculate each `window_index`.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.std()\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n\n        if over_cols:\n            out = data.with_columns(\n                [\n                    pl.col(_column_name)\n                    .std()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_std\"),  # used to be 'S'\n                ]\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).std().alias(\"S\"),\n            )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.mean","title":"mean","text":"<pre><code>mean(data: DataFrame | LazyFrame | Series, _column_name: str = 'log_returns', *, _sort: bool = True) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Function: mean.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>This function calculates the mean of a column (&lt;_column_name&gt;) over a each window in the dataset, if there are any. This window is intended to be the <code>window</code> that is passed in the <code>calc_mandelbrot_channel()</code> function. The mean calculated is meant to be used as the mean of each <code>window</code> within the time series. This way, each block of windows has their own mean, which can then be used to normalize the data (i.e remove the mean) from each window section.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The DataFrame or LazyFrame to calculate the mean on.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the mean on.</p> <code>'log_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date before calculation. Default is False.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The original DataFrame or LazyFrame with a <code>window_mean</code> &amp; <code>date</code> column, which contains the mean of 'log_returns' per range/window.</p> Notes <p>Since this function is an aggregation function, it reduces the # of observations in the dataset,thus, unless I take each value and iterate each window_mean value to correlate to the row in the original dataframe, the function will return a dataframe WITHOUT the original data.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def mean(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _column_name: str = \"log_returns\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Function: mean**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    This function calculates the mean of a column (&lt;_column_name&gt;) over a\n    each window in the dataset, if there are any.\n    This window is intended to be the `window` that is passed in the\n    `calc_mandelbrot_channel()` function. The mean calculated is meant to be\n    used as the mean of each `window` within the time series. This\n    way, each block of windows has their own mean, which can then be used to\n    normalize the data (i.e remove the mean) from each window section.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The DataFrame or LazyFrame to calculate the mean on.\n    _column_name : str\n        The name of the column to calculate the mean on.\n    _sort : bool\n        If True, sorts the DataFrame or LazyFrame by date before calculation.\n        Default is False.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The original DataFrame or LazyFrame with a `window_mean` &amp; `date` column,\n        which contains the mean of 'log_returns' per range/window.\n\n\n    Notes\n    -----\n    Since this function is an aggregation function, it reduces the # of\n    observations in the dataset,thus, unless I take each value and iterate each\n    window_mean value to correlate to the row in the original dataframe, the\n    function will return a dataframe WITHOUT the original data.\n\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.mean()\n    else:\n        if data is None:\n            msg = \"No DataFrame was passed to the `mean()` function.\"\n            raise HumblDataError(msg)\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:  # Check if _sort is True\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        if over_cols:\n            out = data.with_columns(\n                pl.col(_column_name).mean().over(over_cols).alias(\"window_mean\")\n            )\n        else:\n            out = data.with_columns(pl.col(_column_name).mean().alias(\"mean\"))\n        if _sort and sort_cols:\n            out = out.sort(sort_cols)\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.range_","title":"range_","text":"<pre><code>range_(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum', *, _sort: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || Function: mandelbrot_range.</p> <p>Calculate the range (max - min) of the cumulative deviate values of a specified column in a DataFrame for each window in the dataset, if there are any.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The DataFrame to calculate the range from.</p> required <code>_column_name</code> <code>str</code> <p>The column to calculate the range from, by default \"cumdev\".</p> <code>'cum_sum'</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>A DataFrame with the range of the specified column for each window.</p> Source code in <code>src/humbldata/toolbox/toolbox_helpers.py</code> <pre><code>def range_(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series,\n    _column_name: str = \"cum_sum\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || **Function: mandelbrot_range**.\n\n    Calculate the range (max - min) of the cumulative deviate values of a\n    specified column in a DataFrame for each window in the dataset, if there are any.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The DataFrame to calculate the range from.\n    _column_name : str, optional\n        The column to calculate the range from, by default \"cumdev\".\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        A DataFrame with the range of the specified column for each window.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.max() - data.min()\n\n    if isinstance(data, pl.LazyFrame | pl.DataFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        if over_cols:\n            out = (\n                data.with_columns(\n                    [\n                        pl.col(_column_name)\n                        .min()\n                        .over(over_cols)\n                        .alias(f\"{_column_name}_min\"),\n                        pl.col(_column_name)\n                        .max()\n                        .over(over_cols)\n                        .alias(f\"{_column_name}_max\"),\n                    ]\n                )\n                .sort(sort_cols)\n                .with_columns(\n                    (\n                        pl.col(f\"{_column_name}_max\")\n                        - pl.col(f\"{_column_name}_min\")\n                    ).alias(f\"{_column_name}_range\"),  # used to be 'R'\n                )\n            )\n    else:\n        out = (\n            data.with_columns(\n                [\n                    pl.col(_column_name).min().alias(f\"{_column_name}_min\"),\n                    pl.col(_column_name).max().alias(f\"{_column_name}_max\"),\n                ]\n            )\n            .sort(sort_cols)\n            .with_columns(\n                (\n                    pl.col(f\"{_column_name}_max\")\n                    - pl.col(f\"{_column_name}_min\")\n                ).alias(f\"{_column_name}_range\"),\n            )\n        )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller","title":"toolbox_controller","text":"<p>Context: Toolbox.</p> <p>The Toolbox Controller Module.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox","title":"Toolbox","text":"<p>             Bases: <code>ToolboxQueryParams</code></p> <p>A top-level  controller for data analysis tools in <code>humblDATA</code>. <p>This module serves as the primary controller, routing user-specified ToolboxQueryParams as core arguments that are used to fetch time series data.</p> <p>The <code>Toolbox</code> controller also gives access to all sub-modules adn their functions.</p> <p>It is designed to facilitate the collection of data across various types such as stocks, options, or alternative time series by requiring minimal input from the user.</p> Submodules <p>The <code>Toolbox</code> controller is composed of the following submodules:</p> <ul> <li><code>technical</code>:</li> <li><code>quantitative</code>:</li> <li><code>fundamental</code>:</li> </ul> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol or ticker of the stock.</p> required <code>interval</code> <code>str</code> <p>The interval of the data. Defaults to '1d'.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> required <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> required <code>provider</code> <code>str</code> <p>The provider to use for the data query. Defaults to 'yfinance'.</p> required Parameter Notes <p>The parameters (<code>symbol</code>, <code>interval</code>, <code>start_date</code>, <code>end_date</code>) are the <code>ToolboxQueryParams</code>. They are used for data collection further down the pipeline in other commands. Intended to execute operations on core data sets. This approach enables composable and standardized querying while accommodating data-specific collection logic.</p> Source code in <code>src/humbldata/toolbox/toolbox_controller.py</code> <pre><code>class Toolbox(ToolboxQueryParams):\n    \"\"\"\n\n    A top-level &lt;context&gt; controller for data analysis tools in `humblDATA`.\n\n    This module serves as the primary controller, routing user-specified\n    ToolboxQueryParams as core arguments that are used to fetch time series\n    data.\n\n    The `Toolbox` controller also gives access to all sub-modules adn their\n    functions.\n\n    It is designed to facilitate the collection of data across various types such as\n    stocks, options, or alternative time series by requiring minimal input from the user.\n\n    Submodules\n    ----------\n    The `Toolbox` controller is composed of the following submodules:\n\n    - `technical`:\n    - `quantitative`:\n    - `fundamental`:\n\n    Parameters\n    ----------\n    symbol : str\n        The symbol or ticker of the stock.\n    interval : str, optional\n        The interval of the data. Defaults to '1d'.\n    start_date : str\n        The start date for the data query.\n    end_date : str\n        The end date for the data query.\n    provider : str, optional\n        The provider to use for the data query. Defaults to 'yfinance'.\n\n    Parameter Notes\n    -----\n    The parameters (`symbol`, `interval`, `start_date`, `end_date`)\n    are the `ToolboxQueryParams`. They are used for data collection further\n    down the pipeline in other commands. Intended to execute operations on core\n    data sets. This approach enables composable and standardized querying while\n    accommodating data-specific collection logic.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initialize the Toolbox module.\n\n        This method does not take any parameters and does not return anything.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @property\n    def technical(self):\n        \"\"\"\n        The technical submodule of the Toolbox controller.\n\n        Access to all the technical indicators. WHen the Toolbox class is\n        instatiated the parameters are initialized with the ToolboxQueryParams\n        class, which hold all the fields needed for the context_params, like the\n        symbol, interval, start_date, and end_date.\n        \"\"\"\n        return Technical(context_params=self)\n\n    @property\n    def fundamental(self):\n        \"\"\"\n        The fundamental submodule of the Toolbox controller.\n\n        Access to all the Fundamental indicators. When the Toolbox class is\n        instantiated the parameters are initialized with the ToolboxQueryParams\n        class, which hold all the fields needed for the context_params, like the\n        symbol, interval, start_date, and end_date.\n        \"\"\"\n        return Fundamental(context_params=self)\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox.__init__","title":"__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Initialize the Toolbox module.</p> <p>This method does not take any parameters and does not return anything.</p> Source code in <code>src/humbldata/toolbox/toolbox_controller.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initialize the Toolbox module.\n\n    This method does not take any parameters and does not return anything.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox.technical","title":"technical  <code>property</code>","text":"<pre><code>technical\n</code></pre> <p>The technical submodule of the Toolbox controller.</p> <p>Access to all the technical indicators. WHen the Toolbox class is instatiated the parameters are initialized with the ToolboxQueryParams class, which hold all the fields needed for the context_params, like the symbol, interval, start_date, and end_date.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox.fundamental","title":"fundamental  <code>property</code>","text":"<pre><code>fundamental\n</code></pre> <p>The fundamental submodule of the Toolbox controller.</p> <p>Access to all the Fundamental indicators. When the Toolbox class is instantiated the parameters are initialized with the ToolboxQueryParams class, which hold all the fields needed for the context_params, like the symbol, interval, start_date, and end_date.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental","title":"fundamental","text":"<p>Context: Toolbox || Category: Fundamental.</p> <p>A category to group all of the fundamental indicators available in the <code>Toolbox()</code>.</p> <p>Fundamental indicators relies on earnings data, valuation models of companies, balance sheet metrics etc...</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.fundamental_controller","title":"fundamental_controller","text":"<p>Context: Toolbox || Category: Fundamental.</p> <p>A controller to manage and compile all of the Fundamental models available in the <code>toolbox</code> context. This will be passed as a <code>@property</code> to the <code>toolbox()</code> class, giving access to the Fundamental module and its functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.fundamental_controller.Fundamental","title":"Fundamental","text":"<p>Module for all Fundamental analysis.</p> <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>The standard query parameters for toolbox data.</p> <p>Methods:</p> Name Description <code>humbl_compass</code> <p>Execute the HumblCompass command.</p> Source code in <code>src/humbldata/toolbox/fundamental/fundamental_controller.py</code> <pre><code>class Fundamental:\n    \"\"\"\n    Module for all Fundamental analysis.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        The standard query parameters for toolbox data.\n\n    Methods\n    -------\n    humbl_compass(command_params: HumblCompassQueryParams)\n        Execute the HumblCompass command.\n\n    \"\"\"\n\n    def __init__(self, context_params: ToolboxQueryParams):\n        self.context_params = context_params\n\n    def humbl_compass(self, **kwargs):\n        \"\"\"\n        Execute the HumblCompass command.\n\n        Parameters\n        ----------\n        country : str\n            The country or group of countries to analyze\n        recommendations : bool, optional\n            Whether to include investment recommendations based on the HUMBL regime\n        chart : bool, optional\n            Whether to return a chart object\n        template : str, optional\n            The template/theme to use for the plotly figure\n        z_score : str, optional\n            The time window for z-score calculation\n\n        Returns\n        -------\n        HumblObject\n            The HumblObject containing the transformed data and metadata\n        \"\"\"\n        from humbldata.core.standard_models.toolbox.fundamental.humbl_compass import (\n            HumblCompassFetcher,\n            HumblCompassQueryParams,\n        )\n\n        # Convert kwargs to HumblCompassQueryParams\n        command_params = HumblCompassQueryParams(**kwargs)\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = HumblCompassFetcher(\n            context_params=self.context_params, command_params=command_params\n        )\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.fundamental_controller.Fundamental.humbl_compass","title":"humbl_compass","text":"<pre><code>humbl_compass(**kwargs)\n</code></pre> <p>Execute the HumblCompass command.</p> <p>Parameters:</p> Name Type Description Default <code>country</code> <code>str</code> <p>The country or group of countries to analyze</p> required <code>recommendations</code> <code>bool</code> <p>Whether to include investment recommendations based on the HUMBL regime</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object</p> required <code>template</code> <code>str</code> <p>The template/theme to use for the plotly figure</p> required <code>z_score</code> <code>str</code> <p>The time window for z-score calculation</p> required <p>Returns:</p> Type Description <code>HumblObject</code> <p>The HumblObject containing the transformed data and metadata</p> Source code in <code>src/humbldata/toolbox/fundamental/fundamental_controller.py</code> <pre><code>def humbl_compass(self, **kwargs):\n    \"\"\"\n    Execute the HumblCompass command.\n\n    Parameters\n    ----------\n    country : str\n        The country or group of countries to analyze\n    recommendations : bool, optional\n        Whether to include investment recommendations based on the HUMBL regime\n    chart : bool, optional\n        Whether to return a chart object\n    template : str, optional\n        The template/theme to use for the plotly figure\n    z_score : str, optional\n        The time window for z-score calculation\n\n    Returns\n    -------\n    HumblObject\n        The HumblObject containing the transformed data and metadata\n    \"\"\"\n    from humbldata.core.standard_models.toolbox.fundamental.humbl_compass import (\n        HumblCompassFetcher,\n        HumblCompassQueryParams,\n    )\n\n    # Convert kwargs to HumblCompassQueryParams\n    command_params = HumblCompassQueryParams(**kwargs)\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = HumblCompassFetcher(\n        context_params=self.context_params, command_params=command_params\n    )\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass","title":"humbl_compass","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass.helpers","title":"helpers","text":"<p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>The HumblCompass Helpers Module.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass.model","title":"model","text":"<p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>The humbl_compass Command Module. This is typically used in the <code>.transform_data()</code> method of the <code>HumblCompassFetcher</code> class.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass.model.humbl_compass","title":"humbl_compass","text":"<pre><code>humbl_compass()\n</code></pre> <p>Context: Toolbox || Category: Fundamental ||| Command: humbl_compass.</p> <p>Execute the humbl_compass command.</p> <p>Parameters:</p> Name Type Description Default <code>Returns</code> required Source code in <code>src/humbldata/toolbox/fundamental/humbl_compass/model.py</code> <pre><code>def humbl_compass():\n    \"\"\"\n    Context: Toolbox || Category: Fundamental ||| **Command: humbl_compass**.\n\n    Execute the humbl_compass command.\n\n    Parameters\n    ----------\n\n    Returns\n    -------\n    \"\"\"\n    pass\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass.view","title":"view","text":"<p>Context: Toolbox || Category: Fundamental || Command: humbl_compass.</p> <p>The HumblCompass View Module.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass.view.create_humbl_compass_plot","title":"create_humbl_compass_plot","text":"<pre><code>create_humbl_compass_plot(data: DataFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate a HumblCompass plot from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing the data to be plotted.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the HumblCompass plot.</p> Source code in <code>src/humbldata/toolbox/fundamental/humbl_compass/view.py</code> <pre><code>def create_humbl_compass_plot(\n    data: pl.DataFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate a HumblCompass plot from the provided data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing the data to be plotted.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the HumblCompass plot.\n    \"\"\"\n    # Sort data by date and create a color scale\n    data = data.sort(\"date_month_start\")\n    full_color_scale = sequential.Reds\n    custom_colorscale = sample_colorscale(full_color_scale, [0.2, 0.8])\n\n    fig = go.Figure()\n\n    # Calculate the range for x and y axes based on data\n    x_min, x_max = data[\"cpi_3m_delta\"].min(), data[\"cpi_3m_delta\"].max()\n    y_min, y_max = data[\"cli_3m_delta\"].min(), data[\"cli_3m_delta\"].max()\n\n    # Ensure minimum range of -0.3 to 0.3 on both axes\n    x_min = min(x_min if x_min is not None else 0, -0.3)\n    x_max = max(x_max if x_max is not None else 0, 0.3)\n    y_min = min(y_min if y_min is not None else 0, -0.3)\n    y_max = max(y_max if y_max is not None else 0, 0.3)\n\n    # Add some padding to the ranges (e.g., 10% on each side)\n    x_padding = max((x_max - x_min) * 0.1, 0.05)  # Ensure minimum padding\n    y_padding = max((y_max - y_min) * 0.1, 0.05)  # Ensure minimum padding\n\n    # Calculate tick values (e.g., every 0.1)\n    x_ticks = [\n        round(i * 0.1, 1)\n        for i in range(int(x_min * 10) - 1, int(x_max * 10) + 2)\n    ]\n    y_ticks = [\n        round(i * 0.1, 1)\n        for i in range(int(y_min * 10) - 1, int(y_max * 10) + 2)\n    ]\n\n    # Add colored quadrants from -10 to 10\n    quadrants = [\n        {\n            \"x\": [0, 10],\n            \"y\": [0, 10],\n            \"fillcolor\": \"rgba(173, 216, 230, 0.3)\",\n        },  # Light blue\n        {\n            \"x\": [-10, 0],\n            \"y\": [0, 10],\n            \"fillcolor\": \"rgba(144, 238, 144, 0.3)\",\n        },  # Green\n        {\n            \"x\": [0, 10],\n            \"y\": [-10, 0],\n            \"fillcolor\": \"rgba(255, 165, 0, 0.3)\",\n        },  # Orange\n        {\n            \"x\": [-10, 0],\n            \"y\": [-10, 0],\n            \"fillcolor\": \"rgba(255, 99, 71, 0.3)\",\n        },  # Red\n    ]\n\n    for quadrant in quadrants:\n        fig.add_shape(\n            type=\"rect\",\n            x0=quadrant[\"x\"][0],\n            y0=quadrant[\"y\"][0],\n            x1=quadrant[\"x\"][1],\n            y1=quadrant[\"y\"][1],\n            fillcolor=quadrant[\"fillcolor\"],\n            line_color=\"rgba(0,0,0,0)\",\n            layer=\"below\",\n        )\n\n    # Create a color array based on the date order\n    color_array = list(range(len(data)))\n\n    fig.add_trace(\n        go.Scatter(\n            x=data[\"cpi_3m_delta\"],\n            y=data[\"cli_3m_delta\"],\n            mode=\"lines+markers+text\",\n            name=\"HumblCompass Data\",\n            text=[\n                d.strftime(\"%b %Y\") if isinstance(d, datetime.date) else \"\"\n                for d in data[\"date_month_start\"]\n            ],\n            textposition=\"top center\",\n            textfont={\"size\": 10, \"color\": \"white\"},\n            marker={\n                \"size\": 10,\n                \"color\": color_array,\n                \"colorscale\": custom_colorscale,\n                \"showscale\": False,\n            },\n            line={\n                \"color\": \"white\",\n                \"shape\": \"spline\",\n                \"smoothing\": 1.3,\n            },\n            hovertemplate=\"&lt;b&gt;%{text}&lt;/b&gt;&lt;br&gt;CPI 3m \u0394: %{x:.2f}&lt;br&gt;CLI 3m \u0394: %{y:.2f}&lt;extra&gt;&lt;/extra&gt;\",\n        )\n    )\n\n    # Add axis lines with tick marks\n    fig.add_shape(\n        type=\"line\",\n        x0=x_min - x_padding,\n        y0=0,\n        x1=x_max + x_padding,\n        y1=0,\n        line=dict(color=\"white\", width=1),\n    )\n    fig.add_shape(\n        type=\"line\",\n        x0=0,\n        y0=y_min - y_padding,\n        x1=0,\n        y1=y_max + y_padding,\n        line=dict(color=\"white\", width=1),\n    )\n\n    # Add tick marks and labels to the x-axis\n    for x in x_ticks:\n        if x != 0:  # Skip the center point\n            fig.add_shape(\n                type=\"line\",\n                x0=x,\n                y0=-0.005,\n                x1=x,\n                y1=0.005,\n                line=dict(color=\"white\", width=1),\n            )\n            fig.add_annotation(\n                x=x,\n                y=0,\n                text=f\"{x:.1f}\",\n                showarrow=False,\n                yshift=-15,\n                font=dict(size=8, color=\"white\"),\n            )\n\n    # Add tick marks and labels to the y-axis\n    for y in y_ticks:\n        if y != 0:  # Skip the center point\n            fig.add_shape(\n                type=\"line\",\n                x0=-0.005,\n                y0=y,\n                x1=0.005,\n                y1=y,\n                line=dict(color=\"white\", width=1),\n            )\n            fig.add_annotation(\n                x=0,\n                y=y,\n                text=f\"{y:.1f}\",\n                showarrow=False,\n                xshift=-15,\n                font=dict(size=8, color=\"white\"),\n            )\n\n    # Calculate the center of each visible quadrant\n    x_center_pos = (x_max + x_padding + 0) / 2\n    x_center_neg = (x_min - x_padding + 0) / 2\n    y_center_pos = (y_max + y_padding + 0) / 2\n    y_center_neg = (y_min - y_padding + 0) / 2\n\n    # Add quadrant labels\n    quadrant_labels = [\n        {\n            \"text\": \"humblBOOM\",\n            \"x\": x_center_neg,\n            \"y\": y_center_pos,\n            \"color\": \"rgba(144, 238, 144, 0.5)\",  # Changed opacity to 0.5\n        },\n        {\n            \"text\": \"humblBOUNCE\",\n            \"x\": x_center_pos,\n            \"y\": y_center_pos,\n            \"color\": \"rgba(173, 216, 230, 0.5)\",  # Changed opacity to 0.5\n        },\n        {\n            \"text\": \"humblBLOAT\",\n            \"x\": x_center_pos,\n            \"y\": y_center_neg,\n            \"color\": \"rgba(255, 165, 0, 0.5)\",  # Changed opacity to 0.5\n        },\n        {\n            \"text\": \"humblBUST\",\n            \"x\": x_center_neg,\n            \"y\": y_center_neg,\n            \"color\": \"rgba(255, 99, 71, 0.5)\",  # Changed opacity to 0.5\n        },\n    ]\n\n    for label in quadrant_labels:\n        fig.add_annotation(\n            x=label[\"x\"],\n            y=label[\"y\"],\n            text=label[\"text\"],\n            showarrow=False,\n            font={\"size\": 20, \"color\": label[\"color\"]},\n            opacity=0.5,  # Changed opacity to 0.5\n        )\n\n    # Add custom watermark\n    fig.add_annotation(\n        x=0,\n        y=0,\n        text=\"humblDATA\",\n        showarrow=False,\n        font={\"size\": 40, \"color\": \"rgba(255, 255, 255, 0.1)\"},\n        textangle=-25,\n        xanchor=\"center\",\n        yanchor=\"middle\",\n        xref=\"x\",\n        yref=\"y\",\n    )\n\n    # Create a copy of the template without the watermark\n    custom_template = pio.templates[template.value].to_plotly_json()\n    if (\n        \"layout\" in custom_template\n        and \"annotations\" in custom_template[\"layout\"]\n    ):\n        custom_template[\"layout\"][\"annotations\"] = [\n            ann\n            for ann in custom_template[\"layout\"][\"annotations\"]\n            if ann.get(\"name\") != \"draft watermark\"\n        ]\n\n    # Update layout\n    fig.update_layout(\n        title=\"humblCOMPASS: CLI 3m Delta vs CPI 3m Delta\",\n        title_font_color=\"white\",\n        xaxis_title=\"Inflation (CPI) 3-Month Delta\",\n        yaxis_title=\"Growth (CLI) 3-Month Delta\",\n        xaxis={\n            \"color\": \"white\",\n            \"showgrid\": False,\n            \"zeroline\": False,\n            \"range\": [x_min - x_padding, x_max + x_padding],\n            \"showticklabels\": False,  # Hide default tick labels\n            \"ticks\": \"\",  # Hide default ticks\n        },\n        yaxis={\n            \"color\": \"white\",\n            \"showgrid\": False,\n            \"zeroline\": False,\n            \"range\": [y_min - y_padding, y_max + y_padding],\n            \"showticklabels\": False,  # Hide default tick labels\n            \"ticks\": \"\",  # Hide default ticks\n        },\n        template=custom_template,  # Use the custom template without watermark\n        hovermode=\"closest\",\n        plot_bgcolor=\"rgba(0,0,0,0)\",\n        paper_bgcolor=\"rgba(0,0,0,0)\",\n        font={\"color\": \"white\"},\n        margin={\"l\": 50, \"r\": 50, \"t\": 50, \"b\": 50},\n    )\n\n    return fig\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental.humbl_compass.view.generate_plots","title":"generate_plots","text":"<pre><code>generate_plots(data: LazyFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; List[Chart]\n</code></pre> <p>Context: Toolbox || Category: Fundamental || Command: humbl_compass || Function: generate_plots().</p> <p>Generate plots from the given dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The LazyFrame containing the data to be plotted.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>List[Chart]</code> <p>A list of Chart objects, each representing a plot.</p> Source code in <code>src/humbldata/toolbox/fundamental/humbl_compass/view.py</code> <pre><code>def generate_plots(\n    data: pl.LazyFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; List[Chart]:\n    \"\"\"\n    Context: Toolbox || Category: Fundamental || Command: humbl_compass || **Function: generate_plots()**.\n\n    Generate plots from the given dataframe.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The LazyFrame containing the data to be plotted.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure.\n\n    Returns\n    -------\n    List[Chart]\n        A list of Chart objects, each representing a plot.\n    \"\"\"\n    collected_data = data.collect()\n    plot = create_humbl_compass_plot(collected_data, template)\n    return [Chart(content=plot.to_json(), fig=plot)]\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical","title":"technical","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.technical_controller","title":"technical_controller","text":"<p>Context: Toolbox || Category: Technical.</p> <p>A controller to manage and compile all of the technical indicator models available. This will be passed as a <code>@property</code> to the <code>Toolbox()</code> class, giving access to the technical module and its functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.technical_controller.Technical","title":"Technical","text":"<p>Module for all technical analysis.</p> <p>Attributes:</p> Name Type Description <code>context_params</code> <code>ToolboxQueryParams</code> <p>The standard query parameters for toolbox data.</p> <p>Methods:</p> Name Description <code>mandelbrot_channel</code> <p>Calculate the rescaled range statistics.</p> Source code in <code>src/humbldata/toolbox/technical/technical_controller.py</code> <pre><code>class Technical:\n    \"\"\"\n    Module for all technical analysis.\n\n    Attributes\n    ----------\n    context_params : ToolboxQueryParams\n        The standard query parameters for toolbox data.\n\n    Methods\n    -------\n    mandelbrot_channel(command_params: MandelbrotChannelQueryParams)\n        Calculate the rescaled range statistics.\n\n    \"\"\"\n\n    def __init__(self, context_params: ToolboxQueryParams):\n        self.context_params = context_params\n\n    def mandelbrot_channel(self, **kwargs: MandelbrotChannelQueryParams):\n        \"\"\"\n        Calculate the Mandelbrot Channel.\n\n        Parameters\n        ----------\n        window : str, optional\n            The width of the window used for splitting the data into sections for\n            detrending. Defaults to \"1mo\".\n        rv_adjustment : bool, optional\n            Whether to adjust the calculation for realized volatility. If True, the\n            data is filtered to only include observations in the same volatility bucket\n            that the stock is currently in. Defaults to True.\n        rv_method : str, optional\n            The method to calculate the realized volatility. Only need to define\n            when rv_adjustment is True. Defaults to \"std\".\n        rs_method : Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"], optional\n            The method to use for Range/STD calculation. This is either min, max\n            or mean of all RS ranges per window. If not defined, just used the\n            most recent RS window. Defaults to \"RS\".\n        rv_grouped_mean : bool, optional\n            Whether to calculate the mean value of realized volatility over\n            multiple window lengths. Defaults to False.\n        live_price : bool, optional\n            Whether to calculate the ranges using the current live price, or the\n            most recent 'close' observation. Defaults to False.\n        historical : bool, optional\n            Whether to calculate the Historical Mandelbrot Channel (over-time), and\n            return a time-series of channels from the start to the end date. If\n            False, the Mandelbrot Channel calculation is done aggregating all of the\n            data into one observation. If True, then it will enable daily\n            observations over-time. Defaults to False.\n        chart : bool, optional\n            Whether to return a chart object. Defaults to False.\n        template : str, optional\n            The template/theme to use for the plotly figure. Defaults to \"humbl_dark\".\n\n        Returns\n        -------\n        HumblObject\n            An object containing the Mandelbrot Channel data and metadata.\n        \"\"\"\n        from humbldata.core.standard_models.toolbox.technical.mandelbrot_channel import (\n            MandelbrotChannelFetcher,\n        )\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = MandelbrotChannelFetcher(\n            context_params=self.context_params, command_params=kwargs\n        )\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.technical_controller.Technical.mandelbrot_channel","title":"mandelbrot_channel","text":"<pre><code>mandelbrot_channel(**kwargs: MandelbrotChannelQueryParams)\n</code></pre> <p>Calculate the Mandelbrot Channel.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>str</code> <p>The width of the window used for splitting the data into sections for detrending. Defaults to \"1mo\".</p> required <code>rv_adjustment</code> <code>bool</code> <p>Whether to adjust the calculation for realized volatility. If True, the data is filtered to only include observations in the same volatility bucket that the stock is currently in. Defaults to True.</p> required <code>rv_method</code> <code>str</code> <p>The method to calculate the realized volatility. Only need to define when rv_adjustment is True. Defaults to \"std\".</p> required <code>rs_method</code> <code>Literal[RS, RS_min, RS_max, RS_mean]</code> <p>The method to use for Range/STD calculation. This is either min, max or mean of all RS ranges per window. If not defined, just used the most recent RS window. Defaults to \"RS\".</p> required <code>rv_grouped_mean</code> <code>bool</code> <p>Whether to calculate the mean value of realized volatility over multiple window lengths. Defaults to False.</p> required <code>live_price</code> <code>bool</code> <p>Whether to calculate the ranges using the current live price, or the most recent 'close' observation. Defaults to False.</p> required <code>historical</code> <code>bool</code> <p>Whether to calculate the Historical Mandelbrot Channel (over-time), and return a time-series of channels from the start to the end date. If False, the Mandelbrot Channel calculation is done aggregating all of the data into one observation. If True, then it will enable daily observations over-time. Defaults to False.</p> required <code>chart</code> <code>bool</code> <p>Whether to return a chart object. Defaults to False.</p> required <code>template</code> <code>str</code> <p>The template/theme to use for the plotly figure. Defaults to \"humbl_dark\".</p> required <p>Returns:</p> Type Description <code>HumblObject</code> <p>An object containing the Mandelbrot Channel data and metadata.</p> Source code in <code>src/humbldata/toolbox/technical/technical_controller.py</code> <pre><code>def mandelbrot_channel(self, **kwargs: MandelbrotChannelQueryParams):\n    \"\"\"\n    Calculate the Mandelbrot Channel.\n\n    Parameters\n    ----------\n    window : str, optional\n        The width of the window used for splitting the data into sections for\n        detrending. Defaults to \"1mo\".\n    rv_adjustment : bool, optional\n        Whether to adjust the calculation for realized volatility. If True, the\n        data is filtered to only include observations in the same volatility bucket\n        that the stock is currently in. Defaults to True.\n    rv_method : str, optional\n        The method to calculate the realized volatility. Only need to define\n        when rv_adjustment is True. Defaults to \"std\".\n    rs_method : Literal[\"RS\", \"RS_min\", \"RS_max\", \"RS_mean\"], optional\n        The method to use for Range/STD calculation. This is either min, max\n        or mean of all RS ranges per window. If not defined, just used the\n        most recent RS window. Defaults to \"RS\".\n    rv_grouped_mean : bool, optional\n        Whether to calculate the mean value of realized volatility over\n        multiple window lengths. Defaults to False.\n    live_price : bool, optional\n        Whether to calculate the ranges using the current live price, or the\n        most recent 'close' observation. Defaults to False.\n    historical : bool, optional\n        Whether to calculate the Historical Mandelbrot Channel (over-time), and\n        return a time-series of channels from the start to the end date. If\n        False, the Mandelbrot Channel calculation is done aggregating all of the\n        data into one observation. If True, then it will enable daily\n        observations over-time. Defaults to False.\n    chart : bool, optional\n        Whether to return a chart object. Defaults to False.\n    template : str, optional\n        The template/theme to use for the plotly figure. Defaults to \"humbl_dark\".\n\n    Returns\n    -------\n    HumblObject\n        An object containing the Mandelbrot Channel data and metadata.\n    \"\"\"\n    from humbldata.core.standard_models.toolbox.technical.mandelbrot_channel import (\n        MandelbrotChannelFetcher,\n    )\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = MandelbrotChannelFetcher(\n        context_params=self.context_params, command_params=kwargs\n    )\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel","title":"mandelbrot_channel","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers","title":"helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.add_window_index","title":"add_window_index","text":"<pre><code>add_window_index(data: LazyFrame | DataFrame, window: str) -&gt; LazyFrame | DataFrame\n</code></pre> <pre><code>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n</code></pre> <p>Add a column to the dataframe indicating the window grouping for each row in a time series.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input data frame or lazy frame to which the window index will be added.</p> required <code>window</code> <code>str</code> <p>The window size as a string, used to determine the grouping of rows into windows.</p> required <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The original data frame or lazy frame with an additional column named \"window_index\" indicating the window grouping for each row.</p> Notes <ul> <li>This function is essential for calculating the Mandelbrot Channel, where the dataset is split into numerous 'windows', and statistics are calculated for each window.</li> <li>The function adds a dummy <code>symbol</code> column if the data contains only one symbol, to avoid errors in the <code>group_by_dynamic()</code> function.</li> <li>It is utilized within the <code>log_mean()</code> and <code>calc_mandelbrot_channel()</code> functions for window-based calculations.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n&gt;&gt;&gt; window = \"1d\"\n&gt;&gt;&gt; add_window_index(data, window)\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n\u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n\u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def add_window_index(\n    data: pl.LazyFrame | pl.DataFrame, window: str\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n        Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n\n    Add a column to the dataframe indicating the window grouping for each row in\n    a time series.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input data frame or lazy frame to which the window index will be\n        added.\n    window : str\n        The window size as a string, used to determine the grouping of rows into\n        windows.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The original data frame or lazy frame with an additional column named\n        \"window_index\" indicating\n        the window grouping for each row.\n\n    Notes\n    -----\n    - This function is essential for calculating the Mandelbrot Channel, where\n    the dataset is split into\n    numerous 'windows', and statistics are calculated for each window.\n    - The function adds a dummy `symbol` column if the data contains only one\n    symbol, to avoid errors in the `group_by_dynamic()` function.\n    - It is utilized within the `log_mean()` and `calc_mandelbrot_channel()`\n    functions for window-based calculations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n    &gt;&gt;&gt; window = \"1d\"\n    &gt;&gt;&gt; add_window_index(data, window)\n    shape: (2, 4)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n    \u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n    \u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n\n    def _create_monthly_window_index(col: str, k: int = 1):\n        year_diff = pl.col(col).last().dt.year() - pl.col(col).dt.year()\n        month_diff = pl.col(col).last().dt.month() - pl.col(col).dt.month()\n        day_indicator = pl.col(col).dt.day() &gt; pl.col(col).last().dt.day()\n        return (12 * year_diff + month_diff - day_indicator) // k\n\n    # Clean the window into standardized strings (i.e \"1month\"/\"1 month\" = \"1mo\")\n    window = _window_format(window, _return_timedelta=False)  # returns `str`\n\n    if \"w\" in window or \"d\" in window:\n        msg = \"The window cannot include 'd' or 'w', the window needs to be larger than 1 month!\"\n        raise HumblDataError(msg)\n\n    window_monthly = _window_format_monthly(window)\n\n    data = data.with_columns(\n        _create_monthly_window_index(col=\"date\", k=window_monthly)\n        .alias(\"window_index\")\n        .over(\"symbol\")\n    )\n\n    return data\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets","title":"vol_buckets","text":"<pre><code>vol_buckets(data: DataFrame | LazyFrame, lo_quantile: float = 0.4, hi_quantile: float = 0.8, _column_name_volatility: str = 'realized_volatility', *, _boundary_group_down: bool = False) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_buckets.</p> <p>Splitting data observations into 3 volatility buckets: low, mid and high. The function does this for each <code>symbol</code> present in the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input dataframe or lazy frame.</p> required <code>lo_quantile</code> <code>float</code> <p>The lower quantile for bucketing. Default is 0.4.</p> <code>0.4</code> <code>hi_quantile</code> <code>float</code> <p>The higher quantile for bucketing. Default is 0.8.</p> <code>0.8</code> <code>_column_name_volatility</code> <code>str</code> <p>The name of the column to apply volatility bucketing. Default is \"realized_volatility\".</p> <code>'realized_volatility'</code> <code>_boundary_group_down</code> <code>bool</code> <p>If True, then group boundary values down to the lower bucket, using <code>vol_buckets_alt()</code> If False, then group boundary values up to the higher bucket, using the Polars <code>.qcut()</code> method. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The <code>data</code> with an additional column: <code>vol_bucket</code></p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def vol_buckets(\n    data: pl.DataFrame | pl.LazyFrame,\n    lo_quantile: float = 0.4,\n    hi_quantile: float = 0.8,\n    _column_name_volatility: str = \"realized_volatility\",\n    *,\n    _boundary_group_down: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_buckets**.\n\n    Splitting data observations into 3 volatility buckets: low, mid and high.\n    The function does this for each `symbol` present in the data.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input dataframe or lazy frame.\n    lo_quantile : float\n        The lower quantile for bucketing. Default is 0.4.\n    hi_quantile : float\n        The higher quantile for bucketing. Default is 0.8.\n    _column_name_volatility : str\n        The name of the column to apply volatility bucketing. Default is\n        \"realized_volatility\".\n    _boundary_group_down: bool = False\n        If True, then group boundary values down to the lower bucket, using\n        `vol_buckets_alt()` If False, then group boundary values up to the\n        higher bucket, using the Polars `.qcut()` method.\n        Default is False.\n\n    Returns\n    -------\n    pl.LazyFrame\n        The `data` with an additional column: `vol_bucket`\n    \"\"\"\n    _check_required_columns(data, _column_name_volatility, \"symbol\")\n\n    if not _boundary_group_down:\n        # Grouping Boundary Values in Higher Bucket\n        out = data.lazy().with_columns(\n            pl.col(_column_name_volatility)\n            .qcut(\n                [lo_quantile, hi_quantile],\n                labels=[\"low\", \"mid\", \"high\"],\n                left_closed=False,\n                allow_duplicates=True,\n            )\n            .over(\"symbol\")\n            .alias(\"vol_bucket\")\n            .cast(pl.Utf8)\n        )\n    else:\n        out = vol_buckets_alt(\n            data, lo_quantile, hi_quantile, _column_name_volatility\n        )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets_alt","title":"vol_buckets_alt","text":"<pre><code>vol_buckets_alt(data: DataFrame | LazyFrame, lo_quantile: float = 0.4, hi_quantile: float = 0.8, _column_name_volatility: str = 'realized_volatility') -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_buckets_alt.</p> <p>This is an alternative implementation of <code>vol_buckets()</code> using expressions, and not using <code>.qcut()</code>. The biggest difference is how the function groups values on the boundaries of quantiles. This function groups boundary values down Splitting data observations into 3 volatility buckets: low, mid and high. The function does this for each <code>symbol</code> present in the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input dataframe or lazy frame.</p> required <code>lo_quantile</code> <code>float</code> <p>The lower quantile for bucketing. Default is 0.4.</p> <code>0.4</code> <code>hi_quantile</code> <code>float</code> <p>The higher quantile for bucketing. Default is 0.8.</p> <code>0.8</code> <code>_column_name_volatility</code> <code>str</code> <p>The name of the column to apply volatility bucketing. Default is \"realized_volatility\".</p> <code>'realized_volatility'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The <code>data</code> with an additional column: <code>vol_bucket</code></p> Notes <p>The biggest difference is how the function groups values on the boundaries of quantiles. This function groups boundary values down to the lower bucket. So, if there is a value that lies on the mid/low border, this function will group it with <code>low</code>, whereas <code>vol_buckets()</code> will group it with <code>mid</code></p> <p>This function is also slightly less performant.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def vol_buckets_alt(\n    data: pl.DataFrame | pl.LazyFrame,\n    lo_quantile: float = 0.4,\n    hi_quantile: float = 0.8,\n    _column_name_volatility: str = \"realized_volatility\",\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_buckets_alt**.\n\n    This is an alternative implementation of `vol_buckets()` using expressions,\n    and not using `.qcut()`.\n    The biggest difference is how the function groups values on the boundaries\n    of quantiles. This function groups boundary values down\n    Splitting data observations into 3 volatility buckets: low, mid and high.\n    The function does this for each `symbol` present in the data.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input dataframe or lazy frame.\n    lo_quantile : float\n        The lower quantile for bucketing. Default is 0.4.\n    hi_quantile : float\n        The higher quantile for bucketing. Default is 0.8.\n    _column_name_volatility : str\n        The name of the column to apply volatility bucketing. Default is \"realized_volatility\".\n\n    Returns\n    -------\n    pl.LazyFrame\n        The `data` with an additional column: `vol_bucket`\n\n    Notes\n    -----\n    The biggest difference is how the function groups values on the boundaries\n    of quantiles. This function __groups boundary values down__ to the lower bucket.\n    So, if there is a value that lies on the mid/low border, this function will\n    group it with `low`, whereas `vol_buckets()` will group it with `mid`\n\n    This function is also slightly less performant.\n    \"\"\"\n    # Calculate low and high quantiles for each symbol\n    low_vol = pl.col(_column_name_volatility).quantile(lo_quantile)\n    high_vol = pl.col(_column_name_volatility).quantile(hi_quantile)\n\n    # Determine the volatility bucket for each row using expressions\n    vol_bucket = (\n        pl.when(pl.col(_column_name_volatility) &lt;= low_vol)\n        .then(pl.lit(\"low\"))\n        .when(pl.col(_column_name_volatility) &lt;= high_vol)\n        .then(pl.lit(\"mid\"))\n        .otherwise(pl.lit(\"high\"))\n        .alias(\"vol_bucket\")\n    )\n\n    # Add the volatility bucket column to the data\n    out = data.lazy().with_columns(vol_bucket.over(\"symbol\"))\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_filter","title":"vol_filter","text":"<pre><code>vol_filter(data: DataFrame | LazyFrame) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_filter.</p> <p>If <code>_rv_adjustment</code> is True, then filter the data to only include rows that are in the same vol_bucket as the latest row for each symbol.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input dataframe or lazy frame. This should be the output of <code>vol_buckets()</code> function in <code>calc_mandelbrot_channel()</code>.</p> required <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The data with only observations in the same volatility bucket as the most recent data observation</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def vol_filter(\n    data: pl.DataFrame | pl.LazyFrame,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_filter**.\n\n    If `_rv_adjustment` is True, then filter the data to only include rows\n    that are in the same vol_bucket as the latest row for each symbol.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input dataframe or lazy frame. This should be the output of\n        `vol_buckets()` function in `calc_mandelbrot_channel()`.\n\n    Returns\n    -------\n    pl.LazyFrame\n        The data with only observations in the same volatility bucket as the\n        most recent data observation\n    \"\"\"\n    _check_required_columns(data, \"vol_bucket\", \"symbol\")\n\n    data = data.lazy().with_columns(\n        pl.col(\"vol_bucket\").last().over(\"symbol\").alias(\"last_vol_bucket\")\n    )\n\n    out = data.filter(\n        (pl.col(\"vol_bucket\") == pl.col(\"last_vol_bucket\")).over(\"symbol\")\n    ).drop(\"last_vol_bucket\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.price_range","title":"price_range","text":"<pre><code>price_range(data: LazyFrame | DataFrame, recent_price_data: DataFrame | LazyFrame | None = None, rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', _detrended_returns: str = 'detrended_log_returns', _column_name_cum_sum_max: str = 'cum_sum_max', _column_name_cum_sum_min: str = 'cum_sum_min', *, _rv_adjustment: bool = False, _sort: bool = True, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: price_range.</p> <p>Calculate the price range for a given dataset using the Mandelbrot method.</p> <p>This function computes the price range based on the recent price data, cumulative sum max and min, and RS method specified. It supports adjustments for real volatility and sorting of the data based on symbols and dates.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The dataset containing the financial data.</p> required <code>recent_price_data</code> <code>DataFrame | LazyFrame | None</code> <p>The dataset containing the most recent price data. If None, the most recent prices are extracted from <code>data</code>.</p> <code>None</code> <code>rs_method</code> <code>Literal['RS', 'RS_mean', 'RS_max', 'RS_min']</code> <p>The RS value to use. Must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'. RS is the column that is the Range/STD of the detrended returns.</p> <code>\"RS\"</code> <code>_detrended_returns</code> <code>str</code> <p>The column name for detrended returns in <code>data</code></p> <code>\"detrended_log_returns\"</code> <code>_column_name_cum_sum_max</code> <code>str</code> <p>The column name for cumulative sum max in <code>data</code></p> <code>\"cum_sum_max\"</code> <code>_column_name_cum_sum_min</code> <code>str</code> <p>The column name for cumulative sum min in <code>data</code></p> <code>\"cum_sum_min\"</code> <code>_rv_adjustment</code> <code>bool</code> <p>If True, calculated the <code>std()</code> for all observations (since they have already been filtered by volatility bucket). If False, then calculates the <code>std()</code> for the most recent <code>window_index</code> and uses that to adjust the price range.</p> <code>False</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the data based on symbols and dates.</p> <code>True</code> <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>The dataset with calculated price range, including columns for top and bottom prices.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If the RS method specified is not supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; price_range_data = price_range(data, recent_price_data=None, rs_method=\"RS\")\n&gt;&gt;&gt; print(price_range_data.columns)\n['symbol', 'bottom_price', 'recent_price', 'top_price']\n</code></pre> Notes <p>For <code>rs_method</code>, you should know how this affects the mandelbrot channel that is produced. Selecting RS uses the most recent RS value to calculate the price range, whereas selecting RS_mean, RS_max, or RS_min uses the mean, max, or min of the RS values, respectively.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/helpers.py</code> <pre><code>def price_range(\n    data: pl.LazyFrame | pl.DataFrame,\n    recent_price_data: pl.DataFrame | pl.LazyFrame | None = None,\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    _detrended_returns: str = \"detrended_log_returns\",  # Parameterized detrended_returns column\n    _column_name_cum_sum_max: str = \"cum_sum_max\",\n    _column_name_cum_sum_min: str = \"cum_sum_min\",\n    *,\n    _rv_adjustment: bool = False,\n    _sort: bool = True,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **price_range**.\n\n    Calculate the price range for a given dataset using the Mandelbrot method.\n\n    This function computes the price range based on the recent price data,\n    cumulative sum max and min, and RS method specified. It supports adjustments\n    for real volatility and sorting of the data based on symbols and dates.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The dataset containing the financial data.\n    recent_price_data : pl.DataFrame | pl.LazyFrame | None\n        The dataset containing the most recent price data. If None, the most recent prices are extracted from `data`.\n    rs_method : Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"], default \"RS\"\n        The RS value to use. Must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'.\n        RS is the column that is the Range/STD of the detrended returns.\n    _detrended_returns : str, default \"detrended_log_returns\"\n        The column name for detrended returns in `data`\n    _column_name_cum_sum_max : str, default \"cum_sum_max\"\n        The column name for cumulative sum max in `data`\n    _column_name_cum_sum_min : str, default \"cum_sum_min\"\n        The column name for cumulative sum min in `data`\n    _rv_adjustment : bool, default False\n        If True, calculated the `std()` for all observations (since they have\n        already been filtered by volatility bucket). If False, then calculates\n        the `std()` for the most recent `window_index`\n        and uses that to adjust the price range.\n    _sort : bool, default True\n        If True, sorts the data based on symbols and dates.\n    **kwargs\n        Arbitrary keyword arguments.\n\n    Returns\n    -------\n    pl.LazyFrame\n        The dataset with calculated price range, including columns for top and\n        bottom prices.\n\n    Raises\n    ------\n    HumblDataError\n        If the RS method specified is not supported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; price_range_data = price_range(data, recent_price_data=None, rs_method=\"RS\")\n    &gt;&gt;&gt; print(price_range_data.columns)\n    ['symbol', 'bottom_price', 'recent_price', 'top_price']\n\n    Notes\n    -----\n    For `rs_method`, you should know how this affects the mandelbrot channel\n    that is produced. Selecting RS uses the most recent RS value to calculate\n    the price range, whereas selecting RS_mean, RS_max, or RS_min uses the mean,\n    max, or min of the RS values, respectively.\n    \"\"\"\n    # Check if RS_method is one of the allowed values\n    if rs_method not in RS_METHODS:\n        msg = \"RS_method must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'\"\n        raise HumblDataError(msg)\n\n    if isinstance(data, pl.DataFrame):\n        data = data.lazy()\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data.sort(sort_cols)\n\n    # Define Polars Expressions ================================================\n    last_cum_sum_max = (\n        pl.col(_column_name_cum_sum_max).last().alias(\"last_cum_sum_max\")\n    )\n    last_cum_sum_min = (\n        pl.col(_column_name_cum_sum_min).last().alias(\"last_cum_sum_min\")\n    )\n    # Define a conditional expression for std_detrended_returns based on _rv_adjustment\n    std_detrended_returns_expr = (\n        pl.col(_detrended_returns).std().alias(f\"std_{_detrended_returns}\")\n        if _rv_adjustment\n        else pl.col(_detrended_returns)\n        .filter(pl.col(\"window_index\") == pl.col(\"window_index\").min())\n        .std()\n        .alias(f\"std_{_detrended_returns}\")\n    )\n    # if rv_adjustment isnt used, then use the most recent window will be used\n    # for calculating the price_range\n    date_expr = pl.col(\"date\").max()\n    # ===========================================================================\n\n    if rs_method == \"RS\":\n        rs_expr = pl.col(\"RS\").last().alias(\"RS\")\n    elif rs_method == \"RS_mean\":\n        rs_expr = pl.col(\"RS\").mean().alias(\"RS_mean\")\n    elif rs_method == \"RS_max\":\n        rs_expr = pl.col(\"RS\").max().alias(\"RS_max\")\n    elif rs_method == \"RS_min\":\n        rs_expr = pl.col(\"RS\").min().alias(\"RS_min\")\n\n    if recent_price_data is None:\n        # if no recent_prices_data is passed, then pull the most recent prices from the data\n        recent_price_expr = pl.col(\"close\").last().alias(\"recent_price\")\n        # Perform a single group_by operation to calculate both STD of detrended returns and RS statistics\n        price_range_data = (\n            data.group_by(\"symbol\")\n            .agg(\n                [\n                    date_expr,\n                    # Conditional STD calculation based on _rv_adjustment\n                    std_detrended_returns_expr,\n                    # Recent Price Data\n                    recent_price_expr,\n                    # cum_sum_max/min last\n                    last_cum_sum_max,\n                    last_cum_sum_min,\n                    # RS statistics\n                    rs_expr,\n                ]\n            )\n            # Join with recent_price_data on symbol\n            .with_columns(\n                (\n                    pl.col(rs_method)\n                    * pl.col(\"std_detrended_log_returns\")\n                    * pl.col(\"recent_price\")\n                ).alias(\"price_range\")\n            )\n            .sort(\"symbol\")\n        )\n    else:\n        price_range_data = (\n            data.group_by(\"symbol\")\n            .agg(\n                [\n                    date_expr,\n                    # Conditional STD calculation based on _rv_adjustment\n                    std_detrended_returns_expr,\n                    # cum_sum_max/min last\n                    last_cum_sum_max,\n                    last_cum_sum_min,\n                    # RS statistics\n                    rs_expr,\n                ]\n            )\n            # Join with recent_price_data on symbol\n            .join(recent_price_data.lazy(), on=\"symbol\")\n            .with_columns(\n                (\n                    pl.col(rs_method)\n                    * pl.col(\"std_detrended_log_returns\")\n                    * pl.col(\"recent_price\")\n                ).alias(\"price_range\")\n            )\n            .sort(\"symbol\")\n        )\n    # Relative Position Modifier\n    out = _price_range_engine(price_range_data)\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model","title":"model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_mandelbrot_channel.</p> <p>A command to generate a Mandelbrot Channel for any time series.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel","title":"calc_mandelbrot_channel","text":"<pre><code>calc_mandelbrot_channel(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: calc_mandelbrot_channel.</p> <p>This command calculates the Mandelbrot Channel for a given time series, utilizing various parameters to adjust the calculation. The Mandelbrot Channel provides insights into the volatility and price range of a stock over a specified window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Mandelbrot Channel. There needs to be a <code>close</code> and <code>date</code> column.</p> required <code>window</code> <code>str</code> <p>The window size for the calculation, specified as a string. This determines the period over which the channel is calculated.</p> <code>'1m'</code> <code>rv_adjustment</code> <code>bool</code> <p>Adjusts the calculation for realized volatility. If True, filters the data to include only observations within the current volatility bucket of the stock.</p> <code>True</code> <code>rv_grouped_mean</code> <code>bool</code> <p>Determines whether to use the grouped mean in the realized volatility calculation.</p> <code>True</code> <code>rv_method</code> <code>str</code> <p>Specifies the method for calculating realized volatility, applicable only if <code>rv_adjustment</code> is True.</p> <code>'std'</code> <code>rs_method</code> <code>Literal['RS', 'RS_mean', 'RS_max', 'RS_min']</code> <p>Defines the method for calculating the range over standard deviation, affecting the width of the Mandelbrot Channel. Options include RS, RS_mean, RS_min, and RS_max.</p> <code>'RS'</code> <code>live_price</code> <code>bool</code> <p>Indicates whether to incorporate live price data into the calculation, which may extend the calculation time by 1-3 seconds.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the function, if you want to change the behavior or pass parameters to internal functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame containing the calculated Mandelbrot Channel data for the specified time series.</p> Notes <p>The function returns a pl.LazyFrame; remember to call <code>.collect()</code> on the result to obtain a DataFrame. This lazy evaluation strategy postpones the calculation until it is explicitly requested.</p> Example <p>To calculate the Mandelbrot Channel for a yearly window with adjustments for realized volatility using the 'yz' method, and incorporating live price data:</p> <pre><code>mandelbrot_channel = calc_mandelbrot_channel(\n    data,\n    window=\"1y\",\n    rv_adjustment=True,\n    rv_method=\"yz\",\n    rv_grouped_mean=False,\n    rs_method=\"RS\",\n    live_price=True\n).collect()\n</code></pre> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel(  # noqa: PLR0913\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: calc_mandelbrot_channel**.\n\n    This command calculates the Mandelbrot Channel for a given time series, utilizing various parameters to adjust the calculation. The Mandelbrot Channel provides insights into the volatility and price range of a stock over a specified window.\n\n    Parameters\n    ----------\n    data: pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Mandelbrot Channel.\n        There needs to be a `close` and `date` column.\n    window: str, default \"1m\"\n        The window size for the calculation, specified as a string. This\n        determines the period over which the channel is calculated.\n    rv_adjustment: bool, default True\n        Adjusts the calculation for realized volatility. If True, filters the\n        data to include only observations within the current volatility bucket\n        of the stock.\n    rv_grouped_mean: bool, default True\n        Determines whether to use the grouped mean in the realized volatility\n        calculation.\n    rv_method: str, default \"std\"\n        Specifies the method for calculating realized volatility, applicable\n        only if `rv_adjustment` is True.\n    rs_method: str, default \"RS\"\n        Defines the method for calculating the range over standard deviation,\n        affecting the width of the Mandelbrot Channel. Options include RS,\n        RS_mean, RS_min, and RS_max.\n    live_price: bool, default True\n        Indicates whether to incorporate live price data into the calculation,\n        which may extend the calculation time by 1-3 seconds.\n    **kwargs\n        Additional keyword arguments to pass to the function, if you want to\n        change the behavior or pass parameters to internal functions.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame containing the calculated Mandelbrot Channel data for the specified time series.\n\n    Notes\n    -----\n    The function returns a pl.LazyFrame; remember to call `.collect()` on the result to obtain a DataFrame. This lazy evaluation strategy postpones the calculation until it is explicitly requested.\n\n    Example\n    -------\n    To calculate the Mandelbrot Channel for a yearly window with adjustments for realized volatility using the 'yz' method, and incorporating live price data:\n\n    ```python\n    mandelbrot_channel = calc_mandelbrot_channel(\n        data,\n        window=\"1y\",\n        rv_adjustment=True,\n        rv_method=\"yz\",\n        rv_grouped_mean=False,\n        rs_method=\"RS\",\n        live_price=True\n    ).collect()\n    ```\n    \"\"\"\n    # Setup ====================================================================\n    # window_datetime = _window_format(window, _return_timedelta=True)\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n\n    data = data.lazy()\n    # Step 1: Collect Price Data -----------------------------------------------\n    # Step X: Add window bins --------------------------------------------------\n    # We want date grouping, non-overlapping window bins\n    data1 = add_window_index(data, window=window)\n\n    # Step X: Calculate Log Returns + Rvol -------------------------------------\n    if \"log_returns\" not in data1.collect_schema().names():\n        data2 = log_returns(data1, _column_name=\"close\")\n    else:\n        data2 = data1\n\n    # Step X: Calculate Log Mean Series ----------------------------------------\n    if isinstance(data2, pl.DataFrame | pl.LazyFrame):\n        data3 = mean(data2)\n    else:\n        msg = \"A series was passed to `mean()` calculation. Please provide a DataFrame or LazyFrame.\"\n        raise HumblDataError(msg)\n    # Step X: Calculate Mean De-trended Series ---------------------------------\n    data4 = detrend(\n        data3, _detrend_value_col=\"window_mean\", _detrend_col=\"log_returns\"\n    )\n    # Step X: Calculate Cumulative Deviate Series ------------------------------\n    data5 = cum_sum(data4, _column_name=\"detrended_log_returns\")\n    # Step X: Calculate Mandelbrot Range ---------------------------------------\n    data6 = range_(data5, _column_name=\"cum_sum\")\n    # Step X: Calculate Standard Deviation -------------------------------------\n    data7 = std(data6, _column_name=\"cum_sum\")\n    # Step X: Calculate Range (R) &amp; Standard Deviation (S) ---------------------\n    if rv_adjustment:\n        # Step 8.1: Calculate Realized Volatility ------------------------------\n        data7 = calc_realized_volatility(\n            data=data7,\n            window=window,\n            method=rv_method,\n            grouped_mean=rv_grouped_mean,\n        )\n        # rename col for easy selection\n        for col in data7.collect_schema().names():\n            if \"volatility_pct\" in col:\n                data7 = data7.rename({col: \"realized_volatility\"})\n        # Step 8.2: Calculate Volatility Bucket Stats --------------------------\n        data7 = vol_buckets(data=data7, lo_quantile=0.3, hi_quantile=0.65)\n        data7 = vol_filter(\n            data7\n        )  # removes rows that arent in the same vol bucket\n\n    # Step X: Calculate RS -----------------------------------------------------\n    data8 = data7.sort(sort_cols).with_columns(\n        (pl.col(\"cum_sum_range\") / pl.col(\"cum_sum_std\")).alias(\"RS\")\n    )\n\n    # Step X: Collect Recent Prices --------------------------------------------\n    if live_price:\n        symbols = (\n            data.select(\"symbol\").unique().sort(\"symbol\").collect().to_series()\n        )\n        recent_prices = get_latest_price(symbols)\n    else:\n        recent_prices = None\n\n    # Step X: Calculate Rescaled Price Range ----------------------------------\n    out = price_range(\n        data=data8,\n        recent_price_data=recent_prices,\n        rs_method=rs_method,\n        _rv_adjustment=rv_adjustment,\n    )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model.acalc_mandelbrot_channel","title":"acalc_mandelbrot_channel  <code>async</code>","text":"<pre><code>acalc_mandelbrot_channel(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, **kwargs) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || Command: acalc_mandelbrot_channel.</p> <p>Asynchronous wrapper for calc_mandelbrot_channel. This function allows calc_mandelbrot_channel to be called in an async context.</p> Notes <p>This does not make <code>calc_mandelbrot_channel()</code> non-blocking or asynchronous.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>async def acalc_mandelbrot_channel(  # noqa: PLR0913\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    **kwargs,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || **Command: acalc_mandelbrot_channel**.\n\n    Asynchronous wrapper for calc_mandelbrot_channel.\n    This function allows calc_mandelbrot_channel to be called in an async context.\n\n    Notes\n    -----\n    This does not make `calc_mandelbrot_channel()` non-blocking or asynchronous.\n    \"\"\"\n    # Directly call the synchronous calc_mandelbrot_channel function\n\n    return calc_mandelbrot_channel(\n        data=data,\n        window=window,\n        rv_adjustment=rv_adjustment,\n        rv_method=rv_method,\n        rs_method=rs_method,\n        rv_grouped_mean=rv_grouped_mean,\n        live_price=live_price,\n        **kwargs,\n    )\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical","title":"calc_mandelbrot_channel_historical","text":"<pre><code>calc_mandelbrot_channel_historical(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || Command: calc_mandelbrot_channel_historical.</p> <p>This function calculates the Mandelbrot Channel for historical data.</p> <p>Synchronous wrapper for the asynchronous Mandelbrot Channel historical calculation.</p> <p>Parameters:</p> Name Type Description Default <code>The</code> required <code>Please</code> required <code>description</code> required <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame containing the historical Mandelbrot Channel calculations.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel_historical(  # noqa: PLR0913\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Mandelbrot Channel || **Command: calc_mandelbrot_channel_historical**.\n\n    This function calculates the Mandelbrot Channel for historical data.\n\n    Synchronous wrapper for the asynchronous Mandelbrot Channel historical calculation.\n\n    Parameters\n    ----------\n    The parameters for this function are the same as those for calc_mandelbrot_channel().\n    Please refer to the documentation of calc_mandelbrot_channel() for a detailed\n    description of each parameter.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame containing the historical Mandelbrot Channel calculations.\n    \"\"\"\n    return run_async(\n        _acalc_mandelbrot_channel_historical_engine(\n            data=data,\n            window=window,\n            rv_adjustment=rv_adjustment,\n            rv_method=rv_method,\n            rs_method=rs_method,\n            rv_grouped_mean=rv_grouped_mean,\n            live_price=live_price,\n            **kwargs,\n        )\n    )\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical_mp","title":"calc_mandelbrot_channel_historical_mp","text":"<pre><code>calc_mandelbrot_channel_historical_mp(data: DataFrame | LazyFrame, window: str = '1m', rv_adjustment: bool = True, rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_grouped_mean: bool = True, live_price: bool = True, n_processes: int = 1, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Calculate the Mandelbrot Channel historically using multiprocessing.</p> Parameters: <p>n_processes : int, optional     Number of processes to use. If None, it uses all available cores.</p> <p>Other parameters are the same as calc_mandelbrot_channel_historical.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel_historical_mp(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_adjustment: bool = True,\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    n_processes: int = 1,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate the Mandelbrot Channel historically using multiprocessing.\n\n    Parameters:\n    -----------\n    n_processes : int, optional\n        Number of processes to use. If None, it uses all available cores.\n\n    Other parameters are the same as calc_mandelbrot_channel_historical.\n    \"\"\"\n    window_days = _window_format(window, _return_timedelta=True)\n    start_date = data.lazy().select(pl.col(\"date\")).min().collect().row(0)[0]\n    start_date = start_date + window_days\n    end_date = data.lazy().select(\"date\").max().collect().row(0)[0]\n\n    if start_date &gt;= end_date:\n        msg = f\"You set &lt;historical=True&gt; \\n\\\n        This calculation needs *at least* one window of data. \\n\\\n        The (start date + window) is: {start_date} and the dataset ended: {end_date}. \\n\\\n        Please adjust dates accordingly.\"\n        raise HumblDataError(msg)\n\n    dates = (\n        data.lazy()\n        .select(pl.col(\"date\"))\n        .filter(pl.col(\"date\") &gt;= start_date)\n        .unique()\n        .sort(\"date\")\n        .collect()\n        .to_series()\n    )\n\n    # Prepare the partial function with all arguments except the date\n    calc_func = partial(\n        _calc_mandelbrot_for_date,\n        data=data,\n        window=window,\n        rv_adjustment=rv_adjustment,\n        rv_method=rv_method,\n        rs_method=rs_method,\n        rv_grouped_mean=rv_grouped_mean,\n        live_price=live_price,\n        **kwargs,\n    )\n\n    # Use multiprocessing to calculate in parallel\n    with multiprocessing.Pool(processes=n_processes) as pool:\n        results = pool.map(calc_func, dates)\n\n    # Combine results\n    out = pl.concat(results, how=\"vertical\").sort([\"symbol\", \"date\"])\n\n    return out.lazy()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel_historical_concurrent","title":"calc_mandelbrot_channel_historical_concurrent","text":"<pre><code>calc_mandelbrot_channel_historical_concurrent(data: DataFrame | LazyFrame, window: str = '1m', rv_method: str = 'std', rs_method: Literal['RS', 'RS_mean', 'RS_max', 'RS_min'] = 'RS', *, rv_adjustment: bool = True, rv_grouped_mean: bool = True, live_price: bool = True, max_workers: int | None = None, use_processes: bool = False, **kwargs) -&gt; LazyFrame\n</code></pre> <p>Calculate the Mandelbrot Channel historically using concurrent.futures.</p> Parameters: <p>max_workers : int, optional     Maximum number of workers to use. If None, it uses the default for ProcessPoolExecutor     or ThreadPoolExecutor (usually the number of processors on the machine, multiplied by 5). use_processes : bool, default True     If True, use ProcessPoolExecutor, otherwise use ThreadPoolExecutor.</p> <p>Other parameters are the same as calc_mandelbrot_channel_historical.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/model.py</code> <pre><code>def calc_mandelbrot_channel_historical_concurrent(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_method: str = \"std\",\n    rs_method: Literal[\"RS\", \"RS_mean\", \"RS_max\", \"RS_min\"] = \"RS\",\n    *,\n    rv_adjustment: bool = True,\n    rv_grouped_mean: bool = True,\n    live_price: bool = True,\n    max_workers: int | None = None,\n    use_processes: bool = False,\n    **kwargs,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate the Mandelbrot Channel historically using concurrent.futures.\n\n    Parameters:\n    -----------\n    max_workers : int, optional\n        Maximum number of workers to use. If None, it uses the default for ProcessPoolExecutor\n        or ThreadPoolExecutor (usually the number of processors on the machine, multiplied by 5).\n    use_processes : bool, default True\n        If True, use ProcessPoolExecutor, otherwise use ThreadPoolExecutor.\n\n    Other parameters are the same as calc_mandelbrot_channel_historical.\n    \"\"\"\n    window_days = _window_format(window, _return_timedelta=True)\n    start_date = data.lazy().select(pl.col(\"date\")).min().collect().row(0)[0]\n    start_date = start_date + window_days\n    end_date = data.lazy().select(\"date\").max().collect().row(0)[0]\n\n    if start_date &gt;= end_date:\n        msg = f\"You set &lt;historical=True&gt; \\n\\\n        This calculation needs *at least* one window of data. \\n\\\n        The (start date + window) is: {start_date} and the dataset ended: {end_date}. \\n\\\n        Please adjust dates accordingly.\"\n        raise HumblDataError(msg)\n\n    dates = (\n        data.lazy()\n        .select(pl.col(\"date\"))\n        .filter(pl.col(\"date\") &gt;= start_date)\n        .unique()\n        .sort(\"date\")\n        .collect()\n        .to_series()\n    )\n\n    # Prepare the partial function with all arguments except the date\n    calc_func = partial(\n        _calc_mandelbrot_for_date,\n        data=data,\n        window=window,\n        rv_adjustment=rv_adjustment,\n        rv_method=rv_method,\n        rs_method=rs_method,\n        rv_grouped_mean=rv_grouped_mean,\n        live_price=live_price,\n        **kwargs,\n    )\n\n    # Choose the appropriate executor\n    executor_class = (\n        concurrent.futures.ProcessPoolExecutor\n        if use_processes\n        else concurrent.futures.ThreadPoolExecutor\n    )\n\n    # Use concurrent.futures to calculate in parallel\n    with executor_class(max_workers=max_workers) as executor:\n        futures = [executor.submit(calc_func, date) for date in dates]\n        results = [\n            future.result()\n            for future in concurrent.futures.as_completed(futures)\n        ]\n\n    # Combine results\n    out = pl.concat(results, how=\"vertical\").sort([\"symbol\", \"date\"])\n\n    return out.lazy()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.view","title":"view","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.view.create_historical_plot","title":"create_historical_plot","text":"<pre><code>create_historical_plot(data: DataFrame, symbol: str, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate a historical plot for a given symbol from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing historical data including dates, bottom prices, close prices, and top prices.</p> required <code>symbol</code> <code>str</code> <p>The symbol for which the historical plot is to be generated.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the historical data of the given symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def create_historical_plot(\n    data: pl.DataFrame,\n    symbol: str,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate a historical plot for a given symbol from the provided data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing historical data including dates, bottom prices, close prices, and top prices.\n    symbol : str\n        The symbol for which the historical plot is to be generated.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the historical data of the given symbol.\n    \"\"\"\n    filtered_data = data.filter(pl.col(\"symbol\") == symbol)\n\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_data.select(\"date\").to_series(),\n            y=filtered_data.select(\"bottom_price\").to_series(),\n            name=\"Bottom Price\",\n            line=dict(color=\"green\"),\n        )\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_data.select(\"date\").to_series(),\n            y=filtered_data.select(\"recent_price\").to_series(),\n            name=\"Recent Price\",\n            line=dict(color=\"blue\"),\n        )\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_data.select(\"date\").to_series(),\n            y=filtered_data.select(\"top_price\").to_series(),\n            name=\"Top Price\",\n            line=dict(color=\"red\"),\n        )\n    )\n    fig.update_layout(\n        title=f\"Historical Mandelbrot Channel for {symbol}\",\n        xaxis_title=\"Date\",\n        yaxis_title=\"Price\",\n        template=template,\n    )\n    return fig\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.view.create_current_plot","title":"create_current_plot","text":"<pre><code>create_current_plot(data: DataFrame, equity_data: DataFrame, symbol: str, template: ChartTemplate = ChartTemplate.plotly) -&gt; Figure\n</code></pre> <p>Generate a current plot for a given symbol from the provided data and equity data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing historical data including top and bottom prices.</p> required <code>equity_data</code> <code>DataFrame</code> <p>The dataframe containing current equity data including dates and close prices.</p> required <code>symbol</code> <code>str</code> <p>The symbol for which the current plot is to be generated.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template to be used for styling the plot.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A plotly figure object representing the current data of the given symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def create_current_plot(\n    data: pl.DataFrame,\n    equity_data: pl.DataFrame,\n    symbol: str,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; go.Figure:\n    \"\"\"\n    Generate a current plot for a given symbol from the provided data and equity data.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing historical data including top and bottom prices.\n    equity_data : pl.DataFrame\n        The dataframe containing current equity data including dates and close prices.\n    symbol : str\n        The symbol for which the current plot is to be generated.\n    template : ChartTemplate\n        The template to be used for styling the plot.\n\n    Returns\n    -------\n    go.Figure\n        A plotly figure object representing the current data of the given symbol.\n    \"\"\"\n    filtered_data = data.filter(pl.col(\"symbol\") == symbol)\n    equity_data = equity_data.filter(pl.col(\"symbol\") == symbol)\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=equity_data.select(\"date\").to_series(),\n            y=equity_data.select(\"close\").to_series(),\n            name=\"Recent Price\",\n            line=dict(color=\"blue\"),\n        )\n    )\n    fig.add_hline(\n        y=filtered_data.select(\"top_price\").row(0)[0],\n        line=dict(color=\"red\", width=2),\n        name=\"Top Price\",\n    )\n    fig.add_hline(\n        y=filtered_data.select(\"bottom_price\").row(0)[0],\n        line=dict(color=\"green\", width=2),\n        name=\"Bottom Price\",\n    )\n    fig.update_layout(\n        title=f\"Current Mandelbrot Channel for {symbol}\",\n        xaxis_title=\"Date\",\n        yaxis_title=\"Price\",\n        template=template,\n    )\n    return fig\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.view.is_historical_data","title":"is_historical_data","text":"<pre><code>is_historical_data(data: DataFrame) -&gt; bool\n</code></pre> <p>Check if the provided dataframe contains historical data based on the uniqueness of dates.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe to check for historical data presence.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Returns True if the dataframe contains historical data (more than one unique date), otherwise False.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def is_historical_data(data: pl.DataFrame) -&gt; bool:\n    \"\"\"\n    Check if the provided dataframe contains historical data based on the uniqueness of dates.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe to check for historical data presence.\n\n    Returns\n    -------\n    bool\n        Returns True if the dataframe contains historical data (more than one unique date), otherwise False.\n    \"\"\"\n    return data.select(\"date\").to_series().unique().shape[0] &gt; 1\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.view.generate_plot_for_symbol","title":"generate_plot_for_symbol","text":"<pre><code>generate_plot_for_symbol(data: DataFrame, equity_data: DataFrame, symbol: str, template: ChartTemplate = ChartTemplate.plotly) -&gt; Chart\n</code></pre> <p>Generate a plot for a specific symbol that is filtered from the original DF.</p> <p>This function will check if the data provided is a Historical or Current Mandelbrot Channel data. If it is historical, it will generate a historical plot. If it is current, it will generate a current plot.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The dataframe containing Mandelbrot channel data for all symbols.</p> required <code>equity_data</code> <code>DataFrame</code> <p>The dataframe containing equity data for all symbols.</p> required <code>symbol</code> <code>str</code> <p>The symbol for which to generate the plot.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure. Options are: \"humbl_light\", \"humbl_dark\", \"plotly_light\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"</p> <code>plotly</code> <p>Returns:</p> Type Description <code>Chart</code> <p>A Chart object containing the generated plot for the specified symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def generate_plot_for_symbol(\n    data: pl.DataFrame,\n    equity_data: pl.DataFrame,\n    symbol: str,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; Chart:\n    \"\"\"\n    Generate a plot for a specific symbol that is filtered from the original DF.\n\n    This function will check if the data provided is a Historical or Current\n    Mandelbrot Channel data. If it is historical, it will generate a historical\n    plot. If it is current, it will generate a current plot.\n\n    Parameters\n    ----------\n    data : pl.DataFrame\n        The dataframe containing Mandelbrot channel data for all symbols.\n    equity_data : pl.DataFrame\n        The dataframe containing equity data for all symbols.\n    symbol : str\n        The symbol for which to generate the plot.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure. Options are:\n        \"humbl_light\", \"humbl_dark\", \"plotly_light\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\n\n    Returns\n    -------\n    Chart\n        A Chart object containing the generated plot for the specified symbol.\n\n    \"\"\"\n    if is_historical_data(data):\n        out = create_historical_plot(data, symbol, template)\n    else:\n        out = create_current_plot(data, equity_data, symbol, template)\n\n    return Chart(\n        content=out.to_json(), fig=out\n    )  # TODO: use to_json() instead of to_plotly_json()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.view.generate_plots","title":"generate_plots","text":"<pre><code>generate_plots(data: LazyFrame, equity_data: LazyFrame, template: ChartTemplate = ChartTemplate.plotly) -&gt; list[Chart]\n</code></pre> <p>Context: Toolbox || Category: Technical || Subcategory: Mandelbrot Channel || Command: generate_plots().</p> <p>Generate plots for each unique symbol in the given dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The LazyFrame containing the symbols and MandelbrotChannelData</p> required <code>equity_data</code> <code>LazyFrame</code> <p>The LazyFrame containing equity data for the symbols.</p> required <code>template</code> <code>ChartTemplate</code> <p>The template/theme to use for the plotly figure.</p> <code>plotly</code> <p>Returns:</p> Type Description <code>list[Chart]</code> <p>A list of Chart objects, each representing a plot for a unique symbol.</p> Source code in <code>src/humbldata/toolbox/technical/mandelbrot_channel/view.py</code> <pre><code>def generate_plots(\n    data: pl.LazyFrame,\n    equity_data: pl.LazyFrame,\n    template: ChartTemplate = ChartTemplate.plotly,\n) -&gt; list[Chart]:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Subcategory: Mandelbrot Channel || **Command: generate_plots()**.\n\n    Generate plots for each unique symbol in the given dataframes.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The LazyFrame containing the symbols and MandelbrotChannelData\n    equity_data : pl.LazyFrame\n        The LazyFrame containing equity data for the symbols.\n    template : ChartTemplate\n        The template/theme to use for the plotly figure.\n\n    Returns\n    -------\n    list[Chart]\n        A list of Chart objects, each representing a plot for a unique symbol.\n\n    \"\"\"\n    symbols = data.select(\"symbol\").unique().collect().to_series()\n\n    plots = [\n        generate_plot_for_symbol(\n            data.collect(), equity_data.collect(), symbol, template\n        )\n        for symbol in symbols\n    ]\n    return plots\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility","title":"volatility","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers","title":"realized_volatility_helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers.</p> <p>All of the volatility estimators used in <code>calc_realized_volatility()</code>. These are various methods to calculate the realized volatility of financial data.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.std","title":"std","text":"<pre><code>std(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _std.</p> <p>This function computes the standard deviation of returns, which is a common measure of volatility.It calculates the rolling standard deviation for a given window size, optionally adjusting for the average number of trading days and scaling the result to an annualized volatility percentage.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data containing the returns. It can be a DataFrame, LazyFrame, or Series.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating the standard deviation. The default is \"1m\" (one month).</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for annualizing the volatility. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>If True, null values will be dropped from the result. The default is True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>If True, the average number of trading days will be used when calculating the window size. The default is True.</p> <code>False</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. This parameter is used when <code>data</code> is a DataFrame or LazyFrame. The default is \"log_returns\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data structure with an additional column for the rolling standard deviation of returns, or the modified Series with the rolling standard deviation values.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def std(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _std**.\n\n    This function computes the standard deviation of returns, which is a common\n    measure of volatility.It calculates the rolling standard deviation for a\n    given window size, optionally adjusting for the average number of trading\n    days and scaling the result to an annualized volatility percentage.\n\n    Parameters\n    ----------\n    data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data containing the returns. It can be a DataFrame, LazyFrame,\n        or Series.\n    window : str, optional\n        The rolling window size for calculating the standard deviation.\n        The default is \"1m\" (one month).\n    trading_periods : int, optional\n        The number of trading periods in a year, used for annualizing the\n        volatility. The default is 252.\n    _drop_nulls : bool, optional\n        If True, null values will be dropped from the result.\n        The default is True.\n    _avg_trading_days : bool, optional\n        If True, the average number of trading days will be used when\n        calculating the window size. The default is True.\n    _column_name_returns : str, optional\n        The name of the column containing the returns. This parameter is used\n        when `data` is a DataFrame or LazyFrame. The default is \"log_returns\".\n\n    Returns\n    -------\n    Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data structure with an additional column for the rolling\n        standard deviation of returns, or the modified Series with the rolling\n        standard deviation values.\n    \"\"\"\n    window_timedelta = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    )\n    if isinstance(data, pl.Series):\n        return data.rolling_std(\n            window_size=window_timedelta.days, min_periods=1\n        )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    # convert window_timedelta to days to use fixed window\n    result = data.lazy().with_columns(\n        (\n            pl.col(_column_name_returns).rolling_std_by(\n                window_size=window_timedelta,\n                min_periods=2,  # using min_periods=2, bc if min_periods=1, the first value will be 0.\n                by=\"date\",\n            )\n            * math.sqrt(trading_periods)\n            * 100\n        ).alias(f\"std_volatility_pct_{window_timedelta.days}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(\n            subset=f\"std_volatility_pct_{window_timedelta.days}D\"\n        )\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.parkinson","title":"parkinson","text":"<pre><code>parkinson(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', *, _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate Parkinson's volatility over a specified window.</p> <p>Parkinson's volatility is a measure that uses the stock's high and low prices of the day rather than just close to close prices. It is particularly useful for capturing large price movements during the day.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the stock prices.</p> required <code>window</code> <code>int</code> <p>The rolling window size for calculating volatility, by default 30.</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, by default 252.</p> required <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The calculated Parkinson's volatility, with an additional column \"parkinson_volatility_pct_{window_int}D\" indicating the percentage volatility.</p> Notes <p>This function requires the input data to have 'high' and 'low' columns to calculate the logarithm of their ratio, which is squared and scaled by a constant to estimate volatility. The result is then annualized and expressed as a percentage.</p> Usage <p>If you pass <code>\"1m</code> as a <code>window</code> argument and  <code>_avg_trading_days=False</code>. The result will be <code>30</code>. If <code>_avg_trading_days=True</code>, the result will be <code>21</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n&gt;&gt;&gt; _parkinson(data)\nA DataFrame with the calculated Parkinson's volatility.\n</code></pre> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def parkinson(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    *,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate Parkinson's volatility over a specified window.\n\n    Parkinson's volatility is a measure that uses the stock's high and low prices\n    of the day rather than just close to close prices. It is particularly useful\n    for capturing large price movements during the day.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the stock prices.\n    window : int, optional\n        The rolling window size for calculating volatility, by default 30.\n    trading_periods : int, optional\n        The number of trading periods in a year, by default 252.\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The calculated Parkinson's volatility, with an additional column\n        \"parkinson_volatility_pct_{window_int}D\"\n        indicating the percentage volatility.\n\n    Notes\n    -----\n    This function requires the input data to have 'high' and 'low' columns to\n    calculate\n    the logarithm of their ratio, which is squared and scaled by a constant to\n    estimate\n    volatility. The result is then annualized and expressed as a percentage.\n\n    Usage\n    -----\n    If you pass `\"1m` as a `window` argument and  `_avg_trading_days=False`.\n    The result will be `30`. If `_avg_trading_days=True`, the result will be\n    `21`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n    &gt;&gt;&gt; _parkinson(data)\n    A DataFrame with the calculated Parkinson's volatility.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    var1 = 1.0 / (4.0 * math.log(2.0))\n    var2 = (\n        data.lazy()\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    rs = var1 * var2**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = data.lazy().with_columns(\n        (\n            rs.rolling_map(_annual_vol, window_size=window_int, min_periods=1)\n            * 100\n        ).alias(f\"parkinson_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(\n            subset=f\"parkinson_volatility_pct_{window_int}D\"\n        )\n\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.garman_klass","title":"garman_klass","text":"<pre><code>garman_klass(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _garman_klass.</p> <p>Calculates the Garman-Klass volatility for a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for volatility calculation, by default \"1m\".</p> <code>'1m'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the opening prices, by default \"open\".</p> <code>'open'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the adjusted closing prices, by default \"close\".</p> <code>'close'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The calculated Garman-Klass volatility, with an additional column \"volatility_pct\" indicating the percentage volatility.</p> Notes <p>Garman-Klass volatility extends Parkinson\u2019s volatility by considering the opening and closing prices in addition to the high and low prices. This approach provides a more accurate estimation of volatility, especially in markets with significant activity at the opening and closing of trading sessions.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def garman_klass(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _garman_klass**.\n\n    Calculates the Garman-Klass volatility for a given dataset.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for volatility calculation, by default \"1m\".\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _column_name_open : str, optional\n        The name of the column containing the opening prices, by default \"open\".\n    _column_name_close : str, optional\n        The name of the column containing the adjusted closing prices, by\n        default \"close\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The calculated Garman-Klass volatility, with an additional column\n        \"volatility_pct\" indicating the percentage volatility.\n\n    Notes\n    -----\n    Garman-Klass volatility extends Parkinson\u2019s volatility by considering the\n    opening and closing prices in addition to the high and low prices. This\n    approach provides a more accurate estimation of volatility, especially in\n    markets with significant activity at the opening and closing of trading\n    sessions.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n    log_hi_lo = (\n        data.lazy()\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    log_close_open = (\n        data.lazy()\n        .select((pl.col(_column_name_close) / pl.col(_column_name_open)).log())\n        .collect()\n        .to_series()\n    )\n    rs: pl.Series = 0.5 * log_hi_lo**2 - (2 * np.log(2) - 1) * log_close_open**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = data.lazy().with_columns(\n        (\n            rs.rolling_map(_annual_vol, window_size=window_int, min_periods=1)\n            * 100\n        ).alias(f\"gk_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"gk_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.hodges_tompkins","title":"hodges_tompkins","text":"<pre><code>hodges_tompkins(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _column_name_returns: str = 'log_returns', *, _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _hodges_tompkins.</p> <p>Hodges-Tompkins volatility is a bias correction for estimation using an overlapping data sample that produces unbiased estimates and a substantial gain in efficiency.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def hodges_tompkins(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _column_name_returns: str = \"log_returns\",\n    *,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _hodges_tompkins**.\n\n    Hodges-Tompkins volatility is a bias correction for estimation using an\n    overlapping data sample that produces unbiased estimates and a\n    substantial gain in efficiency.\n    \"\"\"\n    # When calculating rv_mean, need a different adjustment factor,\n    # so window doesn't influence the Volatility_mean\n    # RV_MEAN\n\n    # Define Window Size\n    window_timedelta = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    )\n    # Calculate STD, assigned to `vol`\n    if isinstance(data, pl.Series):\n        vol = data.rolling_std(window_size=window_timedelta.days, min_periods=1)\n    else:\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.lazy().sort(sort_cols)\n            for col in sort_cols:\n                data = data.set_sorted(col)\n        vol = data.lazy().select(\n            pl.col(_column_name_returns).rolling_std_by(\n                window_size=window_timedelta, min_periods=1, by=\"date\"\n            )\n            * np.sqrt(trading_periods)\n        )\n\n    # Assign window size to h for adjustment\n    h: int = window_timedelta.days\n\n    if isinstance(data, pl.Series):\n        count = data.len()\n    elif isinstance(data, pl.LazyFrame):\n        count = data.collect().shape[0]\n    else:\n        count = data.shape[0]\n\n    n = (count - h) + 1\n    adj_factor = 1.0 / (1.0 - (h / n) + ((h**2 - 1) / (3 * n**2)))\n\n    if isinstance(data, pl.Series):\n        return (vol * adj_factor) * 100\n    else:\n        result = data.lazy().with_columns(\n            ((vol.collect() * adj_factor) * 100)\n            .to_series()\n            .alias(f\"ht_volatility_pct_{h}D\")\n        )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"ht_volatility_pct_{h}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.rogers_satchell","title":"rogers_satchell","text":"<pre><code>rogers_satchell(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _rogers_satchell.</p> <p>Rogers-Satchell is an estimator for measuring the volatility of securities with an average return not equal to zero. Unlike Parkinson and Garman-Klass estimators, Rogers-Satchell incorporates a drift term (mean return not equal to zero). This function calculates the Rogers-Satchell volatility estimator over a specified window and optionally drops null values from the result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data for which to calculate the Rogers-Satchell volatility estimator. This can be either a DataFrame or a LazyFrame. There need to be OHLC columns present in the data.</p> required <code>window</code> <code>str</code> <p>The window over which to calculate the volatility estimator. The window is specified as a string, such as \"1m\" for one month.</p> <code>\"1m\"</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column representing the high prices in the data.</p> <code>\"high\"</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column representing the low prices in the data.</p> <code>\"low\"</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column representing the opening prices in the data.</p> <code>\"open\"</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column representing the adjusted closing prices in the data.</p> <code>\"close\"</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. If True, rows with null values in the calculated volatility column will be removed from the output.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Indicates whether to use the average number of trading days per window. This affects how the window size is interpreted. i.e instead of \"1mo\" returning <code>timedelta(days=31)</code>, it will return <code>timedelta(days=21)</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data with an additional column containing the calculated Rogers-Satchell volatility estimator. The return type matches the input type (DataFrame or LazyFrame).</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def rogers_satchell(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _rogers_satchell**.\n\n    Rogers-Satchell is an estimator for measuring the volatility of\n    securities with an average return not equal to zero. Unlike Parkinson\n    and Garman-Klass estimators, Rogers-Satchell incorporates a drift term\n    (mean return not equal to zero). This function calculates the\n    Rogers-Satchell volatility estimator over a specified window and optionally\n    drops null values from the result.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data for which to calculate the Rogers-Satchell volatility\n        estimator. This can be either a DataFrame or a LazyFrame. There need to\n        be OHLC columns present in the data.\n    window : str, default \"1m\"\n        The window over which to calculate the volatility estimator. The\n        window is specified as a string, such as \"1m\" for one month.\n    _column_name_high : str, default \"high\"\n        The name of the column representing the high prices in the data.\n    _column_name_low : str, default \"low\"\n        The name of the column representing the low prices in the data.\n    _column_name_open : str, default \"open\"\n        The name of the column representing the opening prices in the data.\n    _column_name_close : str, default \"close\"\n        The name of the column representing the adjusted closing prices in the\n        data.\n    _drop_nulls : bool, default True\n        Whether to drop null values from the result. If True, rows with null\n        values in the calculated volatility column will be removed from the\n        output.\n    _avg_trading_days : bool, default True\n        Indicates whether to use the average number of trading days per window.\n        This affects how the window size is interpreted. i.e instead of \"1mo\"\n        returning `timedelta(days=31)`, it will return `timedelta(days=21)`.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data with an additional column containing the calculated\n        Rogers-Satchell volatility estimator. The return type matches the input\n        type (DataFrame or LazyFrame).\n    \"\"\"\n    # Check if all required columns are present in the DataFrame\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n            ]\n        )\n        .with_columns(\n            (\n                pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n            ).alias(\"rs\")\n        )\n    )\n    result = data.lazy().with_columns(\n        (\n            pl.col(\"rs\").rolling_map(\n                _annual_vol, window_size=window_int, min_periods=1\n            )\n            * 100\n        ).alias(f\"rs_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"rs_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.yang_zhang","title":"yang_zhang","text":"<pre><code>yang_zhang(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'close', _avg_trading_days: bool = False, _drop_nulls: bool = True, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _yang_zhang.</p> <p>Yang-Zhang volatility is the combination of the overnight (close-to-open volatility), a weighted average of the Rogers-Satchell volatility and the day\u2019s open-to-close volatility.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def yang_zhang(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"close\",\n    _avg_trading_days: bool = False,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _yang_zhang**.\n\n    Yang-Zhang volatility is the combination of the overnight\n    (close-to-open volatility), a weighted average of the Rogers-Satchell\n    volatility and the day\u2019s open-to-close volatility.\n    \"\"\"\n    # check required columns\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n                (pl.col(_column_name_open) / pl.col(_column_name_close).shift())\n                .log()\n                .alias(\"log_oc\"),\n                (\n                    pl.col(_column_name_close)\n                    / pl.col(_column_name_close).shift()\n                )\n                .log()\n                .alias(\"log_cc\"),\n            ]\n        )\n        .with_columns(\n            [\n                (pl.col(\"log_oc\") ** 2).alias(\"log_oc_sq\"),\n                (pl.col(\"log_cc\") ** 2).alias(\"log_cc_sq\"),\n                (\n                    pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                    + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n                ).alias(\"rs\"),\n            ]\n        )\n    )\n\n    k = 0.34 / (1.34 + (window_int + 1) / (window_int - 1))\n    data = _yang_zhang_engine(data=data, window=window_int)\n    result = (\n        data.lazy()\n        .with_columns(\n            (\n                (\n                    pl.col(\"open_vol\")\n                    + k * pl.col(\"close_vol\")\n                    + (1 - k) * pl.col(\"window_rs\")\n                ).sqrt()\n                * np.sqrt(trading_periods)\n                * 100\n            ).alias(f\"yz_volatility_pct_{window_int}D\")\n        )\n        .select(\n            pl.exclude(\n                [\n                    \"log_ho\",\n                    \"log_lo\",\n                    \"log_co\",\n                    \"log_oc\",\n                    \"log_cc\",\n                    \"log_oc_sq\",\n                    \"log_cc_sq\",\n                    \"rs\",\n                    \"close_vol\",\n                    \"open_vol\",\n                    \"window_rs\",\n                ]\n            )\n        )\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"yz_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.squared_returns","title":"squared_returns","text":"<pre><code>squared_returns(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate squared returns over a rolling window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating squared returns, by default \"1m\".</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for scaling the result. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the price data, by default \"close\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data structure with an additional column for the rolling squared returns.</p> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_helpers.py</code> <pre><code>def squared_returns(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate squared returns over a rolling window.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for calculating squared returns, by default \"1m\".\n    trading_periods : int, optional\n        The number of trading periods in a year, used for scaling the result.\n        The default is 252.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _column_name_returns : str, optional\n        The name of the column containing the price data, by default \"close\".\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data structure with an additional column for the rolling\n        squared returns.\n    \"\"\"\n    _check_required_columns(data, _column_name_returns)\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort and sort_cols:\n        data = data.lazy().sort(sort_cols)\n        for col in sort_cols:\n            data = data.set_sorted(col)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = data.lazy().with_columns(\n        ((pl.col(_column_name_returns) * 100) ** 2).alias(\"sq_log_returns_pct\")\n    )\n    # Calculate rolling squared returns\n    result = (\n        data.lazy()\n        .with_columns(\n            pl.col(\"sq_log_returns_pct\")\n            .rolling_mean(window_size=window_int, min_periods=1)\n            .alias(f\"sq_volatility_pct_{window_int}D\")\n        )\n        .drop(\"sq_log_returns_pct\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"sq_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_model","title":"realized_volatility_model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>A command to generate Realized Volatility for any time series. A complete set of volatility estimators based on Euan Sinclair's Volatility Trading</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_model.calc_realized_volatility","title":"calc_realized_volatility","text":"<pre><code>calc_realized_volatility(data: DataFrame | LazyFrame, window: str = '1m', method: Literal['std', 'parkinson', 'garman_klass', 'gk', 'hodges_tompkins', 'ht', 'rogers_satchell', 'rs', 'yang_zhang', 'yz', 'squared_returns', 'sq'] = 'std', grouped_mean: list[int] | None = None, _trading_periods: int = 252, _column_name_returns: str = 'log_returns', _column_name_close: str = 'close', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', *, _sort: bool = True) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>Calculates the Realized Volatility for a given time series based on the provided standard and extra parameters. This function adds ONE rolling volatility column to the input DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Realized Volatility.</p> required <code>window</code> <code>str</code> <p>The window size for a rolling volatility calculation, default is <code>\"1m\"</code> (1 month).</p> <code>'1m'</code> <code>method</code> <code>Literal['std', 'parkinson', 'garman_klass', 'hodges_tompkins', 'rogers_satchell', 'yang_zhang', 'squared_returns']</code> <p>The volatility estimator to use. You can also use abbreviations to access the same methods. The abbreviations are: <code>gk</code> for <code>garman_klass</code>, <code>ht</code> for <code>hodges_tompkins</code>, <code>rs</code> for <code>rogers_satchell</code>, <code>yz</code> for <code>yang_zhang</code>, <code>sq</code> for <code>squared_returns</code>.</p> <code>'std'</code> <code>grouped_mean</code> <code>list[int] | None</code> <p>A list of window sizes to use for calculating volatility. If provided, the volatility method will be calculated across these various windows, and then an averaged value of all the windows will be returned. If <code>None</code>, a single window size specified by <code>window</code> parameter will be used.</p> <code>None</code> <code>_sort</code> <code>bool</code> <p>If True, the data will be sorted before calculation. Default is True.</p> <code>True</code> <code>_trading_periods</code> <code>int</code> <p>The number of trading periods in a year, default is 252 (the typical number of trading days in a year).</p> <code>252</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. Default is \"log_returns\".</p> <code>'log_returns'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the close prices. Default is \"close\".</p> <code>'close'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices. Default is \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices. Default is \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the open prices. Default is \"open\".</p> <code>'open'</code> <p>Returns:</p> Type Description <code>VolatilityData</code> <p>The calculated Realized Volatility data for the given time series.</p> Notes <ul> <li> <p>Rolling calculations are used to show a time series of recent volatility that captures only a certain number of data points. The window size is used to determine the number of data points to use in the calculation. We do this because when looking at the volatility of a stock, you get a better insight (more granular) into the characteristics of the volatility seeing how 1-month or 3-month rolling volatility looked over time.</p> </li> <li> <p>This function does not accept <code>pl.Series</code> because the methods used to calculate volatility require, high, low, close, open columns for the data. It would be too cumbersome to pass each series needed for the calculation as a separate argument. Therefore, the function only accepts <code>pl.DataFrame</code> or <code>pl.LazyFrame</code> as input.</p> </li> </ul> Source code in <code>src/humbldata/toolbox/technical/volatility/realized_volatility_model.py</code> <pre><code>def calc_realized_volatility(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    method: Literal[  # used to be rvol_method\n        \"std\",\n        \"parkinson\",\n        \"garman_klass\",\n        \"gk\",\n        \"hodges_tompkins\",\n        \"ht\",\n        \"rogers_satchell\",\n        \"rs\",\n        \"yang_zhang\",\n        \"yz\",\n        \"squared_returns\",\n        \"sq\",\n    ] = \"std\",\n    grouped_mean: list[int] | None = None,  # used to be rv_mean\n    _trading_periods: int = 252,\n    _column_name_returns: str = \"log_returns\",\n    _column_name_close: str = \"close\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: calc_realized_volatility**.\n\n    Calculates the Realized Volatility for a given time series based on the\n    provided standard and extra parameters. This function adds ONE rolling\n    volatility column to the input DataFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Realized Volatility.\n    window : str\n        The window size for a rolling volatility calculation, default is `\"1m\"`\n        (1 month).\n    method : Literal[\"std\", \"parkinson\", \"garman_klass\", \"hodges_tompkins\",\"rogers_satchell\", \"yang_zhang\", \"squared_returns\"]\n        The volatility estimator to use. You can also use abbreviations to\n        access the same methods. The abbreviations are: `gk` for `garman_klass`,\n        `ht` for `hodges_tompkins`, `rs` for `rogers_satchell`, `yz` for\n        `yang_zhang`, `sq` for `squared_returns`.\n    grouped_mean : list[int] | None\n        A list of window sizes to use for calculating volatility. If provided,\n        the volatility method will be calculated across these various windows,\n        and then an averaged value of all the windows will be returned. If `None`,\n        a single window size specified by `window` parameter will be used.\n    _sort : bool\n        If True, the data will be sorted before calculation. Default is True.\n    _trading_periods : int\n        The number of trading periods in a year, default is 252 (the typical\n        number of trading days in a year).\n    _column_name_returns : str\n        The name of the column containing the returns. Default is \"log_returns\".\n    _column_name_close : str\n        The name of the column containing the close prices. Default is \"close\".\n    _column_name_high : str\n        The name of the column containing the high prices. Default is \"high\".\n    _column_name_low : str\n        The name of the column containing the low prices. Default is \"low\".\n    _column_name_open : str\n        The name of the column containing the open prices. Default is \"open\".\n\n    Returns\n    -------\n    VolatilityData\n        The calculated Realized Volatility data for the given time series.\n\n    Notes\n    -----\n    - Rolling calculations are used to show a time series of recent volatility\n    that captures only a certain number of data points. The window size is\n    used to determine the number of data points to use in the calculation. We do\n    this because when looking at the volatility of a stock, you get a better\n    insight (more granular) into the characteristics of the volatility seeing how 1-month or\n    3-month rolling volatility looked over time.\n\n    - This function does not accept `pl.Series` because the methods used to\n    calculate volatility require, high, low, close, open columns for the data.\n    It would be too cumbersome to pass each series needed for the calculation\n    as a separate argument. Therefore, the function only accepts `pl.DataFrame`\n    or `pl.LazyFrame` as input.\n    \"\"\"  # noqa: W505\n    # Step 1: Get the correct realized volatility function =====================\n    func = VOLATILITY_METHODS.get(method)\n    if not func:\n        msg = f\"Volatility method: '{method}' is not supported.\"\n        raise HumblDataError(msg)\n\n    # Step 2: Get the names of the parameters that the function accepts ========\n    func_params = inspect.signature(func).parameters\n\n    # Step 3: Filter out the parameters not accepted by the function ===========\n    args_to_pass = {\n        key: value for key, value in locals().items() if key in func_params\n    }\n\n    # Step 4: Calculate Realized Volatility ====================================\n    if grouped_mean:\n        # calculate volatility over multiple windows and average the result, add to a new column\n        print(\"\ud83d\udea7 WIP!\")\n    else:\n        out = func(**args_to_pass)\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.quantitative","title":"quantitative","text":"<p>Context: Toolbox || Category: Quantitative.</p> <p>Quantitative indicators rely on statistical transformations of time series data.</p>"},{"location":"contributing/","title":"Index","text":""},{"location":"contributing/#expectations-for-contributors","title":"\ud83c\udfaf Expectations for Contributors","text":"<p>Here is a set of guidelines that you should follow:</p> <ol> <li> <p>Use Cases:</p> <ul> <li>Ensure that your contributions directly enhance the humbldata's functionality or extension ecosystem.</li> </ul> </li> <li> <p>Documentation:</p> <ul> <li>All code contributions should come with relevant documentation, including the purpose of the contribution, how it works, and any changes it makes to existing functionalities.</li> <li>Update any existing documentation if your contribution alters the behavior of the humbldata.</li> </ul> </li> <li> <p>Code Quality:</p> <ul> <li>Your code should adhere strictly to the humbldata's coding standards and conventions.</li> <li>Ensure clarity, maintainability, and proper organization in your code.</li> </ul> </li> <li> <p>Testing:</p> <ul> <li>All contributions must be thoroughly tested to avoid introducing bugs to the humbldata.</li> <li>Contributions should include relevant automated tests (unit and integration), and any new feature should come with its test cases.</li> </ul> </li> <li> <p>Performance:</p> <ul> <li>Your contributions should be optimized for performance and should not degrade the overall efficiency of the humbldata.</li> <li>Address any potential bottlenecks and ensure scalability.</li> </ul> </li> <li> <p>Collaboration:</p> <ul> <li>Engage actively with the humbldata development team to ensure that your contributions align with the platform's roadmap and standards.</li> <li>Welcome feedback and be open to making revisions based on reviews and suggestions from the community.</li> </ul> </li> <li> <p>We acknowledge and thank the OpenBB team for creating such well documented Guidelines.</p> </li> </ol>"},{"location":"contributing/adding_function/","title":"Adding a Function","text":""},{"location":"contributing/adding_function/#adding-a-function","title":"\u2795 Adding a Function","text":"<p>If you want to add a function, first you must decide. What is the context, category and command? Once, you have done that you will need to do these 3 things:</p>"},{"location":"contributing/adding_function/#define-queryparams-and-data-standard-model","title":"Define <code>QueryParams</code> and <code>Data</code> Standard Model.","text":"<p>Put your new standard model in:</p> <pre><code>humbldata.core.standard_models.&lt;context&gt;.&lt;category&gt;.&lt;your_func&gt;\n</code></pre> <p>This should be a <code>.py</code> file. <pre><code>~\\humbldata\\src\\humbldata\\core\\standard_models\\&lt;context&gt;\\&lt;category&gt;\\&lt;command&gt;.py\n</code></pre></p> <p>You will then define two classes: <code>QueryParams</code> and <code>Data</code>. The fields used to query the data and then the returned data fields, respectively.</p> <p><pre><code>\"\"\"\n&lt;Your Function&gt; Standard Model.\n\nContext: Toolbox || Category: Technical || Command: &lt;Your Function&gt;.\n\nThis module is used to define the QueryParams and Data model for the\n&lt;Your Function&gt; command.\n\"\"\"\nfrom humbldata.core.standard_models.abstract.data import Data\nfrom humbldata.core.standard_models.abstract.query_params import QueryParams\nclass &lt;YourFunc&gt;QueryParams(QueryParams):\n    \"\"\"\n    QueryParam for the &lt;Your Function&gt; command.\n    \"\"\"\nclass &lt;YourFunc&gt;Data(Data):\n    \"\"\"\n    Data model for the &lt;Your Function&gt; command.\n    \"\"\"\n</code></pre> 2. ### Add the Function Logic (model.py) to the <code>Context</code> module</p> <p>Each <code>&lt;command&gt;</code> has a <code>model.py</code>, <code>view.py</code> and <code>helper.py</code> file.</p> <p>Add these files to the <code>Context</code> module. <pre><code>humbldata/\n\u251c\u2500\u2500 &lt;context&gt;/\n\u2502   \u251c\u2500\u2500 &lt;category&gt;/\n\u2502   \u2502   \u251c\u2500\u2500 &lt;your_func&gt;/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 view.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 helper.py\n\nhumbldata.&lt;context&gt;.&lt;category&gt;.&lt;your_func&gt;.model/view/helper.py\n\n# i.e\n\nhumbldata/\n\u251c\u2500\u2500 toolbox/\n\u2502   \u251c\u2500\u2500 technical/\n\u2502   \u2502   \u251c\u2500\u2500 mandelbrot_channel/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 view.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 helper.py\n\nhumbldata.toolbox.technical.mandelbrot_channel.model\n</code></pre></p> <p>!!! tip</p> <p>It is common practice in the repo to prepend your logic function, in the <code>model.py</code> file, with <code>calc_...</code>.  So the function would be <code>calc_mandelbrot_channel</code>.  There are two main naming schemes for functions:  - <code>calc</code>: These are the functions that calculate raw data, heavy math, etc.  - <code>engine</code>: These are the functions that provide logic for the function, it could be aggregation of data, manipulation of data, but are less math focused and more like a pipeline to get data from one point to another.</p>"},{"location":"contributing/adding_test/","title":"Adding a Test","text":""},{"location":"contributing/adding_test/#adding-a-test","title":"\ud83e\uddea Adding a Test","text":""},{"location":"contributing/adding_test/#test-requirements","title":"Test Requirements","text":"<p>It is required to add tests to cover all the code that you add to the package. Here are the guidelines to help you organize the tests you need to add.</p>"},{"location":"contributing/adding_test/#overview","title":"Overview","text":"<p>Tests are categorized into two main types: 1. Unit Tests:    - These test individual units of functionality.    - They should be independent from other tests and external dependencies. 2. Integration Tests:    - These test the combination of units working together.    - They verify full functionality and interaction between components.</p>"},{"location":"contributing/adding_test/#test-organization","title":"Test Organization","text":"<p>The tests should be organized according to the CCCC framework: Core, Context, Category, Command. The directory structure for tests should reflect this organization.</p>"},{"location":"contributing/adding_test/#directory-structure","title":"Directory Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 context/\n\u2502   \u2502   \u251c\u2500\u2500 category/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 command/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 test_queryParams_data_fetcher.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 test_view.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 test_model.py\n\u2502   \u2502   \u251c\u2500\u2500 test_methods.py\n\u2502   \u2514\u2500\u2500 test_queryParams.py\n\u2514\u2500\u2500 unittests/\n    \u251c\u2500\u2500 context/\n    \u2502   \u251c\u2500\u2500 category/\n    \u2502   \u2502   \u251c\u2500\u2500 command/\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 test_helpers.py\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 test_view.py\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 test_model.py\n    \u2502   \u2502   \u251c\u2500\u2500 test_methods.py\n    \u251c\u2500\u2500 test_helpers.py\n</code></pre>"},{"location":"contributing/adding_test/#detailed-list-of-all-tests","title":"\ud83d\udcdd Detailed List of All Tests","text":""},{"location":"contributing/adding_test/#integration-tests","title":"Integration Tests","text":"<ul> <li>Context: Toolbox<ul> <li><code>test_queryParams.py</code> - test the <code>standard_models</code></li> </ul> </li> <li>Category: Technical<ul> <li><code>test_methods.py</code> - test the methods in the class, and ensure they pass the parameters and instantiate the class correctly</li> </ul> </li> <li>Command: mandelbrot_channel<ul> <li><code>test_queryParams_data_fetcher.py</code> - test the <code>fetcher</code> gets the data correctly and verify it with the standard_models. i.e <code>MandelbrotData()</code></li> <li><code>test_view.py</code> - test the charting visualization creates the right charts</li> <li><code>test_model.py</code> - test logic of functions, uses live data to ensure function runs properly</li> </ul> </li> </ul>"},{"location":"contributing/adding_test/#unit-tests","title":"Unit Tests","text":"<ul> <li>Context: Toolbox<ul> <li><code>test_helpers.py</code> - test the <code>helpers</code> statically</li> </ul> </li> <li>Category: Technical<ul> <li><code>test_methods.py</code> (mock) - test the <code>methods</code> but mock the classes so that there are no dependencies on classes actually instantiating themselves.</li> </ul> </li> <li>Command: mandelbrot_channel<ul> <li><code>test_helpers.py</code> - test the <code>helpers</code> statically</li> <li><code>test_view.py</code> - test the charting visualization returns the correct objects</li> <li><code>test_model.py</code> - test the logic of functions and input validation</li> </ul> </li> </ul> <p>!!! tip Use <code>__init__.py</code> files to group tests together.</p> <p>You should use <code>__init__.py</code> files to group tests together and provide the correct namespace for <code>pytest</code> to find each of the tests, because I have chosen a design pattern to name multiple tests with the same name, and they are just nested in their respective directory.</p> <p>!!! example Check <code>/tests</code> for examples</p> <p>Take a look at tests that have already been created to get a sense of how to test your classes and functions.</p> <p>!!! warning When you update Polars version, you need to update the <code>humblobject</code> pickle files as serialization is not always backwards compatible.</p>"},{"location":"contributing/adding_test/#expectations-for-test-creation","title":"Expectations for Test Creation","text":"<ul> <li>Independence: Ensure unit tests do not rely on external systems or other tests.</li> <li>Comprehensiveness: Write tests to cover all possible edge cases.</li> <li>Clarity: Name tests clearly to indicate what functionality they cover.</li> <li>Consistency: Follow the CCCC framework for organizing tests.</li> <li>Documentation: Document any non-trivial logic within the tests for future reference.</li> </ul>"},{"location":"contributing/best_practices/","title":"Best Practices","text":""},{"location":"contributing/best_practices/#best-practices","title":"\ud83c\udfc6 Best Practices","text":"<ul> <li>Review Platform Dependencies: Before adding any dependency, ensure it aligns with the Platform's existing dependencies.</li> <li>Use Loose Versioning: If possible, specify a range to maintain compatibility. E.g., <code>&gt;=1.4,&lt;1.5</code>.</li> <li>Testing: Test your extension with the Platform's core to avoid conflicts. Both unit and integration tests are recommended.</li> <li>Document Dependencies: Use <code>pyproject.toml</code> and <code>poetry.lock</code> for clear, up-to-date records</li> </ul>"},{"location":"contributing/code_standards/","title":"Code Standards","text":""},{"location":"contributing/code_standards/#code-standards","title":"\ud83d\udc0d Code Standards","text":""},{"location":"contributing/code_standards/#pep-guidelines","title":"\ud83e\udebaPEP Guidelines","text":"<p>You must adhere to the strict guidelines of coding best practices. Here is a non-exhaustive list of the most important guidelines to follow:</p> <ol> <li>PEP 8: This is the de-facto code style guide for Python. It is a set of conventions for how to format your Python code to maximize its readability.<ul> <li>It is a set of conventions for how to format your Python code to maximize its readability.</li> </ul> </li> <li>PEP 484: This PEP introduces a standard for type annotations in Python. It aims to provide a standard syntax for type annotations, opening up Python code to easier static analysis and refactoring.<ul> <li>It aims to provide a standard syntax for type annotations, opening up Python code to easier static analysis and refactoring.</li> </ul> </li> <li>PEP 621: This PEP introduces a mechanism to specify project metadata in a standardized way. It aims to provide a standard way to specify project metadata, making it easier for tools to work with Python projects.<ul> <li>It aims to provide a standard way to specify project metadata, making it easier for tools to work with Python projects.</li> </ul> </li> <li>PEP 20: This PEP is a set of aphorisms that capture the guiding principles of Python's design. It is a must-read for any Python developer.<ul> <li>It is a set of aphorisms that capture the guiding principles of Python's design. It is a must-read for any Python developer.</li> </ul> </li> </ol> The Zen of Python <p>Beautiful is better than ugly.</p> <p>Explicit is better than implicit.</p> <p>Simple is better than complex.</p> <p>Complex is better than complicated.</p> <p>Flat is better than nested.</p> <p>Sparse is better than dense.</p> <p>Readability counts.</p> <p>Special cases aren't special enough to break the rules.</p> <p>Although practicality beats purity.</p> <p>Errors should never pass silently.</p> <p>Unless explicitly silenced.</p> <p>In the face of ambiguity, refuse the temptation to guess.</p> <p>There should be one-- and preferably only one --obvious way to do it.</p> <p>Although that way may not be obvious at first unless you're Dutch.</p> <p>Now is better than never.</p> <p>Although never is often better than right now.</p> <p>If the implementation is hard to explain, it's a bad idea.</p> <p>If the implementation is easy to explain, it may be a good idea.</p> <p>Namespaces are one honking great idea -- let's do more of those!</p>"},{"location":"getting_started/","title":"\ud83c\udfc1 Getting Started","text":"<p>Welcome to the Getting Started guide for the humbldata package. This guide will provide you with an overview of the package and its capabilities.</p>"},{"location":"getting_started/#what-is-humbldata","title":"\ud83d\udce6 What is humbldata?","text":"<p>The humbldata package is a comprehensive data analysis tool that provides a wide range of functionalities for working with financial data. It is designed to be user-friendly and efficient, making it a valuable tool for both beginners and experienced data analysts.</p>"},{"location":"getting_started/#how-was-humbldata-built","title":"\ud83d\udee0 How was humbldata built?","text":"<p>The focus of this package was to be built on a hyper-modern python stack:</p>"},{"location":"getting_started/#features","title":"Features","text":"<ul> <li>\ud83e\uddd1\u200d\ud83d\udcbb Quick and reproducible development environments with VS Code's Dev Containers, PyCharm's Docker Compose interpreter, and GitHub Codespaces</li> <li>\ud83c\udf08 Cross-platform support for Linux, macOS (Apple silicon and Intel), and Windows</li> <li>\ud83d\udce6 Packaging and dependency management with Poetry</li> <li>\ud83c\udf0d Environment management with Micromamba</li> <li>\ud83d\udcd6 Comprehensive documentation generation with MkDocs</li> <li>\ud83d\ude9a Installing from and publishing to private package repositories and PyPI</li> <li>\u26a1\ufe0f Task running with Poe the Poet</li> <li>\u270d\ufe0f Code formatting with Ruff</li> <li>\u2705 Code linting with Pre-commit, Mypy, and Ruff</li> <li>\ud83c\udff7\ufe0f Optionally follows the Conventional Commits standard to automate Semantic Versioning and Keep A Changelog with Commitizen</li> <li>\ud83d\udc8c Verified commits with GPG</li> <li>\u267b\ufe0f Continuous integration with GitHub Actions or GitLab CI/CD</li> <li>\ud83e\uddea Test coverage with Coverage.py</li> <li>\ud83c\udfd7 Scaffolding updates with Cookiecutter and Cruft</li> <li>\ud83e\uddf0 Dependency updates with Dependabot</li> </ul>"},{"location":"getting_started/#project-organization","title":"\ud83d\udcc2 Project Organization","text":"<ul> <li><code>.github/workflows</code>: Contains GitHub Actions used for building, testing, and publishing.</li> <li><code>.devcontainer/Dockerfile</code>: Contains Dockerfile to build a development container for VSCode with all the necessary extensions for Python development installed.</li> <li><code>.devcontainer/devcontainer.json</code>: Contains the configuration for the development container for VSCode, including the Docker image to use, any additional VSCode extensions to install, and whether or not to mount the project directory into the container.</li> <li><code>.vscode/settings.json</code>: Contains VSCode settings specific to the project, such as the Python interpreter to use and the maximum line length for auto-formatting.</li> <li><code>src</code>: Place new source code here.</li> <li><code>tests</code>: Contains Python-based test cases to validate source code.</li> <li><code>pyproject.toml</code>: Contains metadata about the project and configurations for additional tools used to format, lint, type-check, and analyze Python code.</li> <li><code>.prompts/</code>: Contains useful prompts to use during development for modifying and generating code and tests.</li> </ul>"},{"location":"getting_started/configuration/","title":"\u2699\ufe0f Configuration","text":""},{"location":"getting_started/development_setup/","title":"\ud83c\udfd7\ufe0f Development Setup","text":"<p>Here, you will find all the settings needed to setup your machine to contribute to the project, and also understand the coding practices that went into making this package, so you can follow along and understand the code structure.</p>"},{"location":"getting_started/development_setup/#environment-setup","title":"Environment Setup","text":"<p>You can add a <code>.env</code> file to the root of the project to set environment variables. This is useful if you want to use your own Personal Access Token via OpenBB for your own data vendor support. Just set the <code>OBB_PAT</code> variable to your own key.</p> Useful Developer Commands <ul> <li><code>micromamba activate -p ./menv</code>: activate the micromamba env</li> <li><code>poe</code>: list all the available commands for the package</li> <li><code>poetry add {package}</code>: install a run time dependency and add it to <code>pyproject.toml</code> and <code>poetry.lock</code>. Add <code>--group test</code> or <code>--group dev</code> to install a test or development dependency, respectively.</li> <li><code>poetry update</code>: upgrade all dependencies to the latest versions allowed by <code>pyproject.toml</code>.</li> <li><code>cz bump</code>: bump the package's version, update the <code>CHANGELOG.md</code>, and create a git tag, settings can be made in both <code>cz-config.js</code> and <code>bumpversion.yml</code>.</li> <li><code>cruft update</code>: update the current project to mirror the latest cookiecutter template</li> <li><code>mkdocs serve</code>: start a server for documentation</li> </ul>"},{"location":"getting_started/development_setup/#hooks","title":"\ud83c\udfa3 Hooks","text":"<p>This project uses two hooks, <code>pre_gen_project.py</code> and <code>post_gen_project.py</code>, which are scripts that run before and after the project generation process, respectively. <code>post_gen_project.py</code> is repsonsible for setting up the micromamba environment.</p>"},{"location":"getting_started/development_setup/#cruft","title":"\ud83c\udf6a Cruft","text":"<p>This project uses cruft to manage the template and update the project with the latest changes. This has one caveat for now. While using commitizen and customizing the commit messages in <code>pyproject.toml</code> the <code>cruft update</code> command will not work as expected. I think because emojis in the <code>pyproject.toml</code> are not read with the correct encoding.</p> Solution <p>If you need to perform a <code>cruft update</code>, please just remove the sections with emojis, and run <code>cruft update</code>. Then, you will be able to insert the emojis defined in the <code>[tool.commitizen.customize]</code> from the original template, after the update has completed.</p> <p>I should look to move to just use <code>czg</code> or <code>cz-git</code> instead of <code>commitizen</code> + <code>cz-customizable</code> + <code>cz-conventional-gitmoji</code>.</p> Manually Upload <code>pyproject.toml</code> content <p>If you need to manually add the emojis to the <code>pyproject.toml</code> file, you can use the following code to add the emojis to the <code>pyproject.toml</code> file.</p> <pre><code>[tool.commitizen]\nname = \"cz_gitmoji\"\nversion = \"0.11.4\"\ntag_format = \"v$version\"\nupdate_changelog_on_bump = true\nannotated_tag = true\nbump_message = \"\ud83d\udd16 bump(release): v$current_version \u2192 v$new_version\"\nversion_files = [\"pyproject.toml:^version\"]\npath = \".cz-config.js\"\n\n[tool.commitizen.customize]\nexample = \"feat: this feature enables customizing through pyproject.toml file\"\nschema = \"\"\"\n&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt; \\n\n&lt;BLANK LINE&gt; \\n\n&lt;body&gt; \\n\n&lt;BLANK LINE&gt; \\n\n(BREAKING CHANGE: )&lt;breaking&gt; \\n\n&lt;BLANK LINE&gt; \\n\n(ISSUES: )&lt;footer&gt;\n\"\"\"\nschema_pattern = \"(?s)(\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\ud83d\udd27 chore|\u267b\ufe0f refactor|\ud83d\udea7 WIP|\ud83d\udcda docs|\u26a1\ufe0f perf|\ud83d\udc84 style|\ud83c\udfd7\ufe0f build|\ud83d\udc77 ci|\u2705 test|\u23ea revert|\u2795 add_dep|\u2796 rem_dep)(\\\\(\\\\S+\\\\))?!?:( [^\\\\n\\\\r]+)((\\\\n\\\\n.*)|(\\\\s*))?$\"\nbump_pattern = \"^(\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\u26a1\ufe0f perf|\u267b\ufe0f refactor|\u23ea revert|\u2795 dep-add|\u2796 dep-rm)\"\nbump_map = {\"BREAKING CHANGE\" = \"MAJOR\", \"\u2728 feat\" = \"MINOR\", \"\ud83d\udc1b fix\" = \"PATCH\", \"\ud83d\ude91 hotfix\" = \"PATCH\", \"\u26a1\ufe0f perf\" = \"PATCH\", \"\u267b\ufe0f refactor\" = \"PATCH\"}\nchange_type_order = [\"BREAKING CHANGE\", \"\u2728 feat\", \"\ud83d\udc1b fix\", \"\ud83d\ude91 hotfix\", \"\u267b\ufe0f refactor\", \"\u26a1\ufe0f perf\", \"\ud83c\udfd7\ufe0f build\", \"\ud83d\udc84 style\", \"\ud83d\udcda docs\", \"\u2795 dep-add\", \"\u2796 dep-rm\"]\ninfo_path = \"cz_customize_info.txt\"\ninfo = \"\"\"\nThis is customized commitizen info\n\"\"\"\ncommit_parser = \"^(?P&lt;change_type&gt;\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\ud83d\udd27 chore|\u267b\ufe0f refactor|\ud83d\udea7 WIP|\ud83d\udcda docs|\u26a1\ufe0f perf|\ud83d\udc84 style|\ud83c\udfd7\ufe0f build|\ud83d\udc77 ci|\u2705 test|\u23ea revert|\u2795 dep-add|\u2796 dep-rm):\\\\s(?P&lt;message&gt;.*)?\"\nchangelog_pattern = \"^(\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\ud83d\udd27 chore|\u267b\ufe0f refactor|\ud83d\udea7 WIP|\ud83d\udcda docs|\u26a1\ufe0f perf|\ud83d\udc84 style|\ud83c\udfd7\ufe0f build|\ud83d\udc77 ci|\u2705 test|\u23ea revert|\u2795 dep-add|\u2796 dep-rm)?(!)?\"\nchange_type_map = {\"\ud83c\udfd7\ufe0f build\" = \"Build\", \"\ud83d\udc77 ci\" = \"CI\", \"\ud83d\udcda docs\" = \"Docs\", \"\u2728 feat\" = \"Feat\", \"\ud83d\udc1b fix\" = \"Fix\", \"\ud83d\ude91 hotfix\" = \"Hotfix\", \"\u26a1\ufe0f perf\" = \"Perf\", \"\u267b\ufe0f refactor\" = \"Refactor\", \"\ud83d\udc84 style\" = \"Style\", \"\u2705 test\" = \"Test\", \"\ud83d\udd27 chore\" = \"Chore\", \"\u23ea revert\" = \"Revert\", \"\u2795 dep-add\" = \"Added Dependency\", \"\u2796 dep-rm\" = \"Removed Dependency\"}\n</code></pre>"},{"location":"getting_started/development_setup/#setup-micromamba-environment-with-poetry","title":"\ud83d\udc2d Setup Micromamba Environment with Poetry","text":"<p>This section shows users how to setup your environment using your <code>micromamba</code> file and <code>poetry</code>. This project uses a micromamba environment. The micromamba environment will be automatically setup for you after generating the project from the template using a <code>post_gen_project</code> hook. The following steps are for reference only (if you need to recreate the environment). This assumes you use <code>bash</code> as your shell.</p> Prerequisites <ol> <li>Installing micromamba</li> </ol> <pre><code># Windows (Powershell)\nInvoke-Expression ((Invoke-WebRequest -Uri https://micro.mamba.pm/install.ps1).Content)\n</code></pre> <pre><code># Linux and macOS\n\"${SHELL}\" &lt;(curl -L micro.mamba.pm/install.sh)\n</code></pre> Creating Micromamba Environment <ol> <li> <p>I created the environment with a <code>--prefix</code> and not a name, to ensure that it installed in my project directory, not the default path. This is executed in the project root dir.</p> <pre><code>micromamba env create --file micromamba_env.yml\n</code></pre> </li> <li> <p>To avoid displaying the full path when using this environment, modify the <code>.condarc</code> file to show the environment name as the last directory where the environment is located. This can be done manually or by running the command <code>micromamba config --set env_prompt '({name})'</code>.</p> <pre><code>micromamba config --set env_prompt '({name})'\n</code></pre> <p>After the modification, your <code>.condarc</code> file should look like this:</p> <pre><code>channels:\n  - conda-forge\n  - defaults\nenv_prompt: ({name})\nrepodata_threads: 2\nchange_ps1: false\nenvs_dirs:\n  - ~/micromamba/envs\n</code></pre> </li> <li> <p>Activate the environment</p> <pre><code>micromamba init bash / micromamba init zsh\nmicromamba activate ./menv\n</code></pre> </li> <li> <p>Check if poetry is installed</p> <pre><code>poetry --version\n# make sure it is the latest version\n# can use mamba search -f poetry\n</code></pre> </li> <li> <p>If poetry is showing any errors like:</p> <ul> <li><code>Failed to create process</code></li> <li><code>No Python at &lt;path&gt;</code></li> </ul> <p>You can simply run: <pre><code>micromamba remove -p ./menv poetry\nmicromamba install -p ./menv poetry\n</code></pre></p> </li> <li> <p>If the python version doesnt match, just install the version you would like:</p> <pre><code>micromamba install -p ./menv python=3.12.1\n</code></pre> </li> <li> <p>Install Packages from <code>poetry.lock</code> / <code>pyproject.toml</code></p> <pre><code>poetry install\n</code></pre> </li> </ol> Setting Up <code>Commitizen</code> <p>I am using the <code>vscode-commitizen</code> extension to integrate <code>commitizen</code> into my workflow. This allows for nice keyboard shortcuts and UI integration. I have also installed <code>cz_customizable</code> globally to allow me to customize the commit message template using <code>cz-config.js</code>.</p> <p>The <code>pyproject.toml</code> file has the specifications for <code>cz_customizable</code> and <code>commitizen</code> to work together.</p> <p>Follow the quickstart guide to setup <code>cz-customizable</code>. You need to install <code>cz-customizable</code> globally in order for the vscode extension to work along with the settings provided in the <code>pyproject.toml</code> file. This will allow for custom commit types and user-specific settings.</p> <p>You need these two files, to ensure automatic commit linting, and package versioning.</p> <ul> <li> <code>./pre-commit-config.yml</code></li> <li> <code>./github/workflows/bumpversion.yml</code></li> </ul>"},{"location":"getting_started/development_setup/#setup-github-workflows","title":"\u26a1 Setup Github Workflows","text":"<p>There are 4 pre-made github actions that are used with this package. Some actions require API_KEYS/TOKENS to work. Add your tokens to the secrets manager in your repo settings.</p> 1. <code>bump.yml</code> <p>This workflow automates the versioning of the project using bumpversion. - Tokens/Secrets:     - <code>GH_PAT</code>: Github Personal Access Token You need to create a Github Personal Access Token and add it to your secrets manager in your repo settings.</p> 2. <code>deploy.yml</code> <p>This workflow is responsible for deploying the project. It is triggered on push events that include tags in the format \"v(x.x.x)\" and also manually through the GitHub Actions UI.</p> <p>The workflow runs on an Ubuntu-latest environment and only if the GitHub reference starts with 'refs/tags/v'.</p> <ul> <li>Steps:<ul> <li>Checking out the repository.</li> <li>Logging into the Docker registry.</li> <li>Setting the Docker image tag.</li> <li>Building and pushing the Docker image.</li> </ul> </li> <li>Tokens/Secrets:<ul> <li><code>GITHUB_TOKEN</code>: This is a GitHub secret used for authentication.</li> <li><code>DOCKER_REGISTRY</code>: This is an environment variable set to 'ghcr.io'.</li> <li><code>DEFAULT_DEPLOYMENT_ENVIRONMENT</code>: This is an environment variable set to 'feature'.</li> <li><code>POETRY_HTTP_BASIC__USERNAME</code>: This is a secret used for authentication with the private package repository.</li> <li><code>POETRY_HTTP_BASIC__PASSWORD</code>: This is a secret used for authentication with the private package repository.</li> </ul> </li> </ul> 3. <code>publish.yml</code> <p>This workflow is responsible for publishing the project. It is triggered when a new release is created.</p> <p>The workflow runs on an Ubuntu-latest environment.</p> <ul> <li>Steps:<ul> <li>Checking out the repository.</li> <li>Setting up Python with the specified version.</li> <li>Installing Poetry, a tool for dependency management and packaging in Python.</li> <li>Publishing the package using Poetry. If a private package repository is specified, the package is published there. Otherwise, it is published to PyPi.</li> </ul> </li> <li>Tokens/Secrets:<ul> <li><code>GITHUB_TOKEN</code>: This is a GitHub secret used for authentication.</li> <li><code>POETRY_HTTP_BASIC__USERNAME</code>: This is a secret used for authentication with the private package repository.</li> <li><code>POETRY_HTTP_BASIC__PASSWORD</code>: This is a secret used for authentication with the private package repository.</li> <li><code>POETRY_PYPI_TOKEN_PYPI</code>: This is a secret used for authentication with PyPi, if the package is being published there.</li> </ul> </li> </ul> 4. <code>test.yml</code> <p>This workflow is responsible for testing the project. It is triggered on push events to the main and master branches, and on pull requests.</p> <p>The workflow runs on an Ubuntu-latest environment and uses the specified Python version.</p> <ul> <li>Steps:<ul> <li>Checking out the repository.</li> <li>Setting up Node.js with the specified version.</li> <li>Installing @devcontainers/cli.</li> <li>Starting the Dev Container.</li> <li>Linting the package.</li> <li>Testing the package.</li> <li>Uploading coverage.</li> </ul> </li> <li>Tokens/Secrets:<ul> <li><code>GITHUB_TOKEN</code>: This is a GitHub secret used for authentication.</li> </ul> </li> </ul>"},{"location":"getting_started/installation/","title":"\ud83d\udcf2 Installation","text":"<p>To install the humbldata package, simply run the following command in your terminal:</p> <p><pre><code>pip install humbldata\n</code></pre> If you are using poetry: <pre><code>poetry add humbldata\n</code></pre></p>"},{"location":"getting_started/usage/","title":"\ud83d\udee0\ufe0f Usage","text":"<p>We recommend starting with the Toolbox module, which is the entry point for all data analysis in the humbldata package. From there, you can explore the various functionalities and tools available in the package.</p> <p>We hope you find the humbldata package to be a valuable addition to your data analysis toolkit. Happy analyzing!</p>"}]}