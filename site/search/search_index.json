{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"humbldata <p>the humbldata package connects the humblfinance web app to its data sources and in-house analysis. A thin wrapper around the most popular open-source financial data providers, with some extra flair to use the same tools and math as the big guys. how do i know? because i used to pay a pretty penny for it! no longer... OSS is here to save the day</p>"},{"location":"contributing/","title":"\ud83d\udcdd Contributing Guidelines","text":""},{"location":"contributing/#expectations-for-contributors","title":"\ud83c\udfaf Expectations for Contributors","text":"<p>Here is a set of guidelines that you should follow:</p> <ol> <li> <p>Use Cases:</p> <ul> <li>Ensure that your contributions directly enhance the humbldata's functionality or extension ecosystem.</li> </ul> </li> <li> <p>Documentation:</p> <ul> <li>All code contributions should come with relevant documentation, including the purpose of the contribution, how it works, and any changes it makes to existing functionalities.</li> <li>Update any existing documentation if your contribution alters the behavior of the humbldata.</li> </ul> </li> <li> <p>Code Quality:</p> <ul> <li>Your code should adhere strictly to the humbldata's coding standards and conventions.</li> <li>Ensure clarity, maintainability, and proper organization in your code.</li> </ul> </li> <li> <p>Testing:</p> <ul> <li>All contributions must be thoroughly tested to avoid introducing bugs to the humbldata.</li> <li>Contributions should include relevant automated tests (unit and integration), and any new feature should come with its test cases.</li> </ul> </li> <li> <p>Performance:</p> <ul> <li>Your contributions should be optimized for performance and should not degrade the overall efficiency of the humbldata.</li> <li>Address any potential bottlenecks and ensure scalability.</li> </ul> </li> <li> <p>Collaboration:</p> <ul> <li>Engage actively with the humbldata development team to ensure that your contributions align with the platform's roadmap and standards.</li> <li>Welcome feedback and be open to making revisions based on reviews and suggestions from the community.</li> </ul> </li> </ol>"},{"location":"contributing/#best-practices","title":"\ud83c\udfc6 Best Practices","text":"<ul> <li>Review Platform Dependencies: Before adding any dependency, ensure it aligns with the Platform's existing dependencies.</li> <li>Use Loose Versioning: If possible, specify a range to maintain compatibility. E.g., <code>&gt;=1.4,&lt;1.5</code>.</li> <li>Testing: Test your extension with the Platform's core to avoid conflicts. Both unit and integration tests are recommended.</li> <li>Document Dependencies: Use <code>pyproject.toml</code> and <code>poetry.lock</code> for clear, up-to-date records</li> </ul>"},{"location":"contributing/#code-standards","title":"\ud83d\udc0d Code Standards","text":""},{"location":"contributing/#pep-guidelines","title":"\ud83e\udebaPEP Guidelines","text":"<p>You must adhere to the strict guidelines of coding best practices. Here is a non-exhaustive list of the most important guidelines to follow:</p> <ol> <li>PEP 8: This is the de-facto code style guide for Python. It is a set of conventions for how to format your Python code to maximize its readability.<ul> <li>It is a set of conventions for how to format your Python code to maximize its readability.</li> </ul> </li> <li>PEP 484: This PEP introduces a standard for type annotations in Python. It aims to provide a standard syntax for type annotations, opening up Python code to easier static analysis and refactoring.<ul> <li>It aims to provide a standard syntax for type annotations, opening up Python code to easier static analysis and refactoring.</li> </ul> </li> <li>PEP 621: This PEP introduces a mechanism to specify project metadata in a standardized way. It aims to provide a standard way to specify project metadata, making it easier for tools to work with Python projects.<ul> <li>It aims to provide a standard way to specify project metadata, making it easier for tools to work with Python projects.</li> </ul> </li> <li>PEP 20: This PEP is a set of aphorisms that capture the guiding principles of Python's design. It is a must-read for any Python developer.<ul> <li>It is a set of aphorisms that capture the guiding principles of Python's design. It is a must-read for any Python developer.</li> </ul> </li> </ol> The Zen of Python <p>Beautiful is better than ugly.</p> <p>Explicit is better than implicit.</p> <p>Simple is better than complex.</p> <p>Complex is better than complicated.</p> <p>Flat is better than nested.</p> <p>Sparse is better than dense.</p> <p>Readability counts.</p> <p>Special cases aren't special enough to break the rules.</p> <p>Although practicality beats purity.</p> <p>Errors should never pass silently.</p> <p>Unless explicitly silenced.</p> <p>In the face of ambiguity, refuse the temptation to guess.</p> <p>There should be one-- and preferably only one --obvious way to do it.</p> <p>Although that way may not be obvious at first unless you're Dutch.</p> <p>Now is better than never.</p> <p>Although never is often better than right now.</p> <p>If the implementation is hard to explain, it's a bad idea.</p> <p>If the implementation is easy to explain, it may be a good idea.</p> <p>Namespaces are one honking great idea -- let's do more of those!</p>"},{"location":"contributing/#adding-a-function","title":"\u2795 Adding a Function","text":"<p>If you want to add a function, first you must decide. What is the context, category and command? Once, you have done that you will need to do these 3 things:</p> <ol> <li> <p>Define <code>QueryParams</code> and <code>Data</code> Standard Model.</p> <p>Put your new standard model in:</p> <pre><code>humbldata.core.standard_models.&lt;context&gt;.&lt;category&gt;.&lt;your_func&gt;\n</code></pre> <p>This should be a <code>.py</code> file. <pre><code>~\\humbldata\\src\\humbldata\\core\\standard_models\\&lt;context&gt;\\&lt;category&gt;\\&lt;command&gt;.py\n</code></pre> You will then define two classes. The <code>QueryParams</code> and the <code>Data</code>, the fields used to query the data and then the returned data fields, respectively.     <pre><code>\"\"\"\n&lt;Your Function&gt; Standard Model.\n\nContext: Toolbox || Category: Technical || Command: &lt;Your Function&gt;.\n\nThis module is used to define the QueryParams and Data model for the\n&lt;Your Function&gt; command.\n\"\"\"\n\n\nfrom humbldata.core.standard_models.abstract.data import Data\nfrom humbldata.core.standard_models.abstract.query_params import QueryParams\n\nclass &lt;YourFunc&gt;QueryParams(QueryParams):\n    \"\"\"\n    QueryParam for the &lt;Your Function&gt; command.\n    \"\"\"\nclass &lt;YourFunc&gt;Data(Data):\n    \"\"\"\n    Data model for the &lt;Your Function&gt; command.\n    \"\"\"\n</code></pre></p> </li> </ol>"},{"location":"contributing/#acknowledgment","title":"\ud83d\ude4f Acknowledgment","text":"<ul> <li>We acknowledge and thank the OpenBB team for creating such well documented Guidelines.</li> </ul>"},{"location":"roadmap/","title":"\ud83d\ude97 Roadmap","text":"<ul> <li> Add support for Nox for automated testing across various platforms and python versions, instead of Tox.</li> <li> Replace <code>commitizen</code> with <code>cz-git</code> for commit message generation.</li> </ul>"},{"location":"code_design/","title":"Index","text":""},{"location":"code_design/#code-design","title":"\ud83e\uddf1 Code Design","text":"<p>Here...you will learn about the design paradigm that was chosen and used while developing this project. This will include the architecture, the design patterns. The coding standards, will be available in the contributing section.</p>"},{"location":"code_design/cccc_method/","title":"CCCC: core, context, category, command","text":"<p>THe purpose of this design paradigm is to always be thinking of your application and features that you are implementing in a nested hierarchical structure. We do this for 3 main benefits, namely:</p> <ol> <li>It is easy to tell where you should put your piece of code.</li> <li>It is easy to create reusable functions for multiple use cases.</li> <li>It is easy to diagram a flow chart of your application, given that you know where larger modules should go (core/context/category) and where endpoints of the graph (commands) should go.</li> </ol> <p>The point of CCCC is to make creation of Models, View &amp; Controllers simpler.The nested strucutre allows for easy mental organization.</p> <p>CCCC Explained</p> <code>Core</code> <p>The core of your app. Logic used in controllers goes here. This module is intended to contain sub-modules and functions that are not directly utilized from the package, but rather used in building the package itself. i.e The core will hold the <code>[standard_models]</code>(./standardization_framework.md), <code>utils</code> used in the humbldata package.</p> <code>Context</code> <p>This is a grouping of multiple categories. The highest level of modules should go here.</p> <p>i.e <code>context</code> is a top-level directory that contains multiple <code>categories</code>. <code>humbldata.</code> is an example of a context. This directory is at the same level as the <code>core</code> directory. This context holds all the <code>categories</code> that are used to build the <code>toolbox</code>.</p> <code>Category</code> <p>This is the grouping of multiple commands that belongs to a context. Categories can be extended to as many &lt;<code>sub-categories</code>&gt; as needed.</p> <code>Command</code> <p>This is the smallest unit of code that can be executed.</p>"},{"location":"code_design/cccc_method/#cccc-examples","title":"CCCC Examples","text":""},{"location":"code_design/mvcdb/","title":"M-V-C-DB","text":"<pre><code>graph LR\n    User --&gt;|requests| Routes\n    Routes --&gt;|defines| Controller\n    Controller --&gt;|manipulates| Model\n    Model --&gt; |returns data| Controller\n    Model --&gt;|queries| Database\n    Database --&gt;|returns data| Model\n    Model --&gt;|updates| View\n    View --&gt;|renders to| Controller\n    Controller --&gt;|shows data| User</code></pre>"},{"location":"code_design/mvcdb/#model","title":"\ud83e\udde0 Model","text":"<p>The Model represents the data structure and the business logic of the application. It directly manages the data and logic. A model can respond to requests for information, respond to instructions to change its state, and even notify observers in an event-driven system. This layer is where the core functionality of the application resides, dealing with the retrieval, insertion, update, and deletion of data. The model communicates with the database and processes the business logic based on the data received from the controller. It is completely independent of the user interface.</p>"},{"location":"code_design/mvcdb/#view","title":"\ud83d\udc40 View","text":"<p>The View is the user interface of the application. It is responsible for displaying the data that is received from the model. The view is completely independent of the model and the controller. It is only responsible for displaying the data and the user interface.</p>"},{"location":"code_design/mvcdb/#controller","title":"\ud83c\udfae Controller","text":"<p>The Controller is the bridge between the User and the Model/View. It is responsible for processing the user's input and updating the model with the correct <code>QueryParams</code>. The controller is responsible for processing the user's input and updating the model. The controller is the only layer that interacts with the user. It receives the user's input and processes it. It then sends the processed data to the model for processing. The controller is responsible for updating the model based on the user's input and then sending the updated data to the view for display.</p>"},{"location":"code_design/mvcdb/#database","title":"\ud83d\uddc4\ufe0f Database","text":"<p>The Database is the storage of the application. It is responsible for storing the data that is received from the model. The database is completely independent of the model, view, and controller. It is only responsible for storing the data. The only interaction the database has is with the model, to store and retrieve data.</p>"},{"location":"code_design/standardization_framework/","title":"Standardization Framework","text":""},{"location":"code_documentation/","title":"\ud83d\udcda Code Documentation","text":"<p>This is an all encompassing documentation of the code base.</p> <p>It is handwritten and generated from mkdocstrings. Unlike Sphinx, it lacks the <code>.autosummary::</code> syntax for recursive documentation generation, but this design choice facilitates precise introduction and management of how the code base is presented and interacted with.</p> <p>Using the CCCC Organization method is an easier way to showcase a codebase to a new developer rather than just a list of all the Classes, Methods, Functions and Scripts.</p> <p>Yes, there is some low-level recursion to document the codebase, and yes, there is some room for recursive improvement, but, this is a beautiful way to showcase code, and makes you very familiar with the codebase, and in doing so, helps direct your focus towards important areas of the codebase; streamlining and speeding up development time.</p>"},{"location":"code_documentation/api_reference/","title":"\ud83d\udcd1 API Reference","text":"<p>This section holds a comprehensive documentation of all of classes, methods and functions in the <code>humbldata</code> package.</p> <p>humbldata package.</p>"},{"location":"code_documentation/api_reference/#humbldata.cli","title":"humbldata.cli","text":"<p>humbldata CLI.</p>"},{"location":"code_documentation/api_reference/#humbldata.cli.say","title":"humbldata.cli.say","text":"<pre><code>say(message: str = '') -&gt; None\n</code></pre> <p>Say a message.</p> Source code in <code>src\\humbldata\\cli.py</code> <pre><code>@app.command()\ndef say(message: str = \"\") -&gt; None:\n    \"\"\"Say a message.\"\"\"\n    typer.echo(message)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core","title":"humbldata.core","text":"<p>The <code>core</code> module to contain logic &amp; functions used in controllers.</p> <p>This module is intended to contain sub-modules and functions that are not directly utilized from the package, but rather used in building the package itself. This means that the core module should not contain any code that is specific to the package's use case, but rather should be generic and reusable in other contexts.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models","title":"humbldata.core.standard_models","text":"<p>Models to represent core data structures of the Standardization Framework.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract","title":"humbldata.core.standard_models.abstract","text":"<p>Abstract core DATA MODELS to be inherited by other models.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.data","title":"humbldata.core.standard_models.abstract.data","text":"<p>A wrapper around OpenBB Data Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.data.Data","title":"humbldata.core.standard_models.abstract.data.Data","text":"<p>             Bases: <code>Data</code></p> <p>An abstract standard_model to represent a base Data Model.</p> <p>The Data Model should be used to define the data that is being collected and analyzed in a <code>context.category.command</code> call.</p> <p>This Data model is meant to be inherited and built upon by other standard_models for a specific context.</p> Example <pre><code>total_time = f\"{end_time - start_time:.3f}\"\nclass EquityHistoricalData(Data):\n\ndate: Union[dateType, datetime] = Field(\n    description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n)\nopen: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\nhigh: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\nlow: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\nclose: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\nvolume: Optional[Union[float, int]] = Field(\n    default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n)\n\n@field_validator(\"date\", mode=\"before\", check_fields=False)\ndef date_validate(cls, v):  # pylint: disable=E0213\n    v = parser.isoparse(str(v))\n    if v.hour == 0 and v.minute == 0:\n        return v.date()\n    return v\n</code></pre> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\data.py</code> <pre><code>class Data(OpenBBData):\n    \"\"\"\n    An abstract standard_model to represent a base Data Model.\n\n    The Data Model should be used to define the data that is being\n    collected and analyzed in a `context.category.command` call.\n\n    This Data model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Example\n    -------\n    ```py\n    total_time = f\"{end_time - start_time:.3f}\"\n    class EquityHistoricalData(Data):\n\n    date: Union[dateType, datetime] = Field(\n        description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n    )\n    open: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\n    high: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\n    low: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\n    close: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\n    volume: Optional[Union[float, int]] = Field(\n        default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n    )\n\n    @field_validator(\"date\", mode=\"before\", check_fields=False)\n    def date_validate(cls, v):  # pylint: disable=E0213\n        v = parser.isoparse(str(v))\n        if v.hour == 0 and v.minute == 0:\n            return v.date()\n        return v\n\n    ```\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.errors","title":"humbldata.core.standard_models.abstract.errors","text":"<p>An ABSTRACT DATA MODEL to be inherited by custom errors.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.errors.HumblDataError","title":"humbldata.core.standard_models.abstract.errors.HumblDataError","text":"<p>             Bases: <code>BaseException</code></p> <p>Base Error for HumblData logic.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\errors.py</code> <pre><code>class HumblDataError(BaseException):\n    \"\"\"Base Error for HumblData logic.\"\"\"\n\n    def __init__(self, original: str | Exception | None = None):\n        self.original = original\n        super().__init__(str(original))\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.query_params","title":"humbldata.core.standard_models.abstract.query_params","text":"<p>A wrapper around OpenBB QueryParams Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.query_params.QueryParams","title":"humbldata.core.standard_models.abstract.query_params.QueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>An abstract standard_model to represent a base QueryParams Data.</p> <p>QueryParams model should be used to define the query parameters for a <code>context.category.command</code> call.</p> <p>This QueryParams model is meant to be inherited and built upon by other standard_models for a specific context.</p> <p>Examples:</p> <pre><code>class EquityHistoricalQueryParams(QueryParams):\n\n    symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n    interval: Optional[str] = Field(\n        default=\"1d\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n    )\n    end_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n    )\n\n    @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n        if isinstance(v, str):\n            return v.upper()\n        return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre> <p>This would create a class that would be used to query historical price data for equities from any given command.</p> <p>This could then be used to create a <code>MandelbrotChannelEquityHistoricalQueryParams</code> that would define what query parameters are needed for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\query_params.py</code> <pre><code>class QueryParams(OpenBBQueryParams):\n    \"\"\"\n    An abstract standard_model to represent a base QueryParams Data.\n\n    QueryParams model should be used to define the query parameters for a\n    `context.category.command` call.\n\n    This QueryParams model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Examples\n    --------\n    ```py\n    class EquityHistoricalQueryParams(QueryParams):\n\n        symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n        interval: Optional[str] = Field(\n            default=\"1d\",\n            description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n        )\n        start_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n        )\n        end_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n        )\n\n        @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n        @classmethod\n        def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n            if isinstance(v, str):\n                return v.upper()\n            return \",\".join([symbol.upper() for symbol in list(v)])\n    ```\n\n    This would create a class that would be used to query historical price data\n    for equities from any given command.\n\n    This could then be used to create a\n    `MandelbrotChannelEquityHistoricalQueryParams` that would define what query\n    parameters are needed for the Mandelbrot Channel command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.singleton","title":"humbldata.core.standard_models.abstract.singleton","text":"<p>An ABSTRACT DATA MODEL, Singleton, to represent a class that should only have one instance.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.singleton.SingletonMeta","title":"humbldata.core.standard_models.abstract.singleton.SingletonMeta","text":"<p>             Bases: <code>type</code>, <code>Generic[T]</code></p> <p>SingletonMeta is a metaclass that creates a Singleton instance of a class.</p> <p>Singleton design pattern restricts the instantiation of a class to a single instance. This is useful when exactly one object is needed to coordinate actions across the system.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\singleton.py</code> <pre><code>class SingletonMeta(type, Generic[T]):\n    \"\"\"\n    SingletonMeta is a metaclass that creates a Singleton instance of a class.\n\n    Singleton design pattern restricts the instantiation of a class to a single\n    instance. This is useful when exactly one object is needed to coordinate\n    actions across the system.\n    \"\"\"\n\n    _instances: ClassVar[dict[T, T]] = {}  # type: ignore  # noqa: PGH003\n\n    def __call__(cls, *args, **kwargs) -&gt; T:\n        \"\"\"\n        Override the __call__ method.\n\n        If the class exists, otherwise creates a new instance and stores it in\n        the _instances dictionary.\n        \"\"\"\n        if cls not in cls._instances:\n            instance = super().__call__(*args, **kwargs)\n            cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n        return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre> <code></code> humbldata.core.standard_models.abstract.singleton.SingletonMeta.__call__ # <pre><code>__call__(*args, **kwargs) -&gt; T\n</code></pre> <p>Override the call method.</p> <p>If the class exists, otherwise creates a new instance and stores it in the _instances dictionary.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\singleton.py</code> <pre><code>def __call__(cls, *args, **kwargs) -&gt; T:\n    \"\"\"\n    Override the __call__ method.\n\n    If the class exists, otherwise creates a new instance and stores it in\n    the _instances dictionary.\n    \"\"\"\n    if cls not in cls._instances:\n        instance = super().__call__(*args, **kwargs)\n        cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n    return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.tagged","title":"humbldata.core.standard_models.abstract.tagged","text":"<p>An ABSTRACT DATA MODEL, Tagged, to be inherited by other models as identifier.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.abstract.tagged.Tagged","title":"humbldata.core.standard_models.abstract.tagged.Tagged","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class to represent an object tagged with a uuid7.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\tagged.py</code> <pre><code>class Tagged(BaseModel):\n    \"\"\"A class to represent an object tagged with a uuid7.\"\"\"\n\n    id: str = Field(default_factory=uuid7str, alias=\"_id\")\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox","title":"humbldata.core.standard_models.toolbox","text":"<p>Context: Toolbox || Category: Standardized Framework Model.</p> <p>This module defines the QueryParams and Data classes for the Toolbox context. THis is where all of the context(s) of your project go. The STANDARD MODELS for categories and subsequent commands are nested here.</p> <p>Classes:</p> Name Description <code>ToolboxQueryParams</code> <p>Query parameters for the ToolboxController.</p> <code>ToolboxData</code> <p>A Pydantic model that defines the data returned by the ToolboxController.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>The symbol/ticker of the stock.</p> <code>interval</code> <code>Optional[str]</code> <p>The interval of the data. Defaults to '1d'.</p> <code>start_date</code> <code>str</code> <p>The start date of the data.</p> <code>end_date</code> <code>str</code> <p>The end date of the data.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.technical","title":"humbldata.core.standard_models.toolbox.technical","text":"<p>Context: Toolbox || Category: Technical.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.technical.mandelbrotchannel","title":"humbldata.core.standard_models.toolbox.technical.mandelbrotchannel","text":"<p>Mandelbrot Channel Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Mandelbrot Channel.</p> <p>This module is used to define the QueryParams and Data model for the Mandelbrot Channel command.</p> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelQueryParams # <p>             Bases: <code>QueryParams</code></p> <p>QueryParams for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>class MandelbrotChannelQueryParams(QueryParams):\n    \"\"\"\n    QueryParams for the Mandelbrot Channel command.\n\n\n    \"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelData # <p>             Bases: <code>Data</code></p> <p>Data model for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>class MandelbrotChannelData(Data):\n    \"\"\"\n    Data model for the Mandelbrot Channel command.\n    \"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher # <p>             Bases: <code>MandelbrotChannelQueryParams</code>, <code>MandelbrotChannelData</code></p> <p>Fetcher for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>class MandelbrotChannelFetcher(\n    MandelbrotChannelQueryParams, MandelbrotChannelData\n):\n    \"\"\"\n    Fetcher for the Mandelbrot Channel command.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: MandelbrotChannelQueryParams,\n    ):\n        self._context_params = context_params\n        self._command_params = command_params\n\n    def transform_query(self):\n        \"\"\"Transform the params to the command-specific query.\"\"\"\n\n    def extract_data(self):\n        \"\"\"Extract the data from the provider.\"\"\"\n        # Assuming 'obb' is a predefined object in your context\n        df = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbol,\n                start_date=str(self.context_params.start_date),\n                end_date=str(self.context_params.end_date),\n                provider=self.command_params.provider,\n                verbose=not self.command_params.kwargs.get(\"silent\", False),\n                **self.command_params.kwargs,\n            ).to_polars()\n        ).drop([\"dividends\", \"stock_splits\"], axis=1)\n        return df\n\n    def transform_data(self):\n        \"\"\"Transform the command-specific data.\"\"\"\n        # Placeholder for data transformation logic\n\n    def fetch_data(self):\n        # Call the methods in the desired order\n        query = self.transform_query()\n        raw_data = (\n            self.extract_data()\n        )  # This should use 'query' to fetch the data\n        transformed_data = (\n            self.transform_data()\n        )  # This should transform 'raw_data'\n\n        # Validate with MandelbrotChannelData, unpack dict into pydantic row by row\n        return transformed_data\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher.transform_query # <pre><code>transform_query()\n</code></pre> <p>Transform the params to the command-specific query.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>def transform_query(self):\n    \"\"\"Transform the params to the command-specific query.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher.extract_data # <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>def extract_data(self):\n    \"\"\"Extract the data from the provider.\"\"\"\n    # Assuming 'obb' is a predefined object in your context\n    df = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbol,\n            start_date=str(self.context_params.start_date),\n            end_date=str(self.context_params.end_date),\n            provider=self.command_params.provider,\n            verbose=not self.command_params.kwargs.get(\"silent\", False),\n            **self.command_params.kwargs,\n        ).to_polars()\n    ).drop([\"dividends\", \"stock_splits\"], axis=1)\n    return df\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher.transform_data # <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>def transform_data(self):\n    \"\"\"Transform the command-specific data.\"\"\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.technical.realized_volatility","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility","text":"<p>Volatility Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Volatility.</p> <p>This module is used to define the QueryParams and Data model for the Volatility command.</p> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityQueryParams # <p>             Bases: <code>QueryParams</code></p> <p>QueryParams for the Realized Volatility command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>class RealizedVolatilityQueryParams(QueryParams):\n    \"\"\"\n    QueryParams for the Realized Volatility command.\n    \"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityData # <p>             Bases: <code>Data</code></p> <p>Data model for the Realized Volatility command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>class RealizedVolatilityData(Data):\n    \"\"\"\n    Data model for the Realized Volatility command.\n    \"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher # <p>             Bases: <code>RealizedVolatilityQueryParams</code></p> <p>Fetcher for the Realized Volatility command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>class RealizedVolatilityFetcher(RealizedVolatilityQueryParams):\n    \"\"\"\n    Fetcher for the Realized Volatility command.\n    \"\"\"\n\n    data_list: ClassVar[list[RealizedVolatilityData]] = []\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: RealizedVolatilityQueryParams,\n    ):\n        self._context_params = context_params\n        self._command_params = command_params\n\n    def transform_query(self):\n        \"\"\"Transform the params to the command-specific query.\"\"\"\n\n    def extract_data(self):\n        \"\"\"Extract the data from the provider.\"\"\"\n        # Assuming 'obb' is a predefined object in your context\n        df = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbol,\n                start_date=str(self.context_params.start_date),\n                end_date=str(self.context_params.end_date),\n                provider=self.command_params.provider,\n                verbose=not self.command_params.kwargs.get(\"silent\", False),\n                **self.command_params.kwargs,\n            )\n            .to_df()\n            .reset_index()\n        )\n        return df\n\n    def transform_data(self):\n        \"\"\"Transform the command-specific data.\"\"\"\n        # Placeholder for data transformation logic\n\n    def fetch_data(self):\n        \"\"\"Execute the TET pattern.\"\"\"\n        # Call the methods in the desired order\n        query = self.transform_query()\n        raw_data = (\n            self.extract_data()\n        )  # This should use 'query' to fetch the data\n        transformed_data = (\n            self.transform_data()\n        )  # This should transform 'raw_data'\n\n        # Validate with VolatilityData, unpack dict into pydantic row by row\n        return transformed_data\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_query # <pre><code>transform_query()\n</code></pre> <p>Transform the params to the command-specific query.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def transform_query(self):\n    \"\"\"Transform the params to the command-specific query.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.extract_data # <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def extract_data(self):\n    \"\"\"Extract the data from the provider.\"\"\"\n    # Assuming 'obb' is a predefined object in your context\n    df = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbol,\n            start_date=str(self.context_params.start_date),\n            end_date=str(self.context_params.end_date),\n            provider=self.command_params.provider,\n            verbose=not self.command_params.kwargs.get(\"silent\", False),\n            **self.command_params.kwargs,\n        )\n        .to_df()\n        .reset_index()\n    )\n    return df\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_data # <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def transform_data(self):\n    \"\"\"Transform the command-specific data.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.fetch_data # <pre><code>fetch_data()\n</code></pre> <p>Execute the TET pattern.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def fetch_data(self):\n    \"\"\"Execute the TET pattern.\"\"\"\n    # Call the methods in the desired order\n    query = self.transform_query()\n    raw_data = (\n        self.extract_data()\n    )  # This should use 'query' to fetch the data\n    transformed_data = (\n        self.transform_data()\n    )  # This should transform 'raw_data'\n\n    # Validate with VolatilityData, unpack dict into pydantic row by row\n    return transformed_data\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxQueryParams","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>Query parameters for the ToolboxController.</p> <p>This class defines the query parameters used by the ToolboxController, including the stock symbol, data interval, start date, and end date. It also includes a method to ensure the stock symbol is in uppercase.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>The symbol or ticker of the stock.</p> <code>interval</code> <code>Optional[str]</code> <p>The interval of the data. Defaults to '1d'. Can be None.</p> <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> <p>Methods:</p> Name Description <code>upper_symbol</code> <p>A Pydantic <code>@field_validator()</code> that converts the stock symbol to uppercase. If a list or set of symbols is provided, each symbol in the collection is converted to uppercase and returned as a comma-separated string.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\__init__.py</code> <pre><code>class ToolboxQueryParams(QueryParams):\n    \"\"\"\n    Query parameters for the ToolboxController.\n\n    This class defines the query parameters used by the ToolboxController,\n    including the stock symbol, data interval, start date, and end date. It also\n    includes a method to ensure the stock symbol is in uppercase.\n\n    Attributes\n    ----------\n    symbol : str\n        The symbol or ticker of the stock.\n    interval : Optional[str]\n        The interval of the data. Defaults to '1d'. Can be None.\n    start_date : str\n        The start date for the data query.\n    end_date : str\n        The end date for the data query.\n\n    Methods\n    -------\n    upper_symbol(cls, v: Union[str, list[str], set[str]]) -&gt; Union[str, list[str]]\n        A Pydantic `@field_validator()` that converts the stock symbol to\n        uppercase. If a list or set of symbols is provided, each symbol in the\n        collection is converted to uppercase and returned as a comma-separated\n        string.\n    \"\"\"\n\n    symbol: str = Field(\n        default=\"\",\n        title=\"The symbol/ticker of the stock\",\n        description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"),\n    )\n    interval: str | None = Field(\n        default=\"1d\",\n        title=\"The interval of the data\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: str = Field(\n        default=\"\",\n        title=\"The start date of the data\",\n        description=\"The starting date for the data query.\",\n    )\n    end_date: str = Field(\n        default=\"\",\n        title=\"The end date of the data\",\n        description=\"The ending date for the data query.\",\n    )\n\n    @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n        \"\"\"\n        Convert the stock symbol to uppercase.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        Union[str, List[str]]\n            The uppercase stock symbol or a comma-separated string of uppercase\n            symbols.\n        \"\"\"\n        if isinstance(v, str):\n            return v.upper()\n        return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol  <code>classmethod</code>","text":"<pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; str | list[str]\n</code></pre> <p>Convert the stock symbol to uppercase.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>Union[str, List[str]]</code> <p>The uppercase stock symbol or a comma-separated string of uppercase symbols.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\__init__.py</code> <pre><code>@field_validator(\"symbol\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n    \"\"\"\n    Convert the stock symbol to uppercase.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    Union[str, List[str]]\n        The uppercase stock symbol or a comma-separated string of uppercase\n        symbols.\n    \"\"\"\n    if isinstance(v, str):\n        return v.upper()\n    return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.standard_models.toolbox.ToolboxData","title":"humbldata.core.standard_models.toolbox.ToolboxData","text":"<p>             Bases: <code>Data</code></p> <p>The Data for the ToolboxController.</p> <p>WIP: I'm thinking that this is the final layer around which the HumblDataObject will be returned to the user, with all necessary information about the query, command, data and charts that they should want. This HumblDataObject will return values in json/dict format, with methods to allow transformation into polars_df, pandas_df, a list, a dict...</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\__init__.py</code> <pre><code>class ToolboxData(Data):\n    \"\"\"\n    The Data for the ToolboxController.\n\n    WIP: I'm thinking that this is the final layer around which the\n    HumblDataObject will be returned to the user, with all necessary information\n    about the query, command, data and charts that they should want.\n    This HumblDataObject will return values in json/dict format, with methods\n    to allow transformation into polars_df, pandas_df, a list, a dict...\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils","title":"humbldata.core.utils","text":"<p>humbldata core utils.</p> <p>Utils is used to keep; helpers, descriptions, constants, and other useful tools.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.constants","title":"humbldata.core.utils.constants","text":"<p>A module to contain all project-wide constants.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.core_helpers","title":"humbldata.core.utils.core_helpers","text":"<p>A module to contain core helper functions for the program.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.core_helpers.is_debug_mode","title":"humbldata.core.utils.core_helpers.is_debug_mode","text":"<pre><code>is_debug_mode() -&gt; bool\n</code></pre> <p>Check if the current system is in debug mode.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the system is in debug mode, False otherwise.</p> Source code in <code>src\\humbldata\\core\\utils\\core_helpers.py</code> <pre><code>def is_debug_mode() -&gt; bool:\n    \"\"\"\n    Check if the current system is in debug mode.\n\n    Returns\n    -------\n    bool\n        True if the system is in debug mode, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.core_helpers.log_start_end","title":"humbldata.core.utils.core_helpers.log_start_end","text":"<pre><code>log_start_end(func: Callable | None = None, *, log: Logger | None = None) -&gt; Callable\n</code></pre> <p>Add logging at the start and end of any function it decorates, including time tracking.</p> <p>Handles exceptions by logging them and modifies behavior based on the system's debug mode. Logs the total time taken by the function.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Optional[Callable]</code> <p>The function to decorate.</p> <code>None</code> <code>log</code> <code>Optional[Logger]</code> <p>The logger to use for logging.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable</code> <p>The decorated function.</p> Source code in <code>src\\humbldata\\core\\utils\\core_helpers.py</code> <pre><code>def log_start_end(\n    func: Callable | None = None, *, log: logging.Logger | None = None\n) -&gt; Callable:\n    \"\"\"\n    Add logging at the start and end of any function it decorates, including time tracking.\n\n    Handles exceptions by logging them and modifies behavior based on the\n    system's debug mode. Logs the total time taken by the function.\n\n    Parameters\n    ----------\n    func : Optional[Callable]\n        The function to decorate.\n    log : Optional[logging.Logger]\n        The logger to use for logging.\n\n    Returns\n    -------\n    Callable\n        The decorated function.\n    \"\"\"\n    assert callable(func) or func is None\n\n    def decorator(func: Callable) -&gt; Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -&gt; Any:\n            import time  # lazy import\n\n            nonlocal log\n            if log is None:\n                log = logging.getLogger(func.__module__)\n\n            start_time = time.time()\n            log.info(\"START\", extra={\"func_name\": func.__name__})\n\n            try:\n                result = func(*args, **kwargs)\n            except KeyboardInterrupt:\n                end_time = time.time()\n                total_time = end_time - start_time\n                log.info(\n                    \"Interrupted by user\",\n                    extra={\n                        \"func_name\": func.__name__,\n                        \"total_time\": total_time,\n                    },\n                )\n                return []\n            except Exception as e:\n                end_time = time.time()\n                total_time = end_time - start_time\n                log.exception(\n                    \"Exception in:\",\n                    extra={\n                        \"func_name\": func.__name__,\n                        \"exception\": e,\n                        \"total_time\": total_time,\n                    },\n                )\n                return []\n            else:\n                end_time = time.time()\n                total_time = end_time - start_time\n                log.info(\n                    \"END \",\n                    extra={\n                        \"func_name\": func.__name__,\n                        \"total_time\": total_time,\n                    },\n                )\n                return result\n\n        return wrapper\n\n    return decorator(func) if callable(func) else decorator\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.descriptions","title":"humbldata.core.utils.descriptions","text":"<p>Common descriptions for model fields.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env","title":"humbldata.core.utils.env","text":"<p>The Env Module, to control a single instance of environment variables.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env","title":"humbldata.core.utils.env.Env","text":"<p>A singleton environment to hold all Environment variables.</p> Source code in <code>src\\humbldata\\core\\utils\\env.py</code> <pre><code>class Env(metaclass=SingletonMeta):\n    \"\"\"A singleton environment to hold all Environment variables.\"\"\"\n\n    _environ: dict[str, str]\n\n    def __init__(self) -&gt; None:\n        env_path = dotenv.find_dotenv()\n        dotenv.load_dotenv(Path(env_path))\n\n        self._environ = os.environ.copy()\n\n    @property\n    def OBB_PAT(self) -&gt; str | None:  # noqa: N802\n        \"\"\"OpenBB Personal Access Token.\"\"\"\n        return self._environ.get(\"OBB_PAT\", None)\n\n    @property\n    def OBB_LOGGED_IN(self) -&gt; bool:\n        return self.str2bool(self._environ.get(\"OBB_LOGGED_IN\", False))\n\n    @staticmethod\n    def str2bool(value: str | bool) -&gt; bool:\n        \"\"\"Match a value to its boolean correspondent.\n\n        Args:\n            value (str): The string value to be converted to a boolean.\n\n        Returns\n        -------\n            bool: The boolean value corresponding to the input string.\n\n        Raises\n        ------\n            ValueError: If the input string does not correspond to a boolean\n            value.\n        \"\"\"\n        if isinstance(value, bool):\n            return value\n        if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n            return False\n        if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n            return True\n        msg = f\"Failed to cast '{value}' to bool.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env.OBB_PAT","title":"humbldata.core.utils.env.Env.OBB_PAT  <code>property</code>","text":"<pre><code>OBB_PAT: str | None\n</code></pre> <p>OpenBB Personal Access Token.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.env.Env.str2bool","title":"humbldata.core.utils.env.Env.str2bool  <code>staticmethod</code>","text":"<pre><code>str2bool(value: str | bool) -&gt; bool\n</code></pre> <p>Match a value to its boolean correspondent.</p> <p>Args:     value (str): The string value to be converted to a boolean.</p> <p>Returns:</p> Type Description <code>    bool: The boolean value corresponding to the input string.</code> <p>Raises:</p> Type Description <code>    ValueError: If the input string does not correspond to a boolean</code> <p>value.</p> Source code in <code>src\\humbldata\\core\\utils\\env.py</code> <pre><code>@staticmethod\ndef str2bool(value: str | bool) -&gt; bool:\n    \"\"\"Match a value to its boolean correspondent.\n\n    Args:\n        value (str): The string value to be converted to a boolean.\n\n    Returns\n    -------\n        bool: The boolean value corresponding to the input string.\n\n    Raises\n    ------\n        ValueError: If the input string does not correspond to a boolean\n        value.\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n    if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n        return False\n    if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n        return True\n    msg = f\"Failed to cast '{value}' to bool.\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers","title":"humbldata.core.utils.openbb_helpers","text":"<p>Core Module - OpenBB Helpers.</p> <p>This module contains functions used to interact with OpenBB, or wrap commands to have specific data outputs.</p>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.obb_login","title":"humbldata.core.utils.openbb_helpers.obb_login","text":"<pre><code>obb_login(pat: str | None = None) -&gt; bool\n</code></pre> <p>Log into the OpenBB Hub using a Personal Access Token (PAT).</p> <p>This function wraps the <code>obb.account.login</code> method to provide a simplified interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT is provided, it attempts to use the PAT stored in the environment variable <code>OBB_PAT</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pat</code> <code>str | None</code> <p>The personal access token for authentication. If None, the token is retrieved from the environment variable <code>OBB_PAT</code>. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if login is successful, False otherwise.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If an error occurs during the login process.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\nTrue\n</code></pre> Source code in <code>src\\humbldata\\core\\utils\\openbb_helpers.py</code> <pre><code>def obb_login(pat: str | None = None) -&gt; bool:\n    \"\"\"\n    Log into the OpenBB Hub using a Personal Access Token (PAT).\n\n    This function wraps the `obb.account.login` method to provide a simplified\n    interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT\n    is provided, it attempts to use the PAT stored in the environment variable\n    `OBB_PAT`.\n\n    Parameters\n    ----------\n    pat : str | None, optional\n        The personal access token for authentication. If None, the token is\n        retrieved from the environment variable `OBB_PAT`. Default is None.\n\n    Returns\n    -------\n    bool\n        True if login is successful, False otherwise.\n\n    Raises\n    ------\n    HumblDataError\n        If an error occurs during the login process.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\n    True\n\n    &gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\n    True\n\n    \"\"\"\n    if pat is None:\n        pat = Env().OBB_PAT\n    try:\n        obb.account.login(pat=pat, remember_me=True)\n        # obb.account.save()\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"true\")\n\n        return True\n    except Exception as e:\n        from humbldata.core.standard_models.abstract.warnings import (\n            HumblDataWarning,\n        )\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"false\")\n\n        warnings.warn(\n            \"An error occurred while logging into OpenBB. Details below:\\n\"\n            + repr(e),\n            category=HumblDataWarning,\n            stacklevel=1,\n        )\n        return False\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.core.utils.openbb_helpers.get_latest_price","title":"humbldata.core.utils.openbb_helpers.get_latest_price","text":"<pre><code>get_latest_price(symbol: str | list[str] | Series, provider: Literal['fmp', 'intrinio'] | None = None) -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_latest_price.</p> <p>This function queries the latest stock price data using the specified provider. If no provider is specified, it defaults to using FinancialModelingPrep (<code>fmp</code>). The function returns a LazyFrame containing the stock symbols and their corresponding latest prices.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str | list[str] | Series</code> <p>The stock symbol(s) for which to fetch the latest price. Can be a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>Literal['fmp', 'intrinio'] | None</code> <p>The data provider to use for fetching the stock prices. If not specified, a default provider is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame containing columns for the stock symbols ('symbol') and their most recent prices ('last_price').</p> Source code in <code>src\\humbldata\\core\\utils\\openbb_helpers.py</code> <pre><code>def get_latest_price(\n    symbol: str | list[str] | pl.Series,\n    provider: Literal[\"fmp\", \"intrinio\"] | None = None,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_latest_price**.\n\n    This function queries the latest stock price data using the specified\n    provider. If no provider is specified, it defaults to using\n    FinancialModelingPrep (`fmp`). The function returns a LazyFrame containing\n    the stock symbols and their corresponding latest prices.\n\n    Parameters\n    ----------\n    symbol : str | list[str] | pl.Series\n        The stock symbol(s) for which to fetch the latest price. Can be a\n        single symbol, a list of symbols, or a Polars Series of symbols.\n\n    provider : Literal[\"fmp\", \"intrinio\"] | None, optional\n        The data provider to use for fetching the stock prices. If not\n        specified, a default provider is used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame containing columns for the stock symbols ('symbol')\n        and their most recent prices ('last_price').\n    \"\"\"\n    logging.getLogger(\"openbb_terminal.stocks.stocks_model\").setLevel(\n        logging.CRITICAL\n    )\n\n    latest_prices = (\n        obb.equity.price.quote(symbol, provider=provider).to_polars().lazy()\n    )\n    return latest_prices.select([\"symbol\", \"last_price\"])\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox","title":"humbldata.toolbox","text":"<p>Context: Toolbox.</p> <p>A category to group all of the technical indicators available in the <code>Toolbox()</code></p> <p>Technical indicators rely on statistical transformations of time series data. These are raw math operations.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller","title":"humbldata.toolbox.toolbox_controller","text":"<p>Context: Toolbox.</p> <p>The Toolbox Controller Module.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox","title":"humbldata.toolbox.toolbox_controller.Toolbox","text":"<p>             Bases: <code>ToolboxQueryParams</code></p> <p>The top-level controller for all data analysis in the <code>humbldata</code> package.</p> <p>This module serves as the primary controller, routing user-specified ToolboxQueryParams as core arguments that are used to fetch time series data.</p> <p>The <code>Toolbox</code> controller also gives access to all sub-modules adn their functions.</p> <p>It is designed to facilitate the collection of data across various types such as stocks, options, or alternative time series by requiring minimal input from the user.</p> Submodules <p>The <code>Toolbox</code> controller is composed of the following submodules:</p> <ul> <li><code>technical</code>:</li> <li><code>quantitative</code>:</li> <li><code>fundamental</code>:</li> </ul> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol or ticker of the stock.</p> required <code>interval</code> <code>str</code> <p>The interval of the data. Defaults to '1d'.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> required <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> required Parameter Notes <p>The Parameters (<code>symbol</code>, <code>interval</code>, <code>start_date</code>, <code>end_date</code>) are the <code>ToolboxQueryParams</code>. They are used for data collection further down the pipeline. to execute operations on core data sets. This approach enables composable and standardized querying while accommodating data-specific collection logic.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_controller.py</code> <pre><code>class Toolbox(ToolboxQueryParams):\n    \"\"\"\n\n    The top-level controller for all data analysis in the `humbldata` package.\n\n    This module serves as the primary controller, routing user-specified\n    ToolboxQueryParams as core arguments that are used to fetch time series\n    data.\n\n    The `Toolbox` controller also gives access to all sub-modules adn their\n    functions.\n\n    It is designed to facilitate the collection of data across various types such as\n    stocks, options, or alternative time series by requiring minimal input from the user.\n\n    Submodules\n    ----------\n    The `Toolbox` controller is composed of the following submodules:\n\n    - `technical`:\n    - `quantitative`:\n    - `fundamental`:\n\n    Parameters\n    ----------\n    symbol : str\n        The symbol or ticker of the stock.\n    interval : str, optional\n        The interval of the data. Defaults to '1d'.\n    start_date : str\n        The start date for the data query.\n    end_date : str\n        The end date for the data query.\n\n    Parameter Notes\n    -----\n    The Parameters (`symbol`, `interval`, `start_date`, `end_date`)\n    are the `ToolboxQueryParams`. They are used for data collection further\n    down the pipeline. to execute operations on core data sets.\n    This approach enables composable and standardized querying while\n    accommodating data-specific collection logic.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initialize the Toolbox module.\n\n        This method does not take any parameters and does not return anything.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @property\n    def technical(self):\n        \"\"\"\n        The technical submodule of the Toolbox controller.\n\n        Access to all the technical indicators.\n        \"\"\"\n        return Technical(self)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox.__init__","title":"humbldata.toolbox.toolbox_controller.Toolbox.__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Initialize the Toolbox module.</p> <p>This method does not take any parameters and does not return anything.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_controller.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initialize the Toolbox module.\n\n    This method does not take any parameters and does not return anything.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_controller.Toolbox.technical","title":"humbldata.toolbox.toolbox_controller.Toolbox.technical  <code>property</code>","text":"<pre><code>technical\n</code></pre> <p>The technical submodule of the Toolbox controller.</p> <p>Access to all the technical indicators.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers","title":"humbldata.toolbox.toolbox_helpers","text":"<p>Context: Toolbox || Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.log_returns","title":"humbldata.toolbox.toolbox_helpers.log_returns","text":"<pre><code>log_returns(data: Series | DataFrame | LazyFrame | None = None, _column_name: str = 'adj_close', *, _drop_nulls: bool = True, _sort: bool = True) -&gt; Series | DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: log_returns.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY. Calculates the logarithmic returns for a given Polars Series, DataFrame, or LazyFrame. Logarithmic returns are widely used in the financial industry to measure the rate of return on investments over time. This function supports calculations on both individual series and dataframes containing financial time series data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series | DataFrame | LazyFrame</code> <p>The input data for which to calculate the log returns. Default is None.</p> <code>None</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. Default is True.</p> <code>True</code> <code>_column_name</code> <code>str</code> <p>The column name to use for log return calculations in DataFrame or LazyFrame. Default is \"adj_close\".</p> <code>'adj_close'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by <code>date</code> and <code>symbol</code> before calculation. If you want a DUMB function, set to False. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Series | DataFrame | LazyFrame</code> <p>The original <code>data</code>, with an extra column of <code>log returns</code> of the input data. The return type matches the input type.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If neither a series, DataFrame, nor LazyFrame is provided as input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; series = pl.Series([100, 105, 103])\n&gt;&gt;&gt; log_returns(data=series)\nseries([-inf, 0.048790, -0.019418])\n</code></pre> <pre><code>&gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n&gt;&gt;&gt; log_returns(data=df)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 adj_close \u2506 log_returns\u2502\n\u2502 ---       \u2506 ---        \u2502\n\u2502 f64       \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 100.0     \u2506 NaN        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 105.0     \u2506 0.048790   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 103.0     \u2506 -0.019418  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Improvements <p>Add a parameter <code>_sort_cols: list[str] | None = None</code> to make the function even dumber. This way you could specify certain columns to sort by instead of using default <code>date</code> and <code>symbol</code>. If <code>_sort_cols=None</code> and <code>_sort=True</code>, then the function will use the default <code>date</code> and <code>symbol</code> columns for sorting.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def log_returns(\n    data: pl.Series | pl.DataFrame | pl.LazyFrame | None = None,\n    _column_name: str = \"adj_close\",\n    *,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.Series | pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: log_returns**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n    Calculates the logarithmic returns for a given Polars Series, DataFrame, or\n    LazyFrame. Logarithmic returns are widely used in the financial\n    industry to measure the rate of return on investments over time. This\n    function supports calculations on both individual series and dataframes\n    containing financial time series data.\n\n    Parameters\n    ----------\n    data : pl.Series | pl.DataFrame | pl.LazyFrame, optional\n        The input data for which to calculate the log returns. Default is None.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result. Default is True.\n    _column_name : str, optional\n        The column name to use for log return calculations in DataFrame or\n        LazyFrame. Default is \"adj_close\".\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by `date` and `symbol` before\n        calculation. If you want a DUMB function, set to False.\n        Default is True.\n\n    Returns\n    -------\n    pl.Series | pl.DataFrame | pl.LazyFrame\n        The original `data`, with an extra column of `log returns` of the input\n        data. The return type matches the input type.\n\n    Raises\n    ------\n    HumblDataError\n        If neither a series, DataFrame, nor LazyFrame is provided as input.\n\n    Examples\n    --------\n    &gt;&gt;&gt; series = pl.Series([100, 105, 103])\n    &gt;&gt;&gt; log_returns(data=series)\n    series([-inf, 0.048790, -0.019418])\n\n    &gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n    &gt;&gt;&gt; log_returns(data=df)\n    shape: (3, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 adj_close \u2506 log_returns\u2502\n    \u2502 ---       \u2506 ---        \u2502\n    \u2502 f64       \u2506 f64        \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 100.0     \u2506 NaN        \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 105.0     \u2506 0.048790   \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 103.0     \u2506 -0.019418  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    Improvements\n    -----------\n    Add a parameter `_sort_cols: list[str] | None = None` to make the function even\n    dumber. This way you could specify certain columns to sort by instead of\n    using default `date` and `symbol`. If `_sort_cols=None` and `_sort=True`,\n    then the function will use the default `date` and `symbol` columns for\n    sorting.\n\n    \"\"\"\n    # Calculation for Polars Series\n    if isinstance(data, pl.Series):\n        out = data.log().diff()\n        if _drop_nulls:\n            out = out.drop_nulls()\n    # Calculation for Polars DataFrame or LazyFrame\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n        if \"log_returns\" not in data.columns:\n            out = data.set_sorted(sort_cols).with_columns(\n                pl.col(_column_name).log().diff().alias(\"log_returns\")\n            )\n        else:\n            out = data\n        if _drop_nulls:\n            out = out.drop_nulls(subset=\"log_returns\")\n    else:\n        msg = \"No valid data type was provided for `log_returns()` calculation.\"\n        raise HumblDataError(msg)\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.detrend","title":"humbldata.toolbox.toolbox_helpers.detrend","text":"<pre><code>detrend(data: DataFrame | LazyFrame | Series, _detrend_col: str = 'log_returns', _detrend_value_col: str | Series | None = 'window_mean', *, _sort: bool = False) -&gt; DataFrame | LazyFrame | Series\n</code></pre> <pre><code>Context: Toolbox || Category: Helpers || **Command: detrend**.\n\nThis is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\nDetrends a column in a DataFrame, LazyFrame, or Series by subtracting the\nvalues of another column from it. Optionally sorts the data by 'symbol' and\n'date' before detrending if _sort is True.\n</code></pre> <p>Returns:</p> Type Description <code>    Union[pl.DataFrame, pl.LazyFrame, pl.Series]</code> <p>The detrended data structure with the same type as the input, with an added column named <code>f\"detrended_{_detrend_col}\"</code>.</p> Notes <p>Function doesn't use <code>.over()</code> in calculation. Once the data is sorted, subtracting _detrend_value_col from _detrend_col is a simple operation that doesn't need to be grouped, because the sorting has already aligned the rows for subtraction</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def detrend(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _detrend_col: str = \"log_returns\",\n    _detrend_value_col: str | pl.Series | None = \"window_mean\",\n    *,\n    _sort: bool = False,\n) -&gt; pl.DataFrame | pl.LazyFrame | pl.Series:\n    \"\"\"\n        Context: Toolbox || Category: Helpers || **Command: detrend**.\n\n        This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n        Detrends a column in a DataFrame, LazyFrame, or Series by subtracting the\n        values of another column from it. Optionally sorts the data by 'symbol' and\n        'date' before detrending if _sort is True.\n\n    Parameters\n    ----------\n        data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n            The data structure containing the columns to be processed.\n        _detrend_col : str\n            The name of the column from which values will be subtracted.\n        _detrend_value_col : str | pl.Series | None, optional\n            The name of the column whose values will be subtracted OR if you pass a\n            pl.Series to the `data` parameter, then you can use this to pass a\n            second `pl.Series` to\n            subtract from the first.\n        _sort : bool, optional\n            If True, sorts the data by 'symbol' and 'date' before detrending.\n            Default is False.\n\n    Returns\n    -------\n        Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n            The detrended data structure with the same type as the input,\n            with an added column named `f\"detrended_{_detrend_col}\"`.\n\n    Notes\n    -----\n    Function doesn't use `.over()` in calculation. Once the data is sorted,\n    subtracting _detrend_value_col from _detrend_col is a simple operation\n    that doesn't need to be grouped, because the sorting has already aligned\n    the rows for subtraction\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        if (\n            _detrend_value_col not in data.columns\n            or _detrend_col not in data.columns\n        ):\n            msg = f\"Both {_detrend_value_col} and {_detrend_col} must be columns in the data.\"\n            raise HumblDataError(msg)\n        detrended = data.set_sorted(sort_cols).with_columns(\n            (pl.col(_detrend_col) - pl.col(_detrend_value_col)).alias(\n                f\"detrended_{_detrend_col}\"\n            )\n        )\n    elif isinstance(data, pl.Series):\n        if not isinstance(_detrend_value_col, pl.Series):\n            msg = \"When 'data' is a Series, '_detrend_value_col' must also be a Series.\"\n            raise HumblDataError(msg)\n        detrended = data - _detrend_value_col\n        detrended.rename(f\"detrended_{_detrend_col}\")\n\n    return detrended\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.cum_sum","title":"humbldata.toolbox.toolbox_helpers.cum_sum","text":"<pre><code>cum_sum(data: DataFrame | LazyFrame | Series | None = None, _column_name: str = 'detrended_returns', *, _sort: bool = True, _mandelbrot_usage: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: cum_sum.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>Calculate the cumulative sum of a series or column in a DataFrame or LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame | Series | None</code> <p>The data to process.</p> <code>None</code> <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the cumulative sum on, applicable if df is provided.</p> <code>'detrended_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date and symbol before calculation. Default is True.</p> <code>True</code> <code>_mandelbrot_usage</code> <code>bool</code> <p>If True, performs additional checks specific to the Mandelbrot Channel calculation. This should be set to True when you have a cumulative deviate series, and False when not. Please check 'Notes' for more information. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The DataFrame or Series with the cumulative deviate series added as a new column or as itself.</p> Notes <p>This function is used to calculate the cumulative sum for the deviate series of detrended returns for the data in the pipeline for <code>calc_mandelbrot_channel</code>.</p> <p>So, although it is calculating a cumulative sum, it is known as a cumulative deviate because it is a cumulative sum on a deviate series, meaning that the cumulative sum should = 0 for each window. The _mandelbrot_usage parameter allows for checks to ensure the data is suitable for Mandelbrot Channel calculations, i.e that the deviate series was calculated correctly by the end of each series being 0, meaning the trend (the mean over the window_index) was successfully removed from the data.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def cum_sum(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series | None = None,\n    _column_name: str = \"detrended_returns\",\n    *,\n    _sort: bool = True,\n    _mandelbrot_usage: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: cum_sum**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    Calculate the cumulative sum of a series or column in a DataFrame or\n    LazyFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame | pl.Series | None\n        The data to process.\n    _column_name : str\n        The name of the column to calculate the cumulative sum on,\n        applicable if df is provided.\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by date and symbol before\n        calculation. Default is True.\n    _mandelbrot_usage : bool, optional\n        If True, performs additional checks specific to the Mandelbrot Channel\n        calculation. This should be set to True when you have a cumulative\n        deviate series, and False when not. Please check 'Notes' for more\n        information. Default is True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The DataFrame or Series with the cumulative deviate series added as a\n        new column or as itself.\n\n    Notes\n    -----\n    This function is used to calculate the cumulative sum for the deviate series\n    of detrended returns for the data in the pipeline for\n    `calc_mandelbrot_channel`.\n\n    So, although it is calculating a cumulative sum, it is known as a cumulative\n    deviate because it is a cumulative sum on a deviate series, meaning that the\n    cumulative sum should = 0 for each window. The _mandelbrot_usage parameter\n    allows for checks to ensure the data is suitable for Mandelbrot Channel\n    calculations, i.e that the deviate series was calculated correctly by the\n    end of each series being 0, meaning the trend (the mean over the\n    window_index) was successfully removed from the data.\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort:\n            data = data.sort(sort_cols)\n\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if over_cols:\n            out = data.set_sorted(sort_cols).with_columns(\n                pl.col(_column_name).cum_sum().over(over_cols).alias(\"cum_sum\")\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).cum_sum().alias(\"cum_sum\")\n            )\n    elif isinstance(data, pl.Series):\n        out = data.cum_sum().alias(\"cum_sum\")\n    else:\n        msg = \"No DataFrame/LazyFrame/Series was provided.\"\n        raise HumblDataError(msg)\n\n    if _mandelbrot_usage:\n        _cumsum_check(out, _column_name=\"cum_sum\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.std","title":"humbldata.toolbox.toolbox_helpers.std","text":"<pre><code>std(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum') -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: std.</p> <p>Calculate the standard deviation of the cumulative deviate series within each window of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>LazyFrame</code> <p>The LazyFrame from which to calculate the standard deviation.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column from which to calculate the standard deviation, with \"cumdev\" as the default value.</p> <code>'cum_sum'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame with the standard deviation of the specified column for each window, added as a new column named \"S\".</p> Improvements <p>Just need to parametrize <code>.over()</code> call in the function if want an even dumber function, that doesn't calculate each <code>window_index</code>.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def std(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series, _column_name: str = \"cum_sum\"\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: std**.\n\n    Calculate the standard deviation of the cumulative deviate series within\n    each window of the dataset.\n\n    Parameters\n    ----------\n    df : pl.LazyFrame\n        The LazyFrame from which to calculate the standard deviation.\n    _column_name : str, optional\n        The name of the column from which to calculate the standard deviation,\n        with \"cumdev\" as the default value.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame with the standard deviation of the specified column for each\n        window, added as a new column named \"S\".\n\n    Improvements\n    -----------\n    Just need to parametrize `.over()` call in the function if want an even\n    dumber function, that doesn't calculate each `window_index`.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.std()\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n\n        if over_cols:\n            out = data.set_sorted(sort_cols).with_columns(\n                [\n                    pl.col(_column_name)\n                    .std()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_std\"),  # used to be 'S'\n                ]\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).std().alias(\"S\"),\n            )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.mean","title":"humbldata.toolbox.toolbox_helpers.mean","text":"<pre><code>mean(data: DataFrame | LazyFrame | Series, _column_name: str = 'log_returns', *, _sort: bool = True) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Function: mean.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>This function calculates the mean of a column (&lt;_column_name&gt;) over a each window in the dataset, if there are any. This window is intended to be the <code>window</code> that is passed in the <code>calc_mandelbrot_channel()</code> function. The mean calculated is meant to be used as the mean of each <code>window</code> within the time series. This way, each block of windows has their own mean, which can then be used to normalize the data (i.e remove the mean) from each window section.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The DataFrame or LazyFrame to calculate the mean on.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the mean on.</p> <code>'log_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date before calculation. Default is False.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The original DataFrame or LazyFrame with a <code>window_mean</code> &amp; <code>date</code> column, which contains the mean of 'log_returns' per range/window.</p> Notes <p>Since this function is an aggregation function, it reduces the # of observations in the dataset,thus, unless I take each value and iterate each window_mean value to correlate to the row in the original dataframe, the function will return a dataframe WITHOUT the original data.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def mean(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _column_name: str = \"log_returns\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Function: mean**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    This function calculates the mean of a column (&lt;_column_name&gt;) over a\n    each window in the dataset, if there are any.\n    This window is intended to be the `window` that is passed in the\n    `calc_mandelbrot_channel()` function. The mean calculated is meant to be\n    used as the mean of each `window` within the time series. This\n    way, each block of windows has their own mean, which can then be used to\n    normalize the data (i.e remove the mean) from each window section.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The DataFrame or LazyFrame to calculate the mean on.\n    _column_name : str\n        The name of the column to calculate the mean on.\n    _sort : bool\n        If True, sorts the DataFrame or LazyFrame by date before calculation.\n        Default is False.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The original DataFrame or LazyFrame with a `window_mean` &amp; `date` column,\n        which contains the mean of 'log_returns' per range/window.\n\n\n    Notes\n    -----\n    Since this function is an aggregation function, it reduces the # of\n    observations in the dataset,thus, unless I take each value and iterate each\n    window_mean value to correlate to the row in the original dataframe, the\n    function will return a dataframe WITHOUT the original data.\n\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.mean()\n    else:\n        if data is None:\n            msg = \"No DataFrame was passed to the `mean()` function.\"\n            raise HumblDataError(msg)\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:  # Check if _sort is True\n            data = data.sort(sort_cols).set_sorted(sort_cols)\n        if over_cols:\n            out = data.with_columns(\n                pl.col(_column_name).mean().over(over_cols).alias(\"window_mean\")\n            )\n        else:\n            out = data.with_columns(pl.col(_column_name).mean().alias(\"mean\"))\n        if sort_cols:\n            out = out.sort(sort_cols)\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.toolbox_helpers.range_","title":"humbldata.toolbox.toolbox_helpers.range_","text":"<pre><code>range_(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum', *, _sort: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || Function: mandelbrot_range.</p> <p>Calculate the range (max - min) of the cumulative deviate values of a specified column in a DataFrame for each window in the dataset, if there are any.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The DataFrame to calculate the range from.</p> required <code>_column_name</code> <code>str</code> <p>The column to calculate the range from, by default \"cumdev\".</p> <code>'cum_sum'</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>A DataFrame with the range of the specified column for each window.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def range_(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series,\n    _column_name: str = \"cum_sum\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || **Function: mandelbrot_range**.\n\n    Calculate the range (max - min) of the cumulative deviate values of a\n    specified column in a DataFrame for each window in the dataset, if there are any.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The DataFrame to calculate the range from.\n    _column_name : str, optional\n        The column to calculate the range from, by default \"cumdev\".\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        A DataFrame with the range of the specified column for each window.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.max() - data.min()\n\n    if isinstance(data, pl.LazyFrame | pl.DataFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n    if _sort:\n        data = data.sort(sort_cols)\n    if over_cols:\n        out = (\n            data.set_sorted(sort_cols)\n            .with_columns(\n                [\n                    pl.col(_column_name)\n                    .min()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_min\"),\n                    pl.col(_column_name)\n                    .max()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_max\"),\n                ]\n            )\n            .sort(sort_cols)\n            .with_columns(\n                (\n                    pl.col(f\"{_column_name}_max\")\n                    - pl.col(f\"{_column_name}_min\")\n                ).alias(f\"{_column_name}_range\"),  # used to be 'R'\n            )\n        )\n    else:\n        out = (\n            data.with_columns(\n                [\n                    pl.col(_column_name).min().alias(f\"{_column_name}_min\"),\n                    pl.col(_column_name).max().alias(f\"{_column_name}_max\"),\n                ]\n            )\n            .sort(sort_cols)\n            .with_columns(\n                (\n                    pl.col(f\"{_column_name}_max\")\n                    - pl.col(f\"{_column_name}_min\")\n                ).alias(f\"{_column_name}_range\"),\n            )\n        )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.fundamental","title":"humbldata.toolbox.fundamental","text":"<p>Context: Toolbox || Category: Fundamental.</p> <p>A category to group all of the fundamental indicators available in the <code>Toolbox()</code>.</p> <p>Fundamental indicators relies on earnings data, valuation models of companies, balance sheet metrics etc...</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.quantitative","title":"humbldata.toolbox.quantitative","text":"<p>Context: Toolbox || Category: Quantitative.</p> <p>Quantitative indicators rely on statistical transformations of time series data.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical","title":"humbldata.toolbox.technical","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.technical_controller","title":"humbldata.toolbox.technical.technical_controller","text":"<p>Context: Toolbox || Category: Technical.</p> <p>A controller to manage and compile all of the technical indicator models available. This will be passed as a <code>@property</code> to the <code>Toolbox()</code> class, giving access to the technical module and its functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.technical_controller.Technical","title":"humbldata.toolbox.technical.technical_controller.Technical","text":"<p>Module for all technical analysis.</p> <p>Attributes:</p> Name Type Description <code>standard_params</code> <code>ToolboxQueryParams</code> <p>The standard query parameters for toolbox data.</p> <p>Methods:</p> Name Description <code>mandelbrot_channel</code> <p>Calculate the rescaled range statistics.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\technical_controller.py</code> <pre><code>class Technical:\n    \"\"\"\n    Module for all technical analysis.\n\n    Attributes\n    ----------\n    standard_params : ToolboxQueryParams\n        The standard query parameters for toolbox data.\n\n    Methods\n    -------\n    mandelbrot_channel(command_params: MandelbrotChannelQueryParams)\n        Calculate the rescaled range statistics.\n\n    \"\"\"\n\n    def __init__(self, context_params):\n        self._context_params = context_params\n\n    def mandelbrot_channel(self, command_params: MandelbrotChannelQueryParams):\n        \"\"\"\n        Calculate the rescaled range statistics.\n\n        Explain the math...\n        \"\"\"\n        from humbldata.core.standard_models.toolbox.technical.mandelbrotchannel import (\n            MandelbrotChannelFetcher,\n        )\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = MandelbrotChannelFetcher(self._context_params, command_params)\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.technical_controller.Technical.mandelbrot_channel","title":"humbldata.toolbox.technical.technical_controller.Technical.mandelbrot_channel","text":"<pre><code>mandelbrot_channel(command_params: MandelbrotChannelQueryParams)\n</code></pre> <p>Calculate the rescaled range statistics.</p> <p>Explain the math...</p> Source code in <code>src\\humbldata\\toolbox\\technical\\technical_controller.py</code> <pre><code>def mandelbrot_channel(self, command_params: MandelbrotChannelQueryParams):\n    \"\"\"\n    Calculate the rescaled range statistics.\n\n    Explain the math...\n    \"\"\"\n    from humbldata.core.standard_models.toolbox.technical.mandelbrotchannel import (\n        MandelbrotChannelFetcher,\n    )\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = MandelbrotChannelFetcher(self._context_params, command_params)\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel","title":"humbldata.toolbox.technical.mandelbrot_channel","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.add_window_index","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.add_window_index","text":"<pre><code>add_window_index(data: LazyFrame | DataFrame, window: str) -&gt; LazyFrame | DataFrame\n</code></pre> <pre><code>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n</code></pre> <p>Add a column to the dataframe indicating the window grouping for each row in a time series.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input data frame or lazy frame to which the window index will be added.</p> required <code>window</code> <code>str</code> <p>The window size as a string, used to determine the grouping of rows into windows.</p> required <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The original data frame or lazy frame with an additional column named \"window_index\" indicating the window grouping for each row.</p> Notes <ul> <li>This function is essential for calculating the Mandelbrot Channel, where the dataset is split into numerous 'windows', and statistics are calculated for each window.</li> <li>The function adds a dummy <code>symbol</code> column if the data contains only one symbol, to avoid errors in the <code>group_by_dynamic()</code> function.</li> <li>It is utilized within the <code>log_mean()</code> function for window-based calculations.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n&gt;&gt;&gt; window = \"1d\"\n&gt;&gt;&gt; add_window_index(data, window)\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n\u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n\u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def add_window_index(\n    data: pl.LazyFrame | pl.DataFrame, window: str\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n        Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n\n    Add a column to the dataframe indicating the window grouping for each row in\n    a time series.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input data frame or lazy frame to which the window index will be\n        added.\n    window : str\n        The window size as a string, used to determine the grouping of rows into\n        windows.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The original data frame or lazy frame with an additional column named\n        \"window_index\" indicating\n        the window grouping for each row.\n\n    Notes\n    -----\n    - This function is essential for calculating the Mandelbrot Channel, where\n    the dataset is split into\n    numerous 'windows', and statistics are calculated for each window.\n    - The function adds a dummy `symbol` column if the data contains only one\n    symbol, to avoid errors in the `group_by_dynamic()` function.\n    - It is utilized within the `log_mean()` function for window-based\n    calculations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n    &gt;&gt;&gt; window = \"1d\"\n    &gt;&gt;&gt; add_window_index(data, window)\n    shape: (2, 4)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n    \u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n    \u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n\n    def _create_monthly_window_index(col: str, k: int = 1):\n        year_diff = pl.col(col).last().dt.year() - pl.col(col).dt.year()\n        month_diff = pl.col(col).last().dt.month() - pl.col(col).dt.month()\n        day_indicator = pl.col(col).dt.day() &gt; pl.col(col).last().dt.day()\n        return (12 * year_diff + month_diff - day_indicator) // k\n\n    # Clean the window into stnaardized strings (i.e \"1month\"/\"1 month\" = \"1mo\")\n    window = _window_format(window, _return_timedelta=False)  # returns `str`\n\n    if \"w\" in window or \"d\" in window:\n        msg = \"The window cannot include 'd' or 'w', the window needs to be larger than 1 month!\"\n        raise HumblDataError(msg)\n\n    window_monthly = _window_format_monthly(window)\n\n    # Adding a 'dummy' column if only one symbol is present in data, to avoid\n    # errors in the group_by_dynamic() function\n    if \"symbol\" not in data.columns:\n        data = data.with_columns(pl.lit(\"dummy\").alias(\"symbol\"))\n\n    data = data.with_columns(\n        _create_monthly_window_index(col=\"date\", k=window_monthly)\n        .alias(\"window_index\")\n        .over(\"symbol\")\n    )\n\n    return data\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets","text":"<pre><code>vol_buckets(data: DataFrame | LazyFrame, lo_quantile: float = 0.4, hi_quantile: float = 0.8, _column_name_volatility: str = 'realized_volatility') -&gt; DataFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_buckets.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input dataframe or lazy frame.</p> required <code>lo_quantile</code> <code>float</code> <p>The lower quantile for bucketing. Default is 0.4.</p> <code>0.4</code> <code>hi_quantile</code> <code>float</code> <p>The higher quantile for bucketing. Default is 0.8.</p> <code>0.8</code> <code>window</code> <code>str</code> <p>The window for bucketing. Default is \"1m\".</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The output dataframe or lazy frame with the bucketed volatility.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def vol_buckets(\n    data: pl.DataFrame | pl.LazyFrame,\n    lo_quantile: float = 0.4,\n    hi_quantile: float = 0.8,\n    _column_name_volatility: str = \"realized_volatility\",\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_buckets**.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input dataframe or lazy frame.\n    lo_quantile : float\n        The lower quantile for bucketing. Default is 0.4.\n    hi_quantile : float\n        The higher quantile for bucketing. Default is 0.8.\n    window : str\n        The window for bucketing. Default is \"1m\".\n\n    Returns\n    -------\n    pl.DataFrame\n        The output dataframe or lazy frame with the bucketed volatility.\n    \"\"\"\n    # Group by 'symbol' and apply 'calculate_vol_buckets' to each group\n    if isinstance(data, pl.LazyFrame):\n        data = data.collect()\n\n    result = data.group_by(\"symbol\").map_groups(\n        lambda group_df: _calculate_vol_buckets(\n            group_df, lo_quantile, hi_quantile, _column_name_volatility\n        ),\n    )\n\n    return result.lazy()\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_filter","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_filter","text":"<pre><code>vol_filter(data: DataFrame | LazyFrame) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_filter.</p> <p>If <code>_rv_adjustment</code> is True, then filter the data to only include rows that are in the same vol_bucket as the latest row for each symbol.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def vol_filter(\n    data: pl.DataFrame | pl.LazyFrame,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_filter**.\n\n    If `_rv_adjustment` is True, then filter the data to only include rows\n    that are in the same vol_bucket as the latest row for each symbol.\n    \"\"\"\n    data = data.with_columns(\n        pl.col(\"vol_bucket\").last().over(\"symbol\").alias(\"last_vol_bucket\")\n    )\n\n    out = data.filter(\n        (pl.col(\"vol_bucket\") == pl.col(\"last_vol_bucket\")).over(\"symbol\")\n    ).drop(\"last_vol_bucket\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.helpers.price_range","title":"humbldata.toolbox.technical.mandelbrot_channel.helpers.price_range","text":"<pre><code>price_range(data: LazyFrame | DataFrame, rs_data: DataFrame | LazyFrame, recent_price_data: DataFrame | LazyFrame, _rs_method: str = 'RS', _detrended_returns: str = 'detrended_log_returns', *, _rv_adjustment: bool = False, **kwargs) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Calculate the price range based on the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[LazyFrame, DataFrame]</code> <p>The DataFrame to calculate the price range from.</p> required <code>_rs_method</code> <code>str</code> <p>Whether to use the fast method, by default True.</p> <code>'RS'</code> <code>RS</code> <code>Optional[Series]</code> <p>The RS series, by default None.</p> required <code>RS_mean</code> <code>Optional[float]</code> <p>The mean of the RS series, by default None.</p> required <code>RS_max</code> <code>Optional[float]</code> <p>The maximum of the RS series, by default None.</p> required <code>RS_min</code> <code>Optional[float]</code> <p>The minimum of the RS series, by default None.</p> required <code>recent_price</code> <code>Optional[float]</code> <p>The recent price, by default None.</p> required <code>cumdev_max</code> <code>Optional[DataFrame]</code> <p>The maximum range, by default None.</p> required <code>cumdev_min</code> <code>Optional[DataFrame]</code> <p>The minimum range, by default None.</p> required <code>RS_method</code> <code>str</code> <p>The method to calculate the RS, by default \"RS\".</p> required <code>_detrended_returns</code> <code>str</code> <p>The column name for detrended returns, by default \"detrended_log_returns\".</p> <code>'detrended_log_returns'</code> <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>The top and bottom price.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the RS_method is not one of 'RS', 'RS_mean', 'RS_max', 'RS_min'.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def price_range(\n    data: pl.LazyFrame | pl.DataFrame,\n    rs_data: pl.DataFrame | pl.LazyFrame,\n    recent_price_data: pl.DataFrame | pl.LazyFrame,\n    _rs_method: str = \"RS\",\n    _detrended_returns: str = \"detrended_log_returns\",  # Parameterized detrended_returns column\n    *,\n    _rv_adjustment: bool = False,\n    **kwargs,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Calculate the price range based on the specified method.\n\n    Parameters\n    ----------\n    data : Union[pl.LazyFrame, pl.DataFrame]\n        The DataFrame to calculate the price range from.\n    _rs_method : str, optional\n        Whether to use the fast method, by default True.\n    RS : Optional[pl.Series], optional\n        The RS series, by default None.\n    RS_mean : Optional[float], optional\n        The mean of the RS series, by default None.\n    RS_max : Optional[float], optional\n        The maximum of the RS series, by default None.\n    RS_min : Optional[float], optional\n        The minimum of the RS series, by default None.\n    recent_price : Optional[float], optional\n        The recent price, by default None.\n    cumdev_max : Optional[pl.DataFrame], optional\n        The maximum range, by default None.\n    cumdev_min : Optional[pl.DataFrame], optional\n        The minimum range, by default None.\n    RS_method : str, optional\n        The method to calculate the RS, by default \"RS\".\n    _detrended_returns: str, optional\n        The column name for detrended returns, by default \"detrended_log_returns\".\n    **kwargs\n        Arbitrary keyword arguments.\n\n    Returns\n    -------\n    Tuple[float, float]\n        The top and bottom price.\n\n    Raises\n    ------\n    ValueError\n        If the RS_method is not one of 'RS', 'RS_mean', 'RS_max', 'RS_min'.\n    \"\"\"\n    # Check if RS_method is one of the allowed values\n    if _rs_method not in RS_METHODS:\n        msg = \"RS_method must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'\"\n        raise HumblDataError(msg)\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n\n    if _rv_adjustment:\n        # Calculate STD where detrended_returns are in the same rvol_bucket\n        std_detrended_returns = (\n            data.lazy()\n            .sort(sort_cols)\n            .group_by(\"symbol\")\n            .agg(\n                [\n                    pl.col(_detrended_returns)\n                    .std()\n                    .alias(f\"std_{_detrended_returns}\")\n                ]\n            )\n        )\n    else:\n        # Calculate STD where detrended_returns are from the latest range for each symbol\n        std_detrended_returns = (\n            data.filter(\n                (pl.col(\"window_index\") == pl.col(\"window_index\").max()).over(\n                    \"symbol\"\n                )\n            )\n            .group_by(\"symbol\")\n            .agg(\n                [\n                    pl.col(_detrended_returns)\n                    .std()\n                    .alias(f\"std_{_detrended_returns}\")\n                ]\n            )\n            # get the latest window of data\n            .select(pl.col([\"symbol\", f\"std_{_detrended_returns}\"]))\n        )\n    # Merge RS stats with STD of detrended returns and recent price\n    price_range = rs_data.join(std_detrended_returns, on=\"symbol\").join(\n        recent_price_data.lazy(), on=\"symbol\"\n    )\n\n    price_range = price_range.with_columns(\n        (\n            pl.col(_rs_method)\n            * pl.col(\"std_detrended_log_returns\")\n            * pl.col(\"recent_price\")\n        ).alias(\"price_range\")\n    )\n\n    # Relative Position Modifier\n    out = _modify_mandelbrot_prices(\n        data,\n        price_range,\n        \"cum_sum_max\",\n        \"cum_sum_min\",\n    )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model","title":"humbldata.toolbox.technical.mandelbrot_channel.model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_mandelbrot_channel.</p> <p>A command to generate a Mandelbrot Channel for any time series.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel","title":"humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel","text":"<pre><code>calc_mandelbrot_channel(data: DataFrame | LazyFrame, window: str = '1m', rv_adjustment: bool = True, _rv_grouped_mean: bool = True, _rv_method: str = 'std', _rs_method: str = 'RS', _live_price: bool = True) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: Mandelbrot Channel.</p> <p>Calculates the Mandelbrot Channel for a given time series based on the provided standard and extra parameters.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Mandelbrot Channel.</p> required <code>window</code> <code>str</code> <p>The window size for the calculation, specified as a string.</p> <code>'1m'</code> <code>rv_adjustment</code> <code>bool</code> <p>Whether to adjust the calculation for realized volatility.</p> <code>True</code> <code>_rv_grouped_mean</code> <code>bool</code> <p>Whether to use the grouped mean in the realized volatility calculation.</p> <code>True</code> <code>_rv_method</code> <code>str</code> <p>The method to use for calculating realized volatility. You only need to supply a value if <code>rv_adjustment</code> is True.</p> <code>'std'</code> <code>_rs_method</code> <code>str</code> <p>The method to use for calculating the range over standard deviation. You can choose either RS/RS_mean/RS_min/RS_max. This changes the width of the calculated Mandelbrot Channel</p> <code>'RS'</code> <code>_live_price</code> <code>bool</code> <p>Whether to use live price data in the calculation. This may add a significant amount of time to the calculation (1-3s)</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The calculated Mandelbrot Channel data for the given time series.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\model.py</code> <pre><code>def calc_mandelbrot_channel(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_adjustment: bool = True,\n    _rv_grouped_mean: bool = True,\n    _rv_method: str = \"std\",\n    _rs_method: str = \"RS\",\n    _live_price: bool = True,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: Mandelbrot Channel**.\n\n    Calculates the Mandelbrot Channel for a given time series based on the\n    provided standard and extra parameters.\n\n    Parameters\n    ----------\n    data: pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Mandelbrot Channel.\n    window: str, default \"1m\"\n        The window size for the calculation, specified as a string.\n    rv_adjustment: bool, default True\n        Whether to adjust the calculation for realized volatility.\n    _rv_grouped_mean: bool, default True\n        Whether to use the grouped mean in the realized volatility calculation.\n    _rv_method: str, default \"std\"\n        The method to use for calculating realized volatility. You only need to\n        supply a value if `rv_adjustment` is True.\n    _rs_method: str, default \"RS\"\n        The method to use for calculating the range over standard deviation.\n        You can choose either RS/RS_mean/RS_min/RS_max. This changes the width of\n        the calculated Mandelbrot Channel\n    _live_price: bool, default True\n        Whether to use live price data in the calculation. This may add a\n        significant amount of time to the calculation (1-3s)\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The calculated Mandelbrot Channel data for the given time series.\n    \"\"\"\n    # Setup ====================================================\n    window_int = _window_format(window, _return_timedelta=True)\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n\n    data = data.lazy()\n    # Step 1: Collect Price Data -------------------------------------------\n    # Step X: Add window bins ----------------------------------------------\n    # We want date grouping, non-overlapping window bins\n    data1 = add_window_index(data, window=window)\n\n    # Step X: Calculate Log Returns + Rvol ---------------------------------\n    if \"log_returns\" not in data1.columns:\n        data2 = log_returns(data1, _column_name=\"close\")\n    else:\n        data2 = data1\n\n    # Step X: Calculate Log Mean Series ------------------------------------\n    if isinstance(data2, pl.DataFrame | pl.LazyFrame):\n        data3 = mean(data2)\n    else:\n        msg = \"A series was passed to `mean()` calculation. Please provide a DataFrame or LazyFrame.\"\n        raise HumblDataError(msg)\n    # Step X: Calculate Mean De-trended Series -----------------------------\n    data4 = detrend(\n        data3, _detrend_value_col=\"window_mean\", _detrend_col=\"log_returns\"\n    )\n    # Step X: Calculate Cumulative Deviate Series --------------------------\n    data5 = cum_sum(data4, _column_name=\"detrended_log_returns\")\n    # Step X: Calculate Mandelbrot Range -----------------------------------\n    data6 = range_(data5, _column_name=\"cum_sum\")\n    # Step X: Calculate Standard Deviation ---------------------------------\n    data7 = std(data6, _column_name=\"cum_sum\")\n    # Step X: Calculate Range (R) &amp; Standard Deviation (S) -----------------\n    if rv_adjustment:\n        # Step 8.1: Calculate Realized Volatility --------------------------\n        data7 = calc_realized_volatility(\n            data=data7,\n            window=window,\n            method=_rv_method,\n            grouped_mean=_rv_grouped_mean,\n        )\n        # rename col for easy selection\n        for col in data7.columns:\n            if \"volatility_pct\" in col:\n                data7 = data7.rename({col: \"realized_volatility\"})\n        # Step 8.2: Calculate Volatility Bucket Stats ----------------------\n        data7 = vol_buckets(data=data7, lo_quantile=0.3, hi_quantile=0.65)\n        data7 = vol_filter(data7)\n\n    # Step X: Calculate RS -------------------------------------------------\n    data8 = data7.sort(sort_cols).with_columns(\n        (pl.col(\"cum_sum_range\") / pl.col(\"cum_sum_std\")).alias(\"RS\")\n    )\n    # Calculate mean, min, and max of 'RS' for each 'symbol' group\n    # do i need to collect only the last window for RS or do i want the calcs over the whole data\n    rs_data = (\n        data8.group_by(\"symbol\")\n        .agg(\n            [\n                pl.col(\"RS\").last().alias(\"RS\"),\n                pl.col(\"RS\").mean().alias(\"RS_mean\"),\n                pl.col(\"RS\").min().alias(\"RS_min\"),\n                pl.col(\"RS\").max().alias(\"RS_max\"),\n            ]\n        )\n        .sort(\"symbol\")\n    )\n\n    # Step X: Collect Recent Prices ----------------------------------------\n    if _live_price:\n        symbols = (\n            data.select(\"symbol\").unique().to_pandas().sort_values(\"symbol\")\n        )\n        recent_prices = get_latest_price(symbols)\n    else:\n        recent_prices = (\n            data1.group_by(\"symbol\")\n            .agg(pl.col(\"close\").last().alias(\"recent_price\"))\n            .sort(\"symbol\")\n        )\n\n    # Step X: Calculate Rescaled Price Range ------------------------------\n    out = price_range(\n        data=data8,\n        rs_data=rs_data,\n        recent_price_data=recent_prices,\n        _rs_method=_rs_method,\n        _rv_adjustment=rv_adjustment,\n    )\n\n    return out\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility","title":"humbldata.toolbox.technical.volatility","text":""},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers.</p> <p>All of the volatility estimators used in <code>calc_realized_volatility()</code>. These are various methods to calculate the realized volatility of financial data.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.std","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.std","text":"<pre><code>std(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _std.</p> <p>This function computes the standard deviation of returns, which is a common measure of volatility.It calculates the rolling standard deviation for a given window size, optionally adjusting for the average number of trading days and scaling the result to an annualized volatility percentage.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data containing the returns. It can be a DataFrame, LazyFrame, or Series.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating the standard deviation. The default is \"1m\" (one month).</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for annualizing the volatility. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>If True, null values will be dropped from the result. The default is True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>If True, the average number of trading days will be used when calculating the window size. The default is True.</p> <code>False</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. This parameter is used when <code>data</code> is a DataFrame or LazyFrame. The default is \"log_returns\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data structure with an additional column for the rolling standard deviation of returns, or the modified Series with the rolling standard deviation values.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def std(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _std**.\n\n    This function computes the standard deviation of returns, which is a common\n    measure of volatility.It calculates the rolling standard deviation for a\n    given window size, optionally adjusting for the average number of trading\n    days and scaling the result to an annualized volatility percentage.\n\n    Parameters\n    ----------\n    data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data containing the returns. It can be a DataFrame, LazyFrame,\n        or Series.\n    window : str, optional\n        The rolling window size for calculating the standard deviation.\n        The default is \"1m\" (one month).\n    trading_periods : int, optional\n        The number of trading periods in a year, used for annualizing the\n        volatility. The default is 252.\n    _drop_nulls : bool, optional\n        If True, null values will be dropped from the result.\n        The default is True.\n    _avg_trading_days : bool, optional\n        If True, the average number of trading days will be used when\n        calculating the window size. The default is True.\n    _column_name_returns : str, optional\n        The name of the column containing the returns. This parameter is used\n        when `data` is a DataFrame or LazyFrame. The default is \"log_returns\".\n\n    Returns\n    -------\n    Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data structure with an additional column for the rolling\n        standard deviation of returns, or the modified Series with the rolling\n        standard deviation values.\n    \"\"\"\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    if isinstance(data, pl.Series):\n        return data.rolling_std(window_size=window_int, min_periods=1)\n    else:\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort:\n            data = data.lazy().sort(sort_cols)\n        # convert window_timedelta to days to use fixed window\n        result = (\n            data.lazy()\n            .set_sorted(sort_cols)\n            .with_columns(\n                (\n                    pl.col(_column_name_returns).rolling_std(\n                        window_size=window_int,\n                        min_periods=2,  # using min_periods=2, bc if min_periods=1, the first value will be 0.\n                        by=\"date\",\n                    )\n                    * math.sqrt(trading_periods)\n                    * 100\n                ).alias(f\"std_volatility_pct_{window_int}D\")\n            )\n        )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"std_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.parkinson","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.parkinson","text":"<pre><code>parkinson(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate Parkinson's volatility over a specified window.</p> <p>Parkinson's volatility is a measure that uses the stock's high and low prices of the day rather than just close to close prices. It is particularly useful for capturing large price movements during the day.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the stock prices.</p> required <code>window</code> <code>int</code> <p>The rolling window size for calculating volatility, by default 30.</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, by default 252.</p> required <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The calculated Parkinson's volatility, with an additional column \"parkinson_volatility_pct_{window_int}D\" indicating the percentage volatility.</p> Notes <p>This function requires the input data to have 'high' and 'low' columns to calculate the logarithm of their ratio, which is squared and scaled by a constant to estimate volatility. The result is then annualized and expressed as a percentage.</p> Usage <p>If you pass <code>\"1m</code> as a <code>window</code> argument and  <code>_avg_trading_days=False</code>. The result will be <code>30</code>. If <code>_avg_trading_days=True</code>, the result will be <code>21</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n&gt;&gt;&gt; _parkinson(data)\nA DataFrame with the calculated Parkinson's volatility.\n</code></pre> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def parkinson(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate Parkinson's volatility over a specified window.\n\n    Parkinson's volatility is a measure that uses the stock's high and low prices\n    of the day rather than just close to close prices. It is particularly useful\n    for capturing large price movements during the day.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the stock prices.\n    window : int, optional\n        The rolling window size for calculating volatility, by default 30.\n    trading_periods : int, optional\n        The number of trading periods in a year, by default 252.\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The calculated Parkinson's volatility, with an additional column\n        \"parkinson_volatility_pct_{window_int}D\"\n        indicating the percentage volatility.\n\n    Notes\n    -----\n    This function requires the input data to have 'high' and 'low' columns to\n    calculate\n    the logarithm of their ratio, which is squared and scaled by a constant to\n    estimate\n    volatility. The result is then annualized and expressed as a percentage.\n\n    Usage\n    -----\n    If you pass `\"1m` as a `window` argument and  `_avg_trading_days=False`.\n    The result will be `30`. If `_avg_trading_days=True`, the result will be\n    `21`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n    &gt;&gt;&gt; _parkinson(data)\n    A DataFrame with the calculated Parkinson's volatility.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n\n    var1 = 1.0 / (4.0 * math.log(2.0))\n    var2 = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    rs = var1 * var2**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            (\n                rs.rolling_map(\n                    _annual_vol, window_size=window_int, min_periods=1\n                )\n                * 100\n            ).alias(f\"parkinson_volatility_pct_{window_int}D\")\n        )\n    )\n    if _drop_nulls:\n        return result.drop_nulls(\n            subset=f\"parkinson_volatility_pct_{window_int}D\"\n        )\n\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.garman_klass","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.garman_klass","text":"<pre><code>garman_klass(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'adj_close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _garman_klass.</p> <p>Calculates the Garman-Klass volatility for a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for volatility calculation, by default \"1m\".</p> <code>'1m'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the opening prices, by default \"open\".</p> <code>'open'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the adjusted closing prices, by default \"adj_close\".</p> <code>'adj_close'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The calculated Garman-Klass volatility, with an additional column \"volatility_pct\" indicating the percentage volatility.</p> Notes <p>Garman-Klass volatility extends Parkinson\u2019s volatility by considering the opening and closing prices in addition to the high and low prices. This approach provides a more accurate estimation of volatility, especially in markets with significant activity at the opening and closing of trading sessions.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def garman_klass(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"adj_close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _garman_klass**.\n\n    Calculates the Garman-Klass volatility for a given dataset.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for volatility calculation, by default \"1m\".\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _column_name_open : str, optional\n        The name of the column containing the opening prices, by default \"open\".\n    _column_name_close : str, optional\n        The name of the column containing the adjusted closing prices, by\n        default \"adj_close\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The calculated Garman-Klass volatility, with an additional column\n        \"volatility_pct\" indicating the percentage volatility.\n\n    Notes\n    -----\n    Garman-Klass volatility extends Parkinson\u2019s volatility by considering the\n    opening and closing prices in addition to the high and low prices. This\n    approach provides a more accurate estimation of volatility, especially in\n    markets with significant activity at the opening and closing of trading\n    sessions.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n    log_hi_lo = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    log_close_open = (\n        data.lazy()\n        .select((pl.col(_column_name_close) / pl.col(_column_name_open)).log())\n        .collect()\n        .to_series()\n    )\n    rs: pl.Series = 0.5 * log_hi_lo**2 - (2 * np.log(2) - 1) * log_close_open**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = data.lazy().with_columns(\n        (\n            rs.rolling_map(_annual_vol, window_size=window_int, min_periods=1)\n            * 100\n        ).alias(f\"gk_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"gk_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.hodges_tompkins","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.hodges_tompkins","text":"<pre><code>hodges_tompkins(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _column_name_returns: str = 'log_returns', *, _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _hodges_tompkins.</p> <p>Hodges-Tompkins volatility is a bias correction for estimation using an overlapping data sample that produces unbiased estimates and a substantial gain in efficiency.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def hodges_tompkins(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _column_name_returns: str = \"log_returns\",\n    *,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _hodges_tompkins**.\n\n    Hodges-Tompkins volatility is a bias correction for estimation using an\n    overlapping data sample that produces unbiased estimates and a\n    substantial gain in efficiency.\n    \"\"\"\n    # When calculating rv_mean, need a different adjustment factor,\n    # so window doesn't influence the Volatility_mean\n    # RV_MEAN\n\n    # Define Window Size\n    window_timedelta = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    )\n    # Calculate STD, assigned to `vol`\n    if isinstance(data, pl.Series):\n        vol = data.rolling_std(window_size=window_timedelta.days, min_periods=1)\n    else:\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort:\n            data = data.lazy().sort(sort_cols)\n        vol = (\n            data.lazy()\n            .set_sorted(sort_cols)\n            .select(\n                pl.col(_column_name_returns).rolling_std(\n                    window_size=window_timedelta, min_periods=1, by=\"date\"\n                )\n                * np.sqrt(trading_periods)\n            )\n        )\n\n    # Assign window size to h for adjustment\n    h: int = window_timedelta.days\n\n    if isinstance(data, pl.Series):\n        count = data.len()\n    elif isinstance(data, pl.LazyFrame):\n        count = data.collect().shape[0]\n    else:\n        count = data.shape[0]\n\n    n = (count - h) + 1\n    adj_factor = 1.0 / (1.0 - (h / n) + ((h**2 - 1) / (3 * n**2)))\n\n    if isinstance(data, pl.Series):\n        return (vol * adj_factor) * 100\n    else:\n        result = data.lazy().with_columns(\n            ((vol.collect() * adj_factor) * 100)\n            .to_series()\n            .alias(f\"ht_volatility_pct_{h}D\")\n        )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"ht_volatility_pct_{h}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.rogers_satchell","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.rogers_satchell","text":"<pre><code>rogers_satchell(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'adj_close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _rogers_satchell.</p> <p>Rogers-Satchell is an estimator for measuring the volatility of securities with an average return not equal to zero. Unlike Parkinson and Garman-Klass estimators, Rogers-Satchell incorporates a drift term (mean return not equal to zero). This function calculates the Rogers-Satchell volatility estimator over a specified window and optionally drops null values from the result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data for which to calculate the Rogers-Satchell volatility estimator. This can be either a DataFrame or a LazyFrame. There need to be OHLC columns present in the data.</p> required <code>window</code> <code>str</code> <p>The window over which to calculate the volatility estimator. The window is specified as a string, such as \"1m\" for one month.</p> <code>\"1m\"</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column representing the high prices in the data.</p> <code>\"high\"</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column representing the low prices in the data.</p> <code>\"low\"</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column representing the opening prices in the data.</p> <code>\"open\"</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column representing the adjusted closing prices in the data.</p> <code>\"adj_close\"</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. If True, rows with null values in the calculated volatility column will be removed from the output.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Indicates whether to use the average number of trading days per window. This affects how the window size is interpreted. i.e instead of \"1mo\" returning <code>timedelta(days=31)</code>, it will return <code>timedelta(days=21)</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data with an additional column containing the calculated Rogers-Satchell volatility estimator. The return type matches the input type (DataFrame or LazyFrame).</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def rogers_satchell(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"adj_close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _rogers_satchell**.\n\n    Rogers-Satchell is an estimator for measuring the volatility of\n    securities with an average return not equal to zero. Unlike Parkinson\n    and Garman-Klass estimators, Rogers-Satchell incorporates a drift term\n    (mean return not equal to zero). This function calculates the\n    Rogers-Satchell volatility estimator over a specified window and optionally\n    drops null values from the result.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data for which to calculate the Rogers-Satchell volatility\n        estimator. This can be either a DataFrame or a LazyFrame. There need to\n        be OHLC columns present in the data.\n    window : str, default \"1m\"\n        The window over which to calculate the volatility estimator. The\n        window is specified as a string, such as \"1m\" for one month.\n    _column_name_high : str, default \"high\"\n        The name of the column representing the high prices in the data.\n    _column_name_low : str, default \"low\"\n        The name of the column representing the low prices in the data.\n    _column_name_open : str, default \"open\"\n        The name of the column representing the opening prices in the data.\n    _column_name_close : str, default \"adj_close\"\n        The name of the column representing the adjusted closing prices in the\n        data.\n    _drop_nulls : bool, default True\n        Whether to drop null values from the result. If True, rows with null\n        values in the calculated volatility column will be removed from the\n        output.\n    _avg_trading_days : bool, default True\n        Indicates whether to use the average number of trading days per window.\n        This affects how the window size is interpreted. i.e instead of \"1mo\"\n        returning `timedelta(days=31)`, it will return `timedelta(days=21)`.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data with an additional column containing the calculated\n        Rogers-Satchell volatility estimator. The return type matches the input\n        type (DataFrame or LazyFrame).\n    \"\"\"\n    # Check if all required columns are present in the DataFrame\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n            ]\n        )\n        .with_columns(\n            (\n                pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n            ).alias(\"rs\")\n        )\n    )\n    result = data.lazy().with_columns(\n        (\n            pl.col(\"rs\").rolling_map(\n                _annual_vol, window_size=window_int, min_periods=1\n            )\n            * 100\n        ).alias(f\"rs_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"rs_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.yang_zhang","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.yang_zhang","text":"<pre><code>yang_zhang(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'adj_close', _avg_trading_days: bool = False, _drop_nulls: bool = True, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _yang_zhang.</p> <p>Yang-Zhang volatility is the combination of the overnight (close-to-open volatility), a weighted average of the Rogers-Satchell volatility and the day\u2019s open-to-close volatility.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def yang_zhang(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"adj_close\",\n    _avg_trading_days: bool = False,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _yang_zhang**.\n\n    Yang-Zhang volatility is the combination of the overnight\n    (close-to-open volatility), a weighted average of the Rogers-Satchell\n    volatility and the day\u2019s open-to-close volatility.\n    \"\"\"\n    # check required columns\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n                (pl.col(_column_name_open) / pl.col(_column_name_close).shift())\n                .log()\n                .alias(\"log_oc\"),\n                (\n                    pl.col(_column_name_close)\n                    / pl.col(_column_name_close).shift()\n                )\n                .log()\n                .alias(\"log_cc\"),\n            ]\n        )\n        .with_columns(\n            [\n                (pl.col(\"log_oc\") ** 2).alias(\"log_oc_sq\"),\n                (pl.col(\"log_cc\") ** 2).alias(\"log_cc_sq\"),\n                (\n                    pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                    + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n                ).alias(\"rs\"),\n            ]\n        )\n    )\n\n    k = 0.34 / (1.34 + (window_int + 1) / (window_int - 1))\n    data = _yang_zhang_engine(data=data, window=window_int)\n    result = (\n        data.lazy()\n        .with_columns(\n            (\n                (\n                    pl.col(\"open_vol\")\n                    + k * pl.col(\"close_vol\")\n                    + (1 - k) * pl.col(\"window_rs\")\n                ).sqrt()\n                * np.sqrt(trading_periods)\n                * 100\n            ).alias(f\"yz_volatility_pct_{window_int}D\")\n        )\n        .select(\n            pl.exclude(\n                [\n                    \"log_ho\",\n                    \"log_lo\",\n                    \"log_co\",\n                    \"log_oc\",\n                    \"log_cc\",\n                    \"log_oc_sq\",\n                    \"log_cc_sq\",\n                    \"rs\",\n                    \"close_vol\",\n                    \"open_vol\",\n                    \"window_rs\",\n                ]\n            )\n        )\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"yz_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.squared_returns","title":"humbldata.toolbox.technical.volatility.realized_volatility_helpers.squared_returns","text":"<pre><code>squared_returns(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate squared returns over a rolling window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating squared returns, by default \"1m\".</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for scaling the result. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the price data, by default \"adj_close\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data structure with an additional column for the rolling squared returns.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def squared_returns(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate squared returns over a rolling window.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for calculating squared returns, by default \"1m\".\n    trading_periods : int, optional\n        The number of trading periods in a year, used for scaling the result.\n        The default is 252.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _column_name_returns : str, optional\n        The name of the column containing the price data, by default \"adj_close\".\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data structure with an additional column for the rolling\n        squared returns.\n    \"\"\"\n    _check_required_columns(data, _column_name_returns)\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            ((pl.col(_column_name_returns) * 100) ** 2).alias(\n                \"sq_log_returns_pct\"\n            )\n        )\n    )\n    # Calculate rolling squared returns\n    result = (\n        data.lazy()\n        .with_columns(\n            pl.col(\"sq_log_returns_pct\")\n            .rolling_mean(window_size=window_int, min_periods=1)\n            .alias(f\"sq_volatility_pct_{window_int}D\")\n        )\n        .drop(\"sq_log_returns_pct\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"sq_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_model","title":"humbldata.toolbox.technical.volatility.realized_volatility_model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>A command to generate Realized Volatility for any time series.</p>"},{"location":"code_documentation/api_reference/#humbldata.toolbox.technical.volatility.realized_volatility_model.calc_realized_volatility","title":"humbldata.toolbox.technical.volatility.realized_volatility_model.calc_realized_volatility","text":"<pre><code>calc_realized_volatility(data: DataFrame | LazyFrame, window: str = '1m', method: Literal['std', 'parkinson', 'garman_klass', 'gk', 'hodges_tompkins', 'ht', 'rogers_satchell', 'rs', 'yang_zhang', 'yz', 'squared_returns', 'sq'] = 'std', grouped_mean: list[int] | None = None, _trading_periods: int = 252, _column_name_returns: str = 'log_returns', _column_name_close: str = 'close', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', *, _sort: bool = True) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>Calculates the Realized Volatility for a given time series based on the provided standard and extra parameters. This function adds ONE rolling volatility column to the input DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Realized Volatility.</p> required <code>window</code> <code>str</code> <p>The window size for a rolling volatility calculation, default is <code>\"1m\"</code> (1 month).</p> <code>'1m'</code> <code>method</code> <code>Literal['std', 'parkinson', 'garman_klass', 'hodges_tompkins', 'rogers_satchell', 'yang_zhang', 'squared_returns']</code> <p>The volatility estimator to use. You can also use abbreviations to access the same methods. The abbreviations are: <code>gk</code> for <code>garman_klass</code>, <code>ht</code> for <code>hodges_tompkins</code>, <code>rs</code> for <code>rogers_satchell</code>, <code>yz</code> for <code>yang_zhang</code>, <code>sq</code> for <code>squared_returns</code>.</p> <code>'std'</code> <code>grouped_mean</code> <code>list[int] | None</code> <p>A list of window sizes to use for calculating volatility. If provided, the volatility method will be calculated across these various windows, and then an averaged value of all the windows will be returned. If <code>None</code>, a single window size specified by <code>window</code> parameter will be used.</p> <code>None</code> <code>_sort</code> <code>bool</code> <p>If True, the data will be sorted before calculation. Default is True.</p> <code>True</code> <code>_trading_periods</code> <code>int</code> <p>The number of trading periods in a year, default is 252 (the typical number of trading days in a year).</p> <code>252</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. Default is \"log_returns\".</p> <code>'log_returns'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the close prices. Default is \"close\".</p> <code>'close'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices. Default is \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices. Default is \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the open prices. Default is \"open\".</p> <code>'open'</code> <p>Returns:</p> Type Description <code>VolatilityData</code> <p>The calculated Realized Volatility data for the given time series.</p> Notes <ul> <li> <p>Rolling calculations are used to show a time series of recent volatility that captures only a certain number of data points. The window size is used to determine the number of data points to use in the calculation. We do this because when looking at the volatility of a stock, you get a better insight (more granular) into the characteristics of the volatility seeing how 1-month or 3-month rolling volatility looked over time.</p> </li> <li> <p>This function does not accept <code>pl.Series</code> because the methods used to calculate volatility require, high, low, close, open columns for the data. It would be too cumbersome to pass each series needed for the calculation as a separate argument. Therefore, the function only accepts <code>pl.DataFrame</code> or <code>pl.LazyFrame</code> as input.</p> </li> </ul> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_model.py</code> <pre><code>def calc_realized_volatility(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    method: Literal[  # used to be rvol_method\n        \"std\",\n        \"parkinson\",\n        \"garman_klass\",\n        \"gk\",\n        \"hodges_tompkins\",\n        \"ht\",\n        \"rogers_satchell\",\n        \"rs\",\n        \"yang_zhang\",\n        \"yz\",\n        \"squared_returns\",\n        \"sq\",\n    ] = \"std\",\n    grouped_mean: list[int] | None = None,  # used to be rv_mean\n    _trading_periods: int = 252,\n    _column_name_returns: str = \"log_returns\",\n    _column_name_close: str = \"close\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: calc_realized_volatility**.\n\n    Calculates the Realized Volatility for a given time series based on the\n    provided standard and extra parameters. This function adds ONE rolling\n    volatility column to the input DataFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Realized Volatility.\n    window : str\n        The window size for a rolling volatility calculation, default is `\"1m\"`\n        (1 month).\n    method : Literal[\"std\", \"parkinson\", \"garman_klass\", \"hodges_tompkins\",\"rogers_satchell\", \"yang_zhang\", \"squared_returns\"]\n        The volatility estimator to use. You can also use abbreviations to\n        access the same methods. The abbreviations are: `gk` for `garman_klass`,\n        `ht` for `hodges_tompkins`, `rs` for `rogers_satchell`, `yz` for\n        `yang_zhang`, `sq` for `squared_returns`.\n    grouped_mean : list[int] | None\n        A list of window sizes to use for calculating volatility. If provided,\n        the volatility method will be calculated across these various windows,\n        and then an averaged value of all the windows will be returned. If `None`,\n        a single window size specified by `window` parameter will be used.\n    _sort : bool\n        If True, the data will be sorted before calculation. Default is True.\n    _trading_periods : int\n        The number of trading periods in a year, default is 252 (the typical\n        number of trading days in a year).\n    _column_name_returns : str\n        The name of the column containing the returns. Default is \"log_returns\".\n    _column_name_close : str\n        The name of the column containing the close prices. Default is \"close\".\n    _column_name_high : str\n        The name of the column containing the high prices. Default is \"high\".\n    _column_name_low : str\n        The name of the column containing the low prices. Default is \"low\".\n    _column_name_open : str\n        The name of the column containing the open prices. Default is \"open\".\n\n    Returns\n    -------\n    VolatilityData\n        The calculated Realized Volatility data for the given time series.\n\n    Notes\n    -----\n    - Rolling calculations are used to show a time series of recent volatility\n    that captures only a certain number of data points. The window size is\n    used to determine the number of data points to use in the calculation. We do\n    this because when looking at the volatility of a stock, you get a better\n    insight (more granular) into the characteristics of the volatility seeing how 1-month or\n    3-month rolling volatility looked over time.\n\n    - This function does not accept `pl.Series` because the methods used to\n    calculate volatility require, high, low, close, open columns for the data.\n    It would be too cumbersome to pass each series needed for the calculation\n    as a separate argument. Therefore, the function only accepts `pl.DataFrame`\n    or `pl.LazyFrame` as input.\n    \"\"\"  # noqa: W505\n    # Step 1: Get the correct realized volatility function =====================\n    func = VOLATILITY_METHODS.get(method)\n    if not func:\n        msg = f\"Volatility method: '{method}' is not supported.\"\n        raise HumblDataError(msg)\n\n    # Step 2: Get the names of the parameters that the function accepts ========\n    func_params = inspect.signature(func).parameters\n\n    # Step 3: Filter out the parameters not accepted by the function ===========\n    args_to_pass = {\n        key: value for key, value in locals().items() if key in func_params\n    }\n\n    # Step 4: Calculate Realized Volatility ====================================\n    if grouped_mean:\n        # calculate volatility over multiple windows and average the result, add to a new column\n        print(\"\ud83d\udea7 WIP!\")\n    else:\n        out = func(**args_to_pass)\n\n    return out\n</code></pre>"},{"location":"code_documentation/category/","title":"\ud83d\udcda Category","text":""},{"location":"code_documentation/command/","title":"\ud83c\udfc3\ud83c\udffc\u200d\u2642\ufe0f Command","text":""},{"location":"code_documentation/core/","title":"\ud83d\udd78\ufe0f Core","text":"<p>The <code>core</code> module to contain logic &amp; functions used in controllers.</p> <p>This module is intended to contain sub-modules and functions that are not directly utilized from the package, but rather used in building the package itself. This means that the core module should not contain any code that is specific to the package's use case, but rather should be generic and reusable in other contexts.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models","title":"humbldata.core.standard_models","text":"<p>Models to represent core data structures of the Standardization Framework.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract","title":"humbldata.core.standard_models.abstract","text":"<p>Abstract core DATA MODELS to be inherited by other models.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.data","title":"humbldata.core.standard_models.abstract.data","text":"<p>A wrapper around OpenBB Data Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.data.Data","title":"humbldata.core.standard_models.abstract.data.Data","text":"<p>             Bases: <code>Data</code></p> <p>An abstract standard_model to represent a base Data Model.</p> <p>The Data Model should be used to define the data that is being collected and analyzed in a <code>context.category.command</code> call.</p> <p>This Data model is meant to be inherited and built upon by other standard_models for a specific context.</p> Example <pre><code>total_time = f\"{end_time - start_time:.3f}\"\nclass EquityHistoricalData(Data):\n\ndate: Union[dateType, datetime] = Field(\n    description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n)\nopen: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\nhigh: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\nlow: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\nclose: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\nvolume: Optional[Union[float, int]] = Field(\n    default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n)\n\n@field_validator(\"date\", mode=\"before\", check_fields=False)\ndef date_validate(cls, v):  # pylint: disable=E0213\n    v = parser.isoparse(str(v))\n    if v.hour == 0 and v.minute == 0:\n        return v.date()\n    return v\n</code></pre> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\data.py</code> <pre><code>class Data(OpenBBData):\n    \"\"\"\n    An abstract standard_model to represent a base Data Model.\n\n    The Data Model should be used to define the data that is being\n    collected and analyzed in a `context.category.command` call.\n\n    This Data model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Example\n    -------\n    ```py\n    total_time = f\"{end_time - start_time:.3f}\"\n    class EquityHistoricalData(Data):\n\n    date: Union[dateType, datetime] = Field(\n        description=DATA_DESCRIPTIONS.get(\"date\", \"\")\n    )\n    open: float = Field(description=DATA_DESCRIPTIONS.get(\"open\", \"\"))\n    high: float = Field(description=DATA_DESCRIPTIONS.get(\"high\", \"\"))\n    low: float = Field(description=DATA_DESCRIPTIONS.get(\"low\", \"\"))\n    close: float = Field(description=DATA_DESCRIPTIONS.get(\"close\", \"\"))\n    volume: Optional[Union[float, int]] = Field(\n        default=None, description=DATA_DESCRIPTIONS.get(\"volume\", \"\")\n    )\n\n    @field_validator(\"date\", mode=\"before\", check_fields=False)\n    def date_validate(cls, v):  # pylint: disable=E0213\n        v = parser.isoparse(str(v))\n        if v.hour == 0 and v.minute == 0:\n            return v.date()\n        return v\n\n    ```\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.errors","title":"humbldata.core.standard_models.abstract.errors","text":"<p>An ABSTRACT DATA MODEL to be inherited by custom errors.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.errors.HumblDataError","title":"humbldata.core.standard_models.abstract.errors.HumblDataError","text":"<p>             Bases: <code>BaseException</code></p> <p>Base Error for HumblData logic.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\errors.py</code> <pre><code>class HumblDataError(BaseException):\n    \"\"\"Base Error for HumblData logic.\"\"\"\n\n    def __init__(self, original: str | Exception | None = None):\n        self.original = original\n        super().__init__(str(original))\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.query_params","title":"humbldata.core.standard_models.abstract.query_params","text":"<p>A wrapper around OpenBB QueryParams Standardized Model to use with humbldata.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.query_params.QueryParams","title":"humbldata.core.standard_models.abstract.query_params.QueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>An abstract standard_model to represent a base QueryParams Data.</p> <p>QueryParams model should be used to define the query parameters for a <code>context.category.command</code> call.</p> <p>This QueryParams model is meant to be inherited and built upon by other standard_models for a specific context.</p> <p>Examples:</p> <pre><code>class EquityHistoricalQueryParams(QueryParams):\n\n    symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n    interval: Optional[str] = Field(\n        default=\"1d\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n    )\n    end_date: Optional[dateType] = Field(\n        default=None,\n        description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n    )\n\n    @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n        if isinstance(v, str):\n            return v.upper()\n        return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre> <p>This would create a class that would be used to query historical price data for equities from any given command.</p> <p>This could then be used to create a <code>MandelbrotChannelEquityHistoricalQueryParams</code> that would define what query parameters are needed for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\query_params.py</code> <pre><code>class QueryParams(OpenBBQueryParams):\n    \"\"\"\n    An abstract standard_model to represent a base QueryParams Data.\n\n    QueryParams model should be used to define the query parameters for a\n    `context.category.command` call.\n\n    This QueryParams model is meant to be inherited and built upon by other\n    standard_models for a specific context.\n\n    Examples\n    --------\n    ```py\n    class EquityHistoricalQueryParams(QueryParams):\n\n        symbol: str = Field(description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"))\n        interval: Optional[str] = Field(\n            default=\"1d\",\n            description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n        )\n        start_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"start_date\", \"\"),\n        )\n        end_date: Optional[dateType] = Field(\n            default=None,\n            description=QUERY_DESCRIPTIONS.get(\"end_date\", \"\"),\n        )\n\n        @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n        @classmethod\n        def upper_symbol(cls, v: Union[str, List[str], Set[str]]):\n            if isinstance(v, str):\n                return v.upper()\n            return \",\".join([symbol.upper() for symbol in list(v)])\n    ```\n\n    This would create a class that would be used to query historical price data\n    for equities from any given command.\n\n    This could then be used to create a\n    `MandelbrotChannelEquityHistoricalQueryParams` that would define what query\n    parameters are needed for the Mandelbrot Channel command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.singleton","title":"humbldata.core.standard_models.abstract.singleton","text":"<p>An ABSTRACT DATA MODEL, Singleton, to represent a class that should only have one instance.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.singleton.SingletonMeta","title":"humbldata.core.standard_models.abstract.singleton.SingletonMeta","text":"<p>             Bases: <code>type</code>, <code>Generic[T]</code></p> <p>SingletonMeta is a metaclass that creates a Singleton instance of a class.</p> <p>Singleton design pattern restricts the instantiation of a class to a single instance. This is useful when exactly one object is needed to coordinate actions across the system.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\singleton.py</code> <pre><code>class SingletonMeta(type, Generic[T]):\n    \"\"\"\n    SingletonMeta is a metaclass that creates a Singleton instance of a class.\n\n    Singleton design pattern restricts the instantiation of a class to a single\n    instance. This is useful when exactly one object is needed to coordinate\n    actions across the system.\n    \"\"\"\n\n    _instances: ClassVar[dict[T, T]] = {}  # type: ignore  # noqa: PGH003\n\n    def __call__(cls, *args, **kwargs) -&gt; T:\n        \"\"\"\n        Override the __call__ method.\n\n        If the class exists, otherwise creates a new instance and stores it in\n        the _instances dictionary.\n        \"\"\"\n        if cls not in cls._instances:\n            instance = super().__call__(*args, **kwargs)\n            cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n        return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.singleton.SingletonMeta.__call__","title":"humbldata.core.standard_models.abstract.singleton.SingletonMeta.__call__","text":"<pre><code>__call__(*args, **kwargs) -&gt; T\n</code></pre> <p>Override the call method.</p> <p>If the class exists, otherwise creates a new instance and stores it in the _instances dictionary.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\singleton.py</code> <pre><code>def __call__(cls, *args, **kwargs) -&gt; T:\n    \"\"\"\n    Override the __call__ method.\n\n    If the class exists, otherwise creates a new instance and stores it in\n    the _instances dictionary.\n    \"\"\"\n    if cls not in cls._instances:\n        instance = super().__call__(*args, **kwargs)\n        cls._instances[cls] = instance  # type: ignore  # noqa: PGH003\n\n    return cls._instances[cls]  # type: ignore  # noqa: PGH003\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.tagged","title":"humbldata.core.standard_models.abstract.tagged","text":"<p>An ABSTRACT DATA MODEL, Tagged, to be inherited by other models as identifier.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.abstract.tagged.Tagged","title":"humbldata.core.standard_models.abstract.tagged.Tagged","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class to represent an object tagged with a uuid7.</p> Source code in <code>src\\humbldata\\core\\standard_models\\abstract\\tagged.py</code> <pre><code>class Tagged(BaseModel):\n    \"\"\"A class to represent an object tagged with a uuid7.\"\"\"\n\n    id: str = Field(default_factory=uuid7str, alias=\"_id\")\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox","title":"humbldata.core.standard_models.toolbox","text":"<p>Context: Toolbox || Category: Standardized Framework Model.</p> <p>This module defines the QueryParams and Data classes for the Toolbox context. THis is where all of the context(s) of your project go. The STANDARD MODELS for categories and subsequent commands are nested here.</p> <p>Classes:</p> Name Description <code>ToolboxQueryParams</code> <p>Query parameters for the ToolboxController.</p> <code>ToolboxData</code> <p>A Pydantic model that defines the data returned by the ToolboxController.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>The symbol/ticker of the stock.</p> <code>interval</code> <code>Optional[str]</code> <p>The interval of the data. Defaults to '1d'.</p> <code>start_date</code> <code>str</code> <p>The start date of the data.</p> <code>end_date</code> <code>str</code> <p>The end date of the data.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical","title":"humbldata.core.standard_models.toolbox.technical","text":"<p>Context: Toolbox || Category: Technical.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrotchannel","title":"humbldata.core.standard_models.toolbox.technical.mandelbrotchannel","text":"<p>Mandelbrot Channel Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Mandelbrot Channel.</p> <p>This module is used to define the QueryParams and Data model for the Mandelbrot Channel command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelQueryParams","title":"humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>QueryParams for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>class MandelbrotChannelQueryParams(QueryParams):\n    \"\"\"\n    QueryParams for the Mandelbrot Channel command.\n\n\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelData","title":"humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>class MandelbrotChannelData(Data):\n    \"\"\"\n    Data model for the Mandelbrot Channel command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher","title":"humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher","text":"<p>             Bases: <code>MandelbrotChannelQueryParams</code>, <code>MandelbrotChannelData</code></p> <p>Fetcher for the Mandelbrot Channel command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>class MandelbrotChannelFetcher(\n    MandelbrotChannelQueryParams, MandelbrotChannelData\n):\n    \"\"\"\n    Fetcher for the Mandelbrot Channel command.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: MandelbrotChannelQueryParams,\n    ):\n        self._context_params = context_params\n        self._command_params = command_params\n\n    def transform_query(self):\n        \"\"\"Transform the params to the command-specific query.\"\"\"\n\n    def extract_data(self):\n        \"\"\"Extract the data from the provider.\"\"\"\n        # Assuming 'obb' is a predefined object in your context\n        df = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbol,\n                start_date=str(self.context_params.start_date),\n                end_date=str(self.context_params.end_date),\n                provider=self.command_params.provider,\n                verbose=not self.command_params.kwargs.get(\"silent\", False),\n                **self.command_params.kwargs,\n            ).to_polars()\n        ).drop([\"dividends\", \"stock_splits\"], axis=1)\n        return df\n\n    def transform_data(self):\n        \"\"\"Transform the command-specific data.\"\"\"\n        # Placeholder for data transformation logic\n\n    def fetch_data(self):\n        # Call the methods in the desired order\n        query = self.transform_query()\n        raw_data = (\n            self.extract_data()\n        )  # This should use 'query' to fetch the data\n        transformed_data = (\n            self.transform_data()\n        )  # This should transform 'raw_data'\n\n        # Validate with MandelbrotChannelData, unpack dict into pydantic row by row\n        return transformed_data\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher.transform_query # <pre><code>transform_query()\n</code></pre> <p>Transform the params to the command-specific query.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>def transform_query(self):\n    \"\"\"Transform the params to the command-specific query.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher.extract_data # <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>def extract_data(self):\n    \"\"\"Extract the data from the provider.\"\"\"\n    # Assuming 'obb' is a predefined object in your context\n    df = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbol,\n            start_date=str(self.context_params.start_date),\n            end_date=str(self.context_params.end_date),\n            provider=self.command_params.provider,\n            verbose=not self.command_params.kwargs.get(\"silent\", False),\n            **self.command_params.kwargs,\n        ).to_polars()\n    ).drop([\"dividends\", \"stock_splits\"], axis=1)\n    return df\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.mandelbrotchannel.MandelbrotChannelFetcher.transform_data # <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\mandelbrotchannel.py</code> <pre><code>def transform_data(self):\n    \"\"\"Transform the command-specific data.\"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility","text":"<p>Volatility Standard Model.</p> <p>Context: Toolbox || Category: Technical || Command: Volatility.</p> <p>This module is used to define the QueryParams and Data model for the Volatility command.</p>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityQueryParams","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>QueryParams for the Realized Volatility command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>class RealizedVolatilityQueryParams(QueryParams):\n    \"\"\"\n    QueryParams for the Realized Volatility command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityData","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityData","text":"<p>             Bases: <code>Data</code></p> <p>Data model for the Realized Volatility command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>class RealizedVolatilityData(Data):\n    \"\"\"\n    Data model for the Realized Volatility command.\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher","title":"humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher","text":"<p>             Bases: <code>RealizedVolatilityQueryParams</code></p> <p>Fetcher for the Realized Volatility command.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>class RealizedVolatilityFetcher(RealizedVolatilityQueryParams):\n    \"\"\"\n    Fetcher for the Realized Volatility command.\n    \"\"\"\n\n    data_list: ClassVar[list[RealizedVolatilityData]] = []\n\n    def __init__(\n        self,\n        context_params: ToolboxQueryParams,\n        command_params: RealizedVolatilityQueryParams,\n    ):\n        self._context_params = context_params\n        self._command_params = command_params\n\n    def transform_query(self):\n        \"\"\"Transform the params to the command-specific query.\"\"\"\n\n    def extract_data(self):\n        \"\"\"Extract the data from the provider.\"\"\"\n        # Assuming 'obb' is a predefined object in your context\n        df = (\n            obb.equity.price.historical(\n                symbol=self.context_params.symbol,\n                start_date=str(self.context_params.start_date),\n                end_date=str(self.context_params.end_date),\n                provider=self.command_params.provider,\n                verbose=not self.command_params.kwargs.get(\"silent\", False),\n                **self.command_params.kwargs,\n            )\n            .to_df()\n            .reset_index()\n        )\n        return df\n\n    def transform_data(self):\n        \"\"\"Transform the command-specific data.\"\"\"\n        # Placeholder for data transformation logic\n\n    def fetch_data(self):\n        \"\"\"Execute the TET pattern.\"\"\"\n        # Call the methods in the desired order\n        query = self.transform_query()\n        raw_data = (\n            self.extract_data()\n        )  # This should use 'query' to fetch the data\n        transformed_data = (\n            self.transform_data()\n        )  # This should transform 'raw_data'\n\n        # Validate with VolatilityData, unpack dict into pydantic row by row\n        return transformed_data\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_query # <pre><code>transform_query()\n</code></pre> <p>Transform the params to the command-specific query.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def transform_query(self):\n    \"\"\"Transform the params to the command-specific query.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.extract_data # <pre><code>extract_data()\n</code></pre> <p>Extract the data from the provider.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def extract_data(self):\n    \"\"\"Extract the data from the provider.\"\"\"\n    # Assuming 'obb' is a predefined object in your context\n    df = (\n        obb.equity.price.historical(\n            symbol=self.context_params.symbol,\n            start_date=str(self.context_params.start_date),\n            end_date=str(self.context_params.end_date),\n            provider=self.command_params.provider,\n            verbose=not self.command_params.kwargs.get(\"silent\", False),\n            **self.command_params.kwargs,\n        )\n        .to_df()\n        .reset_index()\n    )\n    return df\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.transform_data # <pre><code>transform_data()\n</code></pre> <p>Transform the command-specific data.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def transform_data(self):\n    \"\"\"Transform the command-specific data.\"\"\"\n</code></pre> <code></code> humbldata.core.standard_models.toolbox.technical.realized_volatility.RealizedVolatilityFetcher.fetch_data # <pre><code>fetch_data()\n</code></pre> <p>Execute the TET pattern.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\technical\\realized_volatility.py</code> <pre><code>def fetch_data(self):\n    \"\"\"Execute the TET pattern.\"\"\"\n    # Call the methods in the desired order\n    query = self.transform_query()\n    raw_data = (\n        self.extract_data()\n    )  # This should use 'query' to fetch the data\n    transformed_data = (\n        self.transform_data()\n    )  # This should transform 'raw_data'\n\n    # Validate with VolatilityData, unpack dict into pydantic row by row\n    return transformed_data\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxQueryParams","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams","text":"<p>             Bases: <code>QueryParams</code></p> <p>Query parameters for the ToolboxController.</p> <p>This class defines the query parameters used by the ToolboxController, including the stock symbol, data interval, start date, and end date. It also includes a method to ensure the stock symbol is in uppercase.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>The symbol or ticker of the stock.</p> <code>interval</code> <code>Optional[str]</code> <p>The interval of the data. Defaults to '1d'. Can be None.</p> <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> <p>Methods:</p> Name Description <code>upper_symbol</code> <p>A Pydantic <code>@field_validator()</code> that converts the stock symbol to uppercase. If a list or set of symbols is provided, each symbol in the collection is converted to uppercase and returned as a comma-separated string.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\__init__.py</code> <pre><code>class ToolboxQueryParams(QueryParams):\n    \"\"\"\n    Query parameters for the ToolboxController.\n\n    This class defines the query parameters used by the ToolboxController,\n    including the stock symbol, data interval, start date, and end date. It also\n    includes a method to ensure the stock symbol is in uppercase.\n\n    Attributes\n    ----------\n    symbol : str\n        The symbol or ticker of the stock.\n    interval : Optional[str]\n        The interval of the data. Defaults to '1d'. Can be None.\n    start_date : str\n        The start date for the data query.\n    end_date : str\n        The end date for the data query.\n\n    Methods\n    -------\n    upper_symbol(cls, v: Union[str, list[str], set[str]]) -&gt; Union[str, list[str]]\n        A Pydantic `@field_validator()` that converts the stock symbol to\n        uppercase. If a list or set of symbols is provided, each symbol in the\n        collection is converted to uppercase and returned as a comma-separated\n        string.\n    \"\"\"\n\n    symbol: str = Field(\n        default=\"\",\n        title=\"The symbol/ticker of the stock\",\n        description=QUERY_DESCRIPTIONS.get(\"symbol\", \"\"),\n    )\n    interval: str | None = Field(\n        default=\"1d\",\n        title=\"The interval of the data\",\n        description=QUERY_DESCRIPTIONS.get(\"interval\", \"\"),\n    )\n    start_date: str = Field(\n        default=\"\",\n        title=\"The start date of the data\",\n        description=\"The starting date for the data query.\",\n    )\n    end_date: str = Field(\n        default=\"\",\n        title=\"The end date of the data\",\n        description=\"The ending date for the data query.\",\n    )\n\n    @field_validator(\"symbol\", mode=\"before\", check_fields=False)\n    @classmethod\n    def upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n        \"\"\"\n        Convert the stock symbol to uppercase.\n\n        Parameters\n        ----------\n        v : Union[str, List[str], Set[str]]\n            The stock symbol or collection of symbols to be converted.\n\n        Returns\n        -------\n        Union[str, List[str]]\n            The uppercase stock symbol or a comma-separated string of uppercase\n            symbols.\n        \"\"\"\n        if isinstance(v, str):\n            return v.upper()\n        return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol","title":"humbldata.core.standard_models.toolbox.ToolboxQueryParams.upper_symbol  <code>classmethod</code>","text":"<pre><code>upper_symbol(v: str | list[str] | set[str]) -&gt; str | list[str]\n</code></pre> <p>Convert the stock symbol to uppercase.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[str, List[str], Set[str]]</code> <p>The stock symbol or collection of symbols to be converted.</p> required <p>Returns:</p> Type Description <code>Union[str, List[str]]</code> <p>The uppercase stock symbol or a comma-separated string of uppercase symbols.</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\__init__.py</code> <pre><code>@field_validator(\"symbol\", mode=\"before\", check_fields=False)\n@classmethod\ndef upper_symbol(cls, v: str | list[str] | set[str]) -&gt; str | list[str]:\n    \"\"\"\n    Convert the stock symbol to uppercase.\n\n    Parameters\n    ----------\n    v : Union[str, List[str], Set[str]]\n        The stock symbol or collection of symbols to be converted.\n\n    Returns\n    -------\n    Union[str, List[str]]\n        The uppercase stock symbol or a comma-separated string of uppercase\n        symbols.\n    \"\"\"\n    if isinstance(v, str):\n        return v.upper()\n    return \",\".join([symbol.upper() for symbol in list(v)])\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.standard_models.toolbox.ToolboxData","title":"humbldata.core.standard_models.toolbox.ToolboxData","text":"<p>             Bases: <code>Data</code></p> <p>The Data for the ToolboxController.</p> <p>WIP: I'm thinking that this is the final layer around which the HumblDataObject will be returned to the user, with all necessary information about the query, command, data and charts that they should want. This HumblDataObject will return values in json/dict format, with methods to allow transformation into polars_df, pandas_df, a list, a dict...</p> Source code in <code>src\\humbldata\\core\\standard_models\\toolbox\\__init__.py</code> <pre><code>class ToolboxData(Data):\n    \"\"\"\n    The Data for the ToolboxController.\n\n    WIP: I'm thinking that this is the final layer around which the\n    HumblDataObject will be returned to the user, with all necessary information\n    about the query, command, data and charts that they should want.\n    This HumblDataObject will return values in json/dict format, with methods\n    to allow transformation into polars_df, pandas_df, a list, a dict...\n    \"\"\"\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils","title":"humbldata.core.utils","text":"<p>humbldata core utils.</p> <p>Utils is used to keep; helpers, descriptions, constants, and other useful tools.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.constants","title":"humbldata.core.utils.constants","text":"<p>A module to contain all project-wide constants.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.core_helpers","title":"humbldata.core.utils.core_helpers","text":"<p>A module to contain core helper functions for the program.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.core_helpers.is_debug_mode","title":"humbldata.core.utils.core_helpers.is_debug_mode","text":"<pre><code>is_debug_mode() -&gt; bool\n</code></pre> <p>Check if the current system is in debug mode.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the system is in debug mode, False otherwise.</p> Source code in <code>src\\humbldata\\core\\utils\\core_helpers.py</code> <pre><code>def is_debug_mode() -&gt; bool:\n    \"\"\"\n    Check if the current system is in debug mode.\n\n    Returns\n    -------\n    bool\n        True if the system is in debug mode, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.core_helpers.log_start_end","title":"humbldata.core.utils.core_helpers.log_start_end","text":"<pre><code>log_start_end(func: Callable | None = None, *, log: Logger | None = None) -&gt; Callable\n</code></pre> <p>Add logging at the start and end of any function it decorates, including time tracking.</p> <p>Handles exceptions by logging them and modifies behavior based on the system's debug mode. Logs the total time taken by the function.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Optional[Callable]</code> <p>The function to decorate.</p> <code>None</code> <code>log</code> <code>Optional[Logger]</code> <p>The logger to use for logging.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable</code> <p>The decorated function.</p> Source code in <code>src\\humbldata\\core\\utils\\core_helpers.py</code> <pre><code>def log_start_end(\n    func: Callable | None = None, *, log: logging.Logger | None = None\n) -&gt; Callable:\n    \"\"\"\n    Add logging at the start and end of any function it decorates, including time tracking.\n\n    Handles exceptions by logging them and modifies behavior based on the\n    system's debug mode. Logs the total time taken by the function.\n\n    Parameters\n    ----------\n    func : Optional[Callable]\n        The function to decorate.\n    log : Optional[logging.Logger]\n        The logger to use for logging.\n\n    Returns\n    -------\n    Callable\n        The decorated function.\n    \"\"\"\n    assert callable(func) or func is None\n\n    def decorator(func: Callable) -&gt; Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -&gt; Any:\n            import time  # lazy import\n\n            nonlocal log\n            if log is None:\n                log = logging.getLogger(func.__module__)\n\n            start_time = time.time()\n            log.info(\"START\", extra={\"func_name\": func.__name__})\n\n            try:\n                result = func(*args, **kwargs)\n            except KeyboardInterrupt:\n                end_time = time.time()\n                total_time = end_time - start_time\n                log.info(\n                    \"Interrupted by user\",\n                    extra={\n                        \"func_name\": func.__name__,\n                        \"total_time\": total_time,\n                    },\n                )\n                return []\n            except Exception as e:\n                end_time = time.time()\n                total_time = end_time - start_time\n                log.exception(\n                    \"Exception in:\",\n                    extra={\n                        \"func_name\": func.__name__,\n                        \"exception\": e,\n                        \"total_time\": total_time,\n                    },\n                )\n                return []\n            else:\n                end_time = time.time()\n                total_time = end_time - start_time\n                log.info(\n                    \"END \",\n                    extra={\n                        \"func_name\": func.__name__,\n                        \"total_time\": total_time,\n                    },\n                )\n                return result\n\n        return wrapper\n\n    return decorator(func) if callable(func) else decorator\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.descriptions","title":"humbldata.core.utils.descriptions","text":"<p>Common descriptions for model fields.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env","title":"humbldata.core.utils.env","text":"<p>The Env Module, to control a single instance of environment variables.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env","title":"humbldata.core.utils.env.Env","text":"<p>A singleton environment to hold all Environment variables.</p> Source code in <code>src\\humbldata\\core\\utils\\env.py</code> <pre><code>class Env(metaclass=SingletonMeta):\n    \"\"\"A singleton environment to hold all Environment variables.\"\"\"\n\n    _environ: dict[str, str]\n\n    def __init__(self) -&gt; None:\n        env_path = dotenv.find_dotenv()\n        dotenv.load_dotenv(Path(env_path))\n\n        self._environ = os.environ.copy()\n\n    @property\n    def OBB_PAT(self) -&gt; str | None:  # noqa: N802\n        \"\"\"OpenBB Personal Access Token.\"\"\"\n        return self._environ.get(\"OBB_PAT\", None)\n\n    @property\n    def OBB_LOGGED_IN(self) -&gt; bool:\n        return self.str2bool(self._environ.get(\"OBB_LOGGED_IN\", False))\n\n    @staticmethod\n    def str2bool(value: str | bool) -&gt; bool:\n        \"\"\"Match a value to its boolean correspondent.\n\n        Args:\n            value (str): The string value to be converted to a boolean.\n\n        Returns\n        -------\n            bool: The boolean value corresponding to the input string.\n\n        Raises\n        ------\n            ValueError: If the input string does not correspond to a boolean\n            value.\n        \"\"\"\n        if isinstance(value, bool):\n            return value\n        if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n            return False\n        if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n            return True\n        msg = f\"Failed to cast '{value}' to bool.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env.OBB_PAT","title":"humbldata.core.utils.env.Env.OBB_PAT  <code>property</code>","text":"<pre><code>OBB_PAT: str | None\n</code></pre> <p>OpenBB Personal Access Token.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.env.Env.str2bool","title":"humbldata.core.utils.env.Env.str2bool  <code>staticmethod</code>","text":"<pre><code>str2bool(value: str | bool) -&gt; bool\n</code></pre> <p>Match a value to its boolean correspondent.</p> <p>Args:     value (str): The string value to be converted to a boolean.</p> <p>Returns:</p> Type Description <code>    bool: The boolean value corresponding to the input string.</code> <p>Raises:</p> Type Description <code>    ValueError: If the input string does not correspond to a boolean</code> <p>value.</p> Source code in <code>src\\humbldata\\core\\utils\\env.py</code> <pre><code>@staticmethod\ndef str2bool(value: str | bool) -&gt; bool:\n    \"\"\"Match a value to its boolean correspondent.\n\n    Args:\n        value (str): The string value to be converted to a boolean.\n\n    Returns\n    -------\n        bool: The boolean value corresponding to the input string.\n\n    Raises\n    ------\n        ValueError: If the input string does not correspond to a boolean\n        value.\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n    if value.lower() in {\"false\", \"f\", \"0\", \"no\", \"n\"}:\n        return False\n    if value.lower() in {\"true\", \"t\", \"1\", \"yes\", \"y\"}:\n        return True\n    msg = f\"Failed to cast '{value}' to bool.\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers","title":"humbldata.core.utils.openbb_helpers","text":"<p>Core Module - OpenBB Helpers.</p> <p>This module contains functions used to interact with OpenBB, or wrap commands to have specific data outputs.</p>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.obb_login","title":"humbldata.core.utils.openbb_helpers.obb_login","text":"<pre><code>obb_login(pat: str | None = None) -&gt; bool\n</code></pre> <p>Log into the OpenBB Hub using a Personal Access Token (PAT).</p> <p>This function wraps the <code>obb.account.login</code> method to provide a simplified interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT is provided, it attempts to use the PAT stored in the environment variable <code>OBB_PAT</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pat</code> <code>str | None</code> <p>The personal access token for authentication. If None, the token is retrieved from the environment variable <code>OBB_PAT</code>. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if login is successful, False otherwise.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If an error occurs during the login process.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\nTrue\n</code></pre> Source code in <code>src\\humbldata\\core\\utils\\openbb_helpers.py</code> <pre><code>def obb_login(pat: str | None = None) -&gt; bool:\n    \"\"\"\n    Log into the OpenBB Hub using a Personal Access Token (PAT).\n\n    This function wraps the `obb.account.login` method to provide a simplified\n    interface for logging into OpenBB Hub. It optionally accepts a PAT. If no PAT\n    is provided, it attempts to use the PAT stored in the environment variable\n    `OBB_PAT`.\n\n    Parameters\n    ----------\n    pat : str | None, optional\n        The personal access token for authentication. If None, the token is\n        retrieved from the environment variable `OBB_PAT`. Default is None.\n\n    Returns\n    -------\n    bool\n        True if login is successful, False otherwise.\n\n    Raises\n    ------\n    HumblDataError\n        If an error occurs during the login process.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # obb_login(\"your_personal_access_token_here\")\n    True\n\n    &gt;&gt;&gt; # obb_login()  # Assumes `OBB_PAT` is set in the environment\n    True\n\n    \"\"\"\n    if pat is None:\n        pat = Env().OBB_PAT\n    try:\n        obb.account.login(pat=pat, remember_me=True)\n        # obb.account.save()\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"true\")\n\n        return True\n    except Exception as e:\n        from humbldata.core.standard_models.abstract.warnings import (\n            HumblDataWarning,\n        )\n\n        # dotenv.set_key(dotenv.find_dotenv(), \"OBB_LOGGED_IN\", \"false\")\n\n        warnings.warn(\n            \"An error occurred while logging into OpenBB. Details below:\\n\"\n            + repr(e),\n            category=HumblDataWarning,\n            stacklevel=1,\n        )\n        return False\n</code></pre>"},{"location":"code_documentation/core/#humbldata.core.utils.openbb_helpers.get_latest_price","title":"humbldata.core.utils.openbb_helpers.get_latest_price","text":"<pre><code>get_latest_price(symbol: str | list[str] | Series, provider: Literal['fmp', 'intrinio'] | None = None) -&gt; LazyFrame\n</code></pre> <p>Context: Core || Category: Utils || Subcategory: OpenBB Helpers || Command: get_latest_price.</p> <p>This function queries the latest stock price data using the specified provider. If no provider is specified, it defaults to using FinancialModelingPrep (<code>fmp</code>). The function returns a LazyFrame containing the stock symbols and their corresponding latest prices.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str | list[str] | Series</code> <p>The stock symbol(s) for which to fetch the latest price. Can be a single symbol, a list of symbols, or a Polars Series of symbols.</p> required <code>provider</code> <code>Literal['fmp', 'intrinio'] | None</code> <p>The data provider to use for fetching the stock prices. If not specified, a default provider is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame containing columns for the stock symbols ('symbol') and their most recent prices ('last_price').</p> Source code in <code>src\\humbldata\\core\\utils\\openbb_helpers.py</code> <pre><code>def get_latest_price(\n    symbol: str | list[str] | pl.Series,\n    provider: Literal[\"fmp\", \"intrinio\"] | None = None,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Core || Category: Utils || Subcategory: OpenBB Helpers || **Command: get_latest_price**.\n\n    This function queries the latest stock price data using the specified\n    provider. If no provider is specified, it defaults to using\n    FinancialModelingPrep (`fmp`). The function returns a LazyFrame containing\n    the stock symbols and their corresponding latest prices.\n\n    Parameters\n    ----------\n    symbol : str | list[str] | pl.Series\n        The stock symbol(s) for which to fetch the latest price. Can be a\n        single symbol, a list of symbols, or a Polars Series of symbols.\n\n    provider : Literal[\"fmp\", \"intrinio\"] | None, optional\n        The data provider to use for fetching the stock prices. If not\n        specified, a default provider is used.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A Polars LazyFrame containing columns for the stock symbols ('symbol')\n        and their most recent prices ('last_price').\n    \"\"\"\n    logging.getLogger(\"openbb_terminal.stocks.stocks_model\").setLevel(\n        logging.CRITICAL\n    )\n\n    latest_prices = (\n        obb.equity.price.quote(symbol, provider=provider).to_polars().lazy()\n    )\n    return latest_prices.select([\"symbol\", \"last_price\"])\n</code></pre>"},{"location":"code_documentation/context/","title":"\ud83d\udce5 Context","text":"<p>This tab holds all of the Contexts that have been defined for <code>humbldata</code>.</p> <p>You can have as many contexts as you would like in your package. Each context is a top-level directory</p>"},{"location":"code_documentation/context/toolbox/","title":"\ud83e\uddf0 Toolbox","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox","title":"humbldata.toolbox","text":"<p>Context: Toolbox.</p> <p>A category to group all of the technical indicators available in the <code>Toolbox()</code></p> <p>Technical indicators rely on statistical transformations of time series data. These are raw math operations.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller","title":"toolbox_controller","text":"<p>Context: Toolbox.</p> <p>The Toolbox Controller Module.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox","title":"Toolbox","text":"<p>             Bases: <code>ToolboxQueryParams</code></p> <p>The top-level controller for all data analysis in the <code>humbldata</code> package.</p> <p>This module serves as the primary controller, routing user-specified ToolboxQueryParams as core arguments that are used to fetch time series data.</p> <p>The <code>Toolbox</code> controller also gives access to all sub-modules adn their functions.</p> <p>It is designed to facilitate the collection of data across various types such as stocks, options, or alternative time series by requiring minimal input from the user.</p> Submodules <p>The <code>Toolbox</code> controller is composed of the following submodules:</p> <ul> <li><code>technical</code>:</li> <li><code>quantitative</code>:</li> <li><code>fundamental</code>:</li> </ul> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol or ticker of the stock.</p> required <code>interval</code> <code>str</code> <p>The interval of the data. Defaults to '1d'.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data query.</p> required <code>end_date</code> <code>str</code> <p>The end date for the data query.</p> required Parameter Notes <p>The Parameters (<code>symbol</code>, <code>interval</code>, <code>start_date</code>, <code>end_date</code>) are the <code>ToolboxQueryParams</code>. They are used for data collection further down the pipeline. to execute operations on core data sets. This approach enables composable and standardized querying while accommodating data-specific collection logic.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_controller.py</code> <pre><code>class Toolbox(ToolboxQueryParams):\n    \"\"\"\n\n    The top-level controller for all data analysis in the `humbldata` package.\n\n    This module serves as the primary controller, routing user-specified\n    ToolboxQueryParams as core arguments that are used to fetch time series\n    data.\n\n    The `Toolbox` controller also gives access to all sub-modules adn their\n    functions.\n\n    It is designed to facilitate the collection of data across various types such as\n    stocks, options, or alternative time series by requiring minimal input from the user.\n\n    Submodules\n    ----------\n    The `Toolbox` controller is composed of the following submodules:\n\n    - `technical`:\n    - `quantitative`:\n    - `fundamental`:\n\n    Parameters\n    ----------\n    symbol : str\n        The symbol or ticker of the stock.\n    interval : str, optional\n        The interval of the data. Defaults to '1d'.\n    start_date : str\n        The start date for the data query.\n    end_date : str\n        The end date for the data query.\n\n    Parameter Notes\n    -----\n    The Parameters (`symbol`, `interval`, `start_date`, `end_date`)\n    are the `ToolboxQueryParams`. They are used for data collection further\n    down the pipeline. to execute operations on core data sets.\n    This approach enables composable and standardized querying while\n    accommodating data-specific collection logic.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initialize the Toolbox module.\n\n        This method does not take any parameters and does not return anything.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @property\n    def technical(self):\n        \"\"\"\n        The technical submodule of the Toolbox controller.\n\n        Access to all the technical indicators.\n        \"\"\"\n        return Technical(self)\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox.__init__","title":"__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Initialize the Toolbox module.</p> <p>This method does not take any parameters and does not return anything.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_controller.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initialize the Toolbox module.\n\n    This method does not take any parameters and does not return anything.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_controller.Toolbox.technical","title":"technical  <code>property</code>","text":"<pre><code>technical\n</code></pre> <p>The technical submodule of the Toolbox controller.</p> <p>Access to all the technical indicators.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers","title":"toolbox_helpers","text":"<p>Context: Toolbox || Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.log_returns","title":"log_returns","text":"<pre><code>log_returns(data: Series | DataFrame | LazyFrame | None = None, _column_name: str = 'adj_close', *, _drop_nulls: bool = True, _sort: bool = True) -&gt; Series | DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: log_returns.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY. Calculates the logarithmic returns for a given Polars Series, DataFrame, or LazyFrame. Logarithmic returns are widely used in the financial industry to measure the rate of return on investments over time. This function supports calculations on both individual series and dataframes containing financial time series data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series | DataFrame | LazyFrame</code> <p>The input data for which to calculate the log returns. Default is None.</p> <code>None</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. Default is True.</p> <code>True</code> <code>_column_name</code> <code>str</code> <p>The column name to use for log return calculations in DataFrame or LazyFrame. Default is \"adj_close\".</p> <code>'adj_close'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by <code>date</code> and <code>symbol</code> before calculation. If you want a DUMB function, set to False. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Series | DataFrame | LazyFrame</code> <p>The original <code>data</code>, with an extra column of <code>log returns</code> of the input data. The return type matches the input type.</p> <p>Raises:</p> Type Description <code>HumblDataError</code> <p>If neither a series, DataFrame, nor LazyFrame is provided as input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; series = pl.Series([100, 105, 103])\n&gt;&gt;&gt; log_returns(data=series)\nseries([-inf, 0.048790, -0.019418])\n</code></pre> <pre><code>&gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n&gt;&gt;&gt; log_returns(data=df)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 adj_close \u2506 log_returns\u2502\n\u2502 ---       \u2506 ---        \u2502\n\u2502 f64       \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 100.0     \u2506 NaN        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 105.0     \u2506 0.048790   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 103.0     \u2506 -0.019418  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Improvements <p>Add a parameter <code>_sort_cols: list[str] | None = None</code> to make the function even dumber. This way you could specify certain columns to sort by instead of using default <code>date</code> and <code>symbol</code>. If <code>_sort_cols=None</code> and <code>_sort=True</code>, then the function will use the default <code>date</code> and <code>symbol</code> columns for sorting.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def log_returns(\n    data: pl.Series | pl.DataFrame | pl.LazyFrame | None = None,\n    _column_name: str = \"adj_close\",\n    *,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.Series | pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: log_returns**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n    Calculates the logarithmic returns for a given Polars Series, DataFrame, or\n    LazyFrame. Logarithmic returns are widely used in the financial\n    industry to measure the rate of return on investments over time. This\n    function supports calculations on both individual series and dataframes\n    containing financial time series data.\n\n    Parameters\n    ----------\n    data : pl.Series | pl.DataFrame | pl.LazyFrame, optional\n        The input data for which to calculate the log returns. Default is None.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result. Default is True.\n    _column_name : str, optional\n        The column name to use for log return calculations in DataFrame or\n        LazyFrame. Default is \"adj_close\".\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by `date` and `symbol` before\n        calculation. If you want a DUMB function, set to False.\n        Default is True.\n\n    Returns\n    -------\n    pl.Series | pl.DataFrame | pl.LazyFrame\n        The original `data`, with an extra column of `log returns` of the input\n        data. The return type matches the input type.\n\n    Raises\n    ------\n    HumblDataError\n        If neither a series, DataFrame, nor LazyFrame is provided as input.\n\n    Examples\n    --------\n    &gt;&gt;&gt; series = pl.Series([100, 105, 103])\n    &gt;&gt;&gt; log_returns(data=series)\n    series([-inf, 0.048790, -0.019418])\n\n    &gt;&gt;&gt; df = pl.DataFrame({\"adj_close\": [100, 105, 103]})\n    &gt;&gt;&gt; log_returns(data=df)\n    shape: (3, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 adj_close \u2506 log_returns\u2502\n    \u2502 ---       \u2506 ---        \u2502\n    \u2502 f64       \u2506 f64        \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 100.0     \u2506 NaN        \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 105.0     \u2506 0.048790   \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 103.0     \u2506 -0.019418  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    Improvements\n    -----------\n    Add a parameter `_sort_cols: list[str] | None = None` to make the function even\n    dumber. This way you could specify certain columns to sort by instead of\n    using default `date` and `symbol`. If `_sort_cols=None` and `_sort=True`,\n    then the function will use the default `date` and `symbol` columns for\n    sorting.\n\n    \"\"\"\n    # Calculation for Polars Series\n    if isinstance(data, pl.Series):\n        out = data.log().diff()\n        if _drop_nulls:\n            out = out.drop_nulls()\n    # Calculation for Polars DataFrame or LazyFrame\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n        if \"log_returns\" not in data.columns:\n            out = data.set_sorted(sort_cols).with_columns(\n                pl.col(_column_name).log().diff().alias(\"log_returns\")\n            )\n        else:\n            out = data\n        if _drop_nulls:\n            out = out.drop_nulls(subset=\"log_returns\")\n    else:\n        msg = \"No valid data type was provided for `log_returns()` calculation.\"\n        raise HumblDataError(msg)\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.detrend","title":"detrend","text":"<pre><code>detrend(data: DataFrame | LazyFrame | Series, _detrend_col: str = 'log_returns', _detrend_value_col: str | Series | None = 'window_mean', *, _sort: bool = False) -&gt; DataFrame | LazyFrame | Series\n</code></pre> <pre><code>Context: Toolbox || Category: Helpers || **Command: detrend**.\n\nThis is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\nDetrends a column in a DataFrame, LazyFrame, or Series by subtracting the\nvalues of another column from it. Optionally sorts the data by 'symbol' and\n'date' before detrending if _sort is True.\n</code></pre> <p>Returns:</p> Type Description <code>    Union[pl.DataFrame, pl.LazyFrame, pl.Series]</code> <p>The detrended data structure with the same type as the input, with an added column named <code>f\"detrended_{_detrend_col}\"</code>.</p> Notes <p>Function doesn't use <code>.over()</code> in calculation. Once the data is sorted, subtracting _detrend_value_col from _detrend_col is a simple operation that doesn't need to be grouped, because the sorting has already aligned the rows for subtraction</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def detrend(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _detrend_col: str = \"log_returns\",\n    _detrend_value_col: str | pl.Series | None = \"window_mean\",\n    *,\n    _sort: bool = False,\n) -&gt; pl.DataFrame | pl.LazyFrame | pl.Series:\n    \"\"\"\n        Context: Toolbox || Category: Helpers || **Command: detrend**.\n\n        This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n        Detrends a column in a DataFrame, LazyFrame, or Series by subtracting the\n        values of another column from it. Optionally sorts the data by 'symbol' and\n        'date' before detrending if _sort is True.\n\n    Parameters\n    ----------\n        data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n            The data structure containing the columns to be processed.\n        _detrend_col : str\n            The name of the column from which values will be subtracted.\n        _detrend_value_col : str | pl.Series | None, optional\n            The name of the column whose values will be subtracted OR if you pass a\n            pl.Series to the `data` parameter, then you can use this to pass a\n            second `pl.Series` to\n            subtract from the first.\n        _sort : bool, optional\n            If True, sorts the data by 'symbol' and 'date' before detrending.\n            Default is False.\n\n    Returns\n    -------\n        Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n            The detrended data structure with the same type as the input,\n            with an added column named `f\"detrended_{_detrend_col}\"`.\n\n    Notes\n    -----\n    Function doesn't use `.over()` in calculation. Once the data is sorted,\n    subtracting _detrend_value_col from _detrend_col is a simple operation\n    that doesn't need to be grouped, because the sorting has already aligned\n    the rows for subtraction\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort and sort_cols:\n            data = data.sort(sort_cols)\n        elif _sort and not sort_cols:\n            msg = \"Data must contain 'symbol' and 'date' columns for sorting.\"\n            raise HumblDataError(msg)\n\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        if (\n            _detrend_value_col not in data.columns\n            or _detrend_col not in data.columns\n        ):\n            msg = f\"Both {_detrend_value_col} and {_detrend_col} must be columns in the data.\"\n            raise HumblDataError(msg)\n        detrended = data.set_sorted(sort_cols).with_columns(\n            (pl.col(_detrend_col) - pl.col(_detrend_value_col)).alias(\n                f\"detrended_{_detrend_col}\"\n            )\n        )\n    elif isinstance(data, pl.Series):\n        if not isinstance(_detrend_value_col, pl.Series):\n            msg = \"When 'data' is a Series, '_detrend_value_col' must also be a Series.\"\n            raise HumblDataError(msg)\n        detrended = data - _detrend_value_col\n        detrended.rename(f\"detrended_{_detrend_col}\")\n\n    return detrended\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.cum_sum","title":"cum_sum","text":"<pre><code>cum_sum(data: DataFrame | LazyFrame | Series | None = None, _column_name: str = 'detrended_returns', *, _sort: bool = True, _mandelbrot_usage: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: cum_sum.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>Calculate the cumulative sum of a series or column in a DataFrame or LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame | Series | None</code> <p>The data to process.</p> <code>None</code> <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the cumulative sum on, applicable if df is provided.</p> <code>'detrended_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date and symbol before calculation. Default is True.</p> <code>True</code> <code>_mandelbrot_usage</code> <code>bool</code> <p>If True, performs additional checks specific to the Mandelbrot Channel calculation. This should be set to True when you have a cumulative deviate series, and False when not. Please check 'Notes' for more information. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The DataFrame or Series with the cumulative deviate series added as a new column or as itself.</p> Notes <p>This function is used to calculate the cumulative sum for the deviate series of detrended returns for the data in the pipeline for <code>calc_mandelbrot_channel</code>.</p> <p>So, although it is calculating a cumulative sum, it is known as a cumulative deviate because it is a cumulative sum on a deviate series, meaning that the cumulative sum should = 0 for each window. The _mandelbrot_usage parameter allows for checks to ensure the data is suitable for Mandelbrot Channel calculations, i.e that the deviate series was calculated correctly by the end of each series being 0, meaning the trend (the mean over the window_index) was successfully removed from the data.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def cum_sum(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series | None = None,\n    _column_name: str = \"detrended_returns\",\n    *,\n    _sort: bool = True,\n    _mandelbrot_usage: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: cum_sum**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    Calculate the cumulative sum of a series or column in a DataFrame or\n    LazyFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame | pl.Series | None\n        The data to process.\n    _column_name : str\n        The name of the column to calculate the cumulative sum on,\n        applicable if df is provided.\n    _sort : bool, optional\n        If True, sorts the DataFrame or LazyFrame by date and symbol before\n        calculation. Default is True.\n    _mandelbrot_usage : bool, optional\n        If True, performs additional checks specific to the Mandelbrot Channel\n        calculation. This should be set to True when you have a cumulative\n        deviate series, and False when not. Please check 'Notes' for more\n        information. Default is True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The DataFrame or Series with the cumulative deviate series added as a\n        new column or as itself.\n\n    Notes\n    -----\n    This function is used to calculate the cumulative sum for the deviate series\n    of detrended returns for the data in the pipeline for\n    `calc_mandelbrot_channel`.\n\n    So, although it is calculating a cumulative sum, it is known as a cumulative\n    deviate because it is a cumulative sum on a deviate series, meaning that the\n    cumulative sum should = 0 for each window. The _mandelbrot_usage parameter\n    allows for checks to ensure the data is suitable for Mandelbrot Channel\n    calculations, i.e that the deviate series was calculated correctly by the\n    end of each series being 0, meaning the trend (the mean over the\n    window_index) was successfully removed from the data.\n    \"\"\"\n    if isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort:\n            data = data.sort(sort_cols)\n\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if over_cols:\n            out = data.set_sorted(sort_cols).with_columns(\n                pl.col(_column_name).cum_sum().over(over_cols).alias(\"cum_sum\")\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).cum_sum().alias(\"cum_sum\")\n            )\n    elif isinstance(data, pl.Series):\n        out = data.cum_sum().alias(\"cum_sum\")\n    else:\n        msg = \"No DataFrame/LazyFrame/Series was provided.\"\n        raise HumblDataError(msg)\n\n    if _mandelbrot_usage:\n        _cumsum_check(out, _column_name=\"cum_sum\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.std","title":"std","text":"<pre><code>std(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum') -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Helpers || Command: std.</p> <p>Calculate the standard deviation of the cumulative deviate series within each window of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>LazyFrame</code> <p>The LazyFrame from which to calculate the standard deviation.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column from which to calculate the standard deviation, with \"cumdev\" as the default value.</p> <code>'cum_sum'</code> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A LazyFrame with the standard deviation of the specified column for each window, added as a new column named \"S\".</p> Improvements <p>Just need to parametrize <code>.over()</code> call in the function if want an even dumber function, that doesn't calculate each <code>window_index</code>.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def std(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series, _column_name: str = \"cum_sum\"\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Command: std**.\n\n    Calculate the standard deviation of the cumulative deviate series within\n    each window of the dataset.\n\n    Parameters\n    ----------\n    df : pl.LazyFrame\n        The LazyFrame from which to calculate the standard deviation.\n    _column_name : str, optional\n        The name of the column from which to calculate the standard deviation,\n        with \"cumdev\" as the default value.\n\n    Returns\n    -------\n    pl.LazyFrame\n        A LazyFrame with the standard deviation of the specified column for each\n        window, added as a new column named \"S\".\n\n    Improvements\n    -----------\n    Just need to parametrize `.over()` call in the function if want an even\n    dumber function, that doesn't calculate each `window_index`.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.std()\n    elif isinstance(data, pl.DataFrame | pl.LazyFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n\n        if over_cols:\n            out = data.set_sorted(sort_cols).with_columns(\n                [\n                    pl.col(_column_name)\n                    .std()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_std\"),  # used to be 'S'\n                ]\n            )\n        else:\n            out = data.with_columns(\n                pl.col(_column_name).std().alias(\"S\"),\n            )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.mean","title":"mean","text":"<pre><code>mean(data: DataFrame | LazyFrame | Series, _column_name: str = 'log_returns', *, _sort: bool = True) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Helpers || Function: mean.</p> <p>This is a DUMB command. It can be used in any CONTEXT or CATEGORY.</p> <p>This function calculates the mean of a column (&lt;_column_name&gt;) over a each window in the dataset, if there are any. This window is intended to be the <code>window</code> that is passed in the <code>calc_mandelbrot_channel()</code> function. The mean calculated is meant to be used as the mean of each <code>window</code> within the time series. This way, each block of windows has their own mean, which can then be used to normalize the data (i.e remove the mean) from each window section.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The DataFrame or LazyFrame to calculate the mean on.</p> required <code>_column_name</code> <code>str</code> <p>The name of the column to calculate the mean on.</p> <code>'log_returns'</code> <code>_sort</code> <code>bool</code> <p>If True, sorts the DataFrame or LazyFrame by date before calculation. Default is False.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The original DataFrame or LazyFrame with a <code>window_mean</code> &amp; <code>date</code> column, which contains the mean of 'log_returns' per range/window.</p> Notes <p>Since this function is an aggregation function, it reduces the # of observations in the dataset,thus, unless I take each value and iterate each window_mean value to correlate to the row in the original dataframe, the function will return a dataframe WITHOUT the original data.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def mean(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    _column_name: str = \"log_returns\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Helpers || **Function: mean**.\n\n    This is a DUMB command. It can be used in any CONTEXT or CATEGORY.\n\n    This function calculates the mean of a column (&lt;_column_name&gt;) over a\n    each window in the dataset, if there are any.\n    This window is intended to be the `window` that is passed in the\n    `calc_mandelbrot_channel()` function. The mean calculated is meant to be\n    used as the mean of each `window` within the time series. This\n    way, each block of windows has their own mean, which can then be used to\n    normalize the data (i.e remove the mean) from each window section.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The DataFrame or LazyFrame to calculate the mean on.\n    _column_name : str\n        The name of the column to calculate the mean on.\n    _sort : bool\n        If True, sorts the DataFrame or LazyFrame by date before calculation.\n        Default is False.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The original DataFrame or LazyFrame with a `window_mean` &amp; `date` column,\n        which contains the mean of 'log_returns' per range/window.\n\n\n    Notes\n    -----\n    Since this function is an aggregation function, it reduces the # of\n    observations in the dataset,thus, unless I take each value and iterate each\n    window_mean value to correlate to the row in the original dataframe, the\n    function will return a dataframe WITHOUT the original data.\n\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.mean()\n    else:\n        if data is None:\n            msg = \"No DataFrame was passed to the `mean()` function.\"\n            raise HumblDataError(msg)\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n        if _sort and sort_cols:  # Check if _sort is True\n            data = data.sort(sort_cols).set_sorted(sort_cols)\n        if over_cols:\n            out = data.with_columns(\n                pl.col(_column_name).mean().over(over_cols).alias(\"window_mean\")\n            )\n        else:\n            out = data.with_columns(pl.col(_column_name).mean().alias(\"mean\"))\n        if sort_cols:\n            out = out.sort(sort_cols)\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.toolbox_helpers.range_","title":"range_","text":"<pre><code>range_(data: LazyFrame | DataFrame | Series, _column_name: str = 'cum_sum', *, _sort: bool = True) -&gt; LazyFrame | DataFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || Function: mandelbrot_range.</p> <p>Calculate the range (max - min) of the cumulative deviate values of a specified column in a DataFrame for each window in the dataset, if there are any.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame</code> <p>The DataFrame to calculate the range from.</p> required <code>_column_name</code> <code>str</code> <p>The column to calculate the range from, by default \"cumdev\".</p> <code>'cum_sum'</code> <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>A DataFrame with the range of the specified column for each window.</p> Source code in <code>src\\humbldata\\toolbox\\toolbox_helpers.py</code> <pre><code>def range_(\n    data: pl.LazyFrame | pl.DataFrame | pl.Series,\n    _column_name: str = \"cum_sum\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers || **Function: mandelbrot_range**.\n\n    Calculate the range (max - min) of the cumulative deviate values of a\n    specified column in a DataFrame for each window in the dataset, if there are any.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame\n        The DataFrame to calculate the range from.\n    _column_name : str, optional\n        The column to calculate the range from, by default \"cumdev\".\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        A DataFrame with the range of the specified column for each window.\n    \"\"\"\n    if isinstance(data, pl.Series):\n        out = data.max() - data.min()\n\n    if isinstance(data, pl.LazyFrame | pl.DataFrame):\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    over_cols = _set_over_cols(data, \"symbol\", \"window_index\")\n    if _sort:\n        data = data.sort(sort_cols)\n    if over_cols:\n        out = (\n            data.set_sorted(sort_cols)\n            .with_columns(\n                [\n                    pl.col(_column_name)\n                    .min()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_min\"),\n                    pl.col(_column_name)\n                    .max()\n                    .over(over_cols)\n                    .alias(f\"{_column_name}_max\"),\n                ]\n            )\n            .sort(sort_cols)\n            .with_columns(\n                (\n                    pl.col(f\"{_column_name}_max\")\n                    - pl.col(f\"{_column_name}_min\")\n                ).alias(f\"{_column_name}_range\"),  # used to be 'R'\n            )\n        )\n    else:\n        out = (\n            data.with_columns(\n                [\n                    pl.col(_column_name).min().alias(f\"{_column_name}_min\"),\n                    pl.col(_column_name).max().alias(f\"{_column_name}_max\"),\n                ]\n            )\n            .sort(sort_cols)\n            .with_columns(\n                (\n                    pl.col(f\"{_column_name}_max\")\n                    - pl.col(f\"{_column_name}_min\")\n                ).alias(f\"{_column_name}_range\"),\n            )\n        )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.fundamental","title":"fundamental","text":"<p>Context: Toolbox || Category: Fundamental.</p> <p>A category to group all of the fundamental indicators available in the <code>Toolbox()</code>.</p> <p>Fundamental indicators relies on earnings data, valuation models of companies, balance sheet metrics etc...</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.quantitative","title":"quantitative","text":"<p>Context: Toolbox || Category: Quantitative.</p> <p>Quantitative indicators rely on statistical transformations of time series data.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical","title":"technical","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.technical_controller","title":"technical_controller","text":"<p>Context: Toolbox || Category: Technical.</p> <p>A controller to manage and compile all of the technical indicator models available. This will be passed as a <code>@property</code> to the <code>Toolbox()</code> class, giving access to the technical module and its functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.technical_controller.Technical","title":"Technical","text":"<p>Module for all technical analysis.</p> <p>Attributes:</p> Name Type Description <code>standard_params</code> <code>ToolboxQueryParams</code> <p>The standard query parameters for toolbox data.</p> <p>Methods:</p> Name Description <code>mandelbrot_channel</code> <p>Calculate the rescaled range statistics.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\technical_controller.py</code> <pre><code>class Technical:\n    \"\"\"\n    Module for all technical analysis.\n\n    Attributes\n    ----------\n    standard_params : ToolboxQueryParams\n        The standard query parameters for toolbox data.\n\n    Methods\n    -------\n    mandelbrot_channel(command_params: MandelbrotChannelQueryParams)\n        Calculate the rescaled range statistics.\n\n    \"\"\"\n\n    def __init__(self, context_params):\n        self._context_params = context_params\n\n    def mandelbrot_channel(self, command_params: MandelbrotChannelQueryParams):\n        \"\"\"\n        Calculate the rescaled range statistics.\n\n        Explain the math...\n        \"\"\"\n        from humbldata.core.standard_models.toolbox.technical.mandelbrotchannel import (\n            MandelbrotChannelFetcher,\n        )\n\n        # Instantiate the Fetcher with the query parameters\n        fetcher = MandelbrotChannelFetcher(self._context_params, command_params)\n\n        # Use the fetcher to get the data\n        return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.technical_controller.Technical.mandelbrot_channel","title":"mandelbrot_channel","text":"<pre><code>mandelbrot_channel(command_params: MandelbrotChannelQueryParams)\n</code></pre> <p>Calculate the rescaled range statistics.</p> <p>Explain the math...</p> Source code in <code>src\\humbldata\\toolbox\\technical\\technical_controller.py</code> <pre><code>def mandelbrot_channel(self, command_params: MandelbrotChannelQueryParams):\n    \"\"\"\n    Calculate the rescaled range statistics.\n\n    Explain the math...\n    \"\"\"\n    from humbldata.core.standard_models.toolbox.technical.mandelbrotchannel import (\n        MandelbrotChannelFetcher,\n    )\n\n    # Instantiate the Fetcher with the query parameters\n    fetcher = MandelbrotChannelFetcher(self._context_params, command_params)\n\n    # Use the fetcher to get the data\n    return fetcher.fetch_data()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel","title":"mandelbrot_channel","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers","title":"helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: MandelBrot Channel || Sub-Category: Helpers.</p> <p>These <code>Toolbox()</code> helpers are used in various calculations in the toolbox context. Most of the helpers will be mathematical transformations of data. These functions should be DUMB functions.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.add_window_index","title":"add_window_index","text":"<pre><code>add_window_index(data: LazyFrame | DataFrame, window: str) -&gt; LazyFrame | DataFrame\n</code></pre> <pre><code>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n</code></pre> <p>Add a column to the dataframe indicating the window grouping for each row in a time series.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input data frame or lazy frame to which the window index will be added.</p> required <code>window</code> <code>str</code> <p>The window size as a string, used to determine the grouping of rows into windows.</p> required <p>Returns:</p> Type Description <code>LazyFrame | DataFrame</code> <p>The original data frame or lazy frame with an additional column named \"window_index\" indicating the window grouping for each row.</p> Notes <ul> <li>This function is essential for calculating the Mandelbrot Channel, where the dataset is split into numerous 'windows', and statistics are calculated for each window.</li> <li>The function adds a dummy <code>symbol</code> column if the data contains only one symbol, to avoid errors in the <code>group_by_dynamic()</code> function.</li> <li>It is utilized within the <code>log_mean()</code> function for window-based calculations.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n&gt;&gt;&gt; window = \"1d\"\n&gt;&gt;&gt; add_window_index(data, window)\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n\u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n\u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def add_window_index(\n    data: pl.LazyFrame | pl.DataFrame, window: str\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n        Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **add_window_index**.\n\n    Add a column to the dataframe indicating the window grouping for each row in\n    a time series.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input data frame or lazy frame to which the window index will be\n        added.\n    window : str\n        The window size as a string, used to determine the grouping of rows into\n        windows.\n\n    Returns\n    -------\n    pl.LazyFrame | pl.DataFrame\n        The original data frame or lazy frame with an additional column named\n        \"window_index\" indicating\n        the window grouping for each row.\n\n    Notes\n    -----\n    - This function is essential for calculating the Mandelbrot Channel, where\n    the dataset is split into\n    numerous 'windows', and statistics are calculated for each window.\n    - The function adds a dummy `symbol` column if the data contains only one\n    symbol, to avoid errors in the `group_by_dynamic()` function.\n    - It is utilized within the `log_mean()` function for window-based\n    calculations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({\"date\": [\"2021-01-01\", \"2021-01-02\"], \"symbol\": [\"AAPL\", \"AAPL\"], \"value\": [1, 2]})\n    &gt;&gt;&gt; window = \"1d\"\n    &gt;&gt;&gt; add_window_index(data, window)\n    shape: (2, 4)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 date       \u2506 symbol \u2506 value \u2506 window_index \u2502\n    \u2502 ---        \u2506 ---    \u2506 ---   \u2506 ---          \u2502\n    \u2502 date       \u2506 str    \u2506 i64   \u2506 i64          \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 2021-01-01 \u2506 AAPL   \u2506 1     \u2506 0            \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 2021-01-02 \u2506 AAPL   \u2506 2     \u2506 1            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n\n    def _create_monthly_window_index(col: str, k: int = 1):\n        year_diff = pl.col(col).last().dt.year() - pl.col(col).dt.year()\n        month_diff = pl.col(col).last().dt.month() - pl.col(col).dt.month()\n        day_indicator = pl.col(col).dt.day() &gt; pl.col(col).last().dt.day()\n        return (12 * year_diff + month_diff - day_indicator) // k\n\n    # Clean the window into stnaardized strings (i.e \"1month\"/\"1 month\" = \"1mo\")\n    window = _window_format(window, _return_timedelta=False)  # returns `str`\n\n    if \"w\" in window or \"d\" in window:\n        msg = \"The window cannot include 'd' or 'w', the window needs to be larger than 1 month!\"\n        raise HumblDataError(msg)\n\n    window_monthly = _window_format_monthly(window)\n\n    # Adding a 'dummy' column if only one symbol is present in data, to avoid\n    # errors in the group_by_dynamic() function\n    if \"symbol\" not in data.columns:\n        data = data.with_columns(pl.lit(\"dummy\").alias(\"symbol\"))\n\n    data = data.with_columns(\n        _create_monthly_window_index(col=\"date\", k=window_monthly)\n        .alias(\"window_index\")\n        .over(\"symbol\")\n    )\n\n    return data\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_buckets","title":"vol_buckets","text":"<pre><code>vol_buckets(data: DataFrame | LazyFrame, lo_quantile: float = 0.4, hi_quantile: float = 0.8, _column_name_volatility: str = 'realized_volatility') -&gt; DataFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_buckets.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LazyFrame | DataFrame</code> <p>The input dataframe or lazy frame.</p> required <code>lo_quantile</code> <code>float</code> <p>The lower quantile for bucketing. Default is 0.4.</p> <code>0.4</code> <code>hi_quantile</code> <code>float</code> <p>The higher quantile for bucketing. Default is 0.8.</p> <code>0.8</code> <code>window</code> <code>str</code> <p>The window for bucketing. Default is \"1m\".</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The output dataframe or lazy frame with the bucketed volatility.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def vol_buckets(\n    data: pl.DataFrame | pl.LazyFrame,\n    lo_quantile: float = 0.4,\n    hi_quantile: float = 0.8,\n    _column_name_volatility: str = \"realized_volatility\",\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_buckets**.\n\n    Parameters\n    ----------\n    data : pl.LazyFrame | pl.DataFrame\n        The input dataframe or lazy frame.\n    lo_quantile : float\n        The lower quantile for bucketing. Default is 0.4.\n    hi_quantile : float\n        The higher quantile for bucketing. Default is 0.8.\n    window : str\n        The window for bucketing. Default is \"1m\".\n\n    Returns\n    -------\n    pl.DataFrame\n        The output dataframe or lazy frame with the bucketed volatility.\n    \"\"\"\n    # Group by 'symbol' and apply 'calculate_vol_buckets' to each group\n    if isinstance(data, pl.LazyFrame):\n        data = data.collect()\n\n    result = data.group_by(\"symbol\").map_groups(\n        lambda group_df: _calculate_vol_buckets(\n            group_df, lo_quantile, hi_quantile, _column_name_volatility\n        ),\n    )\n\n    return result.lazy()\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.vol_filter","title":"vol_filter","text":"<pre><code>vol_filter(data: DataFrame | LazyFrame) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: vol_filter.</p> <p>If <code>_rv_adjustment</code> is True, then filter the data to only include rows that are in the same vol_bucket as the latest row for each symbol.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def vol_filter(\n    data: pl.DataFrame | pl.LazyFrame,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: MandelBrot Channel || Sub-Category: Helpers || Command: **vol_filter**.\n\n    If `_rv_adjustment` is True, then filter the data to only include rows\n    that are in the same vol_bucket as the latest row for each symbol.\n    \"\"\"\n    data = data.with_columns(\n        pl.col(\"vol_bucket\").last().over(\"symbol\").alias(\"last_vol_bucket\")\n    )\n\n    out = data.filter(\n        (pl.col(\"vol_bucket\") == pl.col(\"last_vol_bucket\")).over(\"symbol\")\n    ).drop(\"last_vol_bucket\")\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.helpers.price_range","title":"price_range","text":"<pre><code>price_range(data: LazyFrame | DataFrame, rs_data: DataFrame | LazyFrame, recent_price_data: DataFrame | LazyFrame, _rs_method: str = 'RS', _detrended_returns: str = 'detrended_log_returns', *, _rv_adjustment: bool = False, **kwargs) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Calculate the price range based on the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[LazyFrame, DataFrame]</code> <p>The DataFrame to calculate the price range from.</p> required <code>_rs_method</code> <code>str</code> <p>Whether to use the fast method, by default True.</p> <code>'RS'</code> <code>RS</code> <code>Optional[Series]</code> <p>The RS series, by default None.</p> required <code>RS_mean</code> <code>Optional[float]</code> <p>The mean of the RS series, by default None.</p> required <code>RS_max</code> <code>Optional[float]</code> <p>The maximum of the RS series, by default None.</p> required <code>RS_min</code> <code>Optional[float]</code> <p>The minimum of the RS series, by default None.</p> required <code>recent_price</code> <code>Optional[float]</code> <p>The recent price, by default None.</p> required <code>cumdev_max</code> <code>Optional[DataFrame]</code> <p>The maximum range, by default None.</p> required <code>cumdev_min</code> <code>Optional[DataFrame]</code> <p>The minimum range, by default None.</p> required <code>RS_method</code> <code>str</code> <p>The method to calculate the RS, by default \"RS\".</p> required <code>_detrended_returns</code> <code>str</code> <p>The column name for detrended returns, by default \"detrended_log_returns\".</p> <code>'detrended_log_returns'</code> <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>The top and bottom price.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the RS_method is not one of 'RS', 'RS_mean', 'RS_max', 'RS_min'.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\helpers.py</code> <pre><code>def price_range(\n    data: pl.LazyFrame | pl.DataFrame,\n    rs_data: pl.DataFrame | pl.LazyFrame,\n    recent_price_data: pl.DataFrame | pl.LazyFrame,\n    _rs_method: str = \"RS\",\n    _detrended_returns: str = \"detrended_log_returns\",  # Parameterized detrended_returns column\n    *,\n    _rv_adjustment: bool = False,\n    **kwargs,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Calculate the price range based on the specified method.\n\n    Parameters\n    ----------\n    data : Union[pl.LazyFrame, pl.DataFrame]\n        The DataFrame to calculate the price range from.\n    _rs_method : str, optional\n        Whether to use the fast method, by default True.\n    RS : Optional[pl.Series], optional\n        The RS series, by default None.\n    RS_mean : Optional[float], optional\n        The mean of the RS series, by default None.\n    RS_max : Optional[float], optional\n        The maximum of the RS series, by default None.\n    RS_min : Optional[float], optional\n        The minimum of the RS series, by default None.\n    recent_price : Optional[float], optional\n        The recent price, by default None.\n    cumdev_max : Optional[pl.DataFrame], optional\n        The maximum range, by default None.\n    cumdev_min : Optional[pl.DataFrame], optional\n        The minimum range, by default None.\n    RS_method : str, optional\n        The method to calculate the RS, by default \"RS\".\n    _detrended_returns: str, optional\n        The column name for detrended returns, by default \"detrended_log_returns\".\n    **kwargs\n        Arbitrary keyword arguments.\n\n    Returns\n    -------\n    Tuple[float, float]\n        The top and bottom price.\n\n    Raises\n    ------\n    ValueError\n        If the RS_method is not one of 'RS', 'RS_mean', 'RS_max', 'RS_min'.\n    \"\"\"\n    # Check if RS_method is one of the allowed values\n    if _rs_method not in RS_METHODS:\n        msg = \"RS_method must be one of 'RS', 'RS_mean', 'RS_max', 'RS_min'\"\n        raise HumblDataError(msg)\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n\n    if _rv_adjustment:\n        # Calculate STD where detrended_returns are in the same rvol_bucket\n        std_detrended_returns = (\n            data.lazy()\n            .sort(sort_cols)\n            .group_by(\"symbol\")\n            .agg(\n                [\n                    pl.col(_detrended_returns)\n                    .std()\n                    .alias(f\"std_{_detrended_returns}\")\n                ]\n            )\n        )\n    else:\n        # Calculate STD where detrended_returns are from the latest range for each symbol\n        std_detrended_returns = (\n            data.filter(\n                (pl.col(\"window_index\") == pl.col(\"window_index\").max()).over(\n                    \"symbol\"\n                )\n            )\n            .group_by(\"symbol\")\n            .agg(\n                [\n                    pl.col(_detrended_returns)\n                    .std()\n                    .alias(f\"std_{_detrended_returns}\")\n                ]\n            )\n            # get the latest window of data\n            .select(pl.col([\"symbol\", f\"std_{_detrended_returns}\"]))\n        )\n    # Merge RS stats with STD of detrended returns and recent price\n    price_range = rs_data.join(std_detrended_returns, on=\"symbol\").join(\n        recent_price_data.lazy(), on=\"symbol\"\n    )\n\n    price_range = price_range.with_columns(\n        (\n            pl.col(_rs_method)\n            * pl.col(\"std_detrended_log_returns\")\n            * pl.col(\"recent_price\")\n        ).alias(\"price_range\")\n    )\n\n    # Relative Position Modifier\n    out = _modify_mandelbrot_prices(\n        data,\n        price_range,\n        \"cum_sum_max\",\n        \"cum_sum_min\",\n    )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model","title":"model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_mandelbrot_channel.</p> <p>A command to generate a Mandelbrot Channel for any time series.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.mandelbrot_channel.model.calc_mandelbrot_channel","title":"calc_mandelbrot_channel","text":"<pre><code>calc_mandelbrot_channel(data: DataFrame | LazyFrame, window: str = '1m', rv_adjustment: bool = True, _rv_grouped_mean: bool = True, _rv_method: str = 'std', _rs_method: str = 'RS', _live_price: bool = True) -&gt; DataFrame | LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: Mandelbrot Channel.</p> <p>Calculates the Mandelbrot Channel for a given time series based on the provided standard and extra parameters.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Mandelbrot Channel.</p> required <code>window</code> <code>str</code> <p>The window size for the calculation, specified as a string.</p> <code>'1m'</code> <code>rv_adjustment</code> <code>bool</code> <p>Whether to adjust the calculation for realized volatility.</p> <code>True</code> <code>_rv_grouped_mean</code> <code>bool</code> <p>Whether to use the grouped mean in the realized volatility calculation.</p> <code>True</code> <code>_rv_method</code> <code>str</code> <p>The method to use for calculating realized volatility. You only need to supply a value if <code>rv_adjustment</code> is True.</p> <code>'std'</code> <code>_rs_method</code> <code>str</code> <p>The method to use for calculating the range over standard deviation. You can choose either RS/RS_mean/RS_min/RS_max. This changes the width of the calculated Mandelbrot Channel</p> <code>'RS'</code> <code>_live_price</code> <code>bool</code> <p>Whether to use live price data in the calculation. This may add a significant amount of time to the calculation (1-3s)</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The calculated Mandelbrot Channel data for the given time series.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\mandelbrot_channel\\model.py</code> <pre><code>def calc_mandelbrot_channel(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    rv_adjustment: bool = True,\n    _rv_grouped_mean: bool = True,\n    _rv_method: str = \"std\",\n    _rs_method: str = \"RS\",\n    _live_price: bool = True,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: Mandelbrot Channel**.\n\n    Calculates the Mandelbrot Channel for a given time series based on the\n    provided standard and extra parameters.\n\n    Parameters\n    ----------\n    data: pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Mandelbrot Channel.\n    window: str, default \"1m\"\n        The window size for the calculation, specified as a string.\n    rv_adjustment: bool, default True\n        Whether to adjust the calculation for realized volatility.\n    _rv_grouped_mean: bool, default True\n        Whether to use the grouped mean in the realized volatility calculation.\n    _rv_method: str, default \"std\"\n        The method to use for calculating realized volatility. You only need to\n        supply a value if `rv_adjustment` is True.\n    _rs_method: str, default \"RS\"\n        The method to use for calculating the range over standard deviation.\n        You can choose either RS/RS_mean/RS_min/RS_max. This changes the width of\n        the calculated Mandelbrot Channel\n    _live_price: bool, default True\n        Whether to use live price data in the calculation. This may add a\n        significant amount of time to the calculation (1-3s)\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The calculated Mandelbrot Channel data for the given time series.\n    \"\"\"\n    # Setup ====================================================\n    window_int = _window_format(window, _return_timedelta=True)\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n\n    data = data.lazy()\n    # Step 1: Collect Price Data -------------------------------------------\n    # Step X: Add window bins ----------------------------------------------\n    # We want date grouping, non-overlapping window bins\n    data1 = add_window_index(data, window=window)\n\n    # Step X: Calculate Log Returns + Rvol ---------------------------------\n    if \"log_returns\" not in data1.columns:\n        data2 = log_returns(data1, _column_name=\"close\")\n    else:\n        data2 = data1\n\n    # Step X: Calculate Log Mean Series ------------------------------------\n    if isinstance(data2, pl.DataFrame | pl.LazyFrame):\n        data3 = mean(data2)\n    else:\n        msg = \"A series was passed to `mean()` calculation. Please provide a DataFrame or LazyFrame.\"\n        raise HumblDataError(msg)\n    # Step X: Calculate Mean De-trended Series -----------------------------\n    data4 = detrend(\n        data3, _detrend_value_col=\"window_mean\", _detrend_col=\"log_returns\"\n    )\n    # Step X: Calculate Cumulative Deviate Series --------------------------\n    data5 = cum_sum(data4, _column_name=\"detrended_log_returns\")\n    # Step X: Calculate Mandelbrot Range -----------------------------------\n    data6 = range_(data5, _column_name=\"cum_sum\")\n    # Step X: Calculate Standard Deviation ---------------------------------\n    data7 = std(data6, _column_name=\"cum_sum\")\n    # Step X: Calculate Range (R) &amp; Standard Deviation (S) -----------------\n    if rv_adjustment:\n        # Step 8.1: Calculate Realized Volatility --------------------------\n        data7 = calc_realized_volatility(\n            data=data7,\n            window=window,\n            method=_rv_method,\n            grouped_mean=_rv_grouped_mean,\n        )\n        # rename col for easy selection\n        for col in data7.columns:\n            if \"volatility_pct\" in col:\n                data7 = data7.rename({col: \"realized_volatility\"})\n        # Step 8.2: Calculate Volatility Bucket Stats ----------------------\n        data7 = vol_buckets(data=data7, lo_quantile=0.3, hi_quantile=0.65)\n        data7 = vol_filter(data7)\n\n    # Step X: Calculate RS -------------------------------------------------\n    data8 = data7.sort(sort_cols).with_columns(\n        (pl.col(\"cum_sum_range\") / pl.col(\"cum_sum_std\")).alias(\"RS\")\n    )\n    # Calculate mean, min, and max of 'RS' for each 'symbol' group\n    # do i need to collect only the last window for RS or do i want the calcs over the whole data\n    rs_data = (\n        data8.group_by(\"symbol\")\n        .agg(\n            [\n                pl.col(\"RS\").last().alias(\"RS\"),\n                pl.col(\"RS\").mean().alias(\"RS_mean\"),\n                pl.col(\"RS\").min().alias(\"RS_min\"),\n                pl.col(\"RS\").max().alias(\"RS_max\"),\n            ]\n        )\n        .sort(\"symbol\")\n    )\n\n    # Step X: Collect Recent Prices ----------------------------------------\n    if _live_price:\n        symbols = (\n            data.select(\"symbol\").unique().to_pandas().sort_values(\"symbol\")\n        )\n        recent_prices = get_latest_price(symbols)\n    else:\n        recent_prices = (\n            data1.group_by(\"symbol\")\n            .agg(pl.col(\"close\").last().alias(\"recent_price\"))\n            .sort(\"symbol\")\n        )\n\n    # Step X: Calculate Rescaled Price Range ------------------------------\n    out = price_range(\n        data=data8,\n        rs_data=rs_data,\n        recent_price_data=recent_prices,\n        _rs_method=_rs_method,\n        _rv_adjustment=rv_adjustment,\n    )\n\n    return out\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility","title":"volatility","text":""},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers","title":"realized_volatility_helpers","text":"<p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers.</p> <p>All of the volatility estimators used in <code>calc_realized_volatility()</code>. These are various methods to calculate the realized volatility of financial data.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.std","title":"std","text":"<pre><code>std(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _std.</p> <p>This function computes the standard deviation of returns, which is a common measure of volatility.It calculates the rolling standard deviation for a given window size, optionally adjusting for the average number of trading days and scaling the result to an annualized volatility percentage.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data containing the returns. It can be a DataFrame, LazyFrame, or Series.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating the standard deviation. The default is \"1m\" (one month).</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for annualizing the volatility. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>If True, null values will be dropped from the result. The default is True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>If True, the average number of trading days will be used when calculating the window size. The default is True.</p> <code>False</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. This parameter is used when <code>data</code> is a DataFrame or LazyFrame. The default is \"log_returns\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>Union[DataFrame, LazyFrame, Series]</code> <p>The input data structure with an additional column for the rolling standard deviation of returns, or the modified Series with the rolling standard deviation values.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def std(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _std**.\n\n    This function computes the standard deviation of returns, which is a common\n    measure of volatility.It calculates the rolling standard deviation for a\n    given window size, optionally adjusting for the average number of trading\n    days and scaling the result to an annualized volatility percentage.\n\n    Parameters\n    ----------\n    data : Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data containing the returns. It can be a DataFrame, LazyFrame,\n        or Series.\n    window : str, optional\n        The rolling window size for calculating the standard deviation.\n        The default is \"1m\" (one month).\n    trading_periods : int, optional\n        The number of trading periods in a year, used for annualizing the\n        volatility. The default is 252.\n    _drop_nulls : bool, optional\n        If True, null values will be dropped from the result.\n        The default is True.\n    _avg_trading_days : bool, optional\n        If True, the average number of trading days will be used when\n        calculating the window size. The default is True.\n    _column_name_returns : str, optional\n        The name of the column containing the returns. This parameter is used\n        when `data` is a DataFrame or LazyFrame. The default is \"log_returns\".\n\n    Returns\n    -------\n    Union[pl.DataFrame, pl.LazyFrame, pl.Series]\n        The input data structure with an additional column for the rolling\n        standard deviation of returns, or the modified Series with the rolling\n        standard deviation values.\n    \"\"\"\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    if isinstance(data, pl.Series):\n        return data.rolling_std(window_size=window_int, min_periods=1)\n    else:\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort:\n            data = data.lazy().sort(sort_cols)\n        # convert window_timedelta to days to use fixed window\n        result = (\n            data.lazy()\n            .set_sorted(sort_cols)\n            .with_columns(\n                (\n                    pl.col(_column_name_returns).rolling_std(\n                        window_size=window_int,\n                        min_periods=2,  # using min_periods=2, bc if min_periods=1, the first value will be 0.\n                        by=\"date\",\n                    )\n                    * math.sqrt(trading_periods)\n                    * 100\n                ).alias(f\"std_volatility_pct_{window_int}D\")\n            )\n        )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"std_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.parkinson","title":"parkinson","text":"<pre><code>parkinson(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate Parkinson's volatility over a specified window.</p> <p>Parkinson's volatility is a measure that uses the stock's high and low prices of the day rather than just close to close prices. It is particularly useful for capturing large price movements during the day.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the stock prices.</p> required <code>window</code> <code>int</code> <p>The rolling window size for calculating volatility, by default 30.</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, by default 252.</p> required <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The calculated Parkinson's volatility, with an additional column \"parkinson_volatility_pct_{window_int}D\" indicating the percentage volatility.</p> Notes <p>This function requires the input data to have 'high' and 'low' columns to calculate the logarithm of their ratio, which is squared and scaled by a constant to estimate volatility. The result is then annualized and expressed as a percentage.</p> Usage <p>If you pass <code>\"1m</code> as a <code>window</code> argument and  <code>_avg_trading_days=False</code>. The result will be <code>30</code>. If <code>_avg_trading_days=True</code>, the result will be <code>21</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n&gt;&gt;&gt; _parkinson(data)\nA DataFrame with the calculated Parkinson's volatility.\n</code></pre> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def parkinson(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate Parkinson's volatility over a specified window.\n\n    Parkinson's volatility is a measure that uses the stock's high and low prices\n    of the day rather than just close to close prices. It is particularly useful\n    for capturing large price movements during the day.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the stock prices.\n    window : int, optional\n        The rolling window size for calculating volatility, by default 30.\n    trading_periods : int, optional\n        The number of trading periods in a year, by default 252.\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The calculated Parkinson's volatility, with an additional column\n        \"parkinson_volatility_pct_{window_int}D\"\n        indicating the percentage volatility.\n\n    Notes\n    -----\n    This function requires the input data to have 'high' and 'low' columns to\n    calculate\n    the logarithm of their ratio, which is squared and scaled by a constant to\n    estimate\n    volatility. The result is then annualized and expressed as a percentage.\n\n    Usage\n    -----\n    If you pass `\"1m` as a `window` argument and  `_avg_trading_days=False`.\n    The result will be `30`. If `_avg_trading_days=True`, the result will be\n    `21`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = pl.DataFrame({'high': [120, 125], 'low': [115, 120]})\n    &gt;&gt;&gt; _parkinson(data)\n    A DataFrame with the calculated Parkinson's volatility.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n\n    var1 = 1.0 / (4.0 * math.log(2.0))\n    var2 = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    rs = var1 * var2**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            (\n                rs.rolling_map(\n                    _annual_vol, window_size=window_int, min_periods=1\n                )\n                * 100\n            ).alias(f\"parkinson_volatility_pct_{window_int}D\")\n        )\n    )\n    if _drop_nulls:\n        return result.drop_nulls(\n            subset=f\"parkinson_volatility_pct_{window_int}D\"\n        )\n\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.garman_klass","title":"garman_klass","text":"<pre><code>garman_klass(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'adj_close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _garman_klass.</p> <p>Calculates the Garman-Klass volatility for a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for volatility calculation, by default \"1m\".</p> <code>'1m'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices, by default \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices, by default \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the opening prices, by default \"open\".</p> <code>'open'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the adjusted closing prices, by default \"adj_close\".</p> <code>'adj_close'</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Whether to use the average number of trading days when calculating the window size, by default True.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame | Series</code> <p>The calculated Garman-Klass volatility, with an additional column \"volatility_pct\" indicating the percentage volatility.</p> Notes <p>Garman-Klass volatility extends Parkinson\u2019s volatility by considering the opening and closing prices in addition to the high and low prices. This approach provides a more accurate estimation of volatility, especially in markets with significant activity at the opening and closing of trading sessions.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def garman_klass(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"adj_close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _garman_klass**.\n\n    Calculates the Garman-Klass volatility for a given dataset.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for volatility calculation, by default \"1m\".\n    _column_name_high : str, optional\n        The name of the column containing the high prices, by default \"high\".\n    _column_name_low : str, optional\n        The name of the column containing the low prices, by default \"low\".\n    _column_name_open : str, optional\n        The name of the column containing the opening prices, by default \"open\".\n    _column_name_close : str, optional\n        The name of the column containing the adjusted closing prices, by\n        default \"adj_close\".\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _avg_trading_days : bool, optional\n        Whether to use the average number of trading days when calculating the\n        window size, by default True.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame | pl.Series\n        The calculated Garman-Klass volatility, with an additional column\n        \"volatility_pct\" indicating the percentage volatility.\n\n    Notes\n    -----\n    Garman-Klass volatility extends Parkinson\u2019s volatility by considering the\n    opening and closing prices in addition to the high and low prices. This\n    approach provides a more accurate estimation of volatility, especially in\n    markets with significant activity at the opening and closing of trading\n    sessions.\n    \"\"\"\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n    log_hi_lo = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .select((pl.col(_column_name_high) / pl.col(_column_name_low)).log())\n        .collect()\n        .to_series()\n    )\n    log_close_open = (\n        data.lazy()\n        .select((pl.col(_column_name_close) / pl.col(_column_name_open)).log())\n        .collect()\n        .to_series()\n    )\n    rs: pl.Series = 0.5 * log_hi_lo**2 - (2 * np.log(2) - 1) * log_close_open**2\n\n    window_int: int = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    ).days\n    result = data.lazy().with_columns(\n        (\n            rs.rolling_map(_annual_vol, window_size=window_int, min_periods=1)\n            * 100\n        ).alias(f\"gk_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"gk_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.hodges_tompkins","title":"hodges_tompkins","text":"<pre><code>hodges_tompkins(data: DataFrame | LazyFrame | Series, window: str = '1m', trading_periods=252, _column_name_returns: str = 'log_returns', *, _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame | Series\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _hodges_tompkins.</p> <p>Hodges-Tompkins volatility is a bias correction for estimation using an overlapping data sample that produces unbiased estimates and a substantial gain in efficiency.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def hodges_tompkins(\n    data: pl.DataFrame | pl.LazyFrame | pl.Series,\n    window: str = \"1m\",\n    trading_periods=252,\n    _column_name_returns: str = \"log_returns\",\n    *,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.Series:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _hodges_tompkins**.\n\n    Hodges-Tompkins volatility is a bias correction for estimation using an\n    overlapping data sample that produces unbiased estimates and a\n    substantial gain in efficiency.\n    \"\"\"\n    # When calculating rv_mean, need a different adjustment factor,\n    # so window doesn't influence the Volatility_mean\n    # RV_MEAN\n\n    # Define Window Size\n    window_timedelta = _window_format(\n        window, _return_timedelta=True, _avg_trading_days=_avg_trading_days\n    )\n    # Calculate STD, assigned to `vol`\n    if isinstance(data, pl.Series):\n        vol = data.rolling_std(window_size=window_timedelta.days, min_periods=1)\n    else:\n        sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n        if _sort:\n            data = data.lazy().sort(sort_cols)\n        vol = (\n            data.lazy()\n            .set_sorted(sort_cols)\n            .select(\n                pl.col(_column_name_returns).rolling_std(\n                    window_size=window_timedelta, min_periods=1, by=\"date\"\n                )\n                * np.sqrt(trading_periods)\n            )\n        )\n\n    # Assign window size to h for adjustment\n    h: int = window_timedelta.days\n\n    if isinstance(data, pl.Series):\n        count = data.len()\n    elif isinstance(data, pl.LazyFrame):\n        count = data.collect().shape[0]\n    else:\n        count = data.shape[0]\n\n    n = (count - h) + 1\n    adj_factor = 1.0 / (1.0 - (h / n) + ((h**2 - 1) / (3 * n**2)))\n\n    if isinstance(data, pl.Series):\n        return (vol * adj_factor) * 100\n    else:\n        result = data.lazy().with_columns(\n            ((vol.collect() * adj_factor) * 100)\n            .to_series()\n            .alias(f\"ht_volatility_pct_{h}D\")\n        )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"ht_volatility_pct_{h}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.rogers_satchell","title":"rogers_satchell","text":"<pre><code>rogers_satchell(data: DataFrame | LazyFrame, window: str = '1m', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'adj_close', _drop_nulls: bool = True, _avg_trading_days: bool = False, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _rogers_satchell.</p> <p>Rogers-Satchell is an estimator for measuring the volatility of securities with an average return not equal to zero. Unlike Parkinson and Garman-Klass estimators, Rogers-Satchell incorporates a drift term (mean return not equal to zero). This function calculates the Rogers-Satchell volatility estimator over a specified window and optionally drops null values from the result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data for which to calculate the Rogers-Satchell volatility estimator. This can be either a DataFrame or a LazyFrame. There need to be OHLC columns present in the data.</p> required <code>window</code> <code>str</code> <p>The window over which to calculate the volatility estimator. The window is specified as a string, such as \"1m\" for one month.</p> <code>\"1m\"</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column representing the high prices in the data.</p> <code>\"high\"</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column representing the low prices in the data.</p> <code>\"low\"</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column representing the opening prices in the data.</p> <code>\"open\"</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column representing the adjusted closing prices in the data.</p> <code>\"adj_close\"</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result. If True, rows with null values in the calculated volatility column will be removed from the output.</p> <code>True</code> <code>_avg_trading_days</code> <code>bool</code> <p>Indicates whether to use the average number of trading days per window. This affects how the window size is interpreted. i.e instead of \"1mo\" returning <code>timedelta(days=31)</code>, it will return <code>timedelta(days=21)</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data with an additional column containing the calculated Rogers-Satchell volatility estimator. The return type matches the input type (DataFrame or LazyFrame).</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def rogers_satchell(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"adj_close\",\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _rogers_satchell**.\n\n    Rogers-Satchell is an estimator for measuring the volatility of\n    securities with an average return not equal to zero. Unlike Parkinson\n    and Garman-Klass estimators, Rogers-Satchell incorporates a drift term\n    (mean return not equal to zero). This function calculates the\n    Rogers-Satchell volatility estimator over a specified window and optionally\n    drops null values from the result.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data for which to calculate the Rogers-Satchell volatility\n        estimator. This can be either a DataFrame or a LazyFrame. There need to\n        be OHLC columns present in the data.\n    window : str, default \"1m\"\n        The window over which to calculate the volatility estimator. The\n        window is specified as a string, such as \"1m\" for one month.\n    _column_name_high : str, default \"high\"\n        The name of the column representing the high prices in the data.\n    _column_name_low : str, default \"low\"\n        The name of the column representing the low prices in the data.\n    _column_name_open : str, default \"open\"\n        The name of the column representing the opening prices in the data.\n    _column_name_close : str, default \"adj_close\"\n        The name of the column representing the adjusted closing prices in the\n        data.\n    _drop_nulls : bool, default True\n        Whether to drop null values from the result. If True, rows with null\n        values in the calculated volatility column will be removed from the\n        output.\n    _avg_trading_days : bool, default True\n        Indicates whether to use the average number of trading days per window.\n        This affects how the window size is interpreted. i.e instead of \"1mo\"\n        returning `timedelta(days=31)`, it will return `timedelta(days=21)`.\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data with an additional column containing the calculated\n        Rogers-Satchell volatility estimator. The return type matches the input\n        type (DataFrame or LazyFrame).\n    \"\"\"\n    # Check if all required columns are present in the DataFrame\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n            ]\n        )\n        .with_columns(\n            (\n                pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n            ).alias(\"rs\")\n        )\n    )\n    result = data.lazy().with_columns(\n        (\n            pl.col(\"rs\").rolling_map(\n                _annual_vol, window_size=window_int, min_periods=1\n            )\n            * 100\n        ).alias(f\"rs_volatility_pct_{window_int}D\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"rs_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.yang_zhang","title":"yang_zhang","text":"<pre><code>yang_zhang(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', _column_name_close: str = 'adj_close', _avg_trading_days: bool = False, _drop_nulls: bool = True, _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || Command: _yang_zhang.</p> <p>Yang-Zhang volatility is the combination of the overnight (close-to-open volatility), a weighted average of the Rogers-Satchell volatility and the day\u2019s open-to-close volatility.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def yang_zhang(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    _column_name_close: str = \"adj_close\",\n    _avg_trading_days: bool = False,\n    _drop_nulls: bool = True,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || Sub-Category: Volatility Helpers || **Command: _yang_zhang**.\n\n    Yang-Zhang volatility is the combination of the overnight\n    (close-to-open volatility), a weighted average of the Rogers-Satchell\n    volatility and the day\u2019s open-to-close volatility.\n    \"\"\"\n    # check required columns\n    _check_required_columns(\n        data,\n        _column_name_high,\n        _column_name_low,\n        _column_name_open,\n        _column_name_close,\n    )\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            [\n                (pl.col(_column_name_high) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_ho\"),\n                (pl.col(_column_name_low) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_lo\"),\n                (pl.col(_column_name_close) / pl.col(_column_name_open))\n                .log()\n                .alias(\"log_co\"),\n                (pl.col(_column_name_open) / pl.col(_column_name_close).shift())\n                .log()\n                .alias(\"log_oc\"),\n                (\n                    pl.col(_column_name_close)\n                    / pl.col(_column_name_close).shift()\n                )\n                .log()\n                .alias(\"log_cc\"),\n            ]\n        )\n        .with_columns(\n            [\n                (pl.col(\"log_oc\") ** 2).alias(\"log_oc_sq\"),\n                (pl.col(\"log_cc\") ** 2).alias(\"log_cc_sq\"),\n                (\n                    pl.col(\"log_ho\") * (pl.col(\"log_ho\") - pl.col(\"log_co\"))\n                    + pl.col(\"log_lo\") * (pl.col(\"log_lo\") - pl.col(\"log_co\"))\n                ).alias(\"rs\"),\n            ]\n        )\n    )\n\n    k = 0.34 / (1.34 + (window_int + 1) / (window_int - 1))\n    data = _yang_zhang_engine(data=data, window=window_int)\n    result = (\n        data.lazy()\n        .with_columns(\n            (\n                (\n                    pl.col(\"open_vol\")\n                    + k * pl.col(\"close_vol\")\n                    + (1 - k) * pl.col(\"window_rs\")\n                ).sqrt()\n                * np.sqrt(trading_periods)\n                * 100\n            ).alias(f\"yz_volatility_pct_{window_int}D\")\n        )\n        .select(\n            pl.exclude(\n                [\n                    \"log_ho\",\n                    \"log_lo\",\n                    \"log_co\",\n                    \"log_oc\",\n                    \"log_cc\",\n                    \"log_oc_sq\",\n                    \"log_cc_sq\",\n                    \"rs\",\n                    \"close_vol\",\n                    \"open_vol\",\n                    \"window_rs\",\n                ]\n            )\n        )\n    )\n    if _drop_nulls:\n        return result.drop_nulls(subset=f\"yz_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_helpers.squared_returns","title":"squared_returns","text":"<pre><code>squared_returns(data: DataFrame | LazyFrame, window: str = '1m', trading_periods: int = 252, _drop_nulls: bool = True, _avg_trading_days: bool = False, _column_name_returns: str = 'log_returns', _sort: bool = True) -&gt; LazyFrame\n</code></pre> <p>Calculate squared returns over a rolling window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The input data containing the price information.</p> required <code>window</code> <code>str</code> <p>The rolling window size for calculating squared returns, by default \"1m\".</p> <code>'1m'</code> <code>trading_periods</code> <code>int</code> <p>The number of trading periods in a year, used for scaling the result. The default is 252.</p> <code>252</code> <code>_drop_nulls</code> <code>bool</code> <p>Whether to drop null values from the result, by default True.</p> <code>True</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the price data, by default \"adj_close\".</p> <code>'log_returns'</code> <p>Returns:</p> Type Description <code>DataFrame | LazyFrame</code> <p>The input data structure with an additional column for the rolling squared returns.</p> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_helpers.py</code> <pre><code>def squared_returns(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    trading_periods: int = 252,\n    _drop_nulls: bool = True,\n    _avg_trading_days: bool = False,\n    _column_name_returns: str = \"log_returns\",\n    _sort: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Calculate squared returns over a rolling window.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The input data containing the price information.\n    window : str, optional\n        The rolling window size for calculating squared returns, by default \"1m\".\n    trading_periods : int, optional\n        The number of trading periods in a year, used for scaling the result.\n        The default is 252.\n    _drop_nulls : bool, optional\n        Whether to drop null values from the result, by default True.\n    _column_name_returns : str, optional\n        The name of the column containing the price data, by default \"adj_close\".\n\n    Returns\n    -------\n    pl.DataFrame | pl.LazyFrame\n        The input data structure with an additional column for the rolling\n        squared returns.\n    \"\"\"\n    _check_required_columns(data, _column_name_returns)\n\n    sort_cols = _set_sort_cols(data, \"symbol\", \"date\")\n    if _sort:\n        data = data.lazy().sort(sort_cols)\n\n    # assign window\n    window_int: int = _window_format(\n        window=window,\n        _return_timedelta=True,\n        _avg_trading_days=_avg_trading_days,\n    ).days\n\n    data = (\n        data.lazy()\n        .set_sorted(sort_cols)\n        .with_columns(\n            ((pl.col(_column_name_returns) * 100) ** 2).alias(\n                \"sq_log_returns_pct\"\n            )\n        )\n    )\n    # Calculate rolling squared returns\n    result = (\n        data.lazy()\n        .with_columns(\n            pl.col(\"sq_log_returns_pct\")\n            .rolling_mean(window_size=window_int, min_periods=1)\n            .alias(f\"sq_volatility_pct_{window_int}D\")\n        )\n        .drop(\"sq_log_returns_pct\")\n    )\n    if _drop_nulls:\n        result = result.drop_nulls(subset=f\"sq_volatility_pct_{window_int}D\")\n    return result\n</code></pre>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_model","title":"realized_volatility_model","text":"<p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>A command to generate Realized Volatility for any time series.</p>"},{"location":"code_documentation/context/toolbox/#humbldata.toolbox.technical.volatility.realized_volatility_model.calc_realized_volatility","title":"calc_realized_volatility","text":"<pre><code>calc_realized_volatility(data: DataFrame | LazyFrame, window: str = '1m', method: Literal['std', 'parkinson', 'garman_klass', 'gk', 'hodges_tompkins', 'ht', 'rogers_satchell', 'rs', 'yang_zhang', 'yz', 'squared_returns', 'sq'] = 'std', grouped_mean: list[int] | None = None, _trading_periods: int = 252, _column_name_returns: str = 'log_returns', _column_name_close: str = 'close', _column_name_high: str = 'high', _column_name_low: str = 'low', _column_name_open: str = 'open', *, _sort: bool = True) -&gt; LazyFrame | DataFrame\n</code></pre> <p>Context: Toolbox || Category: Technical || Command: calc_realized_volatility.</p> <p>Calculates the Realized Volatility for a given time series based on the provided standard and extra parameters. This function adds ONE rolling volatility column to the input DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | LazyFrame</code> <p>The time series data for which to calculate the Realized Volatility.</p> required <code>window</code> <code>str</code> <p>The window size for a rolling volatility calculation, default is <code>\"1m\"</code> (1 month).</p> <code>'1m'</code> <code>method</code> <code>Literal['std', 'parkinson', 'garman_klass', 'hodges_tompkins', 'rogers_satchell', 'yang_zhang', 'squared_returns']</code> <p>The volatility estimator to use. You can also use abbreviations to access the same methods. The abbreviations are: <code>gk</code> for <code>garman_klass</code>, <code>ht</code> for <code>hodges_tompkins</code>, <code>rs</code> for <code>rogers_satchell</code>, <code>yz</code> for <code>yang_zhang</code>, <code>sq</code> for <code>squared_returns</code>.</p> <code>'std'</code> <code>grouped_mean</code> <code>list[int] | None</code> <p>A list of window sizes to use for calculating volatility. If provided, the volatility method will be calculated across these various windows, and then an averaged value of all the windows will be returned. If <code>None</code>, a single window size specified by <code>window</code> parameter will be used.</p> <code>None</code> <code>_sort</code> <code>bool</code> <p>If True, the data will be sorted before calculation. Default is True.</p> <code>True</code> <code>_trading_periods</code> <code>int</code> <p>The number of trading periods in a year, default is 252 (the typical number of trading days in a year).</p> <code>252</code> <code>_column_name_returns</code> <code>str</code> <p>The name of the column containing the returns. Default is \"log_returns\".</p> <code>'log_returns'</code> <code>_column_name_close</code> <code>str</code> <p>The name of the column containing the close prices. Default is \"close\".</p> <code>'close'</code> <code>_column_name_high</code> <code>str</code> <p>The name of the column containing the high prices. Default is \"high\".</p> <code>'high'</code> <code>_column_name_low</code> <code>str</code> <p>The name of the column containing the low prices. Default is \"low\".</p> <code>'low'</code> <code>_column_name_open</code> <code>str</code> <p>The name of the column containing the open prices. Default is \"open\".</p> <code>'open'</code> <p>Returns:</p> Type Description <code>VolatilityData</code> <p>The calculated Realized Volatility data for the given time series.</p> Notes <ul> <li> <p>Rolling calculations are used to show a time series of recent volatility that captures only a certain number of data points. The window size is used to determine the number of data points to use in the calculation. We do this because when looking at the volatility of a stock, you get a better insight (more granular) into the characteristics of the volatility seeing how 1-month or 3-month rolling volatility looked over time.</p> </li> <li> <p>This function does not accept <code>pl.Series</code> because the methods used to calculate volatility require, high, low, close, open columns for the data. It would be too cumbersome to pass each series needed for the calculation as a separate argument. Therefore, the function only accepts <code>pl.DataFrame</code> or <code>pl.LazyFrame</code> as input.</p> </li> </ul> Source code in <code>src\\humbldata\\toolbox\\technical\\volatility\\realized_volatility_model.py</code> <pre><code>def calc_realized_volatility(\n    data: pl.DataFrame | pl.LazyFrame,\n    window: str = \"1m\",\n    method: Literal[  # used to be rvol_method\n        \"std\",\n        \"parkinson\",\n        \"garman_klass\",\n        \"gk\",\n        \"hodges_tompkins\",\n        \"ht\",\n        \"rogers_satchell\",\n        \"rs\",\n        \"yang_zhang\",\n        \"yz\",\n        \"squared_returns\",\n        \"sq\",\n    ] = \"std\",\n    grouped_mean: list[int] | None = None,  # used to be rv_mean\n    _trading_periods: int = 252,\n    _column_name_returns: str = \"log_returns\",\n    _column_name_close: str = \"close\",\n    _column_name_high: str = \"high\",\n    _column_name_low: str = \"low\",\n    _column_name_open: str = \"open\",\n    *,\n    _sort: bool = True,\n) -&gt; pl.LazyFrame | pl.DataFrame:\n    \"\"\"\n    Context: Toolbox || Category: Technical || **Command: calc_realized_volatility**.\n\n    Calculates the Realized Volatility for a given time series based on the\n    provided standard and extra parameters. This function adds ONE rolling\n    volatility column to the input DataFrame.\n\n    Parameters\n    ----------\n    data : pl.DataFrame | pl.LazyFrame\n        The time series data for which to calculate the Realized Volatility.\n    window : str\n        The window size for a rolling volatility calculation, default is `\"1m\"`\n        (1 month).\n    method : Literal[\"std\", \"parkinson\", \"garman_klass\", \"hodges_tompkins\",\"rogers_satchell\", \"yang_zhang\", \"squared_returns\"]\n        The volatility estimator to use. You can also use abbreviations to\n        access the same methods. The abbreviations are: `gk` for `garman_klass`,\n        `ht` for `hodges_tompkins`, `rs` for `rogers_satchell`, `yz` for\n        `yang_zhang`, `sq` for `squared_returns`.\n    grouped_mean : list[int] | None\n        A list of window sizes to use for calculating volatility. If provided,\n        the volatility method will be calculated across these various windows,\n        and then an averaged value of all the windows will be returned. If `None`,\n        a single window size specified by `window` parameter will be used.\n    _sort : bool\n        If True, the data will be sorted before calculation. Default is True.\n    _trading_periods : int\n        The number of trading periods in a year, default is 252 (the typical\n        number of trading days in a year).\n    _column_name_returns : str\n        The name of the column containing the returns. Default is \"log_returns\".\n    _column_name_close : str\n        The name of the column containing the close prices. Default is \"close\".\n    _column_name_high : str\n        The name of the column containing the high prices. Default is \"high\".\n    _column_name_low : str\n        The name of the column containing the low prices. Default is \"low\".\n    _column_name_open : str\n        The name of the column containing the open prices. Default is \"open\".\n\n    Returns\n    -------\n    VolatilityData\n        The calculated Realized Volatility data for the given time series.\n\n    Notes\n    -----\n    - Rolling calculations are used to show a time series of recent volatility\n    that captures only a certain number of data points. The window size is\n    used to determine the number of data points to use in the calculation. We do\n    this because when looking at the volatility of a stock, you get a better\n    insight (more granular) into the characteristics of the volatility seeing how 1-month or\n    3-month rolling volatility looked over time.\n\n    - This function does not accept `pl.Series` because the methods used to\n    calculate volatility require, high, low, close, open columns for the data.\n    It would be too cumbersome to pass each series needed for the calculation\n    as a separate argument. Therefore, the function only accepts `pl.DataFrame`\n    or `pl.LazyFrame` as input.\n    \"\"\"  # noqa: W505\n    # Step 1: Get the correct realized volatility function =====================\n    func = VOLATILITY_METHODS.get(method)\n    if not func:\n        msg = f\"Volatility method: '{method}' is not supported.\"\n        raise HumblDataError(msg)\n\n    # Step 2: Get the names of the parameters that the function accepts ========\n    func_params = inspect.signature(func).parameters\n\n    # Step 3: Filter out the parameters not accepted by the function ===========\n    args_to_pass = {\n        key: value for key, value in locals().items() if key in func_params\n    }\n\n    # Step 4: Calculate Realized Volatility ====================================\n    if grouped_mean:\n        # calculate volatility over multiple windows and average the result, add to a new column\n        print(\"\ud83d\udea7 WIP!\")\n    else:\n        out = func(**args_to_pass)\n\n    return out\n</code></pre>"},{"location":"getting_started/","title":"\ud83c\udfc1 Getting Started","text":"<p>Welcome to the Getting Started guide for the humbldata package. This guide will provide you with an overview of the package and its capabilities.</p>"},{"location":"getting_started/#what-is-humbldata","title":"\ud83d\udce6 What is humbldata?","text":"<p>The humbldata package is a comprehensive data analysis tool that provides a wide range of functionalities for working with financial data. It is designed to be user-friendly and efficient, making it a valuable tool for both beginners and experienced data analysts.</p>"},{"location":"getting_started/#how-was-humbldata-built","title":"\ud83d\udee0 How was humbldata built?","text":"<p>The focus of this package was to be built on a hyper-modern python stack:</p>"},{"location":"getting_started/#features","title":"Features","text":"<ul> <li>\ud83e\uddd1\u200d\ud83d\udcbb Quick and reproducible development environments with VS Code's Dev Containers, PyCharm's Docker Compose interpreter, and GitHub Codespaces</li> <li>\ud83c\udf08 Cross-platform support for Linux, macOS (Apple silicon and Intel), and Windows</li> <li>\ud83d\udce6 Packaging and dependency management with Poetry</li> <li>\ud83c\udf0d Environment management with Micromamba</li> <li>\ud83d\udcd6 Comprehensive documentation generation with MkDocs</li> <li>\ud83d\ude9a Installing from and publishing to private package repositories and PyPI</li> <li>\u26a1\ufe0f Task running with Poe the Poet</li> <li>\u270d\ufe0f Code formatting with Ruff</li> <li>\u2705 Code linting with Pre-commit, Mypy, and Ruff</li> <li>\ud83c\udff7\ufe0f Optionally follows the Conventional Commits standard to automate Semantic Versioning and Keep A Changelog with Commitizen</li> <li>\ud83d\udc8c Verified commits with GPG</li> <li>\u267b\ufe0f Continuous integration with GitHub Actions or GitLab CI/CD</li> <li>\ud83e\uddea Test coverage with Coverage.py</li> <li>\ud83c\udfd7 Scaffolding updates with Cookiecutter and Cruft</li> <li>\ud83e\uddf0 Dependency updates with Dependabot</li> </ul>"},{"location":"getting_started/#project-organization","title":"\ud83d\udcc2 Project Organization","text":"<ul> <li><code>.github/workflows</code>: Contains GitHub Actions used for building, testing, and publishing.</li> <li><code>.devcontainer/Dockerfile</code>: Contains Dockerfile to build a development container for VSCode with all the necessary extensions for Python development installed.</li> <li><code>.devcontainer/devcontainer.json</code>: Contains the configuration for the development container for VSCode, including the Docker image to use, any additional VSCode extensions to install, and whether or not to mount the project directory into the container.</li> <li><code>.vscode/settings.json</code>: Contains VSCode settings specific to the project, such as the Python interpreter to use and the maximum line length for auto-formatting.</li> <li><code>src</code>: Place new source code here.</li> <li><code>tests</code>: Contains Python-based test cases to validate source code.</li> <li><code>pyproject.toml</code>: Contains metadata about the project and configurations for additional tools used to format, lint, type-check, and analyze Python code.</li> <li><code>.prompts/</code>: Contains useful prompts to use during development for modifying and generating code and tests.</li> </ul>"},{"location":"getting_started/configuration/","title":"\u2699\ufe0f Configuration","text":""},{"location":"getting_started/development_setup/","title":"\ud83c\udfd7\ufe0f Development Setup","text":"<p>Here, you will find all the settings needed to setup your machine to contribute to the project, and also understand the coding practices that went into making this package, so you can follow along and understand the code structure.</p> Useful Developer Commands <ul> <li><code>micromamba activate -p ./menv</code>: activate the micromamba env</li> <li><code>poe</code>: list all the available commands for the package</li> <li><code>poetry add {package}</code>: install a run time dependency and add it to <code>pyproject.toml</code> and <code>poetry.lock</code>. Add <code>--group test</code> or <code>--group dev</code> to install a test or development dependency, respectively.</li> <li><code>poetry update</code>: upgrade all dependencies to the latest versions allowed by <code>pyproject.toml</code>.</li> <li><code>cz bump</code>: bump the package's version, update the <code>CHANGELOG.md</code>, and create a git tag, settings can be made in both <code>cz-config.js</code> and <code>bumpversion.yml</code>.</li> <li><code>cruft update</code>: update the current project to mirror the latest cookiecutter template</li> <li><code>mkdocs serve</code>: start a server for documentation</li> </ul>"},{"location":"getting_started/development_setup/#hooks","title":"\ud83c\udfa3 Hooks","text":"<p>This project uses two hooks, <code>pre_gen_project.py</code> and <code>post_gen_project.py</code>, which are scripts that run before and after the project generation process, respectively. <code>post_gen_project.py</code> is repsonsible for setting up the micromamba environment.</p>"},{"location":"getting_started/development_setup/#cruft","title":"\ud83c\udf6a Cruft","text":"<p>This project uses cruft to manage the template and update the project with the latest changes. This has one caveat for now. While using commitizen and customizing the commit messages in <code>pyproject.toml</code> the <code>cruft update</code> command will not work as expected. I think because emojis in the <code>pyproject.toml</code> are not read with the correct encoding.</p> Solution <p>If you need to perform a <code>cruft update</code>, please just remove the sections with emojis, and run <code>cruft update</code>. Then, you will be able to insert the emojis defined in the <code>[tool.commitizen.customize]</code> from the original template, after the update has completed.</p> <p>I should look to move to just use <code>czg</code> or <code>cz-git</code> instead of <code>commitizen</code> + <code>cz-customizable</code> + <code>cz-conventional-gitmoji</code>.</p> Manually Upload <code>pyproject.toml</code> content <p>If you need to manually add the emojis to the <code>pyproject.toml</code> file, you can use the following code to add the emojis to the <code>pyproject.toml</code> file.</p> <pre><code>[tool.commitizen]\nname = \"cz_gitmoji\"\nversion = \"0.11.4\"\ntag_format = \"v$version\"\nupdate_changelog_on_bump = true\nannotated_tag = true\nbump_message = \"\ud83d\udd16 bump(release): v$current_version \u2192 v$new_version\"\nversion_files = [\"pyproject.toml:^version\"]\npath = \".cz-config.js\"\n\n[tool.commitizen.customize]\nexample = \"feat: this feature enables customizing through pyproject.toml file\"\nschema = \"\"\"\n&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt; \\n\n&lt;BLANK LINE&gt; \\n\n&lt;body&gt; \\n\n&lt;BLANK LINE&gt; \\n\n(BREAKING CHANGE: )&lt;breaking&gt; \\n\n&lt;BLANK LINE&gt; \\n\n(ISSUES: )&lt;footer&gt;\n\"\"\"\nschema_pattern = \"(?s)(\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\ud83d\udd27 chore|\u267b\ufe0f refactor|\ud83d\udea7 WIP|\ud83d\udcda docs|\u26a1\ufe0f perf|\ud83d\udc84 style|\ud83c\udfd7\ufe0f build|\ud83d\udc77 ci|\u2705 test|\u23ea revert|\u2795 add_dep|\u2796 rem_dep)(\\\\(\\\\S+\\\\))?!?:( [^\\\\n\\\\r]+)((\\\\n\\\\n.*)|(\\\\s*))?$\"\nbump_pattern = \"^(\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\u26a1\ufe0f perf|\u267b\ufe0f refactor|\u23ea revert|\u2795 dep-add|\u2796 dep-rm)\"\nbump_map = {\"BREAKING CHANGE\" = \"MAJOR\", \"\u2728 feat\" = \"MINOR\", \"\ud83d\udc1b fix\" = \"PATCH\", \"\ud83d\ude91 hotfix\" = \"PATCH\", \"\u26a1\ufe0f perf\" = \"PATCH\", \"\u267b\ufe0f refactor\" = \"PATCH\"}\nchange_type_order = [\"BREAKING CHANGE\", \"\u2728 feat\", \"\ud83d\udc1b fix\", \"\ud83d\ude91 hotfix\", \"\u267b\ufe0f refactor\", \"\u26a1\ufe0f perf\", \"\ud83c\udfd7\ufe0f build\", \"\ud83d\udc84 style\", \"\ud83d\udcda docs\", \"\u2795 dep-add\", \"\u2796 dep-rm\"]\ninfo_path = \"cz_customize_info.txt\"\ninfo = \"\"\"\nThis is customized commitizen info\n\"\"\"\ncommit_parser = \"^(?P&lt;change_type&gt;\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\ud83d\udd27 chore|\u267b\ufe0f refactor|\ud83d\udea7 WIP|\ud83d\udcda docs|\u26a1\ufe0f perf|\ud83d\udc84 style|\ud83c\udfd7\ufe0f build|\ud83d\udc77 ci|\u2705 test|\u23ea revert|\u2795 dep-add|\u2796 dep-rm):\\\\s(?P&lt;message&gt;.*)?\"\nchangelog_pattern = \"^(\u2728 feat|\ud83d\udc1b fix|\ud83d\ude91 hotfix|\ud83d\udd27 chore|\u267b\ufe0f refactor|\ud83d\udea7 WIP|\ud83d\udcda docs|\u26a1\ufe0f perf|\ud83d\udc84 style|\ud83c\udfd7\ufe0f build|\ud83d\udc77 ci|\u2705 test|\u23ea revert|\u2795 dep-add|\u2796 dep-rm)?(!)?\"\nchange_type_map = {\"\ud83c\udfd7\ufe0f build\" = \"Build\", \"\ud83d\udc77 ci\" = \"CI\", \"\ud83d\udcda docs\" = \"Docs\", \"\u2728 feat\" = \"Feat\", \"\ud83d\udc1b fix\" = \"Fix\", \"\ud83d\ude91 hotfix\" = \"Hotfix\", \"\u26a1\ufe0f perf\" = \"Perf\", \"\u267b\ufe0f refactor\" = \"Refactor\", \"\ud83d\udc84 style\" = \"Style\", \"\u2705 test\" = \"Test\", \"\ud83d\udd27 chore\" = \"Chore\", \"\u23ea revert\" = \"Revert\", \"\u2795 dep-add\" = \"Added Dependency\", \"\u2796 dep-rm\" = \"Removed Dependency\"}\n</code></pre>"},{"location":"getting_started/development_setup/#setup-micromamba-environment-with-poetry","title":"\ud83d\udc2d Setup Micromamba Environment with Poetry","text":"<p>This section shows users how to setup your environment using your <code>micromamba</code> file and <code>poetry</code>. This project uses a micromamba environment. The micromamba environment will be automatically setup for you after generating the project from the template using a <code>post_gen_project</code> hook. The following steps are for reference only (if you need to recreate the environment). This assumes you use <code>bash</code> as your shell.</p> Prerequisites <ol> <li>Installing micromamba</li> </ol> <pre><code># Windows (Powershell)\nInvoke-Expression ((Invoke-WebRequest -Uri https://micro.mamba.pm/install.ps1).Content)\n</code></pre> <pre><code># Linux and macOS\n\"${SHELL}\" &lt;(curl -L micro.mamba.pm/install.sh)\n</code></pre> Creating Micromamba Environment <ol> <li> <p>I created the environment with a <code>--prefix</code> and not a name, to ensure that it installed in my project directory, not the default path. This is executed in the project root dir.</p> <pre><code>micromamba env create --file micromamba_env.yml\n</code></pre> </li> <li> <p>To avoid displaying the full path when using this environment, modify the <code>.condarc</code> file to show the environment name as the last directory where the environment is located. This can be done manually or by running the command <code>micromamba config --set env_prompt '({name})'</code>.</p> <pre><code>micromamba config --set env_prompt '({name})'\n</code></pre> <p>After the modification, your <code>.condarc</code> file should look like this:</p> <pre><code>channels:\n  - conda-forge\n  - defaults\nenv_prompt: ({name})\nrepodata_threads: 2\nchange_ps1: false\nenvs_dirs:\n  - ~/micromamba/envs\n</code></pre> </li> <li> <p>Activate the environment</p> <pre><code>micromamba init bash / micromamba init zsh\nmicromamba activate ./menv\n</code></pre> </li> <li> <p>Check if poetry is installed</p> <pre><code>poetry --version\n# make sure it is the latest version\n# can use mamba search -f poetry\n</code></pre> </li> <li> <p>If poetry is showing any errors like:</p> <ul> <li><code>Failed to create process</code></li> <li><code>No Python at &lt;path&gt;</code></li> </ul> <p>You can simply run: <pre><code>micromamba remove -p ./menv poetry\nmicromamba install -p ./menv poetry\n</code></pre></p> </li> <li> <p>If the python version doesnt match, just install the version you would like:</p> <pre><code>micromamba install -p ./menv python=3.12.1\n</code></pre> </li> <li> <p>Install Packages from <code>poetry.lock</code> / <code>pyproject.toml</code></p> <pre><code>poetry install\n</code></pre> </li> </ol> Setting Up <code>Commitizen</code> <p>I am using the <code>vscode-commitizen</code> extension to integrate <code>commitizen</code> into my workflow. This allows for nice keyboard shortcuts and UI integration. I have also installed <code>cz_customizable</code> globally to allow me to customize the commit message template using <code>cz-config.js</code>.</p> <p>The <code>pyproject.toml</code> file has the specifications for <code>cz_customizable</code> and <code>commitizen</code> to work together.</p> <p>Follow the quickstart guide to setup <code>cz-customizable</code>. You need to install <code>cz-customizable</code> globally in order for the vscode extension to work along with the settings provided in the <code>pyproject.toml</code> file. This will allow for custom commit types and user-specific settings.</p> <p>You need these two files, to ensure automatic commit linting, and package versioning.</p> <ul> <li> <code>./pre-commit-config.yml</code></li> <li> <code>./github/workflows/bumpversion.yml</code></li> </ul>"},{"location":"getting_started/development_setup/#setup-github-workflows","title":"\u26a1 Setup Github Workflows","text":"<p>There are 4 pre-made github actions that are used with this package. Some actions require API_KEYS/TOKENS to work. Add your tokens to the secrets manager in your repo settings.</p> 1. <code>bump.yml</code> <p>This workflow automates the versioning of the project using bumpversion. - Tokens/Secrets:     - <code>GH_PAT</code>: Github Personal Access Token You need to create a Github Personal Access Token and add it to your secrets manager in your repo settings.</p> 2. <code>deploy.yml</code> <p>This workflow is responsible for deploying the project. It is triggered on push events that include tags in the format \"v(x.x.x)\" and also manually through the GitHub Actions UI.</p> <p>The workflow runs on an Ubuntu-latest environment and only if the GitHub reference starts with 'refs/tags/v'.</p> <ul> <li>Steps:<ul> <li>Checking out the repository.</li> <li>Logging into the Docker registry.</li> <li>Setting the Docker image tag.</li> <li>Building and pushing the Docker image.</li> </ul> </li> <li>Tokens/Secrets:<ul> <li><code>GITHUB_TOKEN</code>: This is a GitHub secret used for authentication.</li> <li><code>DOCKER_REGISTRY</code>: This is an environment variable set to 'ghcr.io'.</li> <li><code>DEFAULT_DEPLOYMENT_ENVIRONMENT</code>: This is an environment variable set to 'feature'.</li> <li><code>POETRY_HTTP_BASIC__USERNAME</code>: This is a secret used for authentication with the private package repository.</li> <li><code>POETRY_HTTP_BASIC__PASSWORD</code>: This is a secret used for authentication with the private package repository.</li> </ul> </li> </ul> 3. <code>publish.yml</code> <p>This workflow is responsible for publishing the project. It is triggered when a new release is created.</p> <p>The workflow runs on an Ubuntu-latest environment.</p> <ul> <li>Steps:<ul> <li>Checking out the repository.</li> <li>Setting up Python with the specified version.</li> <li>Installing Poetry, a tool for dependency management and packaging in Python.</li> <li>Publishing the package using Poetry. If a private package repository is specified, the package is published there. Otherwise, it is published to PyPi.</li> </ul> </li> <li>Tokens/Secrets:<ul> <li><code>GITHUB_TOKEN</code>: This is a GitHub secret used for authentication.</li> <li><code>POETRY_HTTP_BASIC__USERNAME</code>: This is a secret used for authentication with the private package repository.</li> <li><code>POETRY_HTTP_BASIC__PASSWORD</code>: This is a secret used for authentication with the private package repository.</li> <li><code>POETRY_PYPI_TOKEN_PYPI</code>: This is a secret used for authentication with PyPi, if the package is being published there.</li> </ul> </li> </ul> 4. <code>test.yml</code> <p>This workflow is responsible for testing the project. It is triggered on push events to the main and master branches, and on pull requests.</p> <p>The workflow runs on an Ubuntu-latest environment and uses the specified Python version.</p> <ul> <li>Steps:<ul> <li>Checking out the repository.</li> <li>Setting up Node.js with the specified version.</li> <li>Installing @devcontainers/cli.</li> <li>Starting the Dev Container.</li> <li>Linting the package.</li> <li>Testing the package.</li> <li>Uploading coverage.</li> </ul> </li> <li>Tokens/Secrets:<ul> <li><code>GITHUB_TOKEN</code>: This is a GitHub secret used for authentication.</li> </ul> </li> </ul>"},{"location":"getting_started/installation/","title":"\ud83d\udcf2 Installation","text":"<p>To install the humbldata package, simply run the following command in your terminal:</p> <p><pre><code>pip install humbldata\n</code></pre> If you are using poetry: <pre><code>poetry add humbldata\n</code></pre></p>"},{"location":"getting_started/usage/","title":"\ud83d\udee0\ufe0f Usage","text":"<p>We recommend starting with the Toolbox module, which is the entry point for all data analysis in the humbldata package. From there, you can explore the various functionalities and tools available in the package.</p> <p>We hope you find the humbldata package to be a valuable addition to your data analysis toolkit. Happy analyzing!</p>"}]}